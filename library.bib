Automatically generated by Mendeley Desktop 1.10.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Hopkins1997,
author = {Hopkins, Budd},
journal = {New England Review},
number = {2},
pages = {5--12},
title = {{Modernism and the Collage Aesthetic}},
volume = {18},
year = {1997}
}
@article{Shamma2001,
abstract = {Unlike visual and tactile stimuli, auditory signals that allow perception of timbre, pitch and localization are temporal. To process these, the auditory nervous system must either possess specialized neural machinery for analyzing temporal input, or transform the initial responses into patterns that are spatially distributed across its sensory epithelium. The former hypothesis, which postulates the existence of structures that facilitate temporal processing, is most popular. However, I argue that the cochlea transforms sound into spatiotemporal response patterns on the auditory nerve and central auditory stages; and that a unified computational framework exists for central auditory, visual and other sensory processing. Specifically, I explain how four fundamental concepts in visual processing play analogous roles in auditory processing.},
author = {Shamma, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shamma/Shamma - 2001 - On the role of space and time in auditory processing. - Trends in cognitive sciences.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = aug,
number = {8},
pages = {340--348},
pmid = {11477003},
title = {{On the role of space and time in auditory processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11477003},
volume = {5},
year = {2001}
}
@article{Sarawagi2005,
author = {Sarawagi, Sunita and Cohen, W.W.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sarawagi, Cohen/Sarawagi, Cohen - 2005 - Semi-markov conditional random fields for information extraction - Advances in Neural Information Processing Systems.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1185--1192},
publisher = {Citeseer},
title = {{Semi-markov conditional random fields for information extraction}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.3524\&amp;rep=rep1\&amp;type=pdf},
volume = {17},
year = {2005}
}
@misc{Franke2013,
author = {Franke, Daniel and Mckiernan, John and Menkman, Rosa},
file = {:Users/pkmital/Documents/Mendeley Desktop/Franke, Mckiernan, Menkman/Franke, Mckiernan, Menkman - 2013 - Glitch Art Genealogies - Unknown.pdf:pdf},
title = {{Glitch Art Genealogies}},
year = {2013}
}
@article{Mullan2009,
author = {Mullan, Eoin},
journal = {2009 International IEEE Consumer Electronics Society's Games Innovations Conference},
month = aug,
pages = {1--9},
publisher = {Ieee},
title = {{Driving sound synthesis from a physics engine}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5293591},
year = {2009}
}
@article{Winkler2007,
author = {Winkler, Istv\'{a}n},
doi = {10.1027/0269-8803.21.34.147},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler/Winkler - 2007 - Interpreting the Mismatch Negativity - Journal of Psychophysiology.pdf:pdf},
issn = {0269-8803},
journal = {Journal of Psychophysiology},
keywords = {auditory,auditory deviance detection,auditory memory,mmn,predictive model,regularity extraction,temporal grouping},
month = jan,
number = {3},
pages = {147--163},
title = {{Interpreting the Mismatch Negativity}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/0269-8803.21.34.147},
volume = {21},
year = {2007}
}
@article{Collomosse2003,
author = {Collomosse, J. P. and Rowntree, D. and Hall, P. M.},
doi = {10.5244/C.17.74},
file = {:Users/pkmital/Documents/Mendeley Desktop/Collomosse, Rowntree, Hall/Collomosse, Rowntree, Hall - 2003 - Video Analysis for Cartoon-like Special Effects - Procedings of the British Machine Vision Conference 2003.pdf:pdf},
isbn = {1-901725-23-5},
journal = {Procedings of the British Machine Vision Conference 2003},
pages = {74.1--74.10},
publisher = {British Machine Vision Association},
title = {{Video Analysis for Cartoon-like Special Effects}},
url = {http://www.bmva.org/bmvc/2003/papers/paper-58.html},
year = {2003}
}
@article{Brockmole2006a,
abstract = {When confronted with a previously encountered scene, what information is used to guide search to a known target? We contrasted the role of a scene's basic-level category membership with its specific arrangement of visual properties. Observers were repeatedly shown photographs of scenes that contained consistently but arbitrarily located targets, allowing target positions to be associated with scene content. Learned scenes were then unexpectedly mirror reversed, spatially translating visual features as well as the target across the display while preserving the scene's identity and concept. Mirror reversals produced a cost as the eyes initially moved toward the position in the display in which the target had previously appeared. The cost was not complete, however; when initial search failed, the eyes were quickly directed to the target's new position. These results suggest that in real-world scenes, shifts of attention are initially based on scene identity, and subsequent shifts are guided by more detailed information regarding scene and object layout.},
author = {Brockmole, James R and Henderson, John M},
doi = {10.1080/17470210600665996},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmole, Henderson/Brockmole, Henderson - 2006 - Recognition and attention guidance during contextual cueing in real-world scenes evidence from eye movements. - Quarterly journal of experimental psychology (2006).pdf:pdf},
issn = {1747-0218},
journal = {Quarterly journal of experimental psychology (2006)},
keywords = {Attention,Cues,Environment,Eye Movements,Fixation, Ocular,Humans,Recognition (Psychology),Visual Perception},
month = jul,
number = {7},
pages = {1177--87},
pmid = {16769618},
title = {{Recognition and attention guidance during contextual cueing in real-world scenes: evidence from eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16769618},
volume = {59},
year = {2006}
}
@inproceedings{Kalinli2008,
author = {Kalinli, O. and Narayanan, S.},
booktitle = {Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalinli, Narayanan/Kalinli, Narayanan - 2008 - A top-down auditory attention model for learning task dependent influences on prominence detection in speech.pdf:pdf},
pages = {3981--3984},
publisher = {IEEE},
title = {{A top-down auditory attention model for learning task dependent influences on prominence detection in speech}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4518526},
year = {2008}
}
@article{Chu2010,
address = {New York, New York, USA},
author = {Chu, Hung-Kuo and Hsu, Wei-Hsin and Mitra, Niloy J. and Cohen-Or, Daniel and Wong, Tien-Tsin and Lee, Tong-Yee},
doi = {10.1145/1833349.1778788},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chu et al/Chu et al. - 2010 - Camouflage images - ACM SIGGRAPH 2010 papers on - SIGGRAPH '10.pdf:pdf},
isbn = {9781450302104},
journal = {ACM SIGGRAPH 2010 papers on - SIGGRAPH '10},
pages = {1},
publisher = {ACM Press},
title = {{Camouflage images}},
url = {http://portal.acm.org/citation.cfm?doid=1833349.1778788},
year = {2010}
}
@book{Palmer1999,
abstract = {This text integrates material on visual perception across disciplines. All major topics related to vision from early neural processing of image structure in the retina to high-level visual attention, memory, imagery, and awareness are covered. The presentation throughout is theoretically sophisticated, yet requires minimal knowledge of mathematics. There is also a glossary, as well as appendices on psychophysical methods, connectionist modeling, and color technology. This book serves not only as a comprehensive textbook for an upper division undergraduate or an entry-level graduate course on vision, but is also a valuable reference for researchers in cognitive science, psychology, neuroscience, computer science, optometry, and philosophy.},
author = {Palmer, Stephen E.},
title = {{Vision science: Photons to phenomenology.}},
year = {1999}
}
@article{Bigdely-Shamlo2008,
abstract = {We report the design and performance of a brain-computer interface (BCI) system for real-time single-trial binary classification of viewed images based on participant-specific dynamic brain response signatures in high-density (128-channel) electroencephalographic (EEG) data acquired during a rapid serial visual presentation (RSVP) task. Image clips were selected from a broad area image and presented in rapid succession (12/s) in 4.1-s bursts. Participants indicated by subsequent button press whether or not each burst of images included a target airplane feature. Image clip creation and search path selection were designed to maximize user comfort and maintain user awareness of spatial context. Independent component analysis (ICA) was used to extract a set of independent source time-courses and their minimally-redundant low-dimensional informative features in the time and time-frequency amplitude domains from 128-channel EEG data recorded during clip burst presentations in a training session. The naive Bayes fusion of two Fisher discriminant classifiers, computed from the 100 most discriminative time and time-frequency features, respectively, was used to estimate the likelihood that each clip contained a target feature. This estimator was applied online in a subsequent test session. Across eight training/test session pairs from seven participants, median area under the receiver operator characteristic curve, by tenfold cross validation, was 0.97 for within-session and 0.87 for between-session estimates, and was nearly as high (0.83) for targets presented in bursts that participants mistakenly reported to include no target features.},
author = {Bigdely-Shamlo, Nima and Vankov, Andrey and Ramirez, Rey R and Makeig, Scott},
doi = {10.1109/TNSRE.2008.2003381},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bigdely-Shamlo et al/Bigdely-Shamlo et al. - 2008 - Brain activity-based image classification from rapid serial visual presentation. - IEEE transactions on n.pdf:pdf},
issn = {1558-0210},
journal = {IEEE transactions on neural systems and rehabilitation engineering : a publication of the IEEE Engineering in Medicine and Biology Society},
keywords = {Adult,Algorithms,Brain Mapping,Brain Mapping: methods,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,User-Computer Interface,Visual Cortex,Visual Cortex: physiology},
month = oct,
number = {5},
pages = {432--41},
pmid = {18990647},
title = {{Brain activity-based image classification from rapid serial visual presentation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18990647},
volume = {16},
year = {2008}
}
@article{Bullier2001,
abstract = {Cortical processing of visual information requires that information be exchanged between neurons coding for distant regions in the visual field. It is argued that feedback connections are the best candidates for such rapid long-distance interconnections. In the integrated model, information arriving in the cortex from the magnocellular layers of the lateral geniculate nucleus is first sent and processed in the parietal cortex that is very rapidly activated by a visual stimulus. Results from this first-pass computation are then sent back by feedback connections to areas V1 and V2 that act as 'active black-boards' for the rest of the visual cortical areas: information retroinjected from the parietal cortex is used to guide further processing of parvocellular and koniocellular information in the inferotemporal cortex.},
author = {Bullier, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bullier/Bullier - 2001 - Integrated model of visual processing. - Brain research. Brain research reviews.pdf:pdf},
journal = {Brain research. Brain research reviews},
keywords = {Animals,Feedback,Feedback: physiology,Geniculate Bodies,Geniculate Bodies: cytology,Geniculate Bodies: physiology,Humans,Models, Neurological,Neurons,Neurons: cytology,Neurons: physiology,Parietal Lobe,Parietal Lobe: physiology,Temporal Lobe,Temporal Lobe: cytology,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {2-3},
pages = {96--107},
pmid = {11690606},
title = {{Integrated model of visual processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11690606},
volume = {36},
year = {2001}
}
@article{Krohn2005a,
author = {Krohn, a. and Beigl, M. and Hazas, M. and Gellersen, H.-W.},
file = {::},
journal = {25th IEEE International Conference on Distributed Computing Systems Workshops},
pages = {463--468},
publisher = {Ieee},
title = {{Using Fine-Grained Infrared Positioning to Support the Surface-Based Activities of Mobile Users}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1437212},
year = {2005}
}
@inproceedings{Collins2004,
author = {Collins, Nick},
booktitle = {Perception},
file = {:Users/pkmital/Documents/Mendeley Desktop/Collins/Collins - 2004 - On onsets on-the-fly Real-time event segmentation and categorisation as a compositional effect - Perception.pdf:pdf},
keywords = {audio capture,categorisation,onset detection,real-time,segmentation},
publisher = {Citeseer},
title = {{On onsets on-the-fly: Real-time event segmentation and categorisation as a compositional effect}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.9680\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@article{Verfaille2006,
author = {Verfaille, V. and Zolzer, U. and Arfib, D.},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = sep,
number = {5},
pages = {1817--1831},
title = {{Adaptive digital audio effects (a-DAFx): a new class of sound transformations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1678000},
volume = {14},
year = {2006}
}
@article{Jhuang,
author = {Jhuang, H and Serre, T and Wolf, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Jhuang, Serre, Wolf/Jhuang, Serre, Wolf - Unknown - To appear in the Proc . of the Eleventh IEEE International Conference on Computer Vision A Biologically Inspired System for Action Recognition - Main.pdf:pdf},
journal = {Main},
title = {{To appear in the Proc . of the Eleventh IEEE International Conference on Computer Vision A Biologically Inspired System for Action Recognition}}
}
@incollection{Bogart2009,
author = {Bogart, Benjamin and Schiphorst, Thecla},
booktitle = {The Handbook of Research on Computational Arts and Creative Informatics},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bogart, Schiphorst/Bogart, Schiphorst - 2009 - Memory Association Machine Growing Form from Context - The Handbook of Research on Computational Arts and Cr.pdf:pdf},
pages = {213--232},
publisher = {IGI Global},
title = {{Memory Association Machine: Growing Form from Context}},
year = {2009}
}
@article{Science1975,
author = {Science, Imaging},
file = {:Users/pkmital/Documents/Mendeley Desktop/Science/Science - 1975 - Influence of foveal load on the functional visual field - Perception.pdf:pdf},
journal = {Perception},
number = {4},
pages = {255--260},
title = {{Influence of foveal load on the functional visual field}},
volume = {18},
year = {1975}
}
@inproceedings{Zils2001,
abstract = {This work addresses the issue of retrieving efficiently sound 
samples in large databases, in the context of digital music 
composition. We propose a sequence generation mechanism called 
musical mosaicing, which enables to generate automatically 
sequences of sound samples by specifying only high-level 
properties of the sequence to generate. The properties of the 
sequence specified by the user are translated automatically into 
constraints holding on descriptors of the samples. The system we 
propose is able to scale up on databases containing more than 
100.000 samples, using a local search method based on constraint 
solving. In this paper, we describe the method for retrieving and 
sequencing audio samples, and illustrate it with rhythmic and 
melodic musical sequences. },
address = {Limerick, Ireland},
author = {Zils, A and Pachet, F},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zils, Pachet/Zils, Pachet - 2001 - Musical Mosaicing - Proc. COST G-6 Conf. Digital Audio Effects.pdf:pdf},
keywords = {CSS},
title = {{Musical Mosaicing}},
year = {2001}
}
@article{Winkler2009,
abstract = {Predictive processing of information is essential for goal-directed behavior. We offer an account of auditory perception suggesting that representations of predictable patterns, or 'regularities', extracted from the incoming sounds serve as auditory perceptual objects. The auditory system continuously searches for regularities within the acoustic signal. Primitive regularities may be encoded by neurons adapting their response to specific sounds. Such neurons have been observed in many parts of the auditory system. Representations of the detected regularities produce predictions of upcoming sounds as well as alternative solutions for parsing the composite input into coherent sequences potentially emitted by putative sound sources. Accuracy of the predictions can be utilized for selecting the most likely interpretation of the auditory input. Thus in our view, perception generates hypotheses about the causal structure of the world.},
author = {Winkler, Istv\'{a}n and Denham, Susan L and Nelken, Israel},
doi = {10.1016/j.tics.2009.09.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler, Denham, Nelken/Winkler, Denham, Nelken - 2009 - Modeling the auditory scene predictive regularity representations and perceptual objects. - Trends in c.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adaptation, Physiological,Adaptation, Physiological: physiology,Animal Communication,Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Hearing,Hearing: physiology,Humans,Models, Neurological,Predictive Value of Tests},
month = dec,
number = {12},
pages = {532--40},
pmid = {19828357},
title = {{Modeling the auditory scene: predictive regularity representations and perceptual objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19828357},
volume = {13},
year = {2009}
}
@inproceedings{Menzies2002,
address = {Espoo, Finland},
author = {Menzies, Dylan},
booktitle = {Proceedings of the 22nd International Conference of the AES on Virtual Synthetic and Entertainment Audio, Espoo, Finland},
file = {::},
publisher = {Citeseer},
title = {{W-panning and O-format, tools for object spatialization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.2792\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Shams2002,
abstract = {We present the first cross-modal modification of visual perception which involves a phenomenological change in the quality-as opposed to a small, gradual, or quantitative change-of the percept of a non-ambiguous visual stimulus. We report a visual illusion which is induced by sound: when a single flash of light is accompanied by multiple auditory beeps, the single flash is perceived as multiple flashes. We present two experiments as well as several observations which establish that this alteration of the visual percept is due to cross-modal perceptual interactions as opposed to cognitive, attentional, or other origins. The results of the second experiment also reveal that the temporal window of these audio-visual interactions is approximately 100 ms.},
author = {Shams, Ladan and Kamitani, Yukiyasu and Shimojo, Shinsuke},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shams, Kamitani, Shimojo/Shams, Kamitani, Shimojo - 2002 - Visual illusion induced by sound. - Brain research. Cognitive brain research.pdf:pdf},
issn = {0926-6410},
journal = {Brain research. Cognitive brain research},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Female,Humans,Illusions,Illusions: physiology,Male,Visual Perception,Visual Perception: physiology},
month = jun,
number = {1},
pages = {147--52},
pmid = {12063138},
title = {{Visual illusion induced by sound.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12063138},
volume = {14},
year = {2002}
}
@article{Endres2010,
author = {Endres, Ian and Hoiem, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Endres, Hoiem/Endres, Hoiem - 2010 - Category independent object proposals - Computer Vision–ECCV 2010.pdf:pdf},
journal = {Computer Vision–ECCV 2010},
title = {{Category independent object proposals}},
url = {http://www.springerlink.com/index/g3327856v63t2wgw.pdf},
year = {2010}
}
@article{Mirolli2009,
author = {Mirolli, Marco and Parisi, Domenico},
doi = {10.1016/j.newideapsych.2009.07.001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mirolli, Parisi/Mirolli, Parisi - 2009 - Towards a Vygotskyan cognitive robotics The role of language as a cognitive tool - New Ideas in Psychology.pdf:pdf},
issn = {0732118X},
journal = {New Ideas in Psychology},
month = aug,
pages = {1--14},
publisher = {Elsevier Ltd},
title = {{Towards a Vygotskyan cognitive robotics: The role of language as a cognitive tool}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0732118X09000348},
year = {2009}
}
@article{Schwarz2011,
author = {Schwarz, Diemo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2011 - State of the Art in Sound Texture Synthesis - International Conference on Digital Audio Effects (DAFx) 2011.pdf:pdf},
journal = {International Conference on Digital Audio Effects (DAFx) 2011},
pages = {1--10},
title = {{State of the Art in Sound Texture Synthesis}},
year = {2011}
}
@inproceedings{Smaragdis2011,
author = {Smaragdis, P},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis/Smaragdis - 2011 - Approximate nearest-subspace representations for sound mixtures - IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).pdf:pdf},
number = {2},
title = {{Approximate nearest-subspace representations for sound mixtures}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5947702},
year = {2011}
}
@article{Chen2013,
author = {Chen, Tao and Zhu, Zhe and Shamir, Ariel and Daniel, Shi-min Hu},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chen et al/Chen et al. - 2013 - 3-Sweep Extracting Editable Objects from a Single Photo - ACM Transactions on Graphics (TOG).pdf:pdf},
journal = {ACM Transactions on Graphics (TOG)},
keywords = {Image processing,image,interactive techniques,photo manipulation},
number = {5},
title = {{3-Sweep: Extracting Editable Objects from a Single Photo}},
volume = {32},
year = {2013}
}
@article{King2004,
author = {King, Andrew J},
doi = {10.1016/j.cub.2004.04.018},
file = {:Users/pkmital/Documents/Mendeley Desktop/King/King - 2004 - The superior colliculus. - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Animals,Brain Mapping,Models, Neurological,Neurons,Neurons: physiology,Perception,Perception: physiology,Saccades,Saccades: physiology,Superior Colliculi},
month = may,
number = {9},
pages = {R335--8},
pmid = {15120083},
title = {{The superior colliculus.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2904598\&tool=pmcentrez\&rendertype=abstract},
volume = {14},
year = {2004}
}
@article{Klaeser2008,
author = {Klaeser, a. and Marszalek, M. and Schmid, C.},
doi = {10.5244/C.22.99},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klaeser, Marszalek, Schmid/Klaeser, Marszalek, Schmid - 2008 - A Spatio-Temporal Descriptor Based on 3D-Gradients - Procedings of the British Machine Vision Conference 2008.pdf:pdf},
isbn = {1-901725-36-7},
journal = {Procedings of the British Machine Vision Conference 2008},
pages = {99.1--99.10},
publisher = {British Machine Vision Association},
title = {{A Spatio-Temporal Descriptor Based on 3D-Gradients}},
url = {http://www.bmva.org/bmvc/2008/papers/275.html},
year = {2008}
}
@article{Itti2004a,
author = {Itti, Laurent},
doi = {10.1117/12.512618},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti/Itti - 2004 - Realistic avatar eye and head animation using a neurobiological model of visual attention - Proceedings of SPIE.pdf:pdf},
issn = {0277786X},
journal = {Proceedings of SPIE},
pages = {64--78},
publisher = {Spie},
title = {{Realistic avatar eye and head animation using a neurobiological model of visual attention}},
url = {http://link.aip.org/link/?PSI/5200/64/1\&Agg=doi},
year = {2004}
}
@article{Comaniciu2001,
author = {Comaniciu, Dorin and Meer, Peter},
file = {:Users/pkmital/Documents/Mendeley Desktop/Comaniciu, Meer/Comaniciu, Meer - 2001 - Mean Shift A Robust Approach toward Feature Space Analysis 1 Introduction - IEEE Transactions on Pattern Analy.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {clustering,feature space,image segmentation,image smoothing,low-level,mean shift},
number = {5},
pages = {603--619},
title = {{Mean Shift : A Robust Approach toward Feature Space Analysis 1 Introduction}},
volume = {24},
year = {2001}
}
@article{Mital2013,
abstract = {Recent evidence of eye-movement behavior during dynamic scene viewing has shown that low-level visual features such as motion are of greater magnitude and contrast at fixation than at non-fixated locations. However, it is still unclear if the features at fixation are causal in attracting attention or merely correlated with higher-level features such as people. We investigated the influence of motion, edge, and luminance contrast features on eye-movements by either retaining or filtering out each of these features in video clips while participants rated their preference for a 3 second clip. Do participants exhibit the same eye movements and attend to the same locations of a scene when individual or combinations of visual features are removed? Our results suggest that motion and edge information are required for normal eye movement behavior in dynamic scenes. Removing contrast has minimal impact on gaze behavior as measured by gaze entropy, fixation durations, and saccade amplitudes. Removing either edge or motion information significantly increases fixation durations and shortens saccade amplitudes. However, the removal of edge information on its own has a significantly greater impact on fixation durations and saccade amplitudes than the removal of motion. This difference may be due to the fact that removing motion does not impair the initial gaze bias towards human figures observed in the original clips whereas removing edges does. Edge information is required to locate people in a dynamic scene and create typical eye movement behavior. Motion is important for typical timing and amplitude of gaze shifts but not for locating typical focal features such as people. These results suggest that typical gaze behavior in dynamic scenes is due to an interaction between low-level visual features and scene semantics which can be used to compensate for impoverished low-level cues and guide attention to relevant scene content. Meeting abstract presented at VSS 2013},
author = {Mital, P. and Smith, T. J. and Luke, S. and Henderson, J.},
doi = {10.1167/13.9.144},
issn = {1534-7362},
journal = {Journal of Vision},
month = jul,
number = {9},
pages = {144--144},
title = {{Do low-level visual features have a causal influence on gaze during dynamic scene viewing?}},
url = {http://www.journalofvision.org/content/13/9/144.abstract?sid=aa334c94-0090-4d41-8162-531e47c2bd7b},
volume = {13},
year = {2013}
}
@article{Smith2011,
author = {Smith, Nicholas a. and Trainor, Laurel J.},
doi = {10.1111/j.1532-7078.2011.00067.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Trainor/Smith, Trainor - 2011 - Auditory Stream Segregation Improves Infants’ Selective Attention to Target Tones Amid Distracters - Infancy.pdf:pdf},
issn = {15250008},
journal = {Infancy},
month = jan,
pages = {no--no},
title = {{Auditory Stream Segregation Improves Infants’ Selective Attention to Target Tones Amid Distracters}},
url = {http://doi.wiley.com/10.1111/j.1532-7078.2011.00067.x},
year = {2011}
}
@article{VanGael2008,
address = {New York, New York, USA},
author = {{Van Gael}, Jurgen and Saatci, Yunus and Teh, Yee Whye and Ghahramani, Zoubin},
doi = {10.1145/1390156.1390293},
file = {:Users/pkmital/Documents/Mendeley Desktop/Van Gael et al/Van Gael et al. - 2008 - Beam sampling for the infinite hidden Markov model - Proceedings of the 25th international conference on Machine learning - ICML '08.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {1088--1095},
publisher = {ACM Press},
title = {{Beam sampling for the infinite hidden Markov model}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390293},
year = {2008}
}
@article{Elazary2008,
abstract = {How do we decide which objects in a visual scene are more interesting? While intuition may point toward high-level object recognition and cognitive processes, here we investigate the contributions of a much simpler process, low-level visual saliency. We used the LabelMe database (24,863 photographs with 74,454 manually outlined objects) to evaluate how often interesting objects were among the few most salient locations predicted by a computational model of bottom-up attention. In 43\% of all images the model's predicted most salient location falls within a labeled region (chance 21\%). Furthermore, in 76\% of the images (chance 43\%), one or more of the top three salient locations fell on an outlined object, with performance leveling off after six predicted locations. The bottom-up attention model has neither notion of object nor notion of semantic relevance. Hence, our results indicate that selecting interesting objects in a scene is largely constrained by low-level visual properties rather than solely determined by higher cognitive processes.},
author = {Elazary, Lior and Itti, Laurent},
file = {:Users/pkmital/Documents/Mendeley Desktop/Elazary, Itti/Elazary, Itti - 2008 - Interesting objects are visually salient. - Journal of Vision.pdf:pdf},
institution = {Department of Computer Science, University of Southern California, Los Angeles, CA, USA. elazary@usc.edu},
journal = {Journal of Vision},
keywords = {1,10,1167,15,2008,3,8,attention,awareness,citation,doi,elazary,http,interesting objects visually,itti,journal vision,journalofvision,l,objects,org,salient,scene understanding,sensory integration},
number = {3},
pages = {3.1--15},
pmid = {18484809},
publisher = {Association for Research in Vision and Ophthalmology},
title = {{Interesting objects are visually salient.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18484809},
volume = {8},
year = {2008}
}
@article{Liu2009,
author = {Liu, Ce and Adviser-Freeman, W.T. and Adviser-Adelson, E.H.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu, Adviser-Freeman, Adviser-Adelson/Liu, Adviser-Freeman, Adviser-Adelson - 2009 - Beyond pixels exploring new representations and applications for motion analysis - Proceedings of the 10th European Conference on Computer Vision Part III.pdf:pdf},
journal = {Proceedings of the 10th European Conference on Computer Vision: Part III},
pages = {28--42},
publisher = {Massachusetts Institute of Technology},
title = {{Beyond pixels: exploring new representations and applications for motion analysis}},
url = {http://portal.acm.org/citation.cfm?id=1478176 http://portal.acm.org/citation.cfm?id=1835239},
year = {2009}
}
@article{Walther2006a,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Walther, Koch/Walther, Koch - 2006 - Modeling attention to salient proto-objects. - Neural networks the official journal of the International Neural.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Attention,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models, Biological,Neural Networks (Computer),Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,ROC Curve},
month = nov,
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling attention to salient proto-objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17098563},
volume = {19},
year = {2006}
}
@article{Kosnik1986,
abstract = {Visual fixation of a small, stationary target was measured in 12 young observers (mean age = 22 yr) and in 12 older observers (mean age = 70 yr). The two groups' fixation behavior did not differ on various dimensions of fixation stability: mean fixation area, intra-subject variability, or changes in fixation over successive test periods. Connections between these results and age-related changes in the oculomotor system are discussed.},
author = {Kosnik, W and Fikre, J and Sekuler, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kosnik, Fikre, Sekuler/Kosnik, Fikre, Sekuler - 1986 - Visual fixation stability in older adults. - Investigative ophthalmology \& visual science.pdf:pdf},
issn = {0146-0404},
journal = {Investigative ophthalmology \& visual science},
keywords = {Adult,Aged,Aging,Fixation, Ocular,Humans,Ocular Physiological Phenomena,Statistics as Topic},
month = dec,
number = {12},
pages = {1720--5},
pmid = {3793400},
title = {{Visual fixation stability in older adults.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3793400},
volume = {27},
year = {1986}
}
@techreport{Pfeiffer2001,
address = {Australia},
author = {Pfeiffer, S and Vincent, T},
institution = {CSIRO Mathematical and Information Sciences},
keywords = {MIR},
title = {{Formalisation of MPEG-1 compressed domain audio features}},
year = {2001}
}
@article{Henderson1999,
abstract = {Three areas of high-level scene perception research are reviewed. The first concerns the role of eye movements in scene perception, focusing on the influence of ongoing cognitive processing on the position and duration of fixations in a scene. The second concerns the nature of the scene representation that is retained across a saccade and other brief time intervals during ongoing scene perception. Finally, we review research on the relationship between scene and object identification, focusing particularly on whether the meaning of a scene influences the identification of constituent objects.},
author = {Henderson, J M and Hollingworth, a},
doi = {10.1146/annurev.psych.50.1.243},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Hollingworth/Henderson, Hollingworth - 1999 - High-level scene perception. - Annual review of psychology.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Eye Movements,Eye Movements: physiology,Female,Form Perception,Form Perception: physiology,Humans,Male,Mental Processes,Mental Processes: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Saccades,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
pages = {243--71},
pmid = {10074679},
title = {{High-level scene perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10074679},
volume = {50},
year = {1999}
}
@article{Tschuch1999,
author = {Tschuch, Gunther and Brothers, Denis J.},
doi = {10.1121/1.428227},
file = {::},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {3706},
title = {{Modeling vibration and sound production in insects with nonresonant stridulatory organs}},
url = {http://link.aip.org/link/JASMAN/v106/i6/p3706/s1\&Agg=doi},
volume = {106},
year = {1999}
}
@article{Chait2011a,
author = {Chait, Maria and Ruff, Christian C. and Griffiths, Timothy D. and McAlpine, David},
doi = {10.1016/j.neuroimage.2011.09.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chait et al/Chait et al. - 2011 - Cortical responses to changes in acoustic regularity are differentially modulated by attentional load - NeuroImage.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {Attention,Attentional load,Auditory cortex,Change detection,Edge detection,MEG,Scene analysis,auditory evoked response,magnetoencephalography},
month = sep,
number = {2},
pages = {1932--1941},
publisher = {Elsevier Inc.},
title = {{Cortical responses to changes in acoustic regularity are differentially modulated by attentional load}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811911010457},
volume = {59},
year = {2011}
}
@article{Slattery2008,
abstract = {Virtual Reality (VR), especially in a technologically focused discourse, is defined by a class of hardware and software, among them head-mounted displays (HMD); navigation and pointing devices; and stereoscopic imaging. This presentation examines an experiential aspect of VR. Putting virtual in front of reality modifies the ontological status of a class of experience that of reality. Reality has also been modified (by artists, new media theorists, technologists and philosophers) as augmented, mixed, simulated, artificial, layered and enhanced. Modifications of reality are closely tied to modifications of perception. Media theorist Roy Ascott creates a model of three VRs: verifiable reality, virtual reality and vegetal (entheogenically induced) reality. The ways in which we shift our perceptual assumptions, create and verify illusions and enter the willing suspension of disbelief that allows us entry into imaginal worlds is central to the experience of VR worlds, whether those worlds are explicitly representational (robotic manipulations) or explicitly imaginal (artistic creations). The early rhetoric surrounding VR was interwoven with psychedelics, a perception amplified by Timothy Leary's presence on the historic SIGGRAPH panel, and the Wall Street Journal's tag of VR as electronic LSD. This article discusses the connections philosophical, social-historical and psychological-perceptual between these two domains. ABSTRACT FROM AUTHOR},
author = {Slattery, Diana Reed},
doi = {10.1386/tear.6.1.3/1},
issn = {0277786X},
journal = {Technoetic Arts a Journal of Speculative Research},
number = {1},
pages = {3--18},
publisher = {Spie},
title = {{VR and hallucination: a technoetic perspective}},
url = {http://search.ebscohost.com/login.aspx?direct=true\&db=aph\&AN=31526305},
volume = {6},
year = {2008}
}
@article{Based2012,
author = {Vieux, R and Benois-Pineau, J and Domenger, JP},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vieux, Benois-Pineau, Domenger/Vieux, Benois-Pineau, Domenger - 2012 - Content Based Image Retrieval Using Bag-Of-Regions - Advances in Multimedia \ldots.pdf:pdf},
journal = {Advances in Multimedia \ldots},
keywords = {bag-of-regions,content based image retrieval,incremental clus-},
title = {{Content Based Image Retrieval Using Bag-Of-Regions}},
url = {http://www.springerlink.com/index/N3K20M44446L7465.pdf},
year = {2012}
}
@article{Press2001,
abstract = {Functional MRI measurements can securely partition the human posterior occipital lobe into retinotopically organized visual areas (V1, V2 and V3) with experiments that last only 30 min. Methods for identifying functional areas in the dorsal and ventral aspect of the human occipital cortex, however, have not achieved this level of precision; in fact, different laboratories have produced inconsistent reports concerning the visual areas in dorsal and ventral occipital lobe. We report four findings concerning the visual representation in dorsal regions of occipital cortex. First, cortex near area V3A contains a central field representation that is distinct from the foveal representation at the confluence of areas V1, V2 and V3. Second, adjacent to V3A there is a second visual area, V3B, which represents both the upper and lower quadrants. The central representation in V3B appears to merge with that of V3A, much as the central representations of V1/2/3 come together on the lateral margin of the posterior pole. Third, there is yet another dorsal representation of the central visual field. This representation falls in area V7, which includes a representation of both the upper and lower quadrants of the visual field. Fourth, based on visual field and spatial summation measurements, it appears that the receptive field properties of neurons in area V7 differ from those in areas V3A and V3B.},
author = {Press, W a and Brewer, a a and Dougherty, R F and Wade, a R and Wandell, B a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Press et al/Press et al. - 2001 - Visual areas and spatial summation in human visual cortex. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Brain Mapping,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Reproducibility of Results,Sensitivity and Specificity,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology},
month = jan,
number = {10-11},
pages = {1321--32},
pmid = {11322977},
title = {{Visual areas and spatial summation in human visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11322977},
volume = {41},
year = {2001}
}
@article{Mariette2006a,
author = {Mariette, Nick},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mariette/Mariette - 2006 - Perceptual Evaluation of Spatial Audio for “Audio Nomad” Augmented Reality Artworks - Cartography.pdf:pdf},
journal = {Cartography},
title = {{Perceptual Evaluation of Spatial Audio for “Audio Nomad” Augmented Reality Artworks}},
year = {2006}
}
@article{Sanmiguel2013,
abstract = {In the present study we investigated the neural code of sensory predictions. Grounded on a variety of empirical findings, we set out from the proposal that sensory predictions are coded via the top-down modulation of the sensory units whose response properties match the specific characteristics of the predicted stimulus (Albright, 2012; Arnal and Giraud, 2012). From this proposal, we derive the hypothesis that when the specific physical characteristics of the predicted stimulus cannot be advanced, the sensory system should not be able to formulate such predictions, as it would lack the means to represent them. In different conditions, participant's self-paced button presses predicted either only the precise time when a random sound would be presented (random sound condition) or both the timing and the identity of the sound (single sound condition). To isolate prediction-related activity, we inspected the event-related potential (ERP) elicited by rare omissions of the sounds following the button press (see SanMiguel et al., 2013). As expected, in the single sound condition, omissions elicited a complex response in the ERP, reflecting the presence of sound prediction and the violation of this prediction. In contrast, in the random sound condition, sound omissions were not followed by any significant responses in the ERP. These results confirmed our hypothesis, and provide support to current proposals advocating that sensory systems rely on the top-down modulation of stimulus-specific sensory representations as the neural code for prediction. In light of these findings, we discuss the significance of the omission ERP as an electrophysiological marker of predictive processing and we address the paradox that no indicators of violations of temporal prediction alone were found in the present paradigm.},
author = {Sanmiguel, Iria and Saupe, Katja and Schr\"{o}ger, Erich},
doi = {10.3389/fnhum.2013.00407},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sanmiguel, Saupe, Schr\"{o}ger/Sanmiguel, Saupe, Schr\"{o}ger - 2013 - I know what is missing here electrophysiological prediction error signals elicited by omissions of.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
month = jan,
pages = {407},
pmid = {23908618},
title = {{I know what is missing here: electrophysiological prediction error signals elicited by omissions of predicted "what" but not "when".}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3725431\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Hansen2001,
author = {Hansen, Mark H and Yu, Bin},
doi = {10.1198/016214501753168398},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hansen, Yu/Hansen, Yu - 2001 - Model Selection and the Principle of Minimum Description Length - Journal of the American Statistical Association.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {1 mark h,aic,bayesian methods,bell laboratories,bic,bin yu is associate,bounds,cluster analysis,code length,coding redundancy,formation theory,hansen is member of,in-,minimum description length,model selection,murray hill,new jersey,pointwise and minimax lower,regression,the technical sta,time series},
month = jun,
number = {454},
pages = {746--774},
title = {{Model Selection and the Principle of Minimum Description Length}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753168398},
volume = {96},
year = {2001}
}
@article{Tavassoli2009,
abstract = {Visual search can simply be defined as the task of looking for objects of interest in cluttered visual environments. Typically, the human visual system succeeds at this by making a series of rapid eye movements called saccades, interleaved by discrete fixations. However, very little is known on how the brain programs saccades and selects fixation loci in such naturalistic tasks. In the current study, we use a technique developed in our laboratory based on reverse-correlation(1) and stimuli that emulate the natural visual environment to examine observers' strategies when seeking low-contrast targets of various spatial frequency and orientation characteristics. We present four major findings. First, we provide strong evidence of visual guidance in saccadic targeting characterized by saccadic selectivity for spatial frequencies and orientations close to that of the search target. Second, we show that observers exhibit inaccuracies and biases in their estimates of target features. Third, a complementarity effect is generally observed: the absence of certain frequency components in distracters affects whether they are fixated or mistakenly selected as the target. Finally, an unusual phenomenon is observed whereby distracters containing close-to-vertical structures are fixated in searches for nonvertically oriented targets. Our results provide evidence for the involvement of band-pass mechanisms along feature dimensions (spatial frequency and orientation) during visual search.},
author = {Tavassoli, a and Linde, I Van Der and Bovik, a C and Cormack, L K},
doi = {10.1016/j.visres.2008.10.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tavassoli et al/Tavassoli et al. - 2009 - Eye movements selective for spatial frequency and orientation during active visual search. - Vision research.pdf:pdf},
issn = {1878-5646},
journal = {Vision research},
keywords = {Adult,Field Dependence-Independence,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Male,Orientation,Photic Stimulation,Photic Stimulation: methods,Psychometrics,Saccades,Saccades: physiology,Space Perception,Space Perception: physiology},
month = jan,
number = {2},
pages = {173--81},
pmid = {18992270},
publisher = {Elsevier Ltd},
title = {{Eye movements selective for spatial frequency and orientation during active visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18992270},
volume = {49},
year = {2009}
}
@article{Hansen2009,
abstract = {Form vision is traditionally regarded as processing primarily achromatic information. Previous investigations into the statistics of color and luminance in natural scenes have claimed that luminance and chromatic edges are not independent of each other and that any chromatic edge most likely occurs together with a luminance edge of similar strength. Here we computed the joint statistics of luminance and chromatic edges in over 700 calibrated color images from natural scenes. We found that isoluminant edges exist in natural scenes and were not rarer than pure luminance edges. Most edges combined luminance and chromatic information but to varying degrees such that luminance and chromatic edges were statistically independent of each other. Independence increased along successive stages of visual processing from cones via postreceptoral color-opponent channels to edges. The results show that chromatic edge contrast is an independent source of information that can be linearly combined with other cues for the proper segmentation of objects in natural and artificial vision systems. Color vision may have evolved in response to the natural scene statistics to gain access to this independent information.},
author = {Hansen, Thorsten and Gegenfurtner, Karl R},
doi = {10.1017/S0952523808080796},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hansen, Gegenfurtner/Hansen, Gegenfurtner - 2009 - Independence of color and luminance edges in natural scenes. - Visual neuroscience.pdf:pdf},
issn = {1469-8714},
journal = {Visual neuroscience},
keywords = {Animals,Color Perception,Color Perception: physiology,Color Vision,Color Vision: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Lighting,Luminescence,Models, Biological,Neural Networks (Computer),Normal Distribution,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology},
number = {1},
pages = {35--49},
pmid = {19152717},
title = {{Independence of color and luminance edges in natural scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19152717},
volume = {26},
year = {2009}
}
@article{Weiss2011a,
author = {Weiss, Ron J. and Mandel, Michael I. and Ellis, Daniel P.W.},
doi = {10.1016/j.specom.2011.01.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weiss, Mandel, Ellis/Weiss, Mandel, Ellis - 2011 - Combining localization cues and source model constraints for binaural source separation - Speech Communica.pdf:pdf},
issn = {01676393},
journal = {Speech Communication},
keywords = {binaural,eigenvoices,em,source models,source separation},
month = may,
number = {5},
pages = {606--621},
title = {{Combining localization cues and source model constraints for binaural source separation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639311000045},
volume = {53},
year = {2011}
}
@article{Hofmann2001,
author = {Hofmann, Thomas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hofmann/Hofmann - 2001 - Unsupervised learning by probabilistic latent semantic analysis - Machine Learning.pdf:pdf},
journal = {Machine Learning},
keywords = {dimension reduction,em algorithm,information retrieval,language modeling,latent class models,mixture models,natural language processing,unsupervised learning},
pages = {177--196},
title = {{Unsupervised learning by probabilistic latent semantic analysis}},
url = {http://www.springerlink.com/index/L5656365840672G8.pdf},
year = {2001}
}
@inproceedings{Dorin1999,
author = {Dorin, Alan},
booktitle = {Proceedings, First Iteration, Dorin \& McCormack (eds), CEMA, Monash University, Australia},
file = {::},
keywords = {algorithmic composition,kinetic art,physically-based modelling,procedural animation},
pages = {68--79},
publisher = {Citeseer},
title = {{Classification of physical processes for virtual-kinetic art}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.4853\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@misc{Paul2003,
author = {Paul, By Leonard J},
booktitle = {Gamasutra.com},
file = {::},
title = {{Audio Prototyping with Pure Data}},
url = {http://www.gamasutra.com/resource\_guide/200 0!2"/pau\#\_0\$.shtm\#},
year = {2003}
}
@article{Donoho2003,
abstract = {Given a dictionary D = \{d(k)\} of vectors d(k), we seek to represent a signal S as a linear combination S = summation operator(k) gamma(k)d(k), with scalar coefficients gamma(k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the l(1) norm of the coefficients gamma. In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.},
author = {Donoho, David L and Elad, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donoho, Elad/Donoho, Elad - 2003 - Optimally sparse representation in general (nonorthogonal) dictionaries via l minimization. - Proceedings of the N.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = mar,
number = {5},
pages = {2197--202},
pmid = {16576749},
title = {{Optimally sparse representation in general (nonorthogonal) dictionaries via l minimization.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=153464\&tool=pmcentrez\&rendertype=abstract},
volume = {100},
year = {2003}
}
@article{Cahtarevic2008a,
author = {Cahtarevic, Rada},
doi = {10.2298/FUACE0802235C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cahtarevic/Cahtarevic - 2008 - Virtuality in architecture From perspective representation to augmented reality - Facta universitatis - series Architecture and Civil Engineering.pdf:pdf},
issn = {0354-4605},
journal = {Facta universitatis - series: Architecture and Civil Engineering},
keywords = {architectural representation,information,virtual space},
number = {2},
pages = {235--241},
title = {{Virtuality in architecture: From perspective representation to augmented reality}},
url = {http://www.doiserbia.nb.rs/Article.aspx?ID=0354-46050802235C},
volume = {6},
year = {2008}
}
@article{Simons2000,
author = {Simons, Daniel J and Franconeri, Steven L and Reimer, Rebecca L},
doi = {10.1068/p3104},
file = {:Users/pkmital/Documents/Mendeley Desktop/Simons, Franconeri, Reimer/Simons, Franconeri, Reimer - 2000 - Change blindness in the absence of a visual disruption - Perception.pdf:pdf},
issn = {0301-0066},
journal = {Perception},
number = {10},
pages = {1143--1154},
title = {{Change blindness in the absence of a visual disruption}},
url = {http://www.perceptionweb.com/abstract.cgi?id=p3104},
volume = {29},
year = {2000}
}
@article{Haikio2009,
abstract = {By means of the moving window paradigm, we examined how many letters can be identified during a single eye fixation and whether this letter identity span changes as a function of reading skill. The results revealed that 8-year-old Finnish readers identify approximately 5 characters, 10-year-old readers identify approximately 7 characters, and 12-year-old and adult readers identify approximately 9 characters to the right of fixation. Comparison with earlier studies revealed that the letter identity span is smaller than the span for identifying letter features and that it is as wide in Finnish as in English. Furthermore, the letter identity span of faster readers of each age group was larger than that of slower readers, indicating that slower readers, unlike faster readers, allocate most of their processing resources to foveally fixated words. Finally, slower second graders were largely not disrupted by smaller windows, suggesting that their word decoding skill is not yet fully automatized.},
author = {H\"{a}iki\"{o}, Tuomo and Bertram, Raymond and Hy\"{o}n\"{a}, Jukka and Niemi, Pekka},
doi = {10.1016/j.jecp.2008.04.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/H\"{a}iki\"{o} et al/H\"{a}iki\"{o} et al. - 2009 - Development of the letter identity span in reading evidence from the eye movement moving window paradigm. - Journal of experimental child psychology.pdf:pdf},
issn = {1096-0457},
journal = {Journal of experimental child psychology},
keywords = {Adult,Age Factors,Analysis of Variance,Child,Child Development,Child Development: physiology,Cognition,Cognition: physiology,Eye Movements,Eye Movements: physiology,Female,Finland,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reaction Time,Reaction Time: physiology,Reading,Students,Students: psychology,Task Performance and Analysis,Visual Fields,Visual Fields: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = feb,
number = {2},
pages = {167--81},
pmid = {18538339},
publisher = {Elsevier Inc.},
title = {{Development of the letter identity span in reading: evidence from the eye movement moving window paradigm.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18538339},
volume = {102},
year = {2009}
}
@inproceedings{Raghuvanshi2006,
abstract = {We present an interactive approach for generating realistic physically-based sounds from rigid-body dynamic simulations. We use spring-mass systems to model each object’s local deformation and vibration, which we demonstrate to be an adequate approxi- mation for capturing physical effects such as magnitude of impact forces, location of impact, and rolling sounds. No assumption is made about the mesh connectivity or topology. Surface meshes used for rigid-body dynamic simulation are utilized for sound simu- lation without any modifications. We use results in auditory percep- tion and a novel priority-based quality scaling scheme to enable the system to meet variable, stringent time constraints in a real-time ap- plication, while ensuring minimal reduction in the perceived sound quality. With this approach, we have observed up to an order of magnitude speed-up compared to an implementation without the acceleration. As a result, we are able to simulate moderately com- plex simulations with upto hundreds of sounding objects at over 100 frames per second (FPS), making this technique well suited for interactive applications like games and virtual environments. Furthermore, we utilize OpenAL and EAXTM on Creative Sound Blaster Audigy 2TM cards for fast hardware-accelerated propaga- tion modeling of the synthesized sound.},
address = {New York, New York, USA},
author = {Raghuvanshi, Nikunj and Lin, Ming C.},
booktitle = {Proceedings of the 2006 symposium on Interactive 3D graphics and games - SI3D '06},
doi = {10.1145/1111411.1111429},
file = {::},
isbn = {159593295X},
keywords = {a three-octave xylophone in,close,figure 1,musical tones,numerous dice fall on,openal,our algorithm is able,playing out the song,rigid-body simulation,see the video,sound synthesis,succession,the entertainer,to produce the corresponding},
pages = {101},
publisher = {ACM Press},
title = {{Interactive sound synthesis for large scale environments}},
url = {http://portal.acm.org/citation.cfm?doid=1111411.1111429},
year = {2006}
}
@article{Hillis2001,
abstract = {Several investigators have claimed that the retinal coordinates of corresponding points shift with vergence eye movements. Two kinds of shifts have been reported. First, global shifts that increase with retinal eccentricity; such shifts would cause a flattening of the horopter at all viewing distances and would facilitate fusion of flat surfaces. Second, local shifts that are centered on the fovea; such shifts would cause a dimple in the horopter near fixation and would facilitate fusion of points fixated at extreme viewing distances. Nearly all of the empirical evidence supporting shifts of corresponding points comes from horopter measurements and from comparisons of subjective and objective fixation disparity. In both cases, the experimenter must infer the retinal coordinates of corresponding points from external measurements. We describe four factors that could affect this inference: (1) changes in the projection from object to image points that accompany eye rotation and accommodation, (2) fixation errors during the experimental measurements, (3) non-uniform retinal stretching, and (4) changes in the perceived direction of a monocular point when presented adjacent to a binocular point. We conducted two experiments that eliminated or compensated for these potential errors. In the first experiment, observers aligned dichoptic test lines using an apparatus and procedure that eliminated all but the third error. In the second experiment, observers judged the alignment of dichoptic afterimages, and this technique eliminates all the errors. The results from both experiments show that the retinal coordinates of corresponding points do not change with vergence eye movements. We conclude that corresponding points are in fixed retinal positions for observers with normal retinal correspondence.},
author = {Hillis, J M and Banks, M S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hillis, Banks/Hillis, Banks - 2001 - Are corresponding points fixed - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Accommodation, Ocular,Accommodation, Ocular: physiology,Afterimage,Afterimage: physiology,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Orientation,Orientation: physiology,Vision Disparity,Vision Disparity: physiology,Vision, Binocular,Vision, Binocular: physiology},
month = sep,
number = {19},
pages = {2457--73},
pmid = {11483177},
title = {{Are corresponding points fixed?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11483177},
volume = {41},
year = {2001}
}
@phdthesis{Noorden1975,
author = {van Noorden, LPAS},
booktitle = {PhD Dissertation},
file = {:Users/pkmital/Documents/Mendeley Desktop/Noorden/Noorden - 1975 - Temporal coherence in the perception of tone sequences - PhD Dissertation.pdf:pdf},
title = {{Temporal coherence in the perception of tone sequences}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Temporal+Coherence+in+the+Perception+of+Tone+Sequences\#0},
year = {1975}
}
@article{Horowitz2007a,
author = {Horowitz, T. S. and Fencsik, D. E. and Fine, E. M. and Yurgenson, S. and Wolfe, J. M.},
doi = {10.1111/j.1467-9280.2007.01905.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Horowitz et al/Horowitz et al. - 2007 - Microsaccades and Attention Does a Weak Correlation Make an Index Reply to Laubrock, Engbert, Rolfs, and Kliegl (2007) - Psychological Science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = apr,
number = {4},
pages = {367--368},
title = {{Microsaccades and Attention: Does a Weak Correlation Make an Index?: Reply to Laubrock, Engbert, Rolfs, and Kliegl (2007)}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.2007.01905.x},
volume = {18},
year = {2007}
}
@article{Stone2001,
abstract = {A measure of temporal predictability is defined and used to separate linear mixtures of signals. Given any set of statistically independent source signals, it is conjectured here that a linear mixture of those signals has the following property: the temporal predictability of any signal mixture is less than (or equal to) that of any of its component source signals. It is shown that this property can be used to recover source signals from a set of linear mixtures of those signals by finding an un-mixing matrix that maximizes a measure of temporal predictability for each recovered signal. This matrix is obtained as the solution to a generalized eigenvalue problem; such problems have scaling characteristics of O(N3), where N is the number of signal mixtures. In contrast to independent component analysis, the temporal predictability method requires minimal assumptions regarding the probability density functions of source signals. It is demonstrated that the method can separate signal mixtures in which each mixture is a linear combination of source signals with supergaussian, subgaussian, and gaussian probability density functions and on mixtures of voices and music.},
author = {Stone, J V},
doi = {10.1162/089976601750265009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stone/Stone - 2001 - Blind source separation using temporal predictability. - Neural computation.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Humans,Models, Theoretical,Music,Normal Distribution,Signal Processing, Computer-Assisted,Sound Localization,Time Factors,Voice},
month = jul,
number = {7},
pages = {1559--74},
pmid = {11440597},
title = {{Blind source separation using temporal predictability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11440597},
volume = {13},
year = {2001}
}
@article{Ng2012,
author = {Ng, Bernard and Siless, Viviana and Varoquaux, Gael and Poline, Jean-Baptiste and Thirion, Bertrand and Abugharbieh, Rafeef},
doi = {10.1109/PRNI.2012.11},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ng et al/Ng et al. - 2012 - Connectivity-informed Sparse Classifiers for fMRI Brain Decoding - 2012 Second International Workshop on Pattern Reco.pdf:pdf},
isbn = {978-1-4673-2182-2},
journal = {2012 Second International Workshop on Pattern Recognition in NeuroImaging},
keywords = {-connectivity,dti,fmri,sparse classifiers},
month = jul,
pages = {101--104},
publisher = {Ieee},
title = {{Connectivity-informed Sparse Classifiers for fMRI Brain Decoding}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6295900},
year = {2012}
}
@article{Neelon2006,
abstract = {Responses to acoustic input were recorded from human temporal cortex using subdural electrodes in order to investigate in greater anatomical detail how attentional load modulates exogenous auditory responses. Four patient-volunteers performed a dichotic listening task in which they listened for rare frequency deviants in a series of tones presented to both ears at interstimulus intervals (ISIs) of 400, 800, and 2000 ms. Across all ISIs, stimuli presented contralateral to electrode location produced the strongest deflections in the averaged ERP at approximately 90 and 170 ms post-stimulus on average (labeled N90stg and P170stg). Maximal recording sites for these peaks most often occurred over the Sylvian fissure or the upper bank of the posterior superior temporal gyrus. Neither ISI nor selective attention exhibited substantial effects on peak latencies. However, as presentation rates increased (decreasing ISI), overall averaged event-related potential (ERP) amplitudes declined significantly, while attending to the contralateral stimulus significantly increased both the N90stg and P170stg peaks for most patients. This effect of attention increased with decreasing ISI for both components most clearly in the difference between the grand-average ERPs for attending to vs. ignoring the contralateral stimulus, and even more dramatically in the percentage ratio of that difference over the mean peak amplitude. This amplifying effect of attention with increasing load, along with its anatomical location, suggests that attention can enhance exogenous sources in auditory cortex.},
author = {Neelon, Michael F and Williams, Justin and Garell, P Charles},
doi = {10.1016/j.brainres.2006.08.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Neelon, Williams, Garell/Neelon, Williams, Garell - 2006 - The effects of attentional load on auditory ERPs recorded from human cortex. - Brain research.pdf:pdf},
issn = {0006-8993},
journal = {Brain research},
keywords = {Acoustic Stimulation,Adult,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Electroencephalography,Evoked Potentials,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Evoked Potentials: physiology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male,Reaction Time,Reaction Time: physiology,Time Factors},
month = nov,
number = {1},
pages = {94--105},
pmid = {16956586},
title = {{The effects of attentional load on auditory ERPs recorded from human cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2577293\&tool=pmcentrez\&rendertype=abstract},
volume = {1118},
year = {2006}
}
@article{Itti2004,
abstract = {We evaluate the applicability of a biologically-motivated algorithm to select visually-salient regions of interest in video streams for multiply-foveated video compression. Regions are selected based on a nonlinear integration of low-level visual cues, mimicking processing in primate occipital, and posterior parietal cortex. A dynamic foveation filter then blurs every frame, increasingly with distance from salient locations. Sixty-three variants of the algorithm (varying number and shape of virtual foveas, maximum blur, and saliency competition) are evaluated against an outdoor video scene, using MPEG-1 and constant-quality MPEG-4 (DivX) encoding. Additional compression radios of 1.1 to 8.5 are achieved by foveation. Two variants of the algorithm are validated against eye fixations recorded from four to six human observers on a heterogeneous collection of 50 video clips (over 45 000 frames in total). Significantly higher overlap than expected by chance is found between human and algorithmic foveations. With both variants, foveated clips are, on average, approximately half the size of unfoveated clips, for both MPEG-1 and MPEG-4. These results suggest a general-purpose usefulness of the algorithm in improving compression ratios of unconstrained video.},
author = {Itti, Laurent},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti/Itti - 2004 - Automatic foveation for video compression using a neurobiological model of visual attention. - IEEE transactions on image processing a publication of the IEEE Signal Processing Society.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Adult,Algorithms,Artificial Intelligence,Attention,Attention: physiology,Biomimetics,Biomimetics: methods,Computer Graphics,Computer Simulation,Data Compression,Data Compression: methods,Eye Movements,Eye Movements: physiology,Female,Fovea Centralis,Fovea Centralis: physiology,Humans,Image Enhancement,Image Enhancement: methods,Male,Models, Neurological,Numerical Analysis, Computer-Assisted,Pattern Recognition, Automated,Reproducibility of Results,Sensitivity and Specificity,Signal Processing, Computer-Assisted,User-Computer Interface,Video Recording,Video Recording: methods,Visual Perception,Visual Perception: physiology},
month = oct,
number = {10},
pages = {1304--18},
pmid = {15462141},
title = {{Automatic foveation for video compression using a neurobiological model of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15462141},
volume = {13},
year = {2004}
}
@article{Samson2010,
abstract = {Investigations of the functional organization of human auditory cortex typically examine responses to different sound categories. An alternative approach is to characterize sounds with respect to their amount of variation in the time and frequency domains (i.e., spectral and temporal complexity). Although the vast majority of published studies examine contrasts between discrete sound categories, an alternative complexity-based taxonomy can be evaluated through meta-analysis. In a quantitative meta-analysis of 58 auditory neuroimaging studies, we examined the evidence supporting current models of functional specialization for auditory processing using grouping criteria based on either categories or spectro-temporal complexity. Consistent with current models, analyses based on typical sound categories revealed hierarchical auditory organization and left-lateralized responses to speech sounds, with high speech sensitivity in the left anterior superior temporal cortex. Classification of contrasts based on spectro-temporal complexity, on the other hand, revealed a striking within-hemisphere dissociation in which caudo-lateral temporal regions in auditory cortex showed greater sensitivity to spectral changes, while anterior superior temporal cortical areas were more sensitive to temporal variation, consistent with recent findings in animal models. The meta-analysis thus suggests that spectro-temporal acoustic complexity represents a useful alternative taxonomy to investigate the functional organization of human auditory cortex.},
author = {Samson, Fabienne and Zeffiro, Thomas a and Toussaint, Alain and Belin, Pascal},
doi = {10.3389/fpsyg.2010.00241},
file = {:Users/pkmital/Documents/Mendeley Desktop/Samson et al/Samson et al. - 2010 - Stimulus complexity and categorical effects in human auditory cortex an activation likelihood estimation meta-ana.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {category,fmri,frequency,hierarchy,time},
month = jan,
number = {January},
pages = {241},
pmid = {21833294},
title = {{Stimulus complexity and categorical effects in human auditory cortex: an activation likelihood estimation meta-analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3153845\&tool=pmcentrez\&rendertype=abstract},
volume = {1},
year = {2010}
}
@article{Cemgil2009,
abstract = {We describe nonnegative matrix factorisation (NMF) with a Kullback-Leibler (KL) error measure in a statistical framework, with a hierarchical generative model consisting of an observation and a prior component. Omitting the prior leads to the standard KL-NMF algorithms as special cases, where maximum likelihood parameter estimation is carried out via the Expectation-Maximisation (EM) algorithm. Starting from this view, we develop full Bayesian inference via variational Bayes or Monte Carlo. Our construction retains conjugacy and enables us to develop more powerful models while retaining attractive features of standard NMF such as monotonic convergence and easy implementation. We illustrate our approach on model order selection and image reconstruction.},
author = {Cemgil, Ali Taylan},
doi = {10.1155/2009/785152},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cemgil/Cemgil - 2009 - Bayesian inference for nonnegative matrix factorisation models. - Computational intelligence and neuroscience.pdf:pdf},
issn = {1687-5273},
journal = {Computational intelligence and neuroscience},
month = jan,
pages = {785152},
pmid = {19536273},
title = {{Bayesian inference for nonnegative matrix factorisation models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2688815\&tool=pmcentrez\&rendertype=abstract},
volume = {2009},
year = {2009}
}
@article{Tervaniemi1997,
abstract = {Neuronal mechanisms involved in the processing of complex sounds with asynchronous onsets were studied in reading subjects. The sound onset asynchrony (SOA) between the leading partial and the remaining complex tone was varied between 0 and 360 ms. Infrequently occurring deviant sounds (in which one out of 10 harmonics was different in pitch relative to the frequently occurring standard sound) elicited the mismatch negativity (MMN), a change-specific cortical event-related potential (ERP) component. This indicates that the pitch of standard stimuli had been pre-attentively coded by sensory-memory traces. Moreover, when the complex-tone onset fell within temporal integration window initiated by the leading-partial onset, the deviants elicited the N2b component. This indexes that involuntary attention switch towards the sound change occurred. In summary, the present results support the existence of pre-perceptual integration mechanism of 100-200 ms duration and emphasize its importance in switching attention towards the stimulus change.},
author = {Tervaniemi, M and Schr\"{o}ger, E and N\"{a}\"{a}t\"{a}nen, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tervaniemi, Schr\"{o}ger, N\"{a}\"{a}t\"{a}nen/Tervaniemi, Schr\"{o}ger, N\"{a}\"{a}t\"{a}nen - 1997 - Pre-attentive processing of spectrally complex sounds with asynchronous onsets an event-rela.pdf:pdf},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Neurons, Afferent,Neurons, Afferent: physiology,Pitch Perception,Pitch Perception: physiology,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology},
month = may,
number = {3},
pages = {197--200},
pmid = {9185684},
title = {{Pre-attentive processing of spectrally complex sounds with asynchronous onsets: an event-related potential study with human subjects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9185684},
volume = {227},
year = {1997}
}
@article{Hunt2003,
abstract = {Inhibition of return (IOR) describes a performance decrement for stimuli appearing at recently cued locations. Both attentional and motor processes have been implicated in the IOR effect. The present data reveal a double dissociation between the attentional and motor components of IOR whereby the motor-based component of IOR is present when the response is oculomotor, and the attention-based component of IOR is present when the response is manual. These 2 distinct components should be considered and studied separately, as well as in relation to each other, if a comprehensive theory of IOR is to be achieved. ((c) 2003 APA, all rights reserved)},
author = {Hunt, Amelia R and Kingstone, Alan},
doi = {10.1037/0096-1523.29.5.1068},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hunt, Kingstone/Hunt, Kingstone - 2003 - Inhibition of return Dissociating attentional and oculomotor components. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adult,Attention,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Inhibition (Psychology),Mental Processes,Mental Processes: physiology,Oculomotor Muscles,Oculomotor Muscles: physiology,Saccades,Saccades: physiology},
month = oct,
number = {5},
pages = {1068--74},
pmid = {14585023},
title = {{Inhibition of return: Dissociating attentional and oculomotor components.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14585023},
volume = {29},
year = {2003}
}
@article{Alain2002,
author = {Alain, Claude and Schuler, Benjamin M. and McDonald, Kelly L.},
doi = {10.1121/1.1434942},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alain, Schuler, McDonald/Alain, Schuler, McDonald - 2002 - Neural activity associated with distinguishing concurrent auditory objects - The Journal of the Acoust.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {2},
pages = {990},
title = {{Neural activity associated with distinguishing concurrent auditory objects}},
url = {http://link.aip.org/link/JASMAN/v111/i2/p990/s1\&Agg=doi},
volume = {111},
year = {2002}
}
@article{Tatler2005b,
abstract = {Object descriptions are extracted and retained across saccades when observers view natural scenes. We investigated whether particular object properties are encoded and the stability of the resulting memories. We tested immediate recall of multiple types of information from real-world scenes and from computer-presented images of the same scenes. The relationship between fixations and properties of object memory was investigated. Position information was encoded and accumulated from multiple fixations. In contrast, identity and colour were encoded but did not require direct fixation and did not accumulate. In the current experiments, participants were unable to recall any information about shape or relative distances between objects. In addition, where information was encoded we found differential patterns of stability. Data from viewing real scenes and images were highly consistent, with stronger effects in the real-world conditions. Our findings imply that object files are not dependent upon the encoding of any particular object property and so are robust to dynamic visual environments.},
author = {Tatler, Benjamin W and Gilchrist, Iain D and Land, Michael F},
doi = {10.1080/02724980443000430},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Gilchrist, Land/Tatler, Gilchrist, Land - 2005 - Visual memory for objects in natural scenes from fixations to object files. - The Quarterly journal of experimental psychology. A, Human experimental psychology.pdf:pdf},
issn = {0272-4987},
journal = {The Quarterly journal of experimental psychology. A, Human experimental psychology},
keywords = {Adult,Eye Movements,Female,Fixation, Ocular,Humans,Male,Memory,Visual Perception,Vocabulary},
month = jul,
number = {5},
pages = {931--60},
pmid = {16194942},
title = {{Visual memory for objects in natural scenes: from fixations to object files.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16194942},
volume = {58},
year = {2005}
}
@article{Hamker2005a,
author = {Hamker, Fred H.},
doi = {10.1016/j.cviu.2004.09.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hamker/Hamker - 2005 - The emergence of attention by population-based inference and its role in distributed processing and cognitive control of.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {attention,cognitive control,computational neuroscience,inference,natural scenes,object detection,object recognition,top-down},
month = oct,
number = {1-2},
pages = {64--106},
title = {{The emergence of attention by population-based inference and its role in distributed processing and cognitive control of vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314205000767},
volume = {100},
year = {2005}
}
@book{Joyce1988,
author = {Joyce, Paul},
isbn = {0517571749},
pages = {192},
publisher = {Harmony},
title = {{Hockney on Photography: Conversations with Paul Joyce}},
url = {http://www.amazon.com/Hockney-Photography-Conversations-Paul-Joyce/dp/0517571749},
year = {1988}
}
@article{Robertson1991,
author = {Robertson, GG and Mackinlay, JD},
file = {:Users/pkmital/Documents/Mendeley Desktop/Robertson, Mackinlay/Robertson, Mackinlay - 1991 - Cone trees animated 3D visualizations of hierarchical information - Proceedings of the SIGCHI.pdf:pdf},
journal = {Proceedings of the SIGCHI},
title = {{Cone trees: animated 3D visualizations of hierarchical information}},
url = {http://dl.acm.org/citation.cfm?id=108883},
year = {1991}
}
@article{Brecht2004,
abstract = {Synchronization of neuronal discharges has been observed in numerous brain structures, but opinions diverge regarding its significance in neuronal processing. Here we investigate whether the motion vectors of saccadic eye movements evoked by electrical multisite stimulation of the cat superior colliculus (SC) are influenced by varying the degree of synchrony between the stimulus trains. With synchronous activation of SC sites, the vectors of the resulting saccades correspond approximately to the averages of the vectors of saccades evoked from each site alone. In contrast, when the pulses of trains applied to the different sites are temporally offset by as little as 5-10 ms, the vectors of the resulting saccades come close to the sum of the individual vectors. Thus saccade vectors depend not only on the site and amplitude of collicular activation but also on the precise temporal relations among the respective spike trains. These data indicate that networks within or downstream from the SC discriminate with high temporal resolution between synchronous and asynchronous population responses. This supports the hypothesis that information is encoded not only in the rate of neuronal responses but also in the precise temporal relations between discharges.},
author = {Brecht, Michael and Singer, Wolf and Engel, Andreas K},
doi = {10.1152/jn.00639.2003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brecht, Singer, Engel/Brecht, Singer, Engel - 2004 - Amplitude and direction of saccadic eye movements depend on the synchronicity of collicular population activity. - Journal of neurophysiology.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cats,Electric Stimulation,Electric Stimulation: methods,Saccades,Saccades: physiology,Superior Colliculi,Superior Colliculi: physiology},
month = jul,
number = {1},
pages = {424--32},
pmid = {14973313},
title = {{Amplitude and direction of saccadic eye movements depend on the synchronicity of collicular population activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14973313},
volume = {92},
year = {2004}
}
@article{Simons1997,
author = {Simons, Daniel J and Levin, Daniel T},
file = {:Users/pkmital/Documents/Mendeley Desktop/Simons, Levin/Simons, Levin - 1997 - Change Blindness - Trends in Cognitive Sciences.pdf:pdf},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {261--267},
title = {{Change Blindness}},
volume = {1},
year = {1997}
}
@article{Smith2008,
abstract = {When multiple viewers attend to the same static naturalistic scene there is a high degree of agreement in terms of the regions viewers attend to but no synchronization of when they attend there. By comparison, real-world scenes are rich with temporally-defined visual events such as motion which have the potential to involuntarily capture attention. Initial studies of attention during dynamic scenes have reported a high degree of spatiotemporal agreement, henceforth referred to as Attentional Synchrony. However, these dynamic scenes are composed with viewer attention in mind e.g. film and TV footage depicting a single subject tracked by a moving camera. Therefore, it is not currently known if attentional synchrony is caused by the presence of motion, scene content, or compositional factors. In this study the degree of attentional synchrony was measured while participants memorized static and dynamic versions of the same real-world scenes. All scenes were filmed by a static camera without any deliberate composition. As predicted, the degree of attentional synchrony was greater in dynamic compared with static versions of the same scene. On average, the gaze position of 6 participants was clustered within 15\% of the screen area during dynamic scenes and 20\% for static scenes. Both static and dynamic scenes began with a 1200ms period of high synchrony ([[lt]]8\%) as all participants attended to the screen center. Following this central-tendency the greatest moments of attentional synchrony appear to be caused by the presence of a single moving person (one person synchrony = 10\%; more than one person = 17\%). People are prioritized by attention in static scenes but do not create synchrony. These results indicate that there is greater attentional synchrony in dynamic compared with static naturalistic scenes when content and composition are controlled.},
author = {Smith, Tim J and Henderson, John M.},
journal = {Journal of Vision},
number = {6:773},
title = {{Attentional synchrony in static and dynamic scenes}},
volume = {8},
year = {2008}
}
@article{Keane2010,
author = {Keane, Brian P. and Rosenthal, Orna and Chun, Nicole H. and Shams, Ladan},
doi = {10.1016/j.rasd.2009.09.015},
file = {:Users/pkmital/Documents/Mendeley Desktop/Keane et al/Keane et al. - 2010 - Audiovisual integration in high functioning adults with autism - Research in Autism Spectrum Disorders.pdf:pdf},
issn = {17509467},
journal = {Research in Autism Spectrum Disorders},
keywords = {audiovisual integration,high-functioning autism,multisensory integration},
month = apr,
number = {2},
pages = {276--289},
title = {{Audiovisual integration in high functioning adults with autism}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1750946709001019},
volume = {4},
year = {2010}
}
@article{Brady2009,
abstract = {The information that individuals can hold in working memory is quite limited, but researchers have typically studied this capacity using simple objects or letter strings with no associations between them. However, in the real world there are strong associations and regularities in the input. In an information theoretic sense, regularities introduce redundancies that make the input more compressible. The current study shows that observers can take advantage of these redundancies, enabling them to remember more items in working memory. In 2 experiments, covariance was introduced between colors in a display so that over trials some color pairs were more likely to appear than other color pairs. Observers remembered more items from these displays than from displays where the colors were paired randomly. The improved memory performance cannot be explained by simply guessing the high-probability color pair, suggesting that observers formed more efficient representations to remember more items. Further, as observers learned the regularities, their working memory performance improved in a way that is quantitatively predicted by a Bayesian learning model and optimal encoding scheme. These results suggest that the underlying capacity of the individuals' working memory is unchanged, but the information they have to remember can be encoded in a more compressed fashion.},
author = {Brady, Timothy F and Konkle, Talia and Alvarez, George a},
doi = {10.1037/a0016797},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brady, Konkle, Alvarez/Brady, Konkle, Alvarez - 2009 - Compression in visual working memory using statistical regularities to form more efficient memory repres.pdf:pdf},
issn = {1939-2222},
journal = {Journal of experimental psychology. General},
keywords = {Adolescent,Adult,Color,Humans,Memory, Short-Term,Memory, Short-Term: physiology,Mental Recall,Mental Recall: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Task Performance and Analysis,Visual Perception,Visual Perception: physiology,Young Adult},
month = nov,
number = {4},
pages = {487--502},
pmid = {19883132},
title = {{Compression in visual working memory: using statistical regularities to form more efficient memory representations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19883132},
volume = {138},
year = {2009}
}
@article{Smith2009a,
abstract = {Inhibition of Return (IOR) is a delay in initiating attentional shifts to previously attended locations. It is believed to facilitate attentional exploration of a scene. Computational models of attention have implemented IOR as a simple mechanism for driving attention through a scene. However, evidence for IOR during scene viewing is inconclusive. In this study IOR during scene memorization and in response to sudden onsets at the last (1-back) and penultimate (2-back) fixation location was measured. The results indicate that there is a tendency for saccades to continue the trajectory of the last saccade (Saccadic Momentum), but contrary to the ?foraging facilitator? hypothesis of IOR, there is also a distinct population of saccades directed back to the last fixation location, especially in response to onsets. Voluntary return saccades to the 1-back location experience temporal delay but this does not affect their likelihood of occurrence. No localized temporal delay is exhibited at 2-back. These results suggest that IOR exists at the last fixation location during scene memorization but that this temporal delay is overridden by Facilitation of Return. Computational models of attention will fail to capture the pattern of saccadic eye movements during scene viewing unless they model the dynamics of visual encoding and can account for the interaction between Facilitation of Return, Saccadic Momentum, and Inhibition of Return.
Inhibition of Return (IOR) is a delay in initiating attentional shifts to previously attended locations. It is believed to facilitate attentional exploration of a scene. Computational models of attention have implemented IOR as a simple mechanism for driving attention through a scene. However, evidence for IOR during scene viewing is inconclusive. In this study IOR during scene memorization and in response to sudden onsets at the last (1-back) and penultimate (2-back) fixation location was measured. The results indicate that there is a tendency for saccades to continue the trajectory of the last saccade (Saccadic Momentum), but contrary to the ?foraging facilitator? hypothesis of IOR, there is also a distinct population of saccades directed back to the last fixation location, especially in response to onsets. Voluntary return saccades to the 1-back location experience temporal delay but this does not affect their likelihood of occurrence. No localized temporal delay is exhibited at 2-back. These results suggest that IOR exists at the last fixation location during scene memorization but that this temporal delay is overridden by Facilitation of Return. Computational models of attention will fail to capture the pattern of saccadic eye movements during scene viewing unless they model the dynamics of visual encoding and can account for the interaction between Facilitation of Return, Saccadic Momentum, and Inhibition of Return.},
author = {Smith, Tim J. and Henderson, John M.},
doi = {10.1080/13506280802678557},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6-7},
pages = {1083--1108},
publisher = {Routledge},
title = {{Facilitation of return during scene viewing}},
url = {http://dx.doi.org/10.1080/13506280802678557},
volume = {17},
year = {2009}
}
@book{Leary2019,
author = {Leary, Timothy},
isbn = {0060928662},
pages = {252},
publisher = {HarperOne},
title = {{Design For Dying}},
url = {http://www.amazon.com/Design-For-Dying-Timothy-Leary/dp/0060928662},
year = {2019}
}
@article{Tipper1999,
abstract = {We investigated whether inhibition of return (IOR) could be observed in location-based, scene-based, and object-centered frames of reference. IOR was found to move both with a separate cued object (scene-based) and with a location within a single rotating object (object-centered). Importantly, however, IOR was also associated with the environmental location cued when cuing was of a separate object (scene-based), whereas facilitation of the cued location was found when cuing was of a component within an object. These results suggest that location is of central importance to scene-based representations of separate objects, which appear to be encoded in viewer-centered coordinates, whereas environmental locus is of little relevance when attention orients within a single object. The results also provide further evidence for the coexistence of both excitation and inhibition associated with uninformative exogenous cues.},
author = {Tipper, S P and Jordan, H and Weaver, B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tipper, Jordan, Weaver/Tipper, Jordan, Weaver - 1999 - Scene-based and object-centered inhibition of return evidence for dual orienting mechanisms. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adult,Attention,Color Perception,Discrimination Learning,Female,Humans,Inhibition (Psychology),Male,Orientation,Pattern Recognition, Visual,Reaction Time},
month = jan,
number = {1},
pages = {50--60},
pmid = {10070199},
title = {{Scene-based and object-centered inhibition of return: evidence for dual orienting mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10070199},
volume = {61},
year = {1999}
}
@article{Arnold2010,
abstract = {Different sources of sensory information can interact, often shaping what we think we have seen or heard. This can enhance the precision of perceptual decisions relative to those made on the basis of a single source of information. From a computational perspective, there are multiple reasons why this might happen, and each predicts a different degree of enhanced precision. Relatively slight improvements can arise when perceptual decisions are made on the basis of multiple independent sensory estimates, as opposed to just one. These improvements can arise as a consequence of probability summation. Greater improvements can occur if two initially independent estimates are summated to form a single integrated code, especially if the summation is weighted in accordance with the variance associated with each independent estimate. This form of combination is often described as a Bayesian maximum likelihood estimate. Still greater improvements are possible if the two sources of information are encoded via a common physiological process.},
author = {Arnold, Derek H and Tear, Morgan and Schindel, Ryan and Roseboom, Warrick},
doi = {10.1371/journal.pone.0010217},
file = {:Users/pkmital/Documents/Mendeley Desktop/Arnold et al/Arnold et al. - 2010 - Audio-visual speech cue combination. - PloS one.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
month = jan,
number = {4},
pages = {e10217},
pmid = {20419130},
title = {{Audio-visual speech cue combination.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2855706\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2010}
}
@article{Galanter2006,
author = {Galanter, P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Galanter/Galanter - 2006 - Generative art and rules-based art - Vague Terrain.pdf:pdf},
journal = {Vague Terrain},
title = {{Generative art and rules-based art}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:generative+art+and+rules-based+art\#0},
year = {2006}
}
@article{LeszekGorecki2004,
author = {{Leszek Gorecki}, Marek Domanski},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leszek Gorecki/Leszek Gorecki - 2004 - Video Coding Using Matching Pursuit With Image-Adapted Dictionary - International Workshop on Systems, Signals \& Image Processing.pdf:pdf},
journal = {International Workshop on Systems, Signals \& Image Processing},
keywords = {low bitrate coding,matching pursuit,video compression},
number = {September},
pages = {22--24},
title = {{Video Coding Using Matching Pursuit With Image-Adapted Dictionary}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.2856\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@article{Bogart2013,
author = {Bogart, Benjamin David Robert and Pasquier, Philippe},
doi = {10.1162/LEON\_a\_00525},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bogart, Pasquier/Bogart, Pasquier - 2013 - Context Machines A Series of Situated and Self-Organizing Artworks - Leonardo.pdf:pdf},
issn = {0024-094X},
journal = {Leonardo},
month = apr,
number = {2},
pages = {114--122},
title = {{Context Machines: A Series of Situated and Self-Organizing Artworks}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/LEON\_a\_00525},
volume = {46},
year = {2013}
}
@article{Henderson2009b,
author = {Henderson, John M and Smith, Tim J},
doi = {10.1167/9.1.32.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Smith/Henderson, Smith - 2009 - The influence of clutter on real-world scene search Evidence from search efficiency and eye movements - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,2009,32,8,9,and eye movements,chanceaux,citation,clutter,evidence from search efficiency,eye movements,henderson,http,j,journal of vision,journalofvision,m,on real-world scene search,org,scene perception,smith,t,the influence of clutter,visual search},
pages = {1--8},
title = {{The influence of clutter on real-world scene search : Evidence from search efficiency and eye movements}},
volume = {9},
year = {2009}
}
@misc{Singel2012,
author = {Singel, Ryan},
booktitle = {Wired.com},
file = {:Users/pkmital/Documents/Mendeley Desktop/Singel/Singel - 2012 - YouTube Flags Democrats’ Convention Video on Copyright Grounds - Wired.com.html:html},
title = {{YouTube Flags Democrats’ Convention Video on Copyright Grounds}},
url = {http://www.wired.com/threatlevel/2012/09/youtube-flags-democrats-convention-video-on-copyright-grounds/},
urldate = {27/08/13},
year = {2012}
}
@article{Hickey2006,
abstract = {We investigated the ability of salient yet task-irrelevant stimuli to capture attention in two visual search experiments. Participants were presented with circular search arrays that contained a highly salient distractor singleton defined by color and a less salient target singleton defined by form. A component of the event-related potential called the N2pc was used to track the allocation of attention to lateralized positions in the arrays. In Experiment 1, a lateralized distractor elicited an N2pc when a concurrent target was presented on the vertical meridian and thus could not elicit lateralized components such as the N2pc. A similar distractor-elicited N2pc was found in Experiment 2, which was conducted to rule out certain voluntary search strategies. Additionally, in Experiment 2 both the distractor and the target elicited the N2pc component when the two stimuli were presented on opposite sides of the search array. Critically, the distractor-elicited N2pc preceded the target-elicited N2pc on these trials. These results demonstrate that participants shifted attention to the target only after shifting attention to the more salient but task-irrelevant distractor. This pattern of results is in line with theories of attention in which stimulus-driven control plays an integral role.},
author = {Hickey, Clayton and McDonald, John J and Theeuwes, Jan},
doi = {10.1162/jocn.2006.18.4.604},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hickey, McDonald, Theeuwes/Hickey, McDonald, Theeuwes - 2006 - Electrophysiological evidence of the capture of visual attention. - Journal of cognitive neuroscience.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology},
month = apr,
number = {4},
pages = {604--13},
pmid = {16768363},
title = {{Electrophysiological evidence of the capture of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16768363},
volume = {18},
year = {2006}
}
@article{Juillet2003a,
author = {Juillet, Roberto Ortelli and Mireille, Jury and Nova, Nicolas and Schneider, Daniel K},
file = {::},
journal = {Recherche},
title = {{Styles d’interaction dans les PocketPC: analyses et comparaisons}},
year = {2003}
}
@article{Kimura2008d,
abstract = {Change blindness studies using explicit behavioral measures have revealed that humans are remarkably poor at explicitly detecting changes between two successive visual images until focused attention is drawn to the changes, which supports the notion that outside the range of focused attention, our mental representations of the visual world are so volatile as to be unable to support detection of changes. However, change blindness studies using implicit behavioral measures have revealed that changes outside the range of focused attention might be detected even in the absence of awareness, which supports the possibility that our mental representations are not so volatile as has been suggested. The purpose of the present study was to provide further evidence for implicit change detection using event-related brain potentials (ERPs). For this purpose, we compared ERPs elicited on trials where color changes were present but participants failed to report the presence of changes (Change blindness trials) and ERPs on trials where changes were absent and participants correctly did not report the presence of changes (No-change trials). The result showed that compared to No-change trials, Change blindness trials elicited a frontal/central positivity at around 160-180ms, which is highly consistent with the result of Fernandez-Duque et al. [D. Fernandez-Duque, G. Grossi, I.M. Thornton, H.J. Neville, Representation of change: separate electrophysiolocal markers of attention, awareness, and implicit processing, J. Cogn. Neurosci. 15 (2003) 491-507] who firstly reported an ERP correlate of implicit change detection. This result provides further evidence for implicit change detection, which supports the notion that even outside the range of focused attention, our mental representations of the visual world are robust at least enough to support implicit detection of changes.},
author = {Kimura, Motohiro and Katayama, Jun'ichi and Ohira, Hideki},
doi = {10.1016/j.neulet.2008.10.064},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Katayama, Ohira/Kimura, Katayama, Ohira - 2008 - Event-related brain potential evidence for implicit change detection a replication of Fernandez-Duque et al. (2003). - Neuroscience letters.pdf:pdf},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Adult,Attention,Attention: physiology,Electroencephalography,Evoked Potentials,Evoked Potentials: physiology,Female,Humans,Male,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = dec,
number = {3},
pages = {236--9},
pmid = {18973794},
title = {{Event-related brain potential evidence for implicit change detection: a replication of Fernandez-Duque et al. (2003).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18973794},
volume = {448},
year = {2008}
}
@article{Vitevitch2003,
author = {Vitevitch, MS},
doi = {10.1037/0096-1523.29.2.333.Change},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vitevitch/Vitevitch - 2003 - Change deafness the inability to detect changes between two voices. - Journal of Experimental Psychology Human Percep.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {2},
pages = {333--342},
title = {{Change deafness: the inability to detect changes between two voices.}},
url = {http://psycnet.apa.org/journals/xhp/29/2/333/},
volume = {29},
year = {2003}
}
@article{Klein2007b,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces - 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@article{Paine2002,
author = {Paine, Garth},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = dec,
number = {03},
pages = {295--304},
title = {{Interactivity, where to from here?}},
url = {http://journals.cambridge.org/abstract\_S1355771802003096},
volume = {7},
year = {2002}
}
@article{Wang2004a,
abstract = {We present a new method for converting a photo or image to a synthesized painting following the painting style of an example painting. Treating painting styles of brush strokes as sample textures, we reduce the problem of learning an example painting to a texture synthesis problem. The proposed method uses a hierarchical patch-based approach to the synthesis of directional textures. The key features of our method are: 1) Painting styles are represented as one or more blocks of sample textures selected by the user from the example painting; 2) image segmentation and brush stroke directions defined by the medial axis are used to better represent and communicate shapes and objects present in the synthesized painting; 3) image masks and a hierarchy of texture patches are used to efficiently synthesize high-quality directional textures. The synthesis process is further accelerated through texture direction quantization and the use of Gaussian pyramids. Our method has the following advantages: First, the synthesized stroke textures can follow a direction field determined by the shapes of regions to be painted. Second, the method is very efficient; the generation time of a synthesized painting ranges from a few seconds to about one minute, rather than hours, as required by other existing methods, on a commodity PC. Furthermore, the technique presented here provides a new and efficient solution to the problem of synthesizing a 2D directional texture. We use a number of test examples to demonstrate the efficiency of the proposed method and the high quality of results produced by the method.},
author = {Wang, Bin and Wang, Wenping and Yang, Huaiping and Sun, Jiaguang},
doi = {10.1109/TVCG.2004.1272726},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang et al/Wang et al. - 2004 - Efficient example-based painting and synthesis of 2D directional texture. - IEEE transactions on visualization and.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Graphics,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Paintings,Photography,Photography: methods,Reproducibility of Results,Sensitivity and Specificity,User-Computer Interface},
number = {3},
pages = {266--77},
pmid = {18579958},
title = {{Efficient example-based painting and synthesis of 2D directional texture.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18579958},
volume = {10},
year = {2004}
}
@book{Bilbao2009,
abstract = {Digital sound synthesis has long been approached using standard digital filtering techniques. Newer synthesis strategies, however, make use of physical descriptions of musical instruments, and allow for much more realistic and complex sound production and thereby synthesis becomes a problem of simulation. This book has a special focus on time domain finite difference methods presented within an audio framework. It covers time series and difference operators, and basic tools for the construction and analysis of finite difference schemes, including frequency-domain and energy-based methods, with special attention paid to problems inherent to sound synthesis. Various basic lumped systems and excitation mechanisms are covered, followed by a look at the 1D wave equation, linear bar and string vibration, acoustic tube modelling, and linear membrane and plate vibration. Various advanced topics, such as the nonlinear vibration of strings and plates, are given an elaborate treatment. Key features: Includes a historical overview of digital sound synthesis techniques, highlighting the links between the various physical modelling methodologies. A pedagogical presentation containing over 150 problems and programming exercises, and numerous figures and diagrams, and code fragments in the MATLAB programming language helps the reader with limited experience of numerical methods reach an understanding of this subject. Offers a complete treatment of all of the major families of musical instruments, including certain audio effects. Numerical Sound Synthesis is suitable for audio and software engineers, and researchers in digital audio, sound synthesis and more general musical acoustics. Graduate students in electrical engineering, mechanical engineering or computer science, working on the more technical side of digital audio and sound synthesis, will also find this book of interest.},
author = {Bilbao, Stefan},
isbn = {0470510463},
pages = {456},
publisher = {John Wiley and Sons},
title = {{Numerical Sound Synthesis}},
url = {http://catalogo.unipd.it/F?func=find-c\&ccl\_term=IDN=PUV1187104\&local\_base=SBP01},
year = {2009}
}
@article{Hare2012,
author = {Hare, S. and Saffari, a. and Torr, P. H. S.},
doi = {10.1109/CVPR.2012.6247889},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hare, Saffari, Torr/Hare, Saffari, Torr - 2012 - Efficient online structured output learning for keypoint-based object tracking - 2012 IEEE Conference on Co.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1894--1901},
publisher = {Ieee},
title = {{Efficient online structured output learning for keypoint-based object tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247889},
year = {2012}
}
@article{Sittiprapaporn2012,
author = {Sittiprapaporn, W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sittiprapaporn/Sittiprapaporn - 2012 - An Effect of Attention on Mismatch Negativity in Audiovisual Visual Modalities - Pakistan Journal of Biological.pdf:pdf},
journal = {Pakistan Journal of Biological Sciences},
number = {11},
pages = {542--546},
title = {{An Effect of Attention on Mismatch Negativity in Audiovisual Visual Modalities}},
url = {http://docsdrive.com/pdfs/ansinet/pjbs/0000/46050-46050.pdf},
volume = {15},
year = {2012}
}
@article{Tarr1998,
abstract = {Theories of visual object recognition must solve the problem of recognizing 3D objects given that perceivers only receive 2D patterns of light on their retinae. Recent findings from human psychophysics, neurophysiology and machine vision provide converging evidence for 'image-based' models in which objects are represented as collections of viewpoint-specific local features. This approach is contrasted with 'structural-description' models in which objects are represented as configurations of 3D volumes or parts. We then review recent behavioral results that address the biological plausibility of both approaches, a well as some of their computational advantages and limitations. We conclude that, although the image-based approach holds great promise, it has potential pitfalls that may be best overcome by including structural information. Thus, the most viable model of object recognition may be one that incorporates the most appealing aspects of both image-based and structural description theories.},
author = {Tarr, M J and B\"{u}lthoff, H H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tarr, B\"{u}lthoff/Tarr, B\"{u}lthoff - 1998 - Image-based object recognition in man, monkey and machine. - Cognition.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Animals,Artificial Intelligence,Depth Perception,Haplorhini,Humans,Mental Recall,Pattern Recognition, Visual,Psychophysics,Species Specificity},
month = jul,
number = {1-2},
pages = {1--20},
pmid = {9735534},
title = {{Image-based object recognition in man, monkey and machine.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9735534},
volume = {67},
year = {1998}
}
@article{Wilson2013,
author = {Wilson, Stephen},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wilson/Wilson - 1983 - Computer Art Artificial Intelligence and the Arts - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {1},
pages = {15--20},
title = {{Computer Art: Artificial Intelligence and the Arts}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Computer+Art:+Artificial+Intelligence+and+the+Arts\#0},
volume = {16},
year = {1983}
}
@article{Lyon2010,
author = {Lyon, R F and Rehn, M and Bengio, S and Walters, T C and Chechik, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lyon et al/Lyon et al. - 2010 - Sound retrieval and ranking using sparse auditory representations - Neural Computation.pdf:pdf},
journal = {Neural Computation},
number = {9},
title = {{Sound retrieval and ranking using sparse auditory representations}},
volume = {22},
year = {2010}
}
@article{Beer2004,
author = {Beer, Anton L. and Roder, Brigitte},
doi = {10.1016/j.cogbrainres.2003.10.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Beer, Roder/Beer, Roder - 2004 - Attention to motion enhances processing of both visual and auditory stimuli an event-related potential study - Cogn.pdf:pdf},
isbn = {4964212823917},
issn = {09266410},
journal = {Cognitive Brain Research},
keywords = {auditory motion,event-related potentials,selective attention,visual motion},
month = jan,
number = {2},
pages = {205--225},
title = {{Attention to motion enhances processing of both visual and auditory stimuli: an event-related potential study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926641003002507},
volume = {18},
year = {2004}
}
@inproceedings{Smaragdis2008,
author = {Smaragdis, P. and Raj, B. and Shashanka, M.},
booktitle = {Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Raj, Shashanka/Smaragdis, Raj, Shashanka - 2008 - Sparse and shift-invariant feature extraction from non-negative data - Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on.pdf:pdf},
issn = {1520-6149},
pages = {2069--2072},
publisher = {IEEE},
title = {{Sparse and shift-invariant feature extraction from non-negative data}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4518048},
year = {2008}
}
@inproceedings{Hofmann1999,
author = {Hofmann, Thomas},
booktitle = {Proc. of Uncertainty in Artificial Intelligence, UAI’99},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hofmann/Hofmann - 1999 - Probabilistic latent semantic analysis - Proc. of Uncertainty in Artificial Intelligence, UAI’99.pdf:pdf},
pages = {21},
publisher = {Citeseer},
title = {{Probabilistic latent semantic analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.1137\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@article{Hoiem2007,
author = {Hoiem, Derek and Stein, AN and Efros, Alexei A and Herbert, Martial},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hoiem et al/Hoiem et al. - 2007 - Recovering occlusion boundaries from a single image - Robotics Institute.pdf:pdf},
journal = {Robotics Institute},
title = {{Recovering occlusion boundaries from a single image}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4408985},
volume = {278},
year = {2007}
}
@book{Marr1982,
author = {Marr, David},
booktitle = {Inc., New York, NY},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marr/Marr - 1982 - Vision A Computational investigation into the Human Representation and Processing of Visual Information - Inc., New York,.pdf:pdf},
isbn = {9780262514620},
title = {{Vision: A Computational investigation into the Human Representation and Processing of Visual Information}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Vision:+A+Computational+Investigation+into+the+Human+Representation+and+Processing+of+Visual+Information\#0 http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Vision:+A+computational+investigation+into+the+human+representation+and+processing+of+visual+information,+Henry+Holt+and+Co\#0},
year = {1982}
}
@article{Wischnewski2010,
author = {Wischnewski, Marco and Belardinelli, Anna and Schneider, Werner X. and Steil, Jochen J.},
doi = {10.1007/s12559-010-9080-1},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wischnewski et al/Wischnewski et al. - 2010 - Where to Look Next Combining Static and Dynamic Proto-objects in a TVA-based Model of Visual Attention - Cog.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {control,dynamic features \'{a} inhomogeneity,modeling visual attention \'{a},natural scenes \'{a} top-down,objects \'{a} static and,tva \'{a} proto-,\'{a}},
month = nov,
number = {4},
pages = {326--343},
title = {{Where to Look Next? Combining Static and Dynamic Proto-objects in a TVA-based Model of Visual Attention}},
url = {http://www.springerlink.com/index/10.1007/s12559-010-9080-1},
volume = {2},
year = {2010}
}
@article{Leuba1994,
author = {Leuba, G. and Kraftsik, R.},
doi = {10.1007/BF00187293},
issn = {0340-2061},
journal = {Anatomy and Embryology},
month = oct,
number = {4},
title = {{Changes in volume, surface estimate, three-dimensional shape and total number of neurons of the human primary visual cortex from midgestation until old age}},
url = {http://link.springer.com/10.1007/BF00187293},
volume = {190},
year = {1994}
}
@article{Lim2009,
author = {Lim, Joseph J and Arbeláez, Pablo and Malik, Jitendra},
doi = {10.1109/ICCV.2009.5459436},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lim, Arbeláez, Malik/Lim, Arbeláez, Malik - 2009 - Context by region ancestry - 2009 IEEE 12th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {1978--1985},
publisher = {Ieee},
title = {{Context by region ancestry}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459436},
year = {2009}
}
@article{Ness2012,
author = {Ness, SR and Walters, Thomas and Lyon, RF},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ness, Walters, Lyon/Ness, Walters, Lyon - 2012 - Auditory Sparse Coding - Music data mining.pdf:pdf},
journal = {Music data mining},
pages = {3--20},
title = {{Auditory Sparse Coding}},
url = {http://books.google.com/books?hl=en\&lr=\&id=\_zc3vKDLUNIC\&oi=fnd\&pg=PA77\&dq=Auditory+Sparse+Coding\&ots=dTpXyD\_ZKJ\&sig=zrcZe1niLj6ncnlE\_4TTZuERt9w},
year = {2012}
}
@article{Buxton2003,
author = {Buxton, Hilary},
doi = {10.1016/S0262-8856(02)00127-0},
file = {:Users/pkmital/Documents/Mendeley Desktop/Buxton/Buxton - 2003 - Learning and understanding dynamic scene activity a review - Image and Vision Computing.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {cognitive computer vision,generative model,visual control,visual learning,visual reasoning},
month = jan,
number = {1},
pages = {125--136},
title = {{Learning and understanding dynamic scene activity: a review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885602001270},
volume = {21},
year = {2003}
}
@article{Shamma2001a,
author = {Shamma, Shihab},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shamma/Shamma - 2001 - On the role of space and time in auditory - Trends in Cognitive Sciences.pdf:pdf},
journal = {Trends in Cognitive Sciences},
number = {8},
pages = {340--348},
title = {{On the role of space and time in auditory}},
volume = {5},
year = {2001}
}
@article{Seeger2004,
abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
author = {Seeger, Matthias},
file = {:Users/pkmital/Documents/Mendeley Desktop/Seeger/Seeger - 2004 - Gaussian processes for machine learning. - International journal of neural systems.pdf:pdf},
issn = {0129-0657},
journal = {International journal of neural systems},
keywords = {Algorithms,Artificial Intelligence,Bayes Theorem,Entropy,Linear Models,Models, Statistical,Normal Distribution,Regression Analysis,Statistics, Nonparametric},
month = apr,
number = {2},
pages = {69--106},
pmid = {15112367},
title = {{Gaussian processes for machine learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15112367},
volume = {14},
year = {2004}
}
@article{Craft2007,
abstract = {Psychophysical studies suggest that figure-ground organization is a largely autonomous process that guides--and thus precedes--allocation of attention and object recognition. The discovery of border-ownership representation in single neurons of early visual cortex has confirmed this view. Recent theoretical studies have demonstrated that border-ownership assignment can be modeled as a process of self-organization by lateral interactions within V2 cortex. However, the mechanism proposed relies on propagation of signals through horizontal fibers, which would result in increasing delays of the border-ownership signal with increasing size of the visual stimulus, in contradiction with experimental findings. It also remains unclear how the resulting border-ownership representation would interact with attention mechanisms to guide further processing. Here we present a model of border-ownership coding based on dedicated neural circuits for contour grouping that produce border-ownership assignment and also provide handles for mechanisms of selective attention. The results are consistent with neurophysiological and psychophysical findings. The model makes predictions about the hypothetical grouping circuits and the role of feedback between cortical areas.},
author = {Craft, Edward and Sch\"{u}tze, Hartmut and Niebur, Ernst and von der Heydt, R\"{u}diger},
doi = {10.1152/jn.00203.2007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Craft et al/Craft et al. - 2007 - A neural model of figure-ground organization. - Journal of neurophysiology.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Animals,Attention,Attention: physiology,Depth Perception,Depth Perception: physiology,Feedback, Psychological,Humans,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Predictive Value of Tests,Reaction Time,Reaction Time: physiology,Visual Cortex,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: physiology},
month = jun,
number = {6},
pages = {4310--26},
pmid = {17442769},
title = {{A neural model of figure-ground organization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17442769},
volume = {97},
year = {2007}
}
@inproceedings{Nordahl2004,
abstract = {In this paper we describe the results of experiments whose goal is to investigate the effect of enhancing a virtual reality experience with the sound of synthetic footsteps.},
author = {Nordahl, Rolf},
booktitle = {Proceedings of the Eight Annual International Workshop Presence, London, UK},
file = {::},
pages = {5--6},
publisher = {Citeseer},
title = {{Self-induced footsteps sounds in virtual reality: Latency, recognition, quality and presence}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.8636\&amp;rep=rep1\&amp;type=pdf},
volume = {5},
year = {2004}
}
@article{Berg2009,
author = {Berg, David J and Boehnke, Susan E and Marino, Robert A and Munoz, Douglas P and Itti, Laurent},
doi = {10.1167/9.5.19.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Berg et al/Berg et al. - 2009 - Free viewing of dynamic stimuli by humans and monkeys - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,1167,15,19,2009,5,9,a,berg,boehnke,citation,computational model,d,doi,e,free viewing,free viewing of dynamic,http,humans and monkeys,itti,j,journal of vision,journalofvision,l,marino,monkeys,munoz,org,p,r,s,saccades,salience,stimuli by,visual attention},
pages = {1--15},
title = {{Free viewing of dynamic stimuli by humans and monkeys}},
volume = {9},
year = {2009}
}
@article{Hickey2009,
abstract = {Attentional selection of a target presented among distractors can be indexed with an event-related potential (ERP) component known as the N2pc. Theoretical interpretation of the N2pc has suggested that it reflects a fundamental mechanism of attention that shelters the cortical representation of targets by suppressing neural activity stemming from distractors. Results from fields other than human electrophysiology, however, suggest that attention does not act solely through distractor suppression; rather, it modulates the processing of both target and distractors. We conducted four ERP experiments designed to investigate whether the N2pc reflects multiple attentional mechanisms. Our goal was to reconcile ostensibly conflicting outcomes obtained in electrophysiological studies of attention with those obtained using other methodologies. Participants viewed visual search arrays containing one target and one distractor. In Experiments 1 through 3, the distractor was isoluminant with the background, and therefore, did not elicit early lateralized ERP activity. This work revealed a novel contralateral ERP component that appears to reflect direct suppression of the cortical representation of the distractor. We accordingly name this component the distractor positivity (P(D)). In Experiment 4, an ERP component associated with target processing was additionally isolated. We refer to this component as the target negativity (N(T)). We believe that the N2pc reflects the summation of the P(D) and N(T), and that these discrete components may have been confounded in earlier electrophysiological studies. Overall, this study demonstrates that attention acts on both target and distractor representations, and that this can be indexed in the visual ERP.},
author = {Hickey, Clayton and {Di Lollo}, Vincent and McDonald, John J},
doi = {10.1162/jocn.2009.21039},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hickey, Di Lollo, McDonald/Hickey, Di Lollo, McDonald - 2009 - Electrophysiological indices of target and distractor processing in visual search. - Journal of cognitive neuroscience.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Adolescent,Analysis of Variance,Attention,Attention: physiology,Brain Mapping,Color Perception,Color Perception: physiology,Contingent Negative Variation,Contingent Negative Variation: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Psychophysics,Reaction Time,Reaction Time: physiology,Young Adult},
month = apr,
number = {4},
pages = {760--75},
pmid = {18564048},
title = {{Electrophysiological indices of target and distractor processing in visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18564048},
volume = {21},
year = {2009}
}
@article{Rasolzadeh2009,
author = {Rasolzadeh, B. and Bjorkman, M. and Huebner, K. and Kragic, D.},
doi = {10.1177/0278364909346069},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasolzadeh et al/Rasolzadeh et al. - 2009 - An Active Vision System for Detecting, Fixating and Manipulating Objects in the Real World - The International Journal of Robotics Research.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
month = aug,
number = {2-3},
pages = {133--154},
title = {{An Active Vision System for Detecting, Fixating and Manipulating Objects in the Real World}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364909346069},
volume = {29},
year = {2009}
}
@inproceedings{Logan2000,
address = {Plymouth, MA},
author = {Logan, Beth},
booktitle = {Int. Symp. Music Info. Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Logan/Logan - 2000 - Mel Frequency Cepstral Coefficients for Music Modeling - Int. Symp. Music Info. Retrieval.pdf:pdf},
pages = {1--13},
title = {{Mel Frequency Cepstral Coefficients for Music Modeling}},
year = {2000}
}
@article{Shown2013,
author = {Shown, John},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shown/Shown - 1975 - An Approach to Collage - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {1},
pages = {55--57},
title = {{An Approach to Collage}},
url = {http://www.jstor.org/stable/10.2307/1573189},
volume = {8},
year = {1975}
}
@article{Senthilmurugan2011,
author = {Senthilmurugan, M and Latha, M and Malmurugan, N},
file = {:Users/pkmital/Documents/Mendeley Desktop/Senthilmurugan, Latha, Malmurugan/Senthilmurugan, Latha, Malmurugan - 2011 - Classification in EEG-Based Brain Computer Interfaces Using Inverse Model - International Jou.pdf:pdf},
journal = {International Journal of Computer Theory and Engineering},
number = {2},
pages = {274--276},
title = {{Classification in EEG-Based Brain Computer Interfaces Using Inverse Model}},
volume = {3},
year = {2011}
}
@article{Abdallah2006a,
author = {Abdallah, Samer and Sandler, Mark and Rhodes, Christophe and Casey, Michael},
doi = {10.1007/s10994-006-0586-4},
file = {::},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {duration prior,gibbs sampling,mcmc,segmentation,wolff},
month = nov,
number = {2-3},
pages = {485--515},
title = {{Using duration models to reduce fragmentation in audio segmentation}},
url = {http://www.springerlink.com/index/10.1007/s10994-006-0586-4},
volume = {65},
year = {2006}
}
@article{Riesenhuber2000,
abstract = {Understanding how biological visual systems recognize objects is one of the ultimate goals in computational neuroscience. From the computational viewpoint of learning, different recognition tasks, such as categorization and identification, are similar, representing different trade-offs between specificity and invariance. Thus, the different tasks do not require different classes of models. We briefly review some recent trends in computational vision and then focus on feedforward, view-based models that are supported by psychophysical and physiological data.},
author = {Riesenhuber, M and Poggio, T},
doi = {10.1038/81479},
file = {:Users/pkmital/Documents/Mendeley Desktop/Riesenhuber, Poggio/Riesenhuber, Poggio - 2000 - Models of object recognition. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Humans,Learning,Learning: physiology,Models, Neurological,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: cytology,Neurons: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Temporal Lobe,Temporal Lobe: anatomy \& histology,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology},
month = nov,
pages = {1199--204},
pmid = {11127838},
title = {{Models of object recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11127838},
volume = {3 Suppl},
year = {2000}
}
@article{Widmann2012,
author = {Widmann, Andreas and Schr\"{o}ger, Erich},
doi = {10.3389/fpsyg.2012.00233},
file = {:Users/pkmital/Documents/Mendeley Desktop/Widmann, Schr\"{o}ger/Widmann, Schr\"{o}ger - 2012 - Filter effects and filter artifacts in the analysis of electrophysiological data. - Frontiers in psychology.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
month = jan,
number = {July},
pages = {233},
pmid = {22787453},
title = {{Filter effects and filter artifacts in the analysis of electrophysiological data.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3391960\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@book{Cook2002,
abstract = {Virtual environments such as games and animated and "real" movies require realistic sound effects that can be integrated by computer synthesis. The book emphasizes physical modeling of sound and focuses on real-world interactive sound effects. It is intended for game developers, graphics programmers, developers of virtual reality systems and training simulators, and others who want to learn about computational sound. It is written at an introductory level with mathematical foundations provided in appendices. An enclosed CD contains code examples and sound files.},
author = {Cook, Perry},
isbn = {1568811683},
pages = {xvii, 263 p.},
publisher = {AK Peters, Ltd.},
title = {{Real Sound Synthesis for Interactive Applications}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1568811683},
year = {2002}
}
@article{Su2011,
author = {Su, F and Yang, L and Lu, Tong},
file = {:Users/pkmital/Documents/Mendeley Desktop/Su, Yang, Lu/Su, Yang, Lu - 2011 - Environmental sound classification for scene recognition using local discriminant bases and HMM - Proceedings of the 19th ACM international.pdf:pdf},
isbn = {9781450306164},
journal = {Proceedings of the 19th ACM international},
keywords = {area chair,auditory scene recognition,bernard merialdo,cal discriminant bases,environmental sound,hmm,lo-},
pages = {1389--1392},
title = {{Environmental sound classification for scene recognition using local discriminant bases and HMM}},
url = {http://dl.acm.org/citation.cfm?id=2072022},
year = {2011}
}
@article{Peterson2004,
abstract = {There is considerable evidence that covert visual attention precedes voluntary eye movements to an intended location. What happens to covert attention when an involuntary saccadic eye movement is made? In agreement with other researchers, we found that attention and voluntary eye movements are tightly coupled in such a way that attention always shifts to the intended location before the eyes begin to move. However, we found that when an involuntary eye movement is made, attention first precedes the eyes to the unintended location and then switches to the intended location, with the eyes following this pattern a short time later. These results support the notion that attention and saccade programming are tightly coupled.},
author = {Peterson, Matthew S and Kramer, Arthur F and Irwin, David E},
file = {:Users/pkmital/Documents/Mendeley Desktop/Peterson, Kramer, Irwin/Peterson, Kramer, Irwin - 2004 - Covert shifts of attention precede involuntary eye movements. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adult,Attention,Female,Humans,Male,Reaction Time,Saccades,Volition},
month = apr,
number = {3},
pages = {398--405},
pmid = {15283065},
title = {{Covert shifts of attention precede involuntary eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15283065},
volume = {66},
year = {2004}
}
@article{Kliegl2004,
author = {Kliegl, Reinhold and Grabner, Ellen and Rolfs, Martin and Engbert, Ralf},
doi = {10.1080/09541440340000213},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kliegl et al/Kliegl et al. - 2004 - Length, frequency, and predictability effects of words on eye movements in reading - European Journal of Cognitive Psychology.pdf:pdf},
issn = {0954-1446},
journal = {European Journal of Cognitive Psychology},
month = jan,
number = {1-2},
pages = {262--284},
title = {{Length, frequency, and predictability effects of words on eye movements in reading}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09541440340000213\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2004}
}
@article{Henderson1997,
author = {Henderson, John M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson/Henderson - 1997 - Research Article TRANSSACCADIC MEMORY AND INTEGRATION DURING REAL-WORLD OBJECT PERCEPTION - East.pdf:pdf},
journal = {East},
number = {1},
pages = {51--56},
title = {{Research Article TRANSSACCADIC MEMORY AND INTEGRATION DURING REAL-WORLD OBJECT PERCEPTION}},
volume = {8},
year = {1997}
}
@article{Sussman1999,
abstract = {We recorded event-related brain potentials (ERPs) to two different infrequent deviant tones presented successively within the repetitive sequence of a standard tone. A separate mismatch negativity (MMN) component was elicited by each of the two deviants when the interval separating their onsets was 300 ms. However, only a single MMN component was elicited when the temporal separation between the onsets of the two deviants was 150 ms. Previous studies obtained similar results using two temporally separated deviations carried by a single sound. Taken together, these results support the notion of a general temporal integration mechanism in the formation of auditory events with ca. 200 ms long window.},
author = {Sussman, E and Winkler, I and Ritter, W and Alho, K and N\"{a}\"{a}t\"{a}nen, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman et al/Sussman et al. - 1999 - Temporal integration of auditory stimulus deviance as reflected by the mismatch negativity. - Neuroscience lette.pdf:pdf},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Time Factors},
month = apr,
number = {1-3},
pages = {161--4},
pmid = {10320039},
title = {{Temporal integration of auditory stimulus deviance as reflected by the mismatch negativity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10320039},
volume = {264},
year = {1999}
}
@article{Harding2007,
author = {Harding, Sue and Cooke, Martin and K\"{o}nig, P.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Harding, Cooke, K\"{o}nig/Harding, Cooke, K\"{o}nig - 2007 - Auditory gist perception an alternative to attentional selection of auditory streams - Attention in Cogn.pdf:pdf},
journal = {Attention in Cognitive Systems. Theories and Systems from an Interdisciplinary Viewpoint},
keywords = {attention,auditory scene analysis,gist perception},
pages = {399--416},
publisher = {Springer},
title = {{Auditory gist perception: an alternative to attentional selection of auditory streams?}},
url = {http://www.springerlink.com/index/R76603201224P3KW.pdf},
year = {2007}
}
@article{Koldovsky2008,
author = {Koldovsky, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Koldovsky/Koldovsky - 2008 - Time-domain blind audio source separation using advanced component clustering and reconstruction - Hands-Free Speech.pdf:pdf},
journal = {Hands-Free Speech},
number = {2},
pages = {3--6},
title = {{Time-domain blind audio source separation using advanced component clustering and reconstruction}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4538725},
year = {2008}
}
@article{Pham2006,
author = {Pham, T V and Smeulders, A},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {4},
pages = {555--567},
title = {{Sparse Representation for Coarse and Fine Object Recognition}},
volume = {28},
year = {2006}
}
@book{Wiener1948,
author = {Wiener, Norbert},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wiener/Wiener - 1948 - Cybernetics or control and communication in the animal and the machine. - Unknown.pdf:pdf},
isbn = {0262230070},
title = {{Cybernetics; or control and communication in the animal and the machine.}},
url = {http://psycnet.apa.org/psycinfo/1949-02471-000},
year = {1948}
}
@article{Pieszek2013,
abstract = {Computational and experimental research has revealed that auditory sensory predictions are derived from regularities of the current environment by using internal generative models. However, so far, what has not been addressed is how the auditory system handles situations giving rise to redundant or even contradictory predictions derived from different sources of information. To this end, we measured error signals in the event-related brain potentials (ERPs) in response to violations of auditory predictions. Sounds could be predicted on the basis of overall probability, i.e., one sound was presented frequently and another sound rarely. Furthermore, each sound was predicted by an informative visual cue. Participants' task was to use the cue and to discriminate the two sounds as fast as possible. Violations of the probability based prediction (i.e., a rare sound) as well as violations of the visual-auditory prediction (i.e., an incongruent sound) elicited error signals in the ERPs (Mismatch Negativity [MMN] and Incongruency Response [IR]). Particular error signals were observed even in case the overall probability and the visual symbol predicted different sounds. That is, the auditory system concurrently maintains and tests contradictory predictions. Moreover, if the same sound was predicted, we observed an additive error signal (scalp potential and primary current density) equaling the sum of the specific error signals. Thus, the auditory system maintains and tolerates functionally independently represented redundant and contradictory predictions. We argue that the auditory system exploits all currently active regularities in order to optimally prepare for future events.},
author = {Pieszek, Marika and Widmann, Andreas and Gruber, Thomas and Schr\"{o}ger, Erich},
doi = {10.1371/journal.pone.0053634},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pieszek et al/Pieszek et al. - 2013 - The human brain maintains contradictory and redundant auditory sensory predictions. - PloS one.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Acoustic Stimulation,Adult,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Cues,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Photic Stimulation,Reaction Time,Sound},
month = jan,
number = {1},
pages = {e53634},
pmid = {23308266},
title = {{The human brain maintains contradictory and redundant auditory sensory predictions.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3538730\&tool=pmcentrez\&rendertype=abstract},
volume = {8},
year = {2013}
}
@article{Kimurab,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - Unknown - Multiterminal source coding with complementary delivery - arXiv preprint arXiv0804.1602.pdf:pdf},
journal = {arXiv preprint arXiv:0804.1602},
keywords = {complementary deliv-,ery,joint encoding,multiterminal source coding,separate decoding},
number = {xx},
pages = {1--13},
title = {{Multiterminal source coding with complementary delivery}},
url = {http://arxiv.org/abs/0804.1602},
year = {2008}
}
@article{Verron2010,
author = {Verron, Charles},
title = {{Synth\`{e}se immersive de sons d ’ environnement}},
year = {2010}
}
@article{Blake2001,
author = {Blake, Andrew and Romdhani, Sami and Torr, Philip and Sch, Bernhard},
file = {:Users/pkmital/Documents/Mendeley Desktop/Blake et al/Blake et al. - 2001 - Computationally Efficient Face Detection 1 Introduction 3 Reduced Set Vectors 2 Non-linear Support Vector Ma- chines - Training.pdf:pdf},
journal = {Training},
title = {{Computationally Efficient Face Detection 1 Introduction 3 Reduced Set Vectors 2 Non-linear Support Vector Ma- chines}},
year = {2001}
}
@article{Hooge2005,
abstract = {The ability to search and scan the environment effectively is a prerequisite for spatial behavior. A longstanding theory proposes that inhibition of previously attended loci (Inhibition of return; IOR) serves to facilitate exploration by increasing the likelihood to inspect new areas instead of returning to locations that have been inspected before. In this eye movement study we tested whether we could find evidence in favor of this hypothesis. Here we report that IOR does occur during search and free viewing, because we found increased fixation times preceding return saccades (eye movements that return to previously fixated locations). Meanwhile we observed no influence of IOR on the search strategy. Rather than the predicted low number we found many return saccades. Therefore, IOR does not serve as a foraging facilitator in saccadic search and free viewing. We hypothesize that IOR is an intrinsic aspect of shifting attention and gaze direction and furthermore that it is not always advantageous to prevent return saccades.},
author = {Hooge, Ignace Th C and Over, Eelco a B and van Wezel, Richard J a and Frens, Maarten a},
doi = {10.1016/j.visres.2005.01.030},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hooge et al/Hooge et al. - 2005 - Inhibition of return is not a foraging facilitator in saccadic search and free viewing. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Attention: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Inhibition (Psychology),Male,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {14},
pages = {1901--8},
pmid = {15797779},
title = {{Inhibition of return is not a foraging facilitator in saccadic search and free viewing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15797779},
volume = {45},
year = {2005}
}
@article{Cardillo2010,
author = {Cardillo, Daniela and Rapp, Amon and Benini, Sergio and Console, Luca and Simeoni, Rossana and Guercio, Elena and Leonardi, Riccardo},
doi = {10.1007/s11042-009-0449-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cardillo et al/Cardillo et al. - 2010 - The art of video MashUp supporting creative users with an innovative and smart application - Multimedia Tools a.pdf:pdf},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
month = feb,
number = {1},
pages = {1--23},
title = {{The art of video MashUp: supporting creative users with an innovative and smart application}},
url = {http://link.springer.com/10.1007/s11042-009-0449-7},
volume = {53},
year = {2010}
}
@article{Dong2009,
author = {Dong, Weiming and Zhou, Ning and Paul, Jean-Claude},
doi = {10.1109/PMA.2009.50},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dong, Zhou, Paul/Dong, Zhou, Paul - 2009 - Interactive Example-Based Natural Scene Synthesis - 2009 Third International Symposium on Plant Growth Modeling, Simulation, Visualization and Applications.pdf:pdf},
isbn = {978-1-4244-6329-9},
journal = {2009 Third International Symposium on Plant Growth Modeling, Simulation, Visualization and Applications},
month = nov,
pages = {409--416},
publisher = {Ieee},
title = {{Interactive Example-Based Natural Scene Synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5474659},
year = {2009}
}
@article{Biederman1987,
abstract = {The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric compo- nents, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensional image: curvature, collinearity, symmetry, parallelism, and cotermmation. The detection of these properties is generally invariant over viewing position and image quality and conse- quently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Repre- sentational power derives from an allowance of free combinations of the geons. A Principle of Com- ponential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory.},
author = {Biederman, I},
file = {:Users/pkmital/Documents/Mendeley Desktop/Biederman/Biederman - 1987 - Recognition-by-components a theory of human image understanding. - Psychological Review.pdf:pdf},
institution = {SUNYBuf},
journal = {Psychological Review},
keywords = {attention,concept formation,discrimination learning,form perception,humans,orientation,pattern recognition,visual},
number = {2},
pages = {115--147},
pmid = {3575582},
publisher = {American Psychological Association},
title = {{Recognition-by-components: a theory of human image understanding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3575582},
volume = {94},
year = {1987}
}
@article{Bacon1999,
abstract = {In Siamese cats, a genetically determined massive misrouting of retinal ganglion cells toward the contralateral hemisphere, as well as an accompanying strabismus, is believed to underlie the extreme paucity of binocular cells in the primary visual cortex. However, binocular cells have been shown to be present in more important numbers at the collicular level. The present study aims at investigating binocular interactions and sensitivity to spatial disparity in the superior colliculus of the Siamese cat. The activity of single units was recorded in the superficial layers of paralyzed and anesthetized Siamese cats. Although most collicular cells were monocularly driven, a significant proportion could be driven through both eyes (34/216 or 16\%). Upon isolation of a binocular cell, the receptive fields were separated, then simultaneously stimulated with two light bars. A temporal delay was introduced between the arrival of the bars in the receptive fields to generate spatial disparities (-3 degrees to +3 degrees, in 0.5 degrees or 1 degree steps). Results showed that some binocular cells presented disparity tuning profiles similar to the tuned excitatory (12/34), tuned inhibitory (2/34), near (2/34) and far (3/34) cells found at various cortical levels in the normal cat. These interactions might allow for coarse binocular fusion as well as play a role in the initiation of vergence and the fixation of the eyes upon the appropriate plane of vision.},
author = {Bacon, B a and Lepore, F and Guillemot, J P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bacon, Lepore, Guillemot/Bacon, Lepore, Guillemot - 1999 - Binocular interactions and spatial disparity sensitivity in the superior colliculus of the Siamese cat. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Animals,Cats,Depth Perception,Depth Perception: genetics,Electrophysiology,Fixation, Ocular,Fixation, Ocular: physiology,Functional Laterality,Functional Laterality: genetics,Mutation,Neurons, Afferent,Neurons, Afferent: physiology,Strabismus,Strabismus: genetics,Superior Colliculi,Superior Colliculi: cytology,Superior Colliculi: physiology,Vision, Binocular,Vision, Binocular: genetics,Visual Pathways,Visual Pathways: cytology},
month = jan,
number = {2},
pages = {181--92},
pmid = {9928841},
title = {{Binocular interactions and spatial disparity sensitivity in the superior colliculus of the Siamese cat.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9928841},
volume = {124},
year = {1999}
}
@article{Kalogerakis2012,
author = {Kalogerakis, Evangelos and Chaudhuri, Siddhartha and Koller, Daphne and Koltun, Vladlen},
doi = {10.1145/2185520.2185551},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalogerakis et al/Kalogerakis et al. - 2012 - A probabilistic model for component-based shape synthesis - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {cal models,data-driven 3d modeling,machine learning,probabilistic graphi-,shape structure,shape synthesis,shape synthesis, shape structure, probabilistic gr},
month = jul,
number = {4},
pages = {1--11},
title = {{A probabilistic model for component-based shape synthesis}},
url = {http://dl.acm.org/citation.cfm?doid=2185520.2185551},
volume = {31},
year = {2012}
}
@misc{Mital2011a,
author = {Mital, Parag K},
booktitle = {(iPhone App)},
title = {{Memory Mosaic}},
url = {http://itunes.apple.com/us/app/memory-mosaic/id475759669},
year = {2011}
}
@article{Horvath2007,
abstract = {Integration of information across time is an essential part of auditory processing. Evidence from a variety of experiments support the notion of an approximately 200-ms long time window following the onset of a sound, during which a unitary sound representation is formed (the temporal window of integration, TWI). The temporal resolution in the auditory system is assumed to decrease with aging suggesting that the duration of the TWI may be longer in elderly than young adults. The TWI duration was assessed in young and elderly adults using the oddball paradigm in which a regular auditory event (standard) is occasionally exchanged for a different event (deviant). Previous studies showed that when the stimulus onset asynchrony (SOA) exceeds the duration of the TWI, two successive deviations occurring infrequently in a repetitive sound sequence elicit two separate mismatch negativity (MMN) event-related brain potentials. However, only one MMN is elicited when the SOA is shorter than the TWI. Experiment 1 tested MMN elicitation for the second of two successive deviant sounds as a function of the SOA. Experiment 2 used the sound omission paradigm, in which MMN is only elicited by omissions when the SOA is shorter than the TWI. Again, MMN elicitation was tested by infrequent tone omissions as a function of the SOA. Results showed no significant differences between elderly and younger participants as a function of SOA. This suggests that the duration of the TWI is approximately between 200 and 250 ms in both groups of subjects. On the other hand, the lower MMN amplitudes elicited by frequency deviation in the elderly compared with the younger participants suggest that the specificity of frequency representation deteriorates with aging.},
author = {Horv\'{a}th, J\'{a}nos and Czigler, Istv\'{a}n and Winkler, Istv\'{a}n and Teder-S\"{a}lej\"{a}rvi, Wolfgang A},
doi = {10.1016/j.neurobiolaging.2006.05.002},
issn = {1558-1497},
journal = {Neurobiology of aging},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Age Factors,Aged,Aging,Aging: physiology,Analysis of Variance,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Contingent Negative Variation,Contingent Negative Variation: physiology,Dose-Response Relationship, Radiation,Electroencephalography,Electroencephalography: methods,Female,Functional Laterality,Humans,Male,Mental Processes,Mental Processes: physiology,Middle Aged,Reaction Time,Reaction Time: physiology},
month = jun,
number = {6},
pages = {964--75},
pmid = {16793177},
title = {{The temporal window of integration in elderly and young adults.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16793177},
volume = {28},
year = {2007}
}
@article{Theeuwes1998,
author = {Theeuwes, J. and Kramer, a. F. and Hahn, S. and Irwin, D. E.},
doi = {10.1111/1467-9280.00071},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theeuwes et al/Theeuwes et al. - 1998 - Our Eyes do Not Always Go Where we Want Them to Go Capture of the Eyes by New Objects - Psychological Science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = sep,
number = {5},
pages = {379--385},
title = {{Our Eyes do Not Always Go Where we Want Them to Go: Capture of the Eyes by New Objects}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.00071},
volume = {9},
year = {1998}
}
@article{Cowling2003a,
abstract = {This paper presents a comprehensive comparative study of artificial neural networks, learning vector quantization and dynamic time warping classification techniques combined with stationary/non-stationary feature extraction for environmental sound recognition. Results show 70\% recognition using mel frequency cepstral coefficients or continuous wavelet transform with dynamic time warping. (C) 2003 Elsevier B.V. All rights reserved.},
author = {Cowling, M and Sitte, Renate},
doi = {10.1016/S0167-8655(03)00147-8},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {acoustic signal processing,audio signal processing,environmental sound recognition,joint time frequency feature extraction,non speech sound recognition},
number = {15},
pages = {2895--2907},
pmid = {184859600038},
publisher = {Elsevier Science Inc.},
title = {{Comparison of techniques for environmental sound recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503001478},
volume = {24},
year = {2003}
}
@article{Fougnie2012,
abstract = {Working memory is a mental storage system that keeps task-relevant information accessible for a brief span of time, and it is strikingly limited. Its limits differ substantially across people but are assumed to be fixed for a given person. Here we show that there is substantial variability in the quality of working memory representations within an individual. This variability can be explained neither by fluctuations in attention or arousal over time, nor by uneven distribution of a limited mental commodity. Variability of this sort is inconsistent with the assumptions of the standard cognitive models of working memory capacity, including both slot- and resource-based models, and so we propose a new framework for understanding the limitations of working memory: a stochastic process of degradation that plays out independently across memories.},
author = {Fougnie, Daryl and Suchow, Jordan W and Alvarez, George a},
doi = {10.1038/ncomms2237},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fougnie, Suchow, Alvarez/Fougnie, Suchow, Alvarez - 2012 - Variability in the quality of visual working memory. - Nature communications.pdf:pdf},
issn = {2041-1723},
journal = {Nature communications},
keywords = {Adolescent,Adult,Attention,Humans,Memory, Short-Term,Models, Psychological,Photic Stimulation,Signal Detection, Psychological,Visual Perception,Young Adult},
month = jan,
pages = {1229},
pmid = {23187629},
title = {{Variability in the quality of visual working memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3563332\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@article{Kennedy2005,
abstract = {A corpus of eye movement data derived from 10 English and 10 French participants, each reading about 50,000 words, was examined for evidence that properties of a word in parafoveal vision have an immediate effect on foveal inspection time. When inspecting a short word, there is evidence that the lexical frequency of an adjacent word affects processing time. When inspecting a long word, there are small effects of lexical frequency, but larger effects of initial-letter constraint and orthographic familiarity. Interactions of this kind are incompatible with models of reading which appeal to the operation of a serial attention switch.},
author = {Kennedy, Alan and Pynte, Jo\"{e}l},
doi = {10.1016/j.visres.2004.07.037},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kennedy, Pynte/Kennedy, Pynte - 2005 - Parafoveal-on-foveal effects in normal reading. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Attention: physiology,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Fovea Centralis,Fovea Centralis: physiology,Humans,Language,Models, Psychological,Pattern Recognition, Visual,Reading,Semantics,Time Factors},
month = jan,
number = {2},
pages = {153--68},
pmid = {15581917},
title = {{Parafoveal-on-foveal effects in normal reading.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15581917},
volume = {45},
year = {2005}
}
@article{Zhaoping2006,
author = {Zhaoping, Li and Dayan, Peter},
doi = {10.1016/j.neunet.2006.09.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhaoping, Dayan/Zhaoping, Dayan - 2006 - Pre-attentive visual selection. - Neural networks the official journal of the International Neural Network Society.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Attention,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Photic Stimulation,Photic Stimulation: methods,Psychological Tests,Visual Perception,Visual Perception: physiology},
month = nov,
number = {9},
pages = {1437--9},
pmid = {17070011},
title = {{Pre-attentive visual selection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17070011},
volume = {19},
year = {2006}
}
@article{Henderson1992,
abstract = {Two object-naming experiments explored the influence of extrafoveal preview information and flanker object context on transsaccadic object identification. Both the presence of an extrafoveal preview of the target object and the contextual constraint provided by extrafoveal flanker objects were found to influence the speed of object identification, but the latter effect occurred only when an extrafoveal preview of the target object was not presented prior to fixation. The context effect was found to be due to facilitation from related flankers rather than inhibition from unrelated flankers. No evidence was obtained for the hypothesis that constraining context can increase the usefulness of an extrafoveal preview of a to-be-fixated object.},
author = {Henderson, J M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson/Henderson - 1992 - Identifying objects across saccades effects of extrafoveal preview and flanker object context. - Journal of experimental psychology. Learning, memory, and cognition.pdf:pdf},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Adult,Attention,Fixation, Ocular,Humans,Pattern Recognition, Visual,Reaction Time,Saccades,Visual Fields},
month = may,
number = {3},
pages = {521--30},
pmid = {1534353},
title = {{Identifying objects across saccades: effects of extrafoveal preview and flanker object context.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1534353},
volume = {18},
year = {1992}
}
@article{Kliegl2007a,
author = {Kliegl, Reinhold},
doi = {10.1037/0096-3445.136.3.530},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kliegl/Kliegl - 2007 - Toward a perceptual-span theory of distributed processing in reading A reply to Rayner, Pollatsek, Drieghe, Slattery, and Reichle (2007). - Journal of Experimental Psychology General.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {0096-3445,10,1037,136,1998,3,530,contributed much knowledge about,doi,dx,eye movements,eye movements in reading,fixation duration,for,http,org,rayner and colleagues have,reading,see rayner,skipping,supp,supplemental materials,with experiments},
number = {3},
pages = {530--537},
title = {{Toward a perceptual-span theory of distributed processing in reading: A reply to Rayner, Pollatsek, Drieghe, Slattery, and Reichle (2007).}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.136.3.530},
volume = {136},
year = {2007}
}
@article{Green2011,
author = {Green, Owen},
doi = {10.1017/S1355771811000082},
file = {:Users/pkmital/Documents/Mendeley Desktop/Green/Green - 2011 - Agility and Playfulness Technology and skill in the performance ecosystem - Organised Sound.pdf:pdf},
isbn = {1355771811},
issn = {1355-7718},
journal = {Organised Sound},
month = jun,
number = {02},
pages = {134--144},
title = {{Agility and Playfulness: Technology and skill in the performance ecosystem}},
url = {http://www.journals.cambridge.org/abstract\_S1355771811000082},
volume = {16},
year = {2011}
}
@article{Souto2008,
author = {Souto, David and Kerzel, Dirk},
doi = {10.1167/8.14.3.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Souto, Kerzel/Souto, Kerzel - 2008 - Dynamics of attention during the initiation of smooth pursuit eye movements - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,1167,14,16,2008,3,8,attention,catch-up saccades,citation,covert and overt,d,doi,dynamics of attention during,endogenous and exogenous attention,http,journal of vision,journalofvision,kerzel,open-loop smooth pursuit,org,pursuit eye movements,smooth pursuit eye movements,souto,the initiation of smooth},
pages = {1--16},
title = {{Dynamics of attention during the initiation of smooth pursuit eye movements}},
volume = {8},
year = {2008}
}
@article{Naatanen2001a,
abstract = {The everyday auditory environment consists of multiple simultaneously active sources with overlapping temporal and spectral acoustic properties. Despite the seemingly chaotic composite signal impinging on our ears, the resulting perception is of an orderly "auditory scene" that is organized according to sources and auditory events, allowing us to select messages easily, recognize familiar sound patterns, and distinguish deviant or novel ones. Recent data suggest that these perceptual achievements are mainly based on processes of a cognitive nature ("sensory intelligence") in the auditory cortex. Even higher cognitive processes than previously thought, such as those that organize the auditory input, extract the common invariant patterns shared by a number of acoustically varying sounds, or anticipate the auditory events of the immediate future, occur at the level of sensory cortex (even when attention is not directed towards the sensory input).},
author = {N\"{a}\"{a}t\"{a}nen, R and Tervaniemi, M and Sussman, E and Paavilainen, P and Winkler, I},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen et al/N\"{a}\"{a}t\"{a}nen et al. - 2001 - Primitive intelligence in the auditory cortex. - Trends in neurosciences(2).pdf:pdf},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Humans,Intelligence,Intelligence: physiology},
month = may,
number = {5},
pages = {283--8},
pmid = {11311381},
title = {{"Primitive intelligence" in the auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11311381},
volume = {24},
year = {2001}
}
@article{Carmi2006,
abstract = {What are the visual causes, rather than mere correlates, of attentional selection and how do they compare to each other during natural vision? To address these questions, we first strung together semantically unrelated dynamic scenes into MTV-style video clips, and performed eye tracking experiments with human observers. We then quantified predictions of saccade target selection based on seven bottom-up models, including intensity variance, orientation contrast, intensity contrast, color contrast, flicker contrast, motion contrast, and integrated saliency. On average, all tested models predicted saccade target selection well above chance. Dynamic models were particularly predictive of saccades that were most likely bottom-up driven-initiated shortly after scene onsets, leading to maximal inter-observer similarity. Static models showed mixed results in these circumstances, with intensity variance and orientation contrast featuring particularly weak prediction accuracy (lower than their own average, and approximately 4 times lower than dynamic models). These results indicate that dynamic visual cues play a dominant causal role in attracting attention. In comparison, some static visual cues play a weaker causal role, while other static cues are not causal at all, and may instead reflect top-down causes.},
author = {Carmi, Ran and Itti, Laurent},
doi = {10.1016/j.visres.2006.08.019},
file = {:Users/pkmital/Documents/Mendeley Desktop/Carmi, Itti/Carmi, Itti - 2006 - Visual causes versus correlates of attentional selection in dynamic scenes. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Cues,Female,Humans,Male,Models, Psychological,Motion Perception,Motion Perception: physiology,Observer Variation,Saccades,Saccades: physiology,Video Recording},
month = dec,
number = {26},
pages = {4333--45},
pmid = {17052740},
title = {{Visual causes versus correlates of attentional selection in dynamic scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17052740},
volume = {46},
year = {2006}
}
@article{Levin2012,
author = {Levin, Daniel T and Hymel, Alicia M and Baker, Lewis},
file = {:Users/pkmital/Documents/Mendeley Desktop/Levin, Hymel, Baker/Levin, Hymel, Baker - 2012 - Belief, Desire, Action and Other Stuff Theory of Mind in Movies - Unknown.pdf:pdf},
pages = {244--266},
title = {{Belief, Desire, Action and Other Stuff: Theory of Mind in Movies}},
year = {2012}
}
@article{Orchard2008,
author = {Orchard, Jeff and Kaplan, CS},
file = {:Users/pkmital/Documents/Mendeley Desktop/Orchard, Kaplan/Orchard, Kaplan - 2008 - Cut-out image mosaics - ACM Transactions on Graphics.pdf:pdf},
isbn = {9781605581507},
journal = {ACM Transactions on Graphics},
keywords = {image mosaic,least-,non-photorealistic,registration},
number = {212},
title = {{Cut-out image mosaics}},
url = {http://dl.acm.org/citation.cfm?id=1377997},
volume = {1},
year = {2008}
}
@article{Horowitz2007,
abstract = {The debate about the nature of fixational eye movements has revived recently with the claim that microsaccades reflect the direction of attentional shifts. A number of studies have shown an association between the direction of attentional cues and the direction of microsaccades. We sought to determine whether microsaccades in attentional tasks are causally related to behavior. Is reaction time (RT) faster when microsaccades point toward the target than when they point in the opposite direction? We used a dual-Purkinje-image eyetracker to measure gaze position while 3 observers (2 of the authors, 1 naive observer) performed an attentional cuing task under three different response conditions: saccadic localization, manual localization, and manual detection. Critical trials were those on which microsaccades moved away from the cue. On these trials, RTs were slower when microsaccades were oriented toward the target than when they were oriented away from the target. We obtained similar results for direction of drift. Cues, not fixational eye movements, predicted behavior.},
author = {Horowitz, Todd S and Fine, Elisabeth M and Fencsik, David E and Yurgenson, Sergey and Wolfe, Jeremy M},
doi = {10.1111/j.1467-9280.2007.01903.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Horowitz et al/Horowitz et al. - 2007 - Fixational eye movements are not an index of covert attention. - Psychological science a journal of the Americ.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science : a journal of the American Psychological Society / APS},
keywords = {Adult,Attention,Cues,Eye Movements,Female,Fixation, Ocular,Humans,Male},
month = apr,
number = {4},
pages = {356--63},
pmid = {17470262},
title = {{Fixational eye movements are not an index of covert attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17470262},
volume = {18},
year = {2007}
}
@phdthesis{Grierson2005,
author = {Grierson, Mick},
file = {:Users/pkmital/Documents/Mendeley Desktop/Grierson/Grierson - 2005 - Audiovisual Composition - Unknown.pdf:pdf},
pages = {1--145},
school = {University of Kent},
title = {{Audiovisual Composition}},
year = {2005}
}
@article{Blei,
author = {Blei, David M and Jordan, Michael I and Griffiths, Thomas L and Tenenbaum, Joshua B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Blei et al/Blei et al. - Unknown - Hierarchical Topic Models and the Nested Chinese Restaurant Process - Communication.pdf:pdf},
journal = {Communication},
title = {{Hierarchical Topic Models and the Nested Chinese Restaurant Process}}
}
@article{Ude,
author = {Ude, a. and Gaskett, C. and Cheng, G.},
doi = {10.1109/IROS.2004.1389429},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ude, Gaskett, Cheng/Ude, Gaskett, Cheng - Unknown - Support vector machines and gabor kernels for object recognition on a humanoid with active foveated visi.pdf:pdf},
isbn = {0-7803-8463-6},
journal = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
pages = {668--673},
publisher = {Ieee},
title = {{Support vector machines and gabor kernels for object recognition on a humanoid with active foveated vision}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1389429},
volume = {1}
}
@article{Trappenberg2001,
abstract = {Significant advances in cognitive neuroscience can be achieved by combining techniques used to measure behavior and brain activity with neural modeling. Here we apply this approach to the initiation of rapid eye movements (saccades), which are used to redirect the visual axis to targets of interest. It is well known that the superior colliculus (SC) in the midbrain plays a major role in generating saccadic eye movements, and physiological studies have provided important knowledge of the activity pattern of neurons in this structure. Based on the observation that the SC receives localized sensory (exogenous) and voluntary (endogenous) inputs, our model assumes that this information is integrated by dynamic competition across local collicular interactions. The model accounts well for the effects upon saccadic reaction time (SRT) due to removal of fixation, the presence of distractors, execution of pro- versus antisaccades, and variation in target probability, and suggests a possible mechanism for the generation of express saccades. In each of these cases, the activity patterns of "neurons" within the model closely resemble actual cell behavior in the intermediate layer of the SC. The interaction structure we employ is instrumental for producing a physiologically faithful model and results in new insights and hypotheses regarding the neural mechanisms underlying saccade initiation.},
author = {Trappenberg, T P and Dorris, M C and Munoz, D P and Klein, R M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Trappenberg et al/Trappenberg et al. - 2001 - A model of saccade initiation based on the competitive integration of exogenous and endogenous signals in th.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Humans,Models, Neurological,Neurons,Neurons: physiology,Saccades,Saccades: physiology,Superior Colliculi,Superior Colliculi: cytology,Superior Colliculi: physiology},
month = feb,
number = {2},
pages = {256--71},
pmid = {11244550},
title = {{A model of saccade initiation based on the competitive integration of exogenous and endogenous signals in the superior colliculus.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11244550},
volume = {13},
year = {2001}
}
@article{Wrigley2000,
author = {Wrigley, S.N. and Brown, GJ},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wrigley, Brown/Wrigley, Brown - 2000 - A model of auditory attention - University of Sheffield, Tech. Rep.pdf:pdf},
journal = {University of Sheffield, Tech. Rep},
number = {June},
publisher = {Citeseer},
title = {{A model of auditory attention}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.6714\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@article{Hachet2008a,
author = {Hachet, M and Kitamura, Y},
file = {::},
journal = {Science},
pages = {1--4},
title = {{3D interaction with and from handheld computers}},
url = {http://www.recolecta.net/buscador/single\_page.jsp?id=oai:hal.archives-ouvertes.fr:hal-00308241\_v1},
year = {2008}
}
@article{Turatto2000,
abstract = {Extant models of visual attention predict that a salient element should produce a bottom-up activation leading to a stimulus-driven attentional capture (e.g. Cave, 1999). However, apart from onset, previous works manipulating set-size in visual search failed to provide empirical evidence for this kind of capture. By varying target-singelton distance method, based on a single set-size, we explored whether, in a serial search task, an attentional capture is triggered by static discontinuities such as those generated through the manipulation of color, form, and luminance. The results suggest that those physical properties are indeed able to capture attention automatically.},
author = {Turatto, M and Galfano, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Turatto, Galfano/Turatto, Galfano - 2000 - Color, form and luminance capture attention in visual search. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Form Perception,Form Perception: physiology,Humans,Lighting,Photic Stimulation,Sample Size},
month = jan,
number = {13},
pages = {1639--43},
pmid = {10814751},
title = {{Color, form and luminance capture attention in visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10814751},
volume = {40},
year = {2000}
}
@article{Kimura2007a,
author = {Kimura, Akisato and Uyematsu, Tomohiko and Kuzuoka, Shigeaki},
doi = {10.1109/ISIT.2007.4557475},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Kuzuoka/Kimura, Uyematsu, Kuzuoka - 2007 - Universal coding for correlated sources with complementary delivery - 2007 IEEE International Symposi.pdf:pdf},
isbn = {978-1-4244-1397-3},
journal = {2007 IEEE International Symposium on Information Theory},
month = jun,
pages = {1756--1760},
publisher = {Ieee},
title = {{Universal coding for correlated sources with complementary delivery}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557475},
year = {2007}
}
@article{Kimura2010a,
abstract = {Our brain recordings reveal that large-scale sequential regularities defined across non-adjacent stimuli can be automatically represented in visual sensory memory. To show that, we adopted an auditory paradigm developed by Sussman, E., Ritter, W., and Vaughan, H. G. Jr. (1998). Predictability of stimulus deviance and the mismatch negativity. NeuroReport, 9, 4167-4170, Sussman, E., and Gumenyuk, V. (2005). Organization of sequential sounds in auditory memory. NeuroReport, 16, 1519-1523 to the visual domain by presenting task-irrelevant infrequent luminance-deviant stimuli (D, 20\%) inserted among task-irrelevant frequent stimuli being of standard luminance (S, 80\%) in randomized (randomized condition, SSSDSSSSSDSSSSD...) and fixed manners (fixed condition, SSSSDSSSSDSSSSD...). Comparing the visual mismatch negativity (visual MMN), an event-related brain potential (ERP) index of memory-mismatch processes in human visual sensory system, revealed that visual MMN elicited by deviant stimuli was reduced in the fixed compared to the randomized condition. Thus, the large-scale sequential regularity being present in the fixed condition (SSSSD) must have been represented in visual sensory memory. Interestingly, this effect did not occur in conditions with stimulus-onset asynchronies (SOAs) of 480 and 800 ms but was confined to the 160-ms SOA condition supporting the hypothesis that large-scale regularity extraction was based on perceptual grouping of the five successive stimuli defining the regularity.},
author = {Kimura, Motohiro and Widmann, Andreas and Schr\"{o}ger, Erich},
doi = {10.1016/j.brainres.2009.12.076},
issn = {1872-6240},
journal = {Brain research},
keywords = {Adult,Brain,Brain: physiology,Electroencephalography,Evoked Potentials,Female,Humans,Male,Memory,Memory: physiology,Neuropsychological Tests,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Reaction Time,Time Factors,Young Adult},
month = mar,
pages = {165--79},
pmid = {20045677},
title = {{Human visual system automatically represents large-scale sequential regularities.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20045677},
volume = {1317},
year = {2010}
}
@article{Chanon2008,
author = {Chanon, Vicki West and Hopfinger, Joseph},
doi = {10.1080/13506280701459026},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chanon, Hopfinger/Chanon, Hopfinger - 2008 - Memory's grip on attention The influence of item memory on the allocation of attention - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {2},
pages = {325--340},
title = {{Memory's grip on attention: The influence of item memory on the allocation of attention}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280701459026\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2008}
}
@article{Kimurad,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - Unknown - Coding theorems for correlated sources with cooperative information - Communications.pdf:pdf},
journal = {Communications},
pages = {1--71},
title = {{Coding theorems for correlated sources with cooperative information}}
}
@article{Bertera2000,
abstract = {The span of the effective stimulus during visual search through an unstructured alphanumeric array was investigated by using eye-contingent-display changes while the subjects searched for a target letter. In one condition, a window exposing the search array moved in synchrony with the subjects' eye movements, and the size of the window was varied. Performance reached asymptotic levels when the window was 5 degrees. In another condition, a foveal mask moved in synchrony with each eye movement, and the size of the mask was varied. The foveal mask conditions were much more detrimental to search behavior than the window conditions, indicating the importance of foveal vision during search. The size of the array also influenced performance, but performance reached asymptote for all array sizes tested at the same window size, and the effect of the foveal mask was the same for all array sizes. The results indicate that both acuity and difficulty of the search task influenced the span of the effective stimulus during visual search.},
author = {Bertera, J H and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bertera, Rayner/Bertera, Rayner - 2000 - Eye movements and the span of the effective stimulus in visual search. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Discrimination Learning,Eye Movements,Humans,Orientation,Pattern Recognition, Visual,Perceptual Masking,Size Perception,Visual Fields},
month = apr,
number = {3},
pages = {576--85},
pmid = {10909248},
title = {{Eye movements and the span of the effective stimulus in visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10909248},
volume = {62},
year = {2000}
}
@article{Dame,
author = {Dame, Amaury},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dame/Dame - 2010 - Accurate real-time tracking using mutual information - Mixed and Augmented Reality (ISMAR.pdf:pdf},
journal = {Mixed and Augmented Reality (ISMAR},
title = {{Accurate real-time tracking using mutual information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5643550},
year = {2010}
}
@article{Qiu2004,
author = {Qiu, Guoping},
file = {:Users/pkmital/Documents/Mendeley Desktop/Qiu/Qiu - 2004 - From content-based image retrieval to examplebased image processing - University of Nottingham Technical Report Report-cv.pdf:pdf},
journal = {University of Nottingham Technical Report: Report-cvip \ldots},
number = {May},
title = {{From content-based image retrieval to examplebased image processing}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.6290\&rep=rep1\&type=pdf},
year = {2004}
}
@article{Kimura2004,
author = {Kimura, a. and Kawanishi, T. and Kashino, K.},
doi = {10.1109/ICPR.2004.1334426},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Kawanishi, Kashino/Kimura, Kawanishi, Kashino - 2004 - Acceleration of similarity-based partial image retrieval using multistage vector quantization - Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.pdf:pdf},
isbn = {0-7695-2128-2},
journal = {Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
number = {C},
pages = {993--996 Vol.2},
publisher = {Ieee},
title = {{Acceleration of similarity-based partial image retrieval using multistage vector quantization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1334426},
volume = {00},
year = {2004}
}
@article{Kliegl2005,
abstract = {We resolve a controversy about reading fixations before word-skipping saccades which were reported as longer or shorter than control fixations in earlier studies. Our statistics are based on resampling of matched sets of fixations before skipped and nonskipped words, drawn from a database of 121,321 single fixations contributed by 230 readers of the Potsdam sentence corpus. Matched fixations originated from single-fixation forward-reading patterns and were equated for their positions within words. Fixations before skipped words were shorter before short or high-frequency words and longer before long or low-frequency words in comparison with control fixations. Reasons for inconsistencies in past research and implications for computational models are discussed.},
author = {Kliegl, Reinhold and Engbert, Ralf},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kliegl, Engbert/Kliegl, Engbert - 2005 - Fixation durations before word skipping in reading. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Adolescent,Adult,Aged,Aged, 80 and over,Attention,Computer Simulation,Contrast Sensitivity,Discrimination Learning,Female,Fixation, Ocular,Humans,Individuality,Male,Middle Aged,Reaction Time,Reading,Saccades,Semantics},
month = feb,
number = {1},
pages = {132--8},
pmid = {15945206},
title = {{Fixation durations before word skipping in reading.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15945206},
volume = {12},
year = {2005}
}
@article{Bulletin2007,
author = {Bulletin, Psychonomic},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bulletin/Bulletin - 2007 - Displaywide visual features associated with a search display ’ s appearance can mediate attentional capture - Psychonomic Bulletin \& Review.pdf:pdf},
journal = {Psychonomic Bulletin \& Review},
number = {3},
pages = {392--422},
title = {{Displaywide visual features associated with a search display ’ s appearance can mediate attentional capture}},
volume = {14},
year = {2007}
}
@book{Augoyard2006,
author = {Augoyard, Jean-Francois and Torgue, Henry},
isbn = {077352942X},
pages = {216},
publisher = {Mcgill Queens Univ Pr},
title = {{Sonic Experience: A Guide To Everyday Sounds}},
url = {http://www.amazon.com/Sonic-Experience-Guide-Everyday-Sounds/dp/077352942X},
year = {2006}
}
@article{Anokhin2001,
abstract = {Previous studies have demonstrated moderate heritability of the P300 component of event-related brain potentials (ERPs) and high heritability of background electroencephalogram (EEG) power spectrum. However, it is unclear whether EEG and ERPs are influenced by common or independent genetic factors. This study examined phenotypic and genetic correlations between EEG spectral power and P300 amplitude using data from 206 Dutch twin pairs, age 16 years. Multivariate genetic models (Cholesky decomposition) were fitted to the observed twin covariances using Mx software. In males, genetic correlations between P300 and EEG power measures were high (0.54-0.74); 30\% of the total P300 variance could be explained by genetic factors influencing EEG delta power and 26\% by P300-specific genetic factors (total heritability 56\%). In females, 45\% of P300 variance could be attributed to familial influences that were shared with the EEG. However, it was not possible to distinguish between the genetic versus shared environmental factors, consistent with previous analysis of P300 in this sample (van Beijsterveldt et al., 1998). The results suggest that a substantial proportion of genetic influences on P300 amplitude can be explained by strong heritability of slow EEG rhythms contributing to P300.},
author = {Anokhin, a P and van Baal, G C and van Beijsterveldt, C E and de Geus, E J and Grant, J and Boomsma, D I},
file = {:Users/pkmital/Documents/Mendeley Desktop/Anokhin et al/Anokhin et al. - 2001 - Genetic correlation between the P300 event-related brain potential and the EEG power spectrum. - Behavior genetics.pdf:pdf},
issn = {0001-8244},
journal = {Behavior genetics},
keywords = {Adolescent,Cerebral Cortex,Cerebral Cortex: physiology,Confidence Intervals,Electroencephalography,Event-Related Potentials, P300,Event-Related Potentials, P300: genetics,Female,Follow-Up Studies,Humans,Individuality,Male,Phenotype,Social Environment,Twins,Twins: genetics},
month = nov,
number = {6},
pages = {545--54},
pmid = {11838532},
title = {{Genetic correlation between the P300 event-related brain potential and the EEG power spectrum.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11838532},
volume = {31},
year = {2001}
}
@article{Yang1992,
author = {Yang, X. and Wang, K. and Shamma, S.A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yang, Wang, Shamma/Yang, Wang, Shamma - 1992 - Auditory representations of acoustic signals - Information Theory, IEEE Transactions on.pdf:pdf},
journal = {Information Theory, IEEE Transactions on},
number = {2},
pages = {824--839},
publisher = {IEEE},
title = {{Auditory representations of acoustic signals}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=119739},
volume = {38},
year = {1992}
}
@article{Naatanen2007a,
abstract = {In the present article, the basic research using the mismatch negativity (MMN) and analogous results obtained by using the magnetoencephalography (MEG) and other brain-imaging technologies is reviewed. This response is elicited by any discriminable change in auditory stimulation but recent studies extended the notion of the MMN even to higher-order cognitive processes such as those involving grammar and semantic meaning. Moreover, MMN data also show the presence of automatic intelligent processes such as stimulus anticipation at the level of auditory cortex. In addition, the MMN enables one to establish the brain processes underlying the initiation of attention switch to, conscious perception of, sound change in an unattended stimulus stream.},
author = {N\"{a}\"{a}t\"{a}nen, R and Paavilainen, P and Rinne, T and Alho, K},
doi = {10.1016/j.clinph.2007.04.026},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen et al/N\"{a}\"{a}t\"{a}nen et al. - 2007 - The mismatch negativity (MMN) in basic research of central auditory processing a review. - Clinical neurophy.pdf:pdf},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Cerebral Cortex,Cerebral Cortex: anatomy \& histology,Cerebral Cortex: physiology,Dominance, Cerebral,Dominance, Cerebral: physiology,Evoked Potentials,Evoked Potentials: physiology,Humans,Magnetoencephalography,Magnetoencephalography: methods,Pitch Discrimination,Pitch Discrimination: physiology,Reaction Time,Reaction Time: physiology,Speech Perception,Speech Perception: physiology},
month = dec,
number = {12},
pages = {2544--90},
pmid = {17931964},
title = {{The mismatch negativity (MMN) in basic research of central auditory processing: a review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17931964},
volume = {118},
year = {2007}
}
@article{Levoy2008,
author = {Levoy, Marc},
file = {:Users/pkmital/Documents/Mendeley Desktop/Levoy/Levoy - 2008 - Computational Photography on Large Collections of Images - Communications of the ACM.pdf:pdf},
journal = {Communications of the ACM},
number = {10},
pages = {86},
title = {{Computational Photography on Large Collections of Images}},
volume = {51},
year = {2008}
}
@inproceedings{Kimura2007,
author = {Kimura, A. and Uyematsu, T. and Kuzuoka, S.},
booktitle = {Information Theory, 2007. ISIT 2007. IEEE International Symposium on},
doi = {10.1093/ietfec/e90},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Kuzuoka/Kimura, Uyematsu, Kuzuoka - 2007 - Universal coding for correlated sources with complementary delivery - Information Theory, 2007. ISIT 2007. IEEE International Symposium on.pdf:pdf},
keywords = {bipartite graphs,complementary delivery,multiterminal source coding,sal coding,types of sequences,univer-},
number = {9},
pages = {1756--1760},
publisher = {IEEE},
title = {{Universal coding for correlated sources with complementary delivery}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4557475},
year = {2007}
}
@article{Kimuraf,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - Unknown - Large Deviations Performance of Interval Algorithm for Random Number Generation - Convergence.pdf:pdf},
journal = {Convergence},
keywords = {error ex-,interval algo-,intrinsic randomness,random number generation,rithm,variational distance},
pages = {0--3},
title = {{Large Deviations Performance of Interval Algorithm for Random Number Generation}}
}
@inproceedings{Bugalho2009,
author = {Bugalho, M and Portelo, J. and Trancoso, I and Pellegrini, T and Abad, A},
booktitle = {Tenth Annual Conference of the International Speech Communication Association},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bugalho et al/Bugalho et al. - 2009 - Detecting audio events for semantic video search - Tenth Annual Conference of the International Speech Communica.pdf:pdf},
pages = {1151--1154},
title = {{Detecting audio events for semantic video search}},
url = {http://www.isca-speech.org/archive/interspeech\_2009/i09\_1151.html},
year = {2009}
}
@article{Rehm2009,
address = {Berlin, Heidelberg},
author = {Rehm, F and Klawonn, F and Kruse, R},
doi = {10.1007/978-3-642-00668-5},
editor = {Gaul, Wolfgang and Bock, Hans-Hermann and Imaizumi, Tadashi and Okada, Akinori},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rehm, Klawonn, Kruse/Rehm, Klawonn, Kruse - 2009 - Cooperation in Classification and Data Analysis - Symposium A Quarterly Journal In Modern Foreign Literatures.pdf:pdf},
isbn = {978-3-642-00667-8},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
pages = {53--60},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Classification, Data Analysis, and Knowledge Organization},
title = {{Cooperation in Classification and Data Analysis}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-00668-5},
year = {2009}
}
@article{Castle,
author = {Castle, Robert and Klein, Georg and Murray, David W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Castle, Klein, Murray/Castle, Klein, Murray - Unknown - Video-rate Localization in Multiple Maps for Wearable Augmented Reality - Unknown.pdf:pdf},
title = {{Video-rate Localization in Multiple Maps for Wearable Augmented Reality}}
}
@article{Hinterstoisser2010,
author = {Hinterstoisser, Stefan and Lepetit, Vincent and Ilic, Slobodan and Fua, Pascal and Navab, Nassir},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hinterstoisser et al/Hinterstoisser et al. - 2010 - Dominant orientation templates for real-time detection of texture-less objects - IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.pdf:pdf},
journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010},
title = {{Dominant orientation templates for real-time detection of texture-less objects}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5539908},
year = {2010}
}
@article{Watson1985,
abstract = {We propose a model of how humans sense the velocity of moving images. The model exploits constraints provided by human psychophysics, notably that motion-sensing elements appear tuned for two-dimensional spatial frequency, and by the frequency spectrum of a moving image, namely, that its support lies in the plane in which the temporal frequency equals the dot product of the spatial frequency and the image velocity. The first stage of the model is a set of spatial-frequency-tuned, direction-selective linear sensors. The temporal frequency of the response of each sensor is shown to encode the component of the image velocity in the sensor direction. At the second stage, these components are resolved in order to measure the velocity of image motion at each of a number of spatial locations and spatial frequencies. The model has been applied to several illustrative examples, including apparent motion, coherent gratings, and natural image sequences. The model agrees qualitatively with human perception.},
author = {Watson, a B and Ahumada, a J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Watson, Ahumada/Watson, Ahumada - 1985 - Model of human visual-motion sensing. - Journal of the Optical Society of America. A, Optics and image science.pdf:pdf},
issn = {0740-3232},
journal = {Journal of the Optical Society of America. A, Optics and image science},
keywords = {Adaptation, Ocular,Differential Threshold,Discrimination (Psychology),Fourier Analysis,Humans,Models, Psychological,Motion Perception,Motion Perception: physiology,Space Perception,Time Factors,Visual Perception,Visual Perception: physiology},
month = feb,
number = {2},
pages = {322--41},
pmid = {3973764},
title = {{Model of human visual-motion sensing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3973764},
volume = {2},
year = {1985}
}
@techreport{Pfeiffer2001,
address = {Australia},
author = {Pfeiffer, S and Vincent, T},
institution = {CSIRO Mathematical and Information Sciences},
keywords = {MIR},
title = {{Formalisation of MPEG-1 compressed domain audio features}},
year = {2001}
}
@article{Kiefer2011,
abstract = {Psychological and neuroscience approaches have promoted much progress in elucidating the cognitive and neural mechanisms that underlie phenomenal visual awareness during the last decades. In this article, we provide an overview of the latest research investigating important phenomena in conscious and unconscious vision. We identify general principles to characterize conscious and unconscious visual perception, which may serve as important building blocks for a unified model to explain the plethora of findings. We argue that in particular the integration of principles from both conscious and unconscious vision is advantageous and provides critical constraints for developing adequate theoretical models. Based on the principles identified in our review, we outline essential components of a unified model of conscious and unconscious visual perception. We propose that awareness refers to consolidated visual representations, which are accessible to the entire brain and therefore globally available. However, visual awareness not only depends on consolidation within the visual system, but is additionally the result of a post-sensory gating process, which is mediated by higher-level cognitive control mechanisms. We further propose that amplification of visual representations by attentional sensitization is not exclusive to the domain of conscious perception, but also applies to visual stimuli, which remain unconscious. Conscious and unconscious processing modes are highly interdependent with influences in both directions. We therefore argue that exactly this interdependence renders a unified model of conscious and unconscious visual perception valuable. Computational modeling jointly with focused experimental research could lead to a better understanding of the plethora of empirical phenomena in consciousness research.},
author = {Kiefer, Markus and Ansorge, Ulrich and Haynes, John-Dylan and Hamker, Fred and Mattler, Uwe and Verleger, Rolf and Niedeggen, Michael},
doi = {10.2478/v10053-008-0090-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kiefer et al/Kiefer et al. - 2011 - Neuro-cognitive mechanisms of conscious and unconscious visual perception From a plethora of phenomena to general.pdf:pdf},
issn = {1895-1171},
journal = {Advances in cognitive psychology / University of Finance and Management in Warsaw},
keywords = {awareness,cognition,consciousness,subliminal,unconscious,visual},
month = jan,
pages = {55--67},
pmid = {22253669},
title = {{Neuro-cognitive mechanisms of conscious and unconscious visual perception: From a plethora of phenomena to general principles.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3259028\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2011}
}
@article{Brockmole2008,
author = {Brockmole, James and Henderson, John},
doi = {10.1080/13506280701453623},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmole, Henderson/Brockmole, Henderson - 2008 - Prioritizing new objects for eye fixation in real-world scenes Effects of object-scene consistency - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {2},
pages = {375--390},
title = {{Prioritizing new objects for eye fixation in real-world scenes: Effects of object-scene consistency}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280701453623\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2008}
}
@article{Turano2003,
abstract = {Laboratory-based models of oculomotor strategy that differ in the amount and type of top-down information were evaluated against a baseline case of random scanning for predicting the gaze patterns of subjects performing a real-world activity--walking to a target. Images of four subjects' eyes and field of view were simultaneously recorded as they performed the mobility task. Offline analyses generated movies of the eye on scene and a categorization scheme was used to classify the locations of the fixations. Frames from each subject's eye-on-scene movie served as input to the models, and the location of each model's predicted fixations was classified using the same categorization scheme. The results showed that models with no top-down information (visual salience model) or with only coarse feature information performed no better than a random scanner; the models' ordered fixation locations (gaze pattern) matched less than a quarter of the subjects' gaze patterns. A model that used only geographic information outperformed the random scanner and matched approximately a third of the gaze patterns. The best performance was obtained from an oculomotor strategy that used both coarse feature and geographic information, matching nearly half the gaze patterns (48\%). Thus, a model that uses top-down information about a target's coarse features and general vicinity does a fairly good job predicting fixation behavior, but it does not fully specify the gaze pattern of a subject walking to a target. Additional information is required, perhaps in the form of finer feature information or knowledge of a task's procedure.},
author = {Turano, Kathleen a and Geruschat, Duane R and Baker, Frank H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Turano, Geruschat, Baker/Turano, Geruschat, Baker - 2003 - Oculomotor strategies for the direction of gaze tested with a real-world activity. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Aged,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Middle Aged,Models, Biological,Psychomotor Performance,Psychomotor Performance: physiology,Videotape Recording,Visual Acuity,Visual Acuity: physiology,Walking,Walking: physiology},
month = feb,
number = {3},
pages = {333--46},
pmid = {12535991},
title = {{Oculomotor strategies for the direction of gaze tested with a real-world activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12535991},
volume = {43},
year = {2003}
}
@article{Neuroscience2008,
author = {Neuroscience, The},
file = {:Users/pkmital/Documents/Mendeley Desktop/Neuroscience/Neuroscience - 2008 - The Neuroscience of Consciousness - Neuroscience.pdf:pdf},
journal = {Neuroscience},
pages = {1225--1237},
title = {{The Neuroscience of Consciousness}},
year = {2008}
}
@book{Naatanen1992,
abstract = {This book delineates cerebral mechanisms of attention in humans as they presently appear in the light of data obtained by using various modern brain-research techniques. While the book focuses primarily on the ways humans select environmental information, the selectivity manifest in human thinking, consciousness, and motor behavior is also dealt with in the framework of an expanded attention concept. By combining the most recent evidence from diverse fields of human brain research and relating these physiological data to achievements of modern cognitive psychology, the author has developed an integrative view of human information processing. This theory concentrates on mechanisms of attentional selection and on the automatic processing which provides a basis for the selective processes.},
author = {N\"{a}\"{a}t\"{a}nen, Risto},
isbn = {0805809848},
pages = {494},
publisher = {L. Erlbaum},
title = {{Attention and Brain Function}},
url = {http://books.google.co.uk/books/about/Attention\_and\_Brain\_Function.html?id=wAXkTlTXqn0C\&pgis=1},
year = {1992}
}
@article{Kimura2007d,
author = {Kimura, a. and Uyematsu, T. and Kuzuoka, S.},
doi = {10.1093/ietfec/e90-a.9.1840},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Kuzuoka/Kimura, Uyematsu, Kuzuoka - 2007 - Universal Coding for Correlated Sources with Complementary Delivery - IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences(2).pdf:pdf},
issn = {0916-8508},
journal = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
month = sep,
number = {9},
pages = {1840--1847},
title = {{Universal Coding for Correlated Sources with Complementary Delivery}},
url = {http://search.ieice.org/bin/summary.php?id=e90-a\_9\_1840\&category=A\&year=2007\&lang=E\&abst=},
volume = {E90-A},
year = {2007}
}
@inproceedings{Bertin-Mahieux2011,
author = {Bertin-Mahieux, Thierry and Ellis, Daniel P. W. and Whitman, Brian and Lamere, Paul},
booktitle = {Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bertin-Mahieux et al/Bertin-Mahieux et al. - 2011 - The million song dataset - Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR 2011).pdf:pdf},
title = {{The million song dataset}},
url = {http://ismir2011.ismir.net/papers/OS6-1.pdf},
year = {2011}
}
@article{Arfib2005,
author = {Arfib, Daniel and Couturier, Jean-Michel and Kessous, Lo\"{\i}c},
doi = {10.1080/09298210500124273},
file = {:Users/pkmital/Documents/Mendeley Desktop/Arfib, Couturier, Kessous/Arfib, Couturier, Kessous - 2005 - Expressiveness and Digital Musical Instrument Design - Journal of New Music Research.pdf:pdf},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = mar,
number = {1},
pages = {125--136},
title = {{Expressiveness and Digital Musical Instrument Design}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09298210500124273},
volume = {34},
year = {2005}
}
@article{Lamy2006,
abstract = {Many theories of visual perception stipulate that Gestalt grouping occurs preattentively. Subjects' failure to report perceiving even salient grouping patterns under conditions of inattention challenges this assumption (see, e.g., Mack, Tang, Tuma, Kahn, \& Rock, 1992), but Moore and Egeth (1997) showed that although subjects are indeed unable to identify grouping patterns outside the focus of attention, effects of these patterns on visual perception can be observed when they are assessed using implicit, rather than explicit, measures. However, this finding, which is the only one to date demonstrating grouping effects without attention, is open to an alternative account. In the present study, we eliminated this confound and replicated Moore and Egeth's findings, using the M\"{u}ller-Lyer illusion (Experiments 1 and 2). Moreover, we found converging evidence for these findings with a variant of the flanker task (Experiment 3), when the amount of available attentional resources was varied (Experiments 4 and 5). The results reinforce the idea that, although grouping outside the focus of attention cannot be the object of overt report, grouping processes can occur without attention.},
author = {Lamy, Dominique and Segal, Hannah and Ruderman, Lital},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lamy, Segal, Ruderman/Lamy, Segal, Ruderman - 2006 - Grouping does not require attention. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Gestalt Theory,Humans,Pattern Recognition, Visual,Reaction Time,Visual Perception},
month = jan,
number = {1},
pages = {17--31},
pmid = {16617826},
title = {{Grouping does not require attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16617826},
volume = {68},
year = {2006}
}
@article{Bruder2009a,
author = {Bruder, G. and Steinicke, F. and Hinrichs, K.H.},
file = {::},
journal = {2009 IEEE Symposium on 3D User Interfaces},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
month = mar,
pages = {75--82},
publisher = {Ieee},
title = {{Arch-Explore: A natural user interface for immersive architectural walkthroughs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4811208},
year = {2009}
}
@article{Kimura2006c,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 2006 - Multiterminal source coding with complementary delivery - Main.pdf:pdf},
journal = {Main},
title = {{Multiterminal source coding with complementary delivery}},
year = {2006}
}
@article{Cassimjee2004,
author = {Cassimjee, Nafisa and Maree, David J F},
journal = {Psychology},
number = {2},
pages = {222--236},
title = {{Change detection in a change blindness flicker paradigm}},
volume = {34},
year = {2004}
}
@inproceedings{Smyth2001,
author = {Smyth, T. and Smith, J.O.},
booktitle = {Proc. of ISMA 2001, Int. Symposium on Musical Acoustics},
file = {::},
publisher = {Citeseer},
title = {{Applications of Bioacoustics in Physical Modeling and the Creation of New Musical Instruments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.8934\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Copeland2002,
author = {Copeland, Roger},
file = {:Users/pkmital/Documents/Mendeley Desktop/Copeland/Copeland - 2002 - Merce Cunningham and the aesthetic of collage - TDRThe Drama Review.pdf:pdf},
journal = {TDR/The Drama Review},
number = {1},
pages = {11--28},
title = {{Merce Cunningham and the aesthetic of collage}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105420402753555822},
volume = {46},
year = {2002}
}
@article{Soltani2010,
abstract = {The primate visual system continuously selects spatial proscribed regions, features or objects for further processing. These selection mechanisms--collectively termed selective visual attention--are guided by intrinsic, bottom-up and by task-dependent, top-down signals. While much psychophysical research has shown that overt and covert attention is partially allocated based on saliency-driven exogenous signals, it is unclear how this is accomplished at the neuronal level. Recent electrophysiological experiments in monkeys point to the gradual emergence of saliency signals when ascending the dorsal visual stream and to the influence of top-down attention on these signals. To elucidate the neural mechanisms underlying these observations, we construct a biologically plausible network of spiking neurons to simulate the formation of saliency signals in different cortical areas. We find that saliency signals are rapidly generated through lateral excitation and inhibition in successive layers of neural populations selective to a single feature. These signals can be improved by feedback from a higher cortical area that represents a saliency map. In addition, we show how top-down attention can affect the saliency signals by disrupting this feedback through its action on the saliency map. While we find that saliency computations require dominant slow NMDA currents, the signal rapidly emerges from successive regions of the network. In conclusion, using a detailed spiking network model we find biophysical mechanisms and limitations of saliency computations which can be tested experimentally.},
author = {Soltani, Alireza and Koch, Christof},
doi = {10.1523/JNEUROSCI.1517-10.2010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Soltani, Koch/Soltani, Koch - 2010 - Visual saliency computations mechanisms, constraints, and the effect of feedback. - The Journal of neuroscience.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Attention,Attention: physiology,Computer Simulation,Feedback, Physiological,Feedback, Physiological: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Photic Stimulation,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = sep,
number = {38},
pages = {12831--43},
pmid = {20861387},
title = {{Visual saliency computations: mechanisms, constraints, and the effect of feedback.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20861387},
volume = {30},
year = {2010}
}
@article{Orabona2007a,
author = {Orabona, Francesco and Metta, Giorgio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Orabona, Metta/Orabona, Metta - 2007 - A proto-object based visual attention model - Attention in cognitive systems. Theories(2).pdf:pdf},
journal = {Attention in cognitive systems. Theories},
pages = {198--215},
title = {{A proto-object based visual attention model}},
url = {http://www.springerlink.com/index/71U3T3262424M763.pdf},
year = {2007}
}
@article{Bajuraa,
author = {Bajura, Michael and Hill, U N C Chapel and Neumann, Ulrich and Reality, Keywords Augmented},
file = {::},
keywords = {augmented reality,reality,registration,virtual},
title = {{Dynamic Registration Correction in Video-Based Augmented Reality Systems}}
}
@article{Thall,
abstract = {A new granular sound signal generator, processor, and control system is presented, developed, and discussed. The unifying principles that exist among past implementations are first examined. The result of this investigation is a systematic design that, through reclassification and generalization, combines and extends these early models. Sets of signal processing sub-routines are then identified, collected and combined into a general-purpose grain generator. A novel user interface is also presented along with various high-level control regimes. This assists the user in navigating the multi-dimensional parameter space inherent in granular transformations. The combination of fast and efficient processing with scalable and customized controllers results in a system designed exclusively for advanced granular synthesis and processing. This system could be used in real, virtual, and mixed immersive environments, providing a real- time synchronized stream of complex spatial ambient and environmental tones and noises alongside synthesized visual and/or tactile streams.},
author = {Thall, David},
file = {::},
journal = {Interactive Digital Multimedia IGERT Annual Research Review},
pages = {4--6},
title = {{Experiments in Sound Granulation and Spatialization for Immersive Environments}}
}
@inproceedings{Saragih2009,
author = {Saragih, J.M. and Lucey, Simon and Cohn, J.F.},
booktitle = {Computer Vision, 2009 IEEE 12th International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Saragih, Lucey, Cohn/Saragih, Lucey, Cohn - 2009 - Face alignment through subspace constrained mean-shifts - Computer Vision, 2009 IEEE 12th International Conference on.pdf:pdf},
number = {Clm},
pages = {1034--1041},
publisher = {Ieee},
title = {{Face alignment through subspace constrained mean-shifts}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5459377},
year = {2009}
}
@article{Henderson2003a,
abstract = {Each time the eyes are spatially reoriented via a saccadic eye movement, the image falling on the retina changes. How visually specific are the representations that are functional across saccades during active scene perception? This question was investigated with a saccade-contingent display-change paradigm in which pictures of complex real-world scenes were globally changed in real time during eye movements. The global changes were effected by presenting each scene as an alternating set of scene strips and occluding gray bars, and by reversing the strips and bars during specific saccades. The results from two experiments demonstrated a global transsaccadic change-blindness effect, suggesting that point-by-point visual representations are not functional across saccades during complex scene perception.},
author = {Henderson, John M and Hollingworth, Andrew},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Hollingworth/Henderson, Hollingworth - 2003 - Global transsaccadic change blindness during scene perception. - Psychological science a journal of the American Psychological Society APS.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science : a journal of the American Psychological Society / APS},
keywords = {Adult,Attention,Discrimination Learning,Female,Humans,Male,Memory, Short-Term,Orientation,Pattern Recognition, Visual,Perceptual Closure,Perceptual Masking,Problem Solving,Psychophysics,Saccades},
month = sep,
number = {5},
pages = {493--7},
pmid = {12930482},
title = {{Global transsaccadic change blindness during scene perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12930482},
volume = {14},
year = {2003}
}
@article{Knott2003,
author = {Knott, Dave and Pai, D.K.},
file = {::},
journal = {Computer Graphics Forum},
keywords = {agespace computations,collision detection,geometric modeling,graphics hardware,im-},
publisher = {Citeseer},
title = {{CInDeR: Collision and interference detection in real-time using graphics hardware}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.316},
year = {2003}
}
@article{Uhde,
author = {Uhde, Jan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Uhde/Uhde - 1994 - Jan Svankmajer The Prodigious Animator From Prague. - Kinema A Journal for Film and Audiovisual Media.html:html},
journal = {Kinema: A Journal for Film and Audiovisual Media},
keywords = {Jan Uhde},
title = {{Jan Svankmajer: The Prodigious Animator From Prague.}},
url = {http://www.kinema.uwaterloo.ca/article.php?id=363},
volume = {Spring},
year = {1994}
}
@article{Harb2006,
abstract = {Accommodation has long been suspected to be involved in the development of myopia because near work, particularly reading, is known to be a risk factor. In this study, we measured several dynamic characteristics of accommodative behavior during extended periods of reading under close-to-natural conditions in 20 young emmetropic and stable myopic subjects. Accommodative responses, errors, and variability (including power spectrum analysis) were analyzed and related to accommodative demand and subject refractive error. All accommodative behaviors showed large inter-subject variability at all of the reading demands. Accommodative lags and variability significantly increased with closer demands for all subjects (ANOVA, p<0.05). Myopes had significantly greater variability in their accommodation responses compared to emmetropes (ANOVA, p<0.05) and had larger accommodative lags at further reading distances (unpaired t test p<0.05). Power spectrum analysis showed a significant increase in the power of accommodative microfluctuations with closer demands (ANOVA, p<0.05) and with increasing myopia at the closest reading demand (ANOVA, p<0.01). The difference in the stability of the accommodative behavior between individuals with different refractive states suggests a possible relationship between variability in accommodation and the development of myopia.},
author = {Harb, Elise and Thorn, Frank and Troilo, David},
doi = {10.1016/j.visres.2006.02.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Harb, Thorn, Troilo/Harb, Thorn, Troilo - 2006 - Characteristics of accommodative behavior during sustained reading in emmetropes and myopes. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Accommodation, Ocular,Adult,Fixation, Ocular,Humans,Linear Models,Myopia,Myopia: physiopathology,Reading,Retinoscopy},
month = aug,
number = {16},
pages = {2581--92},
pmid = {16545421},
title = {{Characteristics of accommodative behavior during sustained reading in emmetropes and myopes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16545421},
volume = {46},
year = {2006}
}
@article{Celsis1999,
abstract = {Using a habituation-recovery paradigm adapted to functional magnetic resonance imaging, we investigated the brain responses to syllables and tones in six right-handed male subjects. We opposed a standard condition (STD) in which the subjects were listening to homogeneous sequences of four identical stimuli, to a deviant condition (DEV) in which the fourth stimulus of the sequence differed in pitch or spectral content for tones and in the initial stop consonant for syllables. The corresponding runs alternated four rest periods with two STD and two DEV conditions. In addition to a marked rightward asymmetry in the primary and secondary auditory cortex for tones and a right inferior frontal activation for the tone condition where the deviant had increased spectral content, the experiment revealed differential activations in the left posterior superior temporal gyrus and in the left supramarginal gyrus. Activations within the left posterior superior temporal gyrus were observed for the DEV condition with tones and for the STD and DEV conditions with syllables. Activation within the inferior part of the left supramarginal gyrus was only observed for the DEV condition with syllables. The analysis of the decreases and increases in the BOLD signal across the STD, DEV, and rest conditions suggests that the left posterior superior temporal gyrus is implicated in the preattentive change detection of acoustic changes in speech as well as nonspeech stimuli, whereas the left supramarginal gyrus is more specifically engaged in the detection of changes in phonological units.},
author = {Celsis, P and Boulanouar, K and Doyon, B and Ranjeva, J P and Berry, I and Nespoulous, J L and Chollet, F},
doi = {10.1006/nimg.1998.0389},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Dominance, Cerebral,Dominance, Cerebral: physiology,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Oxygen Consumption,Oxygen Consumption: physiology,Pitch Perception,Pitch Perception: physiology,Reference Values,Speech Perception,Speech Perception: physiology,Temporal Lobe,Temporal Lobe: physiology},
month = jan,
number = {1},
pages = {135--44},
pmid = {9918735},
title = {{Differential fMRI responses in the left posterior superior temporal gyrus and left supramarginal gyrus to habituation and change detection in syllables and tones.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9918735},
volume = {9},
year = {1999}
}
@article{Yu2012,
author = {Yu, Tsz-Ho and Woodford, Oliver J. and Cipolla, Roberto},
doi = {10.1007/s11263-012-0563-2},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yu, Woodford, Cipolla/Yu, Woodford, Cipolla - 2012 - A Performance Evaluation of Volumetric 3D Interest Point Detectors - International Journal of Computer Vi.pdf:pdf},
isbn = {1126301205},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {3d interest points,feature detection,performance evaluation,volumetric interest points},
month = sep,
number = {1-3},
pages = {180--197},
title = {{A Performance Evaluation of Volumetric 3D Interest Point Detectors}},
url = {http://link.springer.com/10.1007/s11263-012-0563-2},
volume = {102},
year = {2012}
}
@article{Wheeler2008,
author = {Wheeler, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wheeler/Wheeler - 2008 - In Defense of Extended Functionalism - Most.pdf:pdf},
journal = {Most},
number = {section 8},
pages = {1--27},
title = {{In Defense of Extended Functionalism}},
year = {2008}
}
@inproceedings{Smyth2003,
abstract = {In this research, a method is presented for extracting the control parameters of an avian syrinx synthesis model from recorded bird- song. A look-up table pairs combinations of pressure and tension parameters with the model’s corresponding output power spectra. At each time frame, a generalized likelihood ratio fills a pressure- tension matrix indicating similarity between the birdsong power spectrum and the tabulated spectra. Successive pressure-tension matrices are stacked and points exhibiting a good fit to the data align to form trajectories corresponding to changes in pressure and tension over time which can then be used to control the model. In the event a range of trajectories matches the data well, the selected trajectory is that of least action.},
author = {Smyth, Tamara and Abel, Jonathan S and Iii, Julius O Smith},
booktitle = {Proceedings of the Stockholm Music Acoustics Conference.},
file = {::},
number = {Smac 03},
pages = {3--6},
title = {{The Estimation of Birdsong Control Parameters Using Maximum Likelihood and Minimum Action}},
volume = {2003},
year = {2003}
}
@article{Fritz2007,
abstract = {Some fifty years after the first physiological studies of auditory attention, the field is now ripening, with exciting recent insights into the psychophysics, psychology, and neural basis of auditory attention. Current research seeks to unravel the complex interactions of pre-attentive and attentive processing of the acoustic scene, the role of auditory attention in mediating receptive-field plasticity in both auditory spatial and auditory feature processing, the contrasts and parallels between auditory and visual attention pathways and mechanisms, the interplay of bottom-up and top-down attentional mechanisms, the influential role of attention, goals, and expectations in shaping auditory processing, and the orchestration of diverse attentional effects at multiple levels from the cochlea to the cortex.},
author = {Fritz, Jonathan B and Elhilali, Mounya and David, Stephen V and Shamma, Shihab a},
doi = {10.1016/j.conb.2007.07.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fritz et al/Fritz et al. - 2007 - Auditory attention--focusing the searchlight on sound. - Current opinion in neurobiology.pdf:pdf},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animals,Attention,Attention: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Humans,Neuronal Plasticity,Neuronal Plasticity: physiology,Sound,Space Perception,Space Perception: physiology},
month = aug,
number = {4},
pages = {437--55},
pmid = {17714933},
title = {{Auditory attention--focusing the searchlight on sound.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17714933},
volume = {17},
year = {2007}
}
@article{Christel1998,
author = {Christel, Michael and Martin, David},
file = {:Users/pkmital/Documents/Mendeley Desktop/Christel, Martin/Christel, Martin - 1998 - Information visualization within a digital video library - Journal of Intelligent Information Systems.pdf:pdf},
journal = {Journal of Intelligent Information Systems},
keywords = {digital video library,information visualization,multimedia abstraction},
number = {June},
title = {{Information visualization within a digital video library}},
url = {http://www.springerlink.com/index/W53255194JN45Q45.pdf},
year = {1998}
}
@article{Winkler2005a,
abstract = {Auditory stream segregation has been suggested to include two distinct processing stages: (1) forming representations for alternative organizations of the acoustic input and (2) choosing one organization for perception after weighing the evidence that supports the different alternatives. The current study tested the possibility that auditory event-related potentials (ERP) could be used to index both stages of the stream-segregation process. Sequences of tones that could be perceived either as a single coherent auditory stream (integrated organization) or as two separate streams of sounds (segregated organization) were presented to subjects. The stimulus configuration encouraged perception to fluctuate between these alternative organizations. Subjects were instructed to continuously indicate whether they perceived one or the other organization of the tone sequence. Occasionally, a tone was omitted from the otherwise regular sequence. This deviance was expected to be processed differently depending on the perceptual organization of the sequence at the time of the omission. We found an early ERP response to omission, which was fully determined by parameters of the stimulation and was not sensitive to the perceived sound organization. In contrast, modulation of two ERP components elicited by the regular tone patterns as well as later responses elicited by deviants correlated with the perceived sound organization. These results suggest that sound organization goes through at least two distinct stages, the first being fully stimulus driven, whereas the second is partly under top-down control.},
author = {Winkler, Istv\'{a}n and Takegata, Rika and Sussman, Elyse},
doi = {10.1016/j.cogbrainres.2005.06.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler, Takegata, Sussman/Winkler, Takegata, Sussman - 2005 - Event-related brain potentials reveal multiple stages in the perceptual organization of sound. - Bra.pdf:pdf},
issn = {0926-6410},
journal = {Brain research. Cognitive brain research},
keywords = {Adult,Analysis of Variance,Auditory Perception,Auditory Perception: physiology,Brain,Brain Mapping,Brain: physiology,Dose-Response Relationship, Radiation,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Evoked Potentials: physiology,Female,Humans,Male,Sound},
month = sep,
number = {1},
pages = {291--9},
pmid = {16005616},
title = {{Event-related brain potentials reveal multiple stages in the perceptual organization of sound.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16005616},
volume = {25},
year = {2005}
}
@article{Rudall1978,
author = {Rudall, B.H.},
doi = {10.1016/0020-7101(78)90038-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rudall/Rudall - 1978 - Lecture notes in computer science. Vol. 15 - International Journal of Bio-Medical Computing.pdf:pdf},
journal = {International Journal of Bio-Medical Computing},
month = may,
number = {3},
pages = {242--242},
title = {{Lecture notes in computer science. Vol. 15}},
volume = {9},
year = {1978}
}
@article{Ritter2000,
abstract = {The purpose of this study was to determine whether the system that underlies the mismatch negativity (MMN) of event-related potentials would operate on the basis of objects if stimuli were delivered in such a way as to create the impression of two objects. To this end, tones were alternated between ears with one combination of features for each ear. Deviant tones, which differed from the standard tones of both ears, were delivered separately to each ear. The deviants elicited MMNs only with respect to the standards of the ear to which they were delivered. The data indicate that the MMN system operated on the basis of objects and that the integration of objects occurs preattentively in the auditory system.},
author = {Ritter, W and Sussman, E and Molholm, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ritter, Sussman, Molholm/Ritter, Sussman, Molholm - 2000 - Evidence that the mismatch negativity system works on the basis of objects. - Neuroreport.pdf:pdf},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Adult,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male},
month = jan,
number = {1},
pages = {61--3},
pmid = {10683830},
title = {{Evidence that the mismatch negativity system works on the basis of objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10683830},
volume = {11},
year = {2000}
}
@article{Boyce1989,
abstract = {Previous research using briefly presented displays has indicated that objects in a coherent scene are easier to identify than are objects in incoherent backgrounds. Of interest is whether the identification of the target object depends on the identification of the scene or the identification of other diagnostic objects in the scene. Experiment 1 indicated objects are more difficult to identify when located in an "episodically" inconsistent background even when the same diagnostic objects are present in both inconsistent and consistent backgrounds. Experiment 2 demonstrated that the degree to which noncued (cohort) objects are consistent with the target object has no effect on the object identification task. Experiment 3 showed consistent episodic background information facilitated object identification and inconsistent episodic background information did not interfere relative to "nonsense" backgrounds roughly equated on visual characteristics. Implications for models of scene perception are discussed.},
author = {Boyce, S J and Pollatsek, a and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Boyce, Pollatsek, Rayner/Boyce, Pollatsek, Rayner - 1989 - Effect of background information on object identification. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adult,Attention,Discrimination Learning,Form Perception,Humans,Orientation,Pattern Recognition, Visual,Social Environment},
month = aug,
number = {3},
pages = {556--66},
pmid = {2527962},
title = {{Effect of background information on object identification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2527962},
volume = {15},
year = {1989}
}
@article{May1999,
abstract = {We offer a model of how human cortex detects changes in the auditory environment. Auditory change detection has recently been the object of intense investigation via the mismatch negativity (MMN). MMN is a preattentive response to sudden changes in stimulation, measured noninvasively in the electroencephalogram (EEG) and the magnetoencephalogram (MEG). It is elicited in the oddball paradigm, where infrequent deviant tones intersperse a series of repetitive standard tones. However, little apart from the participation of tonotopically organized auditory cortex is known about the neural mechanisms underlying change detection and the MMN. In the present study, we investigate how poststimulus inhibition might account for MMN and compare the effects of adaptation with those of lateral inhibition in a model describing tonotopically organized cortex. To test the predictions of our model, we performed MEG and EEG measurements on human subjects and used both small- (<1/3 octave) and large- (>5 octaves) frequency differences between the standard and deviant tones. The experimental results bear out the prediction that MMN is due to both adaptation and lateral inhibition. Finally, we suggest that MMN might serve as a probe of what stimulus features are mapped by human auditory cortex.},
author = {May, P and Tiitinen, H and Ilmoniemi, R J and Nyman, G and Taylor, J G and N\"{a}\"{a}t\"{a}nen, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/May et al/May et al. - 1999 - Frequency change detection in human auditory cortex. - Journal of computational neuroscience.pdf:pdf},
issn = {0929-5313},
journal = {Journal of computational neuroscience},
keywords = {Adaptation, Physiological,Adaptation, Physiological: physiology,Auditory Cortex,Auditory Cortex: physiology,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Magnetoencephalography,Models, Neurological,Neural Inhibition,Neural Inhibition: physiology,Pitch Perception,Pitch Perception: physiology,Reaction Time,Reaction Time: physiology},
number = {2},
pages = {99--120},
pmid = {10333158},
title = {{Frequency change detection in human auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10333158},
volume = {6},
year = {1999}
}
@article{Naatanen2001,
abstract = {The everyday auditory environment consists of multiple simultaneously active sources with overlapping temporal and spectral acoustic properties. Despite the seemingly chaotic composite signal impinging on our ears, the resulting perception is of an orderly "auditory scene" that is organized according to sources and auditory events, allowing us to select messages easily, recognize familiar sound patterns, and distinguish deviant or novel ones. Recent data suggest that these perceptual achievements are mainly based on processes of a cognitive nature ("sensory intelligence") in the auditory cortex. Even higher cognitive processes than previously thought, such as those that organize the auditory input, extract the common invariant patterns shared by a number of acoustically varying sounds, or anticipate the auditory events of the immediate future, occur at the level of sensory cortex (even when attention is not directed towards the sensory input).},
author = {N\"{a}\"{a}t\"{a}nen, R and Tervaniemi, M and Sussman, E and Paavilainen, P and Winkler, I},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen et al/N\"{a}\"{a}t\"{a}nen et al. - 2001 - Primitive intelligence in the auditory cortex. - Trends in neurosciences.pdf:pdf},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Humans,Intelligence,Intelligence: physiology},
month = may,
number = {5},
pages = {283--8},
pmid = {11311381},
title = {{"Primitive intelligence" in the auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11311381},
volume = {24},
year = {2001}
}
@article{Kalinli2009a,
author = {Kalinli, Ozlem and Sundaram, Shiva and Narayanan, Shrikanth},
doi = {10.1109/MMSP.2009.5293267},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalinli, Sundaram, Narayanan/Kalinli, Sundaram, Narayanan - 2009 - Saliency-driven unstructured acoustic scene classification using latent perceptual indexing - 2009.pdf:pdf},
isbn = {978-1-4244-4463-2},
journal = {2009 IEEE International Workshop on Multimedia Signal Processing},
month = oct,
pages = {1--6},
publisher = {Ieee},
title = {{Saliency-driven unstructured acoustic scene classification using latent perceptual indexing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5293267},
year = {2009}
}
@article{Birmingham2007,
abstract = {Although inhibition of return (IOR) is widely believed to aid search by discouraging reexamination of previously inspected locations, its impact actually appears to decline as the number of target locations increases. We test three possible reasons for this paradoxical result: (1) IOR is capacity-limited, (2) IOR is sensitive to subtle changes in target location probability, and (3) IOR decays with distance from a previously attended location. The present investigation provides strong support for the third explanation, indicating that a gradient of inhibition is centered on previously attended locations. We note that this inhibitory gradient resolves a paradox in the literature. Moreover, we speculate that the inhibitory gradient may reflect a "similarity space" within which target locations near to the cue are tagged with inhibition due to their similarity to the cued location. The farther the target location is away, the less similar it is to the cued location, and thus the less inhibition it receives.},
author = {Birmingham, Elina and Visser, Troy a W and Snyder, Janice J and Kingstone, Alan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Birmingham et al/Birmingham et al. - 2007 - Inhibition of return unraveling a paradox. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Adolescent,Adult,Attention,Cues,Female,Humans,Inhibition (Psychology),Male,Reaction Time},
month = oct,
number = {5},
pages = {957--63},
pmid = {18087966},
title = {{Inhibition of return: unraveling a paradox.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18087966},
volume = {14},
year = {2007}
}
@article{Thickbroom1985,
author = {Thickbroom, G W and Mastaglia, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thickbroom, Mastaglia/Thickbroom, Mastaglia - 1985 - Presaccadic ' Spike ' Potential Investigation of Topography and Source Opisthochronic averaging EEG recording - Science.pdf:pdf},
journal = {Science},
keywords = {a large-amplitude,a saccade,approximately 15-30 ms before,been determined with certainty,can be recorded from,dipole modelling - -,during horizontal saccades in,found it to be,maximal near the eye,normal subjects and have,on the side ipsilateral,potential,presaccadic potentials - -,previously,relatively short duration potential,source derivation,surface distribution - -,surface topography of this,the,the scalp in man,to the direction of,we have measured the,whose source has not},
pages = {271--280},
title = {{Presaccadic ' Spike ' Potential : Investigation of Topography and Source Opisthochronic averaging EEG recording}},
volume = {339},
year = {1985}
}
@inproceedings{Torralba1999,
author = {Torralba, Antonio and Oliva, Aude},
booktitle = {Proceedings of the International Conference on Computer Vision, ICCV99},
file = {:Users/pkmital/Documents/Mendeley Desktop/Torralba, Oliva/Torralba, Oliva - 1999 - Semantic organization of scenes using discriminant structural templates - Proceedings of the International Conference on Computer Vision, ICCV99.pdf:pdf},
number = {1},
pages = {1253--1258},
title = {{Semantic organization of scenes using discriminant structural templates}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=790424},
year = {1999}
}
@article{Shinozaki2000,
abstract = {To investigate a part of the structure of the memory trace, auditory event-related potentials (ERPs) were recorded from reading subjects while they were presented with two different stimulus-series simultaneously. A clear mismatch negativity (MMN) was obtained from each series, when the stimulus sequence consisted of a high-frequency series and a low-frequency series. Moreover, the MMN showed independent elicitation within each series. However, if the frequency range of one series overlapped with that of the other series, the amplitude of the MMN was prominently reduced, suggesting that the two processing functions indexed by MMN coexisted simultaneously in the preattentive acoustic system and were produced by the respective grouping of high-frequency tones and low-frequency tones.},
author = {Shinozaki, N and Yabe, H and Sato, Y and Sutoh, T and Hiruma, T and Nashida, T and Kaneko, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shinozaki et al/Shinozaki et al. - 2000 - Mismatch negativity (MMN) reveals sound grouping in the human brain. - Neuroreport.pdf:pdf},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Electroencephalography,Evoked Potentials, Auditory,Female,Humans},
month = jun,
number = {8},
pages = {1597--601},
pmid = {10852208},
title = {{Mismatch negativity (MMN) reveals sound grouping in the human brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10852208},
volume = {11},
year = {2000}
}
@article{Theeuwes1995,
abstract = {The present studies investigated whether an isoluminant color change pops out, indicating that it can be detected preattentively in parallel. The results of Experiment 1 show that an abrupt color change presented on an equiluminant background does not pop out. However, when the color change is accompanied by a small luminance change, it does pop out. The results of Experiment 2 show that the pop-out is fully due to the luminance change and not to the color change. The results of Experiments 3 and 4 show that the failure to find a pop-out at equiluminance cannot be attributed to the limited temporal resolution for chromatic stimuli. The results of Experiment 5 show that particular search strategies cannot be responsible for the obtained results. The results are in agreement with physiological findings regarding the parvo and magno systems.},
author = {Theeuwes, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theeuwes/Theeuwes - 1995 - Abrupt luminance change pops out abrupt color change does not. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Color Perception,Contrast Sensitivity,Discrimination Learning,Humans,Orientation,Psychophysics,Reaction Time},
month = jul,
number = {5},
pages = {637--44},
pmid = {7644324},
title = {{Abrupt luminance change pops out; abrupt color change does not.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7644324},
volume = {57},
year = {1995}
}
@article{Kayser2005a,
abstract = {Our nervous system is confronted with a barrage of sensory stimuli, but neural resources are limited and not all stimuli can be processed to the same extent. Mechanisms exist to bias attention toward the particularly salient events, thereby providing a weighted representation of our environment. Our understanding of these mechanisms is still limited, but theoretical models can replicate such a weighting of sensory inputs and provide a basis for understanding the underlying principles. Here, we describe such a model for the auditory system-an auditory saliency map. We experimentally validate the model on natural acoustical scenarios, demonstrating that it reproduces human judgments of auditory saliency and predicts the detectability of salient sounds embedded in noisy backgrounds. In addition, it also predicts the natural orienting behavior of naive macaque monkeys to the same salient stimuli. The structure of the suggested model is identical to that of successfully used visual saliency maps. Hence, we conclude that saliency is determined either by implementing similar mechanisms in different unisensory pathways or by the same mechanism in multisensory areas. In any case, our results demonstrate that different primate sensory systems rely on common principles for extracting relevant sensory events.},
author = {Kayser, Christoph and Petkov, Christopher I and Lippert, Michael and Logothetis, Nikos K},
doi = {10.1016/j.cub.2005.09.040},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kayser et al/Kayser et al. - 2005 - Mechanisms for allocating auditory attention an auditory saliency map. - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Acoustic Stimulation,Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Macaca mulatta,Macaca mulatta: physiology,Models, Neurological,Orientation,Orientation: physiology,Species Specificity},
month = nov,
number = {21},
pages = {1943--7},
pmid = {16271872},
title = {{Mechanisms for allocating auditory attention: an auditory saliency map.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271872},
volume = {15},
year = {2005}
}
@article{Kimura2008a,
author = {Kimura, Akisato and Pang, Derek},
doi = {10.1109/ICPR.2008.4761025},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Pang/Kimura, Pang - 2008 - Dynamic Markov random fields for stochastic modeling of visual attention - 2008 19th International Conference on Pattern Recognition(2).pdf:pdf},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition},
month = dec,
pages = {1--5},
publisher = {Ieee},
title = {{Dynamic Markov random fields for stochastic modeling of visual attention}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761025},
year = {2008}
}
@article{Thompson2005,
abstract = {The influential "premotor theory of attention" proposes that developing oculomotor commands mediate covert visual spatial attention. A likely source of this attentional bias is the frontal eye field (FEF), an area of the frontal cortex involved in converting visual information into saccade commands. We investigated the link between FEF activity and covert spatial attention by recording from FEF visual and saccade-related neurons in monkeys performing covert visual search tasks without eye movements. Here we show that the source of attention signals in the FEF is enhanced activity of visually responsive neurons. At the time attention is allocated to the visual search target, nonvisually responsive saccade-related movement neurons are inhibited. Therefore, in the FEF, spatial attention signals are independent of explicit saccade command signals. We propose that spatially selective activity in FEF visually responsive neurons corresponds to the mental spotlight of attention via modulation of ongoing visual processing.},
author = {Thompson, Kirk G and Biscoe, Keri L and Sato, Takashi R},
doi = {10.1523/JNEUROSCI.0741-05.2005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thompson, Biscoe, Sato/Thompson, Biscoe, Sato - 2005 - Neuronal basis of covert spatial attention in the frontal eye field. - The Journal of neuroscience the.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Macaca mulatta,Male,Neurons,Neurons: physiology,Photic Stimulation,Photic Stimulation: methods,Space Perception,Space Perception: physiology,Visual Fields,Visual Fields: physiology},
month = oct,
number = {41},
pages = {9479--87},
pmid = {16221858},
title = {{Neuronal basis of covert spatial attention in the frontal eye field.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2804969\&tool=pmcentrez\&rendertype=abstract},
volume = {25},
year = {2005}
}
@article{DeLong2012,
author = {DeLong, J.E. and Brunick, K.L. and Cutting, J.E.},
file = {:Users/pkmital/Documents/Mendeley Desktop/DeLong, Brunick, Cutting/DeLong, Brunick, Cutting - 2012 - Film through the Human Visual System Finding Patterns and Limits - people.psych.cornell.edu.pdf:pdf},
journal = {people.psych.cornell.edu},
pages = {1--13},
title = {{Film through the Human Visual System: Finding Patterns and Limits}},
url = {http://people.psych.cornell.edu/~jec7/pubs/socialsciencecinema.pdf},
year = {2012}
}
@article{Jehee2009,
abstract = {Biphasic neural response properties, where the optimal stimulus for driving a neural response changes from one stimulus pattern to the opposite stimulus pattern over short periods of time, have been described in several visual areas, including lateral geniculate nucleus (LGN), primary visual cortex (V1), and middle temporal area (MT). We describe a hierarchical model of predictive coding and simulations that capture these temporal variations in neuronal response properties. We focus on the LGN-V1 circuit and find that after training on natural images the model exhibits the brain's LGN-V1 connectivity structure, in which the structure of V1 receptive fields is linked to the spatial alignment and properties of center-surround cells in the LGN. In addition, the spatio-temporal response profile of LGN model neurons is biphasic in structure, resembling the biphasic response structure of neurons in cat LGN. Moreover, the model displays a specific pattern of influence of feedback, where LGN receptive fields that are aligned over a simple cell receptive field zone of the same polarity decrease their responses while neurons of opposite polarity increase their responses with feedback. This phase-reversed pattern of influence was recently observed in neurophysiology. These results corroborate the idea that predictive feedback is a general coding strategy in the brain.},
author = {Jehee, Janneke F M and Ballard, Dana H},
doi = {10.1371/journal.pcbi.1000373},
file = {:Users/pkmital/Documents/Mendeley Desktop/Jehee, Ballard/Jehee, Ballard - 2009 - Predictive feedback can account for biphasic responses in the lateral geniculate nucleus. - PLoS computational biology.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Algorithms,Animals,Artificial Intelligence,Brain,Brain: physiology,Cats,Computer Simulation,Feedback,Geniculate Bodies,Geniculate Bodies: physiology,Models, Neurological,Neurons,Neurons: physiology,Visual Cortex,Visual Cortex: physiology},
month = may,
number = {5},
pages = {e1000373},
pmid = {19412529},
title = {{Predictive feedback can account for biphasic responses in the lateral geniculate nucleus.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2670540\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Bucci2001,
abstract = {In order to examine the minimum value of image-size inequality capable of inducing lasting disconjugacy of the amplitude of saccades, six normal emmetropic subjects were exposed for 16 min to 2\% image size inequality. Subjects were seated at 1 m in front of a screen where a random-dot pattern was projected and made saccades of 7.5 and 15 deg along the horizontal and vertical principal meridians and to tertiary positions in the upper and lower field. During the training period, compensatory disconjugacy of the amplitude of the saccades occurred for the principal horizontal and vertical meridians; such increased disconjugacy persisted after training, suggesting learning. In contrast, for horizontal saccades to or from tertiary positions made in the upper and lower field, no consistent changes in the disconjugacy occurred, either during training or after the training condition. In an additional experiment, three subjects read sequences of words with the 2\% magnifier in front of their dominant eye: in such a task, horizontal saccades to or from tertiary positions at the upper or lower field showed appropriate and lasting disconjugacy for two of the three subjects. We conclude that even a 2\% image size inequality stimulates oculomotor learning, leading to persistent disconjugacy of saccades. The small disparity created by the image-size inequality is thus compensated by the oculomotor system rather than tolerated by the sensory system (e.g. by enlarging the Panum's area).},
author = {Bucci, M P and Gomes, M and Paris, S and Kapoula, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bucci et al/Bucci et al. - 2001 - Disconjugate oculomotor learning caused by feeble image-size inequality differences between secondary and tertiary positions. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Aniseikonia,Aniseikonia: physiopathology,Humans,Learning,Learning: physiology,Reading,Saccades,Saccades: physiology,Vision Disparity,Vision Disparity: physiology},
month = mar,
number = {5},
pages = {625--37},
pmid = {11226507},
title = {{Disconjugate oculomotor learning caused by feeble image-size inequality: differences between secondary and tertiary positions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11226507},
volume = {41},
year = {2001}
}
@article{Guanqun2002,
author = {Guanqun, SJG},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guanqun/Guanqun - 2002 - 4d space Interactive architecture - Journal of Southeast Univwrsity (Natural Science.pdf:pdf},
journal = {Journal of Southeast Univwrsity (Natural Science},
title = {{4d space Interactive architecture}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.5534\&amp;rep=rep1\&amp;type=pdf http://en.cnki.com.cn/Article\_en/CJFDTOTAL-DNDX200201001.htm},
year = {2002}
}
@article{Parikh2009,
author = {Parikh, D. and Zitnick, C.L.},
doi = {10.1109/CVPR.2009.5206549},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Zitnick/Parikh, Zitnick - 2009 - Unsupervised learning of hierarchical spatial structures in images - 2009 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {2743--2750},
publisher = {Ieee},
title = {{Unsupervised learning of hierarchical spatial structures in images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206549},
year = {2009}
}
@inproceedings{Bresin2001,
abstract = {The control of sound synthesis is a well-known problem. This is particularly true if the modeling techniques that sounds are generated with physical typically need specification of numerous control parameters. In the present work outcomes from studies on automatic music performance are used for tackling this problem.},
address = {Limerick, Ireland},
author = {Bresin, R. and Friberg, A. and Dahl, S.},
booktitle = {Proc. COST-G6 Conf. Digital Audio Effects (DAFX-01)},
file = {::},
pages = {45--49},
title = {{Toward a New Model For Sound Control}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Toward+a+New+Model+For+Sound+Control\#0},
year = {2001}
}
@article{Koelewijn2010,
abstract = {Multisensory integration and crossmodal attention have a large impact on how we perceive the world. Therefore, it is important to know under what circumstances these processes take place and how they affect our performance. So far, no consensus has been reached on whether multisensory integration and crossmodal attention operate independently and whether they represent truly automatic processes. This review describes the constraints under which multisensory integration and crossmodal attention occur and in what brain areas these processes take place. Some studies suggest that multisensory integration and crossmodal attention take place in higher heteromodal brain areas, while others show the involvement of early sensory specific areas. Additionally, the current literature suggests that multisensory integration and attention interact depending on what processing level integration takes place. To shed light on this issue, different frameworks regarding the level at which multisensory interactions takes place are discussed. Finally, this review focuses on the question whether audiovisual interactions and crossmodal attention in particular are automatic processes. Recent studies suggest that this is not always the case. Overall, this review provides evidence for a parallel processing framework suggesting that both multisensory integration and attentional processes take place and can interact at multiple stages in the brain.},
author = {Koelewijn, Thomas and Bronkhorst, Adelbert and Theeuwes, Jan},
doi = {10.1016/j.actpsy.2010.03.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Koelewijn, Bronkhorst, Theeuwes/Koelewijn, Bronkhorst, Theeuwes - 2010 - Attention and the multiple stages of multisensory integration A review of audiovisual studies..pdf:pdf},
issn = {1873-6297},
journal = {Acta psychologica},
keywords = {Acoustic Stimulation,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Humans,Photic Stimulation,Visual Perception,Visual Perception: physiology},
month = jul,
number = {3},
pages = {372--84},
pmid = {20427031},
publisher = {Elsevier B.V.},
title = {{Attention and the multiple stages of multisensory integration: A review of audiovisual studies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20427031},
volume = {134},
year = {2010}
}
@article{Cristani2006,
author = {Cristani, M. and Bicego, M. and Murino, V.},
doi = {10.1109/CVPRW.2006.33},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cristani, Bicego, Murino/Cristani, Bicego, Murino - 2006 - Audio-Visual Foreground Extraction for Event Characterization - 2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06).pdf:pdf},
isbn = {0-7695-2646-2},
journal = {2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)},
number = {c},
pages = {116--116},
publisher = {Ieee},
title = {{Audio-Visual Foreground Extraction for Event Characterization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640559},
volume = {00},
year = {2006}
}
@article{Williamson2006,
author = {Williamson, John},
file = {:Users/pkmital/Documents/Mendeley Desktop/Williamson/Williamson - 2006 - Continuous uncertain interaction - Computing.pdf:pdf},
journal = {Computing},
number = {c},
title = {{Continuous uncertain interaction}},
url = {http://eprints.pascal-network.org/archive/00002495/},
volume = {2006},
year = {2006}
}
@article{Balas2006,
abstract = {Traditionally, texture perception has been studied using artificial textures made of random dots or repeated shapes. At the same time, computer algorithms for natural texture synthesis have improved dramatically. We seek to unify these two fields through a psychophysical assessment of a particular computational model, providing insight into which statistics are most vital for natural texture perception. We employ Portilla and Simoncelli's texture synthesis algorithm, a parametric model that mimics computations carried out in human vision. We find an intriguing interaction between texture type (periodic, structured, or 3-D textures) and image statistics (autocorrelation function and filter magnitude correlations), suggesting different representations may be employed for these texture families under pre-attentive viewing.},
author = {Balas, Benjamin J},
doi = {10.1016/j.visres.2005.04.013},
file = {:Users/pkmital/Documents/Mendeley Desktop/Balas/Balas - 2006 - Texture synthesis and perception using computational models to study texture representations in the human visual system..pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Algorithms,Analysis of Variance,Computer Simulation,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Models, Psychological,Psychological Tests,Psychophysics},
month = feb,
number = {3},
pages = {299--309},
pmid = {15964047},
title = {{Texture synthesis and perception: using computational models to study texture representations in the human visual system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15964047},
volume = {46},
year = {2006}
}
@article{Bacon1998,
abstract = {Cells in the superficial layers of the superior colliculus of the cat have mainly binocular receptive fields. The aim of the present experiment was to investigate the sensitivity of these cells to horizontal spatial disparity. Unit recordings were carried out in the superficial layers of the superior colliculus of paralyzed and anesthetized cats. Centrally located receptive fields were mapped, separated using prisms, and then stimulated simultaneously using two luminous bars optimally adjusted to the size of the excitatory region of the receptive fields. Only binocular cells were tested, and 65\% of these units were found to be sensitive to spatial disparities. Some cells (20\%) were clearly insensitive to spatial disparity and the remaining 15\% showed complex, unclassifiable interactions. The sensitive cells could be divided into four classes based on their disparity-sensitivity profiles: 38\% showed excitatory interactions, whereas 9\% showed inhibitory interactions. Moreover, 11\% and 7\% of the cells responded, respectively, to crossed or uncrossed disparities, and were classified as near cells and far cells. Whereas the general shapes of the sensitivity profiles were similar to those of cells in areas 17-18, selectivity in the superior colliculus was significantly coarser. The superficial layers of the superior colliculus project topographically to the deep layers of the superior colliculus, which are known to contain circuits involved in the control of ocular movements. The results thus suggest that disparity-sensitive cells of the superior colliculus could feed information to these oculomotor neurons, allowing for the localization and fixation of objects on the appropriate plane of vision.},
author = {Bacon, B a and Villemagne, J and Bergeron, a and Lepore, F and Guillemot, J P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bacon et al/Bacon et al. - 1998 - Spatial disparity coding in the superior colliculus of the cat. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Animals,Cats,Depth Perception,Depth Perception: physiology,Neurons,Neurons: physiology,Oculomotor Nerve,Oculomotor Nerve: cytology,Oculomotor Nerve: physiology,Sensory Thresholds,Sensory Thresholds: physiology,Superior Colliculi,Superior Colliculi: cytology,Superior Colliculi: physiology,Vision Disparity,Vision Disparity: physiology,Visual Fields,Visual Fields: physiology},
month = apr,
number = {3},
pages = {333--44},
pmid = {9551834},
title = {{Spatial disparity coding in the superior colliculus of the cat.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9551834},
volume = {119},
year = {1998}
}
@phdthesis{Milvich2004c,
author = {Milvich, Michael Lazar},
file = {::},
number = {July},
title = {{JavaCAVE: A 3D Immersive Environment in Java}},
year = {2004}
}
@article{Zheng2009,
author = {Zheng, Changxi and James, Doug L.},
doi = {10.1145/1531326.1531343},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {acoustic bubbles,acoustic transfer,and kinetic energy as,as compressed air and,basically,scale air bubbles,see figure 1,sound synthesis,surface tension,surrounding fluid vibrations,the bubble oscilla-,the impor-,tor stores potential energy},
month = jul,
number = {3},
pages = {1},
title = {{Harmonic fluids}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531343},
volume = {28},
year = {2009}
}
@article{Kimura2006b,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2006 - Universal source coding for complementary delivery - Symposium A Quarterly Journal In Modern Foreign Literatures.pdf:pdf},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
keywords = {bipartite graphs,complementary,delivery,multiterminal source coding,type of sequences,universal coding},
title = {{Universal source coding for complementary delivery}},
year = {2006}
}
@article{Prinz2003,
author = {Prinz, Jesse J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prinz/Prinz - 2003 - A Neurofunctional Theory of Consciousness - Philosophy.pdf:pdf},
journal = {Philosophy},
number = {June},
pages = {1--11},
title = {{A Neurofunctional Theory of Consciousness}},
year = {2003}
}
@article{Kimura2008b,
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
doi = {10.1109/TASL.2007.912362},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - 2008 - A Quick Search Method for Audio Signals Based on a Piecewise Linear Representation of Feature Trajectories - IEEE Transactions on Audio, Speech, and Language Processing.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
month = feb,
number = {2},
pages = {396--407},
title = {{A Quick Search Method for Audio Signals Based on a Piecewise Linear Representation of Feature Trajectories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4432644},
volume = {16},
year = {2008}
}
@article{Naselaris2011,
abstract = {Over the past decade fMRI researchers have developed increasingly sensitive techniques for analyzing the information represented in BOLD activity. The most popular of these techniques is linear classification, a simple technique for decoding information about experimental stimuli or tasks from patterns of activity across an array of voxels. A more recent development is the voxel-based encoding model, which describes the information about the stimulus or task that is represented in the activity of single voxels. Encoding and decoding are complementary operations: encoding uses stimuli to predict activity while decoding uses activity to predict information about the stimuli. However, in practice these two operations are often confused, and their respective strengths and weaknesses have not been made clear. Here we use the concept of a linearizing feature space to clarify the relationship between encoding and decoding. We show that encoding and decoding operations can both be used to investigate some of the most common questions about how information is represented in the brain. However, focusing on encoding models offers two important advantages over decoding. First, an encoding model can in principle provide a complete functional description of a region of interest, while a decoding model can provide only a partial description. Second, while it is straightforward to derive an optimal decoding model from an encoding model it is much more difficult to derive an encoding model from a decoding model. We propose a systematic modeling approach that begins by estimating an encoding model for every voxel in a scan and ends by using the estimated encoding models to perform decoding.},
author = {Naselaris, Thomas and Kay, Kendrick N and Nishimoto, Shinji and Gallant, Jack L},
doi = {10.1016/j.neuroimage.2010.07.073},
file = {:Users/pkmital/Documents/Mendeley Desktop/Naselaris et al/Naselaris et al. - 2011 - Encoding and decoding in fMRI. - NeuroImage.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Computational neuroscience,Decoding,Encoding,Linear classifier,Multi-voxel pattern analysis,fMRI},
month = may,
number = {2},
pages = {400--10},
pmid = {20691790},
publisher = {Elsevier B.V.},
title = {{Encoding and decoding in fMRI.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3037423\&tool=pmcentrez\&rendertype=abstract},
volume = {56},
year = {2011}
}
@article{Brockmole2008a,
author = {Brockmole, James and Henderson, John},
doi = {10.1080/13506280701453623},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmole, Henderson/Brockmole, Henderson - 2008 - Prioritizing new objects for eye fixation in real-world scenes Effects of object-scene consistency - Visual Cognition(2).pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {2},
pages = {375--390},
title = {{Prioritizing new objects for eye fixation in real-world scenes: Effects of object-scene consistency}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280701453623\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2008}
}
@article{Tagg2001,
author = {Tagg, Philip and Collins, Karen E},
file = {::},
journal = {Sound Practice},
pages = {1--11},
title = {{The Sonic Aesthetics of the Industrial: Re-Constructing Yesterday's Soundscape for Today's Alienation and Tomorrow's Dystopia}},
year = {2001}
}
@article{Biederman2008,
author = {Biederman, Irving},
file = {:Users/pkmital/Documents/Mendeley Desktop/Biederman/Biederman - 2008 - Perceiving Real-World Scenes Published by American Association for the Advancement of Science Stable URL httpwww.jstor.orgstable1733939 Perceiving Real-World Scenes - Advancement Of Science.pdf:pdf},
journal = {Advancement Of Science},
number = {4043},
pages = {77--80},
title = {{Perceiving Real-World Scenes Published by : American Association for the Advancement of Science Stable URL : http://www.jstor.org/stable/1733939 Perceiving Real-World Scenes}},
volume = {177},
year = {2008}
}
@inproceedings{Collins2009a,
abstract = {Recently, “smart” table-top touchscreen comput- ers, in which users position themselves around a horizontal computer screen, have been introduced. Although the use of touchscreen computers is still not widespread, given the growing popularity of multi-touch mobility devices (e.g., iPods, smart- phones), the move to multi-user touchscreens and a horizontal surface is a likely trajectory of the technology. However, before table-top touch- screen computing becomes widely accepted, there are many questions, particularly with respect to sound production and reception, and multi-modal interaction for these devices that need to be ex- plored. In this paper we provide an overview of a table-top touchscreen computer setup and de- scribe a simple amplitude panning method for the output of sound amongst four loudspeakers. The paper begins with a background on sound interac- tion design.},
author = {Collins, Karen and Kapralos, Bill and Kanev, Kamen},
booktitle = {Proceedings of the 12th International Conference on Humans and Computers},
file = {::},
keywords = {audio-video interaction,computer,human-computer interaction,smart table computer,sound interac-,table-top,tion design},
title = {{Sound Interface Design for Smart Table Computer Interaction}},
year = {2009}
}
@article{Greene2009,
abstract = {What information is available from a brief glance at a novel scene? Although previous efforts to answer this question have focused on scene categorization or object detection, real-world scenes contain a wealth of information whose perceptual availability has yet to be explored. We compared image exposure thresholds in several tasks involving basic-level categorization or global- property classification. All thresholds were remarkably short: Observers achieved 75\%-correct performance with presentations ranging from 19 to 67 ms, reaching maximum performance at about 100 ms. Global-property categorization was performed with significantly less presentation time than basic-level categorization, which suggests that there exists a time during early visual processing when a scene may be classified as, for example, a large space or navigable, but not yet as a mountain or lake. Comparing the relative availability of visual information reveals bottlenecks in the accumulation of meaning. Understanding these bottlenecks provides critical insight into the computations underlying rapid visual understanding.},
author = {Greene, Michelle R and Oliva, Aude},
file = {:Users/pkmital/Documents/Mendeley Desktop/Greene, Oliva/Greene, Oliva - 2009 - The briefest of glances the time course of natural scene understanding. - Psychological science a journal of the American Psychological Society APS.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science : a journal of the American Psychological Society / APS},
keywords = {Adolescent,Adult,Cognition,Female,Fixation, Ocular,Humans,Male,Time Factors,Visual Perception,Young Adult},
month = apr,
number = {4},
pages = {464--72},
pmid = {19399976},
title = {{The briefest of glances: the time course of natural scene understanding.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2742770\&tool=pmcentrez\&rendertype=abstract},
volume = {20},
year = {2009}
}
@article{Walther2006,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Walther, Koch/Walther, Koch - 2006 - Modeling attention to salient proto-objects. - Neural networks the official journal of the International Neural Network Society.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Attention,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models, Biological,Neural Networks (Computer),Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,ROC Curve},
month = nov,
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling attention to salient proto-objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17098563},
volume = {19},
year = {2006}
}
@article{Biederman1985,
abstract = {The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into simple volumetric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of components N probably 36 can be derived from contrasts of five readily detectable properties of edges in a 2-dimensional image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position and image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. A principle of componential recovery can account for the major phenomena of object recognition: If an arrangement of two or three primitive components can be recovered from the input, objects can be quickly recognized even when they are occluded, rotated in depth, novel, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory.},
author = {Biederman, I},
isbn = {0125973454},
issn = {0734189X},
journal = {Computer Vision Graphics and Image Processing},
number = {1},
pages = {29--73},
publisher = {Elsevier},
title = {{Human image understanding: Recent research and a theory}},
url = {http://www.sciencedirect.com/science/article/pii/0734189X85900027},
volume = {32},
year = {1985}
}
@article{Schwarz2010,
author = {Schwarz, Diemo and Schnell, Norbert},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz, Schnell/Schwarz, Schnell - 2010 - Descriptor-based sound texture sampling - Proceedings of SMC Conference 2010.pdf:pdf},
journal = {Proceedings of SMC Conference 2010},
number = {July},
title = {{Descriptor-based sound texture sampling}},
url = {http://www.topophonie.fr/content/publications/3/file.pdf},
year = {2010}
}
@article{Rizzolatti1987,
abstract = {Stimuli presented in a non-attended location are responded to much slower than stimuli presented in an attended one. The hypotheses proposed to explain this effect make reference to covert movement of attention, hemifield inhibition, or attentional gradients. The experiment reported here was aimed at discriminating among these hypotheses. Subjects were cued to attend to one of four possible stimulus locations, which were arranged either horizontally or vertically, above, below, to the right or left of a fixation point. The instructions were to respond manually as fast as possible to the occurrence of a visual stimulus, regardless of whether it occurred in a cued or in a non-cued location. In 70\% of the cued trials the stimulus was presented in the cued location and in 30\% in one of the non-cued locations. In addition there were trials in which a non-directional cue instructed the subject to pay attention to all four locations. The results showed that the correct orienting of attention yielded a small but significant benefit; the incorrect orienting of attention yielded a large and significant cost; the cost tended to increase as a function of the distance between the attended location and the location that was actually stimulated; and an additional cost was incurred when the stimulated and attended locations were on opposite sides of the vertical or horizontal meridian. We concluded that neither the hypothesis postulating hemifield inhibition nor that postulating movement of attention with a constant time can explain the data. The hypothesis of an attention gradient and that of attention movements with a constant speed are tenable in principle, but they fail to account for the effect of crossing the horizontal and vertical meridians. A hypothesis is proposed that postulates a strict link between covert orienting of attention and programming explicit ocular movements. Attention is oriented to a given point when the oculomotor programme for moving the eyes to this point is ready to be executed. Attentional cost is the time required to erase one ocular program and prepare the next one.},
author = {Rizzolatti, G and Riggio, L and Dascola, I and Umilt\'{a}, C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rizzolatti et al/Rizzolatti et al. - 1987 - Reorienting attention across the horizontal and vertical meridians evidence in favor of a premotor theory of.pdf:pdf},
issn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Attention,Cues,Dominance, Cerebral,Humans,Male,Orientation,Psychomotor Performance,Reaction Time,Visual Perception},
month = jan,
number = {1A},
pages = {31--40},
pmid = {3574648},
title = {{Reorienting attention across the horizontal and vertical meridians: evidence in favor of a premotor theory of attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3574648},
volume = {25},
year = {1987}
}
@article{Theis2005,
author = {Theis, FJ and Gruber, Peter and Keck, IR},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theis, Gruber, Keck/Theis, Gruber, Keck - 2005 - Spatiotemporal blind source separation using double-sided approximate joint diagonalization - Proc. EUSIPCO.pdf:pdf},
journal = {Proc. EUSIPCO},
pages = {1--4},
title = {{Spatiotemporal blind source separation using double-sided approximate joint diagonalization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1144\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@article{Inhoff2006,
abstract = {A. Pollatsek, E. D. Reichle, and K. Rayner argue that the critical findings in A. W. Inhoff, B. M. Eiter, and R. Radach are in general agreement with core assumptions of sequential attention shift models if additional assumptions and facts are considered. The current authors critically discuss the hypothesized time line of processing and indicate that the success of Pollatsek et al.'s simulation is predicated on a gross underestimation of the pretarget word's viewing duration in Inhoff et al. and that the actual data are difficult to reconcile with the strictly serial attention shift assumption. The authors also discuss attention shifting and saccade programming assumptions in the E-Z Reader model and conclude that these are not in harmony with research in related domains of study.},
author = {Inhoff, Albrecht W and Radach, Ralph and Eiter, Brianna},
doi = {10.1037/0096-1523.32.6.1490},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff, Radach, Eiter/Inhoff, Radach, Eiter - 2006 - Temporal overlap in the linguistic processing of successive words in reading reply to Pollatsek, Reichle, and Rayner (2006a). - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Attention,Fixation, Ocular,Humans,Mental Processes,Models, Psychological,Psycholinguistics,Reading,Saccades},
month = dec,
number = {6},
pages = {1490--5},
pmid = {17154788},
title = {{Temporal overlap in the linguistic processing of successive words in reading: reply to Pollatsek, Reichle, and Rayner (2006a).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17154788},
volume = {32},
year = {2006}
}
@article{Liang2001a,
author = {Liang, Lin and Liu, Ce and Xu, Ying-Qing and Guo, Baining and Shum, Heung-Yeung},
doi = {10.1145/501786.501787},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liang et al/Liang et al. - 2001 - Real-time texture synthesis by patch-based sampling - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = jul,
number = {3},
pages = {127--150},
title = {{Real-time texture synthesis by patch-based sampling}},
url = {http://portal.acm.org/citation.cfm?doid=501786.501787},
volume = {20},
year = {2001}
}
@article{Perronnin2012,
author = {Perronnin, F. and Akata, Z. and Harchaoui, Z. and Schmid, C.},
doi = {10.1109/CVPR.2012.6248090},
file = {:Users/pkmital/Documents/Mendeley Desktop/Perronnin et al/Perronnin et al. - 2012 - Towards good practice in large-scale learning for image classification - 2012 IEEE Conference on Computer Visi.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {3482--3489},
publisher = {Ieee},
title = {{Towards good practice in large-scale learning for image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6248090},
year = {2012}
}
@article{Mairal2009,
author = {Mairal, Julien and Bach, Francis and Ponce, J and Sapiro, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mairal et al/Mairal et al. - 2009 - Online dictionary learning for sparse coding - \ldots Conference on Machine Learning.pdf:pdf},
journal = {\ldots Conference on Machine Learning},
title = {{Online dictionary learning for sparse coding}},
url = {http://dl.acm.org/citation.cfm?id=1553463},
year = {2009}
}
@article{Baars1997,
abstract = {When "divided attention" methods were discovered in the 1950s their implications for conscious experience were not widely appreciated. Yet when people process competing streams of sensory input they show both selective processes and clear contrasts between conscious and unconscious events. This paper suggests that the term "attention" may be best applied to the selection and maintenance of conscious contents and distinguished from consciousness itself. This is consistent with common usage. The operational criteria for selective attention, defined in this way, are entirely different from those used to assess consciousness. To illustrate the scientific usefulness of the distinction it is applied to Posner's (1994) brain model of visual attention. It seems that features that are often attributed to attention-like limited capacity-may more accurately be viewed as properties of consciousness.},
author = {Baars, B J},
doi = {10.1006/ccog.1997.0307},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baars/Baars - 1997 - Some essential differences between consciousness and attention, perception, and working memory. - Consciousness and cogni.pdf:pdf},
issn = {1053-8100},
journal = {Consciousness and cognition},
keywords = {Attention,Consciousness,Humans,Memory,Perception},
number = {2-3},
pages = {363--71},
pmid = {9262417},
title = {{Some essential differences between consciousness and attention, perception, and working memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9262417},
volume = {6},
year = {1997}
}
@article{Winkler2005b,
abstract = {We investigated the role of attention in feature binding in the auditory and the visual modality. One auditory and one visual experiment used the mismatch negativity (MMN and vMMN, respectively) event-related potential to index the memory representations created from stimulus sequences, which were either task-relevant and, therefore, attended or task-irrelevant and ignored. In the latter case, the primary task was a continuous demanding within-modality task. The test sequences were composed of two frequently occurring stimuli, which differed from each other in two stimulus features (standard stimuli) and two infrequently occurring stimuli (deviants), which combined one feature from one standard stimulus with the other feature of the other standard stimulus. Deviant stimuli elicited MMN responses of similar parameters across the different attentional conditions. These results suggest that the memory representations involved in the MMN deviance detection response encoded the frequently occurring feature combinations whether or not the test sequences were attended. A possible alternative to the memory-based interpretation of the visual results, the elicitation of the McCollough color-contingent aftereffect, was ruled out by the results of our third experiment. The current results are compared with those supporting the attentive feature integration theory. We conclude that (1) with comparable stimulus paradigms, similar results have been obtained in the two modalities, (2) there exist preattentive processes of feature binding, however, (3) conjoining features within rich arrays of objects under time pressure and/or longterm retention of the feature-conjoined memory representations may require attentive processes.},
author = {Winkler, Istv\'{a}n and Czigler, Istv\'{a}n and Sussman, Elyse and Horv\'{a}th, J\'{a}nos and Bal\'{a}zs, L\'{a}szlo},
doi = {10.1162/0898929053124866},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Acoustic Stimulation,Adolescent,Adult,Analysis of Variance,Attention,Attention: physiology,Brain,Brain Mapping,Brain: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Female,Humans,Male,Memory,Memory: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Speech Perception},
month = feb,
number = {2},
pages = {320--39},
pmid = {15811243},
publisher = {MIT Press},
title = {{Preattentive binding of auditory and visual stimulus features.}},
url = {http://dl.acm.org/citation.cfm?id=1160567.1160571},
volume = {17},
year = {2005}
}
@article{Zeng2009,
author = {Zeng, K and Zhao, M and Xiong, C and Zhu, SC},
doi = {10.1145/1640443.1640445},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zeng et al/Zeng et al. - 2009 - From image parsing to painterly rendering - ACM Transactions on Graphics (TOG).pdf:pdf},
journal = {ACM Transactions on Graphics (TOG)},
number = {1},
title = {{From image parsing to painterly rendering}},
url = {http://dl.acm.org/citation.cfm?id=1640445},
volume = {29},
year = {2009}
}
@article{Kimura2007b,
author = {Kimura, a. and Uyematsu, T. and Kuzuoka, S.},
doi = {10.1093/ietfec/e90-a.9.1840},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Kuzuoka/Kimura, Uyematsu, Kuzuoka - 2007 - Universal Coding for Correlated Sources with Complementary Delivery - IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences.pdf:pdf},
issn = {0916-8508},
journal = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
month = sep,
number = {9},
pages = {1840--1847},
title = {{Universal Coding for Correlated Sources with Complementary Delivery}},
url = {http://search.ieice.org/bin/summary.php?id=e90-a\_9\_1840\&category=A\&year=2007\&lang=E\&abst=},
volume = {E90-A},
year = {2007}
}
@inproceedings{Neumayer2007,
author = {Neumayer, Robert and Rauber, Andreas},
booktitle = {In Proceedings of the 8th Conference Recherche d’Information Assist\'{e}e par Ordinateur (RIAO’07)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Neumayer, Rauber/Neumayer, Rauber - 2007 - Multi-modal music information retrieval visualisation and evaluation of clusterings by both audio and lyr.pdf:pdf},
title = {{Multi-modal music information retrieval: visualisation and evaluation of clusterings by both audio and lyrics}},
url = {http://dl.acm.org/citation.cfm?id=1931398},
year = {2007}
}
@article{Theeuwes1991,
abstract = {Two experiments were carried out to investigate the relation between exogenous and endogenous control of visual attention. Subjects searched for a target letter among three nontarget letters that were positioned on an imaginary circle around a fixation point. At different cue-display intervals, a centrally located arrowhead cue reliably indicated the location of the target letter. At different SOAs, a peripheral line segment near one of the letters was either abruptly switched on (Experiment 1) or abruptly switched off (Experiment 2). Presenting the central arrowhead after display onset prevents attention from being focused in advance on the critical location. In this unfocused attentional state, both onset and offset transients attracted attention. When the central arrowhead was available in advance, the focusing of attention prior to display onset precluded attention attraction to the location of the onset or offset transient. Contrary to an offset transient, an onset transient presented at the attended location disrupted performance, indicating that an onset within the spotlight of attention attracts attention. The results are reconciled by means of the zoom-lens theory of attention, suggesting that outside the focus of attention, abrupt transients are not capable of attracting attention. Since the size of the zoom lens is under voluntary control, it can be argued that transients do not fulfill the intentionality criterion of automaticity.},
author = {Theeuwes, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theeuwes/Theeuwes - 1991 - Exogenous and endogenous control of attention the effect of visual onsets and offsets. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Discrimination Learning,Humans,Orientation,Pattern Recognition, Visual},
month = jan,
number = {1},
pages = {83--90},
pmid = {2011456},
title = {{Exogenous and endogenous control of attention: the effect of visual onsets and offsets.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2011456},
volume = {49},
year = {1991}
}
@article{Kim2004,
author = {Kim, HG and Moreau, Nicolas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kim, Moreau/Kim, Moreau - 2004 - Audio classification based on MPEG-7 spectral basis representations - Circuits and Systems for Video.pdf:pdf},
journal = {Circuits and Systems for Video},
number = {5},
pages = {716--725},
title = {{Audio classification based on MPEG-7 spectral basis representations}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1294962},
volume = {14},
year = {2004}
}
@article{Bencina2005c,
author = {Bencina, R. and Kaltenbrunner, M. and Jorda, S.},
file = {::},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
pages = {99--99},
publisher = {Ieee},
title = {{Improved Topological Fiducial Tracking in the reacTIVision System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565409},
year = {2005}
}
@article{McDermott2013,
abstract = {Sensory signals are transduced at high resolution, but their structure must be stored in a more compact format. Here we provide evidence that the auditory system summarizes the temporal details of sounds using time-averaged statistics. We measured discrimination of 'sound textures' that were characterized by particular statistical properties, as normally result from the superposition of many acoustic features in auditory scenes. When listeners discriminated examples of different textures, performance improved with excerpt duration. In contrast, when listeners discriminated different examples of the same texture, performance declined with duration, a paradoxical result given that the information available for discrimination grows with duration. These results indicate that once these sounds are of moderate length, the brain's representation is limited to time-averaged statistics, which, for different examples of the same texture, converge to the same values with increasing duration. Such statistical representations produce good categorical discrimination, but limit the ability to discern temporal detail.},
author = {McDermott, Josh H and Schemitsch, Michael and Simoncelli, Eero P},
doi = {10.1038/nn.3347},
file = {:Users/pkmital/Documents/Mendeley Desktop/McDermott, Schemitsch, Simoncelli/McDermott, Schemitsch, Simoncelli - 2013 - Summary statistics in auditory perception. - Nature neuroscience.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adolescent,Adult,Auditory Perception,Auditory Perception: physiology,Discrimination Learning,Discrimination Learning: physiology,Female,Humans,Male,Psychomotor Performance,Psychomotor Performance: physiology,Young Adult},
month = apr,
number = {4},
pages = {493--8},
pmid = {23434915},
title = {{Summary statistics in auditory perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23434915},
volume = {16},
year = {2013}
}
@article{Hollingworth1998,
abstract = {The conclusion that scene knowledge interacts with object perception depends on evidence that object detection is facilitated by consistent scene context. Experiment 1 replicated the I. Biederman, R. J. Mezzanotte, and J. C. Rabinowitz (1982) object-detection paradigm. Detection performance was higher for semantically consistent versus inconsistent objects. However, when the paradigm was modified to control for response bias (Experiments 2 and 3) or when response bias was eliminated by means of a forced-choice procedure (Experiment 4), no such advantage obtained. When an additional source of biasing information was eliminated by presenting the object label after the scene (Experiments 3 and 4), there was either no effect of consistency (Experiment 4) or an inconsistent object advantage (Experiment 3). These results suggest that object perception is not facilitated by consistent scene context.},
author = {Hollingworth, a and Henderson, J M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Henderson/Hollingworth, Henderson - 1998 - Does consistent scene context facilitate object perception - Journal of experimental psychology. General.pdf:pdf},
issn = {0096-3445},
journal = {Journal of experimental psychology. General},
keywords = {Adult,Attention,Concept Formation,Discrimination Learning,Female,Field Dependence-Independence,Humans,Male,Mental Recall,Pattern Recognition, Visual,Semantics},
month = dec,
number = {4},
pages = {398--415},
pmid = {9857494},
title = {{Does consistent scene context facilitate object perception?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9857494},
volume = {127},
year = {1998}
}
@article{Duan2012,
author = {Duan, Zhiyao and Mysore, Gautham J and Smaragdis, Paris},
file = {:Users/pkmital/Documents/Mendeley Desktop/Duan, Mysore, Smaragdis/Duan, Mysore, Smaragdis - 2012 - Online PLCA for Real-time Semi-supervised Source Separation - Proceedings of the international conferen.pdf:pdf},
journal = {Proceedings of the international conference on Latent Variable Analysis / Independent Component Analysis},
pages = {1--8},
title = {{Online PLCA for Real-time Semi-supervised Source Separation}},
year = {2012}
}
@article{Treisman1992,
abstract = {A number of experiments exploring priming effects and automatization in the perception of novel objects are described, and a framework for understanding the benefits and costs of re-perceiving previously seen objects is proposed. The suggestion is that perceiving an object creates a temporary representation in an object file that collects, integrates, and updates information about its current characteristics. The contents of an object file may be stored as an object token and retrieved next time the object appears. This facilitates its re-perception when all of the attributes match and may impair it if some are changed. Thus, the world molds our minds to capitalize on earlier experiences but at the same time leaves us able readily to detect and represent any novel or unexpected objects and events.},
author = {Treisman, Anne},
file = {:Users/pkmital/Documents/Mendeley Desktop/Treisman/Treisman - 1992 - Perceiving and re-perceiving objects. - American Psychologist.pdf:pdf},
issn = {0003-066X},
journal = {American Psychologist},
keywords = {Attention,Discrimination Learning,Humans,Memory,Mental Recall,Orientation,Pattern Recognition,Retention (Psychology),Short-Term,Visual},
month = jul,
number = {7},
pages = {862--75},
pmid = {1497217},
title = {{Perceiving and re-perceiving objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1497217},
volume = {47},
year = {1992}
}
@article{Slaney2012,
author = {Slaney, Malcolm and Lifshits, Yury and He, Junfeng},
doi = {10.1109/JPROC.2012.2193849},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slaney, Lifshits, He/Slaney, Lifshits, He - 2012 - Optimal Parameters for Locality-Sensitive Hashing - Proceedings of the IEEE.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = sep,
number = {9},
pages = {2604--2623},
title = {{Optimal Parameters for Locality-Sensitive Hashing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6242372},
volume = {100},
year = {2012}
}
@article{Miyawaki2008,
abstract = {Perceptual experience consists of an enormous number of possible states. Previous fMRI studies have predicted a perceptual state by classifying brain activity into prespecified categories. Constraint-free visual image reconstruction is more challenging, as it is impractical to specify brain activity for all possible images. In this study, we reconstructed visual images by combining local image bases of multiple scales, whose contrasts were independently decoded from fMRI activity by automatically selecting relevant voxels and exploiting their correlated patterns. Binary-contrast, 10 x 10-patch images (2(100) possible states) were accurately reconstructed without any image prior on a single trial or volume basis by measuring brain activity only for several hundred random images. Reconstruction was also used to identify the presented image among millions of candidates. The results suggest that our approach provides an effective means to read out complex perceptual states from brain activity while discovering information representation in multivoxel patterns.},
author = {Miyawaki, Yoichi and Uchida, Hajime and Yamashita, Okito and Sato, Masa-aki and Morito, Yusuke and Tanabe, Hiroki C and Sadato, Norihiro and Kamitani, Yukiyasu},
doi = {10.1016/j.neuron.2008.11.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Miyawaki et al/Miyawaki et al. - 2008 - Visual image reconstruction from human brain activity using a combination of multiscale local image decoders. -.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Brain,Brain Mapping,Brain: anatomy \& histology,Brain: blood supply,Brain: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Female,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Oxygen,Oxygen: blood,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods},
month = dec,
number = {5},
pages = {915--29},
pmid = {19081384},
publisher = {Elsevier Inc.},
title = {{Visual image reconstruction from human brain activity using a combination of multiscale local image decoders.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19081384},
volume = {60},
year = {2008}
}
@article{Fields2007,
author = {Fields, Benjamin and Casey, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fields, Casey/Fields, Casey - 2007 - Using Audio Classifiers as a Mechanism for Content Based Song Similarity - aes.org.pdf:pdf},
journal = {aes.org},
pages = {1--8},
title = {{Using Audio Classifiers as a Mechanism for Content Based Song Similarity}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=14325},
year = {2007}
}
@article{Borst1999,
abstract = {Information theory quantifies how much information a neural response carries about the stimulus. This can be compared to the information transferred in particular models of the stimulus-response function and to maximum possible information transfer. Such comparisons are crucial because they validate assumptions present in any neurophysiological analysis. Here we review information-theory basics before demonstrating its use in neural coding. We show how to use information theory to validate simple stimulus-response models of neural coding of dynamic stimuli. Because these models require specification of spike timing precision, they can reveal which time scales contain information in neural coding. This approach shows that dynamic stimuli can be encoded efficiently by single neurons and that each spike contributes to information transmission. We argue, however, that the data obtained so far do not suggest a temporal code, in which the placement of spikes relative to each other yields additional information.},
author = {Borst, a and Theunissen, F E},
doi = {10.1038/14731},
file = {:Users/pkmital/Documents/Mendeley Desktop/Borst, Theunissen/Borst, Theunissen - 1999 - Information theory and neural coding. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Algorithms,Animals,Entropy,Humans,Information Theory,Linear Models,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Probability,Reproducibility of Results},
month = nov,
number = {11},
pages = {947--57},
pmid = {10526332},
title = {{Information theory and neural coding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10526332},
volume = {2},
year = {1999}
}
@article{Sparacino2001,
author = {Sparacino, Flavia},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sparacino/Sparacino - 2001 - ( Some ) computer vision based interfaces for interactive art and entertainment installations - City.pdf:pdf},
journal = {City},
title = {{( Some ) computer vision based interfaces for interactive art and entertainment installations}},
year = {2001}
}
@article{James,
author = {James, William},
file = {:Users/pkmital/Documents/Mendeley Desktop/James/James - Unknown - The Principles of Psychology - Unknown.pdf:pdf},
title = {{The principles of psychology, Vol I.}},
url = {http://psycnet.apa.org/psycinfo/2004-16192-000},
year = {1890}
}
@article{Casey2008c,
author = {Casey, Michael A and Veltkamp, Remco and Goto, Masataka and Leman, Marc and Rhodes, Christophe and Slaney, Malcolm},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey et al/Casey et al. - 2008 - Content-Based Music Information Retrieval Current Directions and Future Challenges - Proceedings of the IEEE.pdf:pdf},
journal = {Proceedings of the IEEE},
number = {4},
title = {{Content-Based Music Information Retrieval : Current Directions and Future Challenges}},
volume = {96},
year = {2008}
}
@article{Potter1969,
abstract = {Examined memory for visual events occurring at and near the rate of eye fixations. In Exp. I, 48 undergraduates were shown 8 films of 16 unrelated pictures presented at 1/2, 1, 2, 3, 4, 6, or 8/sec. Later recognition ranged from 93-16\%. In Exp. II with 32 Ss, rates were mixed within each sequence to determine whether the probability of recognizing 1 item is independent of the presentation time of the previous item. The results support the hypothesis that rapidly presented pictures are processed 1 by 1 for precisely the time each is in view and are not held with other items in a short-term store as has been reported for verbal material. (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Potter, Mary C and Levy, Ellen I},
doi = {10.1037/h0027470},
issn = {00221015},
journal = {Journal of Experimental Psychology},
number = {1},
pages = {10--15},
title = {{Recognition memory for a rapid sequence of pictures}},
volume = {81},
year = {1969}
}
@article{Tallon-Baudry1997,
abstract = {The coherent representation of an object in the visual system has been suggested to be achieved by the synchronization in the gamma-band (30-70 Hz) of a distributed neuronal assembly. Here we measure variations of high-frequency activity on the human scalp. The experiment is designed to allow the comparison of two different perceptions of the same picture. In the first condition, an apparently meaningless picture that contained a hidden Dalmatian, a neutral stimulus, and a target stimulus (twirled blobs) are presented. After the subject has been trained to perceive the hidden dog and its mirror image, the second part of the recordings is performed (condition 2). The same neutral stimulus is presented, intermixed with the picture of the dog and its mirror image (target stimulus). Early (95 msec) phase-locked (or stimulus-locked) gamma-band oscillations do not vary with stimulus type but can be subdivided into an anterior component (38 Hz) and a posterior component (35 Hz). Nonphase-locked gamma-band oscillations appear with a latency jitter around 280 msec after stimulus onset and disappear in averaged data. They increase in amplitude in response to both target stimuli. They also globally increase in the second condition compared with the first one. It is suggested that this gamma-band energy increase reflects both bottom-up (binding of elementary features) and top-down (search for the hidden dog) activation of the same neural assembly coding for the Dalmatian. The relationships between high- and low-frequency components of the response are discussed, and a possible functional role of each component is suggested.},
author = {Tallon-Baudry, C and Bertrand, O and Delpuech, C and Permier, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tallon-Baudry et al/Tallon-Baudry et al. - 1997 - Oscillatory gamma-band (30-70 Hz) activity induced by a visual search task in humans. - The Journal of neuroscience the official journal of the Society for Neuroscience.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adult,Animals,Attention,Dogs,Electroencephalography,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Time Factors,Visual Perception,Visual Perception: physiology},
month = jan,
number = {2},
pages = {722--34},
pmid = {8987794},
title = {{Oscillatory gamma-band (30-70 Hz) activity induced by a visual search task in humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8987794},
volume = {17},
year = {1997}
}
@article{Mariette2006,
author = {Mariette, Nick},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mariette/Mariette - 2006 - Perceptual Evaluation of Spatial Audio for “Audio Nomad” Augmented Reality Artworks - Cartography(2).pdf:pdf},
journal = {Cartography},
title = {{Perceptual Evaluation of Spatial Audio for “Audio Nomad” Augmented Reality Artworks}},
year = {2006}
}
@article{Huber2008,
author = {Huber, Marco F. and Bailey, Tim and Durrant-Whyte, Hugh and Hanebeck, Uwe D.},
doi = {10.1109/MFI.2008.4648062},
file = {:Users/pkmital/Documents/Mendeley Desktop/Huber et al/Huber et al. - 2008 - On entropy approximation for Gaussian mixture random vectors - 2008 IEEE International Conference on Multisensor F.pdf:pdf},
isbn = {978-1-4244-2143-5},
journal = {2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems},
month = aug,
pages = {181--188},
publisher = {Ieee},
title = {{On entropy approximation for Gaussian mixture random vectors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4648062},
year = {2008}
}
@article{Panin2007a,
author = {Panin, Giorgio and Knoll, Alois},
doi = {10.1007/s11263-007-0083-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Panin, Knoll/Panin, Knoll - 2007 - Mutual Information-Based 3D Object Tracking - International Journal of Computer Vision.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {3d tracking,b-spline,information,interpolation,multiresolution,mutual,nonlinear optimization,surface-image alignment,template},
month = oct,
number = {1},
pages = {107--118},
title = {{Mutual Information-Based 3D Object Tracking}},
url = {http://www.springerlink.com/index/10.1007/s11263-007-0083-7},
volume = {78},
year = {2007}
}
@article{Cutting2010,
abstract = {Reaction times exhibit a spectral patterning known as 1/f, and these patterns can be thought of as reflecting time-varying changes in attention. We investigated the shot structure of Hollywood films to determine if these same patterns are found. We parsed 150 films with release dates from 1935 to 2005 into their sequences of shots and then analyzed the pattern of shot lengths in each film. Autoregressive and power analyses showed that, across that span of 70 years, shots became increasingly more correlated in length with their neighbors and created power spectra approaching 1/f. We suggest, as have others, that 1/f patterns reflect world structure and mental process. Moreover, a 1/f temporal shot structure may help harness observers' attention to the narrative of a film.},
author = {Cutting, James E and DeLong, Jordan E and Nothelfer, Christine E},
doi = {10.1177/0956797610361679},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cutting, DeLong, Nothelfer/Cutting, DeLong, Nothelfer - 2010 - Attention and the evolution of Hollywood film. - Psychological science.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {Attention,Awareness,Fourier Analysis,Humans,Motion Perception,Motion Pictures as Topic,Motion Pictures as Topic: trends,Narration,Optical Illusions,Pattern Recognition, Visual,Photography,Photography: trends,Reaction Time,Signal Detection, Psychological},
month = mar,
number = {3},
pages = {432--9},
pmid = {20424081},
title = {{Attention and the evolution of Hollywood film.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20424081},
volume = {21},
year = {2010}
}
@article{Huang2011,
author = {Huang, PS and Zhuang, Xiaodan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Huang, Zhuang/Huang, Zhuang - 2011 - Improving acoustic event detection using generalizable visual features and multi-modality modeling - Acoustics, S.pdf:pdf},
isbn = {9781457705397},
journal = {Acoustics, Speech and},
pages = {349--352},
title = {{Improving acoustic event detection using generalizable visual features and multi-modality modeling}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5946412},
year = {2011}
}
@article{Horovitz2002,
abstract = {A parametric method is proposed to examine the relationship between neuronal activity, measured with event related potentials (ERPs), and the hemodynamic response, observed with functional magnetic resonance imaging (fMRI), during an auditory oddball paradigm. After verifying that the amplitude of the evoked response P300 increases as the probability of oddball target presentation decreases, we explored the corresponding effect of target frequency on the fMRI signal. We predicted and confirmed that some regions that showed activation changes following each oddball are affected by the rate of presentation of the oddballs, or the probability of an oddball target. We postulated that those regions that increased activation with decreasing probability might be responsible for the corresponding changes in the P300 amplitude. fMRI regions that correlated with the amplitude of the P300 wave were supramarginal gyri, thalamus, insula and right medial frontal gyrus, and are presumably sources of the P300 wave. Other regions, such as anterior and posterior cingulate cortex, were activated during the oddball paradigm but their fMRI signal changes were not correlated with the P300 amplitudes. This study thus shows how combining fMRI and ERP in a parametric design identifies task-relevant sources of activity and allows separation of regions that have different response properties.},
author = {Horovitz, Silvina G and Skudlarski, Pawel and Gore, John C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Horovitz, Skudlarski, Gore/Horovitz, Skudlarski, Gore - 2002 - Correlations and dissociations between BOLD signal and P300 amplitude in an auditory oddball task a parametric approach to combining fMRI and ERP. - Magnetic resonance imaging.pdf:pdf},
issn = {0730-725X},
journal = {Magnetic resonance imaging},
keywords = {Acoustic Stimulation,Adult,Brain,Brain: anatomy \& histology,Brain: physiology,Event-Related Potentials, P300,Event-Related Potentials, P300: physiology,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male},
month = may,
number = {4},
pages = {319--25},
pmid = {12165350},
title = {{Correlations and dissociations between BOLD signal and P300 amplitude in an auditory oddball task: a parametric approach to combining fMRI and ERP.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12165350},
volume = {20},
year = {2002}
}
@article{Vetro2011,
author = {Vetro, a and Wiegand, T and Sullivan, G J},
doi = {10.1109/JPROC.2010.2098830},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vetro, Wiegand, Sullivan/Vetro, Wiegand, Sullivan - 2011 - Overview of the Stereo and Multiview Video Coding Extensions of the H.264MPEG-4 AVC Standard - Proceed.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = apr,
number = {4},
pages = {626--642},
title = {{Overview of the Stereo and Multiview Video Coding Extensions of the H.264/MPEG-4 AVC Standard}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5705534},
volume = {99},
year = {2011}
}
@article{Lin2013,
author = {Lin, Liang and Zeng, Kun and Wang, Yizhou and Xu, Ying-Qing and Zhu, Song-Chun},
doi = {10.1109/TCSVT.2012.2210804},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lin et al/Lin et al. - 2013 - Video Stylization Painterly Rendering and Optimization With Content Extraction - IEEE Transactions on Circuits and S.pdf:pdf},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
month = apr,
number = {4},
pages = {577--590},
title = {{Video Stylization: Painterly Rendering and Optimization With Content Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6253236},
volume = {23},
year = {2013}
}
@article{Haxby2001,
abstract = {The functional architecture of the object vision pathway in the human brain was investigated using functional magnetic resonance imaging to measure patterns of response in ventral temporal cortex while subjects viewed faces, cats, five categories of man-made objects, and nonsense pictures. A distinct pattern of response was found for each stimulus category. The distinctiveness of the response to a given category was not due simply to the regions that responded maximally to that category, because the category being viewed also could be identified on the basis of the pattern of response when those regions were excluded from the analysis. Patterns of response that discriminated among all categories were found even within cortical regions that responded maximally to only one category. These results indicate that the representations of faces and objects in ventral temporal cortex are widely distributed and overlapping.},
author = {Haxby, J V and Gobbini, M I and Furey, M L and Ishai, a and Schouten, J L and Pietrini, P},
doi = {10.1126/science.1063736},
file = {:Users/pkmital/Documents/Mendeley Desktop/Haxby et al/Haxby et al. - 2001 - Distributed and overlapping representations of faces and objects in ventral temporal cortex. - Science (New York,.pdf:pdf},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
keywords = {Brain Mapping,Face,Female,Form Perception,Humans,Magnetic Resonance Imaging,Male,Pattern Recognition, Visual,Recognition (Psychology),Temporal Lobe,Temporal Lobe: physiology,Visual Pathways},
month = sep,
number = {5539},
pages = {2425--30},
pmid = {11577229},
title = {{Distributed and overlapping representations of faces and objects in ventral temporal cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11577229},
volume = {293},
year = {2001}
}
@article{Henderson2003,
author = {Henderson, J},
doi = {10.1016/j.tics.2003.09.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson/Henderson - 2003 - Human gaze control during real-world scene perception - Trends in Cognitive Sciences.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = nov,
number = {11},
pages = {498--504},
title = {{Human gaze control during real-world scene perception}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661303002481},
volume = {7},
year = {2003}
}
@article{Ding2012,
author = {Ding, Shou-Hong and Huang, Fei-Yue and Xie, Zhi-Feng and Wu, Yong-Jian and Sheng, Bin and Ma, Li-Zhuang},
doi = {10.1007/s11390-012-1291-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ding et al/Ding et al. - 2012 - A Customized Framework to Recompress Massive Internet Images - Journal of Computer Science and Technology.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {image quality assessment,image recompression,massive internet image},
month = nov,
number = {6},
pages = {1129--1139},
title = {{A Customized Framework to Recompress Massive Internet Images}},
url = {http://www.springerlink.com/index/10.1007/s11390-012-1291-3},
volume = {27},
year = {2012}
}
@article{Hunt2004,
abstract = {Reflexive responses are often in direct competition with voluntary control. We test two opposing explanations for how this competition is resolved with respect to eye movements. One states that the quickest activation wins. The other states that the strongest activation wins. We show that an eye movement is executed according to the strongest activation, with the competition being staged at a common subcortical site.},
author = {Hunt, Amelia R and Olk, Bettina and von M\"{u}hlenen, Adrian and Kingstone, Alan},
doi = {10.1016/j.cogbrainres.2003.12.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hunt et al/Hunt et al. - 2004 - Integration of competing saccade programs. - Brain research. Cognitive brain research.pdf:pdf},
issn = {0926-6410},
journal = {Brain research. Cognitive brain research},
keywords = {Humans,Models, Neurological,Reflex,Reflex: physiology,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology,Volition,Volition: physiology},
month = apr,
number = {2},
pages = {206--8},
pmid = {15019717},
title = {{Integration of competing saccade programs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15019717},
volume = {19},
year = {2004}
}
@article{Kane2007,
abstract = {An experience-sampling study of 124 undergraduates, pretested on complex memory-span tasks, examined the relation between working memory capacity (WMC) and the experience of mind wandering in daily life. Over 7 days, personal digital assistants signaled subjects eight times daily to report immediately whether their thoughts had wandered from their current activity, and to describe their psychological and physical context. WMC moderated the relation between mind wandering and activities' cognitive demand. During challenging activities requiring concentration and effort, higher-WMC subjects maintained on-task thoughts better, and mind-wandered less, than did lower-WMC subjects. The results were therefore consistent with theories of WMC emphasizing the role of executive attention and control processes in determining individual differences and their cognitive consequences.},
author = {Kane, Michael J and Brown, Leslie H and McVay, Jennifer C and Silvia, Paul J and Myin-Germeys, Inez and Kwapil, Thomas R},
doi = {10.1111/j.1467-9280.2007.01948.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kane et al/Kane et al. - 2007 - For whom the mind wanders, and when an experience-sampling study of working memory and executive control in daily life. - Psychological science a journal of the American Psychological Society APS.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science : a journal of the American Psychological Society / APS},
keywords = {Activities of Daily Living,Activities of Daily Living: psychology,Adolescent,Adult,Attention,Attention: physiology,Cognition,Cognition: physiology,Computers, Handheld,Emotions,Emotions: physiology,Female,Humans,Male,Memory, Short-Term,Memory, Short-Term: physiology,Questionnaires,Students,Students: psychology,Task Performance and Analysis,Thinking,Thinking: physiology,Time},
month = jul,
number = {7},
pages = {614--21},
pmid = {17614870},
title = {{For whom the mind wanders, and when: an experience-sampling study of working memory and executive control in daily life.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17614870},
volume = {18},
year = {2007}
}
@article{Itti,
author = {Itti, Laurent},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti/Itti - Unknown - An Integrated Model of Top-down and Bottom-up Attention for Optimizing - Search.pdf:pdf},
journal = {Search},
title = {{An Integrated Model of Top-down and Bottom-up Attention for Optimizing}}
}
@article{Atrey2006,
author = {Atrey, PK and Maddage, NC},
file = {:Users/pkmital/Documents/Mendeley Desktop/Atrey, Maddage/Atrey, Maddage - 2006 - Audio based event detection for multimedia surveillance - Acoustics, Speech and.pdf:pdf},
journal = {Acoustics, Speech and},
pages = {813--816},
title = {{Audio based event detection for multimedia surveillance}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1661400},
year = {2006}
}
@inproceedings{Riemenschneider2009,
author = {Riemenschneider, Hayko and Donoser, Michael and Bischof, Horst},
booktitle = {British Machine Vision Conference},
file = {:Users/pkmital/Documents/Mendeley Desktop/Riemenschneider, Donoser, Bischof/Riemenschneider, Donoser, Bischof - 2009 - Bag of optical flow volumes for image sequence recognition - British Machine Vision Conference.pdf:pdf},
pages = {1--11},
title = {{Bag of optical flow volumes for image sequence recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.216\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@article{Winkler2005,
abstract = {We investigated the role of attention in feature binding in the auditory and the visual modality. One auditory and one visual experiment used the mismatch negativity (MMN and vMMN, respectively) event-related potential to index the memory representations created from stimulus sequences, which were either task-relevant and, therefore, attended or task-irrelevant and ignored. In the latter case, the primary task was a continuous demanding within-modality task. The test sequences were composed of two frequently occurring stimuli, which differed from each other in two stimulus features (standard stimuli) and two infrequently occurring stimuli (deviants), which combined one feature from one standard stimulus with the other feature of the other standard stimulus. Deviant stimuli elicited MMN responses of similar parameters across the different attentional conditions. These results suggest that the memory representations involved in the MMN deviance detection response encoded the frequently occurring feature combinations whether or not the test sequences were attended. A possible alternative to the memory-based interpretation of the visual results, the elicitation of the McCollough color-contingent aftereffect, was ruled out by the results of our third experiment. The current results are compared with those supporting the attentive feature integration theory. We conclude that (1) with comparable stimulus paradigms, similar results have been obtained in the two modalities, (2) there exist preattentive processes of feature binding, however, (3) conjoining features within rich arrays of objects under time pressure and/or longterm retention of the feature-conjoined memory representations may require attentive processes.},
author = {Winkler, Istv\'{a}n and Czigler, Istv\'{a}n and Sussman, Elyse and Horv\'{a}th, J\'{a}nos and Bal\'{a}zs, L\'{a}szlo},
doi = {10.1162/0898929053124866},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler et al/Winkler et al. - 2005 - Preattentive binding of auditory and visual stimulus features. - Journal of cognitive neuroscience.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Acoustic Stimulation,Adolescent,Adult,Analysis of Variance,Attention,Attention: physiology,Brain,Brain Mapping,Brain: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Female,Humans,Male,Memory,Memory: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Speech Perception},
month = feb,
number = {2},
pages = {320--39},
pmid = {15811243},
title = {{Preattentive binding of auditory and visual stimulus features.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15811243},
volume = {17},
year = {2005}
}
@article{Kwatra2003,
author = {Kwatra, Vivek and Sch\"{o}dl, A and Essa, Irfan and Turk, Greg and Bobick, Aaron},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kwatra et al/Kwatra et al. - 2003 - Graphcut textures image and video synthesis using graph cuts - ACM Transactions on Graphics (TOG).pdf:pdf},
journal = {ACM Transactions on Graphics (TOG)},
keywords = {image and,image-based rendering,machine learning,natural phenomenon,texture synthesis,video processing},
number = {2},
pages = {277--286},
title = {{Graphcut textures: image and video synthesis using graph cuts}},
url = {http://dl.acm.org/citation.cfm?id=882264},
year = {2003}
}
@article{Spevak2002,
author = {Spevak, Christian and Favreau, E},
file = {:Users/pkmital/Documents/Mendeley Desktop/Spevak, Favreau/Spevak, Favreau - 2002 - Soundspotter-a prototype system for content-based audio retrieval - Proceedings of the 5th International Confer.pdf:pdf},
journal = {Proceedings of the 5th International Conference on Digital Audio Effects (DAFx-02)},
pages = {27--32},
title = {{Soundspotter-a prototype system for content-based audio retrieval}},
url = {http://www2.hsu-hh.de/ant/dafx2002/papers/DAFX02\_Spevak\_Favreau\_soundspotter.pdf},
year = {2002}
}
@article{Itti2005a,
abstract = {We investigated the contribution of low-level saliency to human eye movements in complex dynamic scenes. Eye movements were recorded while naive observers viewed a heterogeneous collection of 50 video clips (46,489 frames; 4-6 subjects per clip), yielding 11,916 saccades of amplitude 2. A model of bottom-up visual attention computed instantaneous saliency at the instant each saccade started and at its future endpoint location. Median model-predicted saliency was 45\% the maximum saliency, a significant factor 2.03 greater than expected by chance. Motion and temporal change were stronger predictors of human saccades than colour, intensity, or orientation features, with the best predictor being the sum of all features. There was no significant correlation between model-predicted saliency and duration of fixation. A majority of saccades were directed to a minority of locations reliably marked as salient by the model, suggesting that bottom-up saliency may provide a set of candidate saccade target locations, with the final choice of which location of fixate more strongly determined top-down.},
author = {Itti, Laurent},
doi = {10.1080/13506280444000661},
issn = {13506285},
journal = {Visual Cognition},
number = {6},
pages = {1093--1123},
publisher = {Psychology Press},
title = {{Quantifying the contribution of low-level saliency to human eye movements in dynamic scenes}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280444000661\&magic=crossref},
volume = {12},
year = {2005}
}
@article{Kimura2006f,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2006 - Multiterminal source coding with complementary delivery - Symposium A Quarterly Journal In Modern Foreign Literatures.pdf:pdf},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
pages = {1--21},
title = {{Multiterminal source coding with complementary delivery}},
year = {2006}
}
@article{Kravitz2008,
abstract = {Although object-based attention enhances perceptual processing of information appearing within the boundaries of a selected object, little is known about the consequences for information in the object's surround. The authors show that distance from an attended object's center of mass determines reaction time (RT) to targets in the surround. Of 2 targets in the surround, both equidistant from a cue, the target closer to the center of mass was detected faster. Moreover, RT was shown to be a linear function of distance from the center of mass of a fixed, attended object, and changes to the shape of the object and its center of mass predictably altered RT. Object-based attention leads to a pattern of facilitation in the surround that may contribute to the organization of visual scenes.},
author = {Kravitz, Dwight Jacob and Behrmann, Marlene},
doi = {10.1037/0096-1523.34.2.298},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kravitz, Behrmann/Kravitz, Behrmann - 2008 - The space of an object object attention alters the spatial gradient in the surround. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Analysis of Variance,Attention,Attention: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Reaction Time,Reaction Time: physiology,Reference Values,Space Perception,Space Perception: physiology},
month = apr,
number = {2},
pages = {298--309},
pmid = {18377172},
title = {{The space of an object: object attention alters the spatial gradient in the surround.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18377172},
volume = {34},
year = {2008}
}
@misc{Manovich2008,
title = {{Software Studies: Cultural Analytics}},
url = {http://lab.softwarestudies.com/2008/09/cultural-analytics.html}
}
@article{Miller2012,
author = {Miller, Jordan and Mould, David},
doi = {10.2312/COMPAESTH/COMPAESTH12/115-124},
file = {:Users/pkmital/Documents/Mendeley Desktop/Miller, Mould/Miller, Mould - 2012 - Accurate and Discernible Photocollages - Computational Aesthetics in Graphics, Visualization, and Imaging(2).pdf:pdf},
journal = {Computational Aesthetics in Graphics, Visualization, and Imaging},
pages = {115--124},
title = {{Accurate and Discernible Photocollages}},
year = {2012}
}
@inproceedings{Spevak2001,
author = {Spevak, Christian and Polfreman, Richard},
booktitle = {Proceedings of the Second International Symposium of Music Information Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Spevak, Polfreman/Spevak, Polfreman - 2001 - Sound spotting--A frame-based approach - Proceedings of the Second International Symposium of Music Informati.pdf:pdf},
title = {{Sound spotting--A frame-based approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.223.264\&rep=rep1\&type=pdf\#page=46},
year = {2001}
}
@article{Kosslyn2005,
abstract = {One theory of visual mental imagery posits that early visual cortex is also used to support representations during imagery. This claim is important because it bears on the "imagery debate": Early visual cortex supports depictive representations during perception, not descriptive ones. Thus, if such cortex also plays a functional role in imagery, this is strong evidence that imagery does not rely exclusively on the same sorts of representations that underlie language. The present article first outlines the nature of a processing system in which such a dual use of early visual cortex (in perception and in imagery) makes sense. Following this, literature bearing on the claim that early visual cortex is used in visual mental imagery is reviewed, and key issues are discussed.},
author = {Kosslyn, Stephen M},
doi = {10.1080/02643290442000130},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kosslyn/Kosslyn - 2005 - Mental images and the Brain. - Cognitive neuropsychology.pdf:pdf},
isbn = {0264329044200},
issn = {0264-3294},
journal = {Cognitive neuropsychology},
month = may,
number = {3},
pages = {333--47},
pmid = {21038254},
title = {{Mental images and the Brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21038254},
volume = {22},
year = {2005}
}
@article{Badler2008,
author = {Badler, Jeremy B},
doi = {10.1167/8.16.5.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Badler/Badler - 2008 - Anticipatory pursuit is influenced by a concurrent timing task - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,1167,16,2008,5,8,9,anticipatory pursuit is influenced,attention,b,badler,by a concurrent timing,citation,doi,http,human,j,journal,journalofvision,lef\`{e}vre,m,manual response,missal,of vision,org,p,prediction,smooth pursuit,task},
pages = {1--9},
title = {{Anticipatory pursuit is influenced by a concurrent timing task}},
volume = {8},
year = {2008}
}
@article{Buswell1935,
author = {Buswell, GT},
file = {:Users/pkmital/Documents/Mendeley Desktop/Buswell/Buswell - 1935 - How people look at pictures - Unknown.pdf:pdf},
title = {{How people look at pictures}},
url = {http://psych.wfu.edu/art\_schirillo/articles/Buswell, 1935.pdf},
year = {1935}
}
@article{Klineca,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
journal = {ifp.uni-stuttgart.de},
pages = {1--12},
title = {{POSITIONING AND LOCATION SERVICES}},
url = {http://www.ifp.uni-stuttgart.de/publications/2001/Klinec\_Indoornav2001.pdf}
}
@article{Serre2007a,
abstract = {Human and non-human primates excel at visual recognition tasks. The primate visual system exhibits a strong degree of selectivity while at the same time being robust to changes in the input image. We have developed a quantitative theory to account for the computations performed by the feedforward path in the ventral stream of the primate visual cortex. Here we review recent predictions by a model instantiating the theory about physiological observations in higher visual areas. We also show that the model can perform recognition tasks on datasets of complex natural images at a level comparable to psychophysical measurements on human observers during rapid categorization tasks. In sum, the evidence suggests that the theory may provide a framework to explain the first 100-150 ms of visual object recognition. The model also constitutes a vivid example of how computational models can interact with experimental observations in order to advance our understanding of a complex phenomenon. We conclude by suggesting a number of open questions, predictions, and specific experiments for visual physiology and psychophysics.},
author = {Serre, Thomas and Kreiman, Gabriel and Kouh, Minjoon and Cadieu, Charles and Knoblich, Ulf and Poggio, Tomaso},
doi = {10.1016/S0079-6123(06)65004-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Serre et al/Serre et al. - 2007 - A quantitative theory of immediate visual recognition. - Progress in brain research.pdf:pdf},
issn = {0079-6123},
journal = {Progress in brain research},
keywords = {Animals,Computer Simulation,Field Dependence-Independence,Humans,Models, Biological,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Psychophysics,Visual Cortex,Visual Cortex: physiology},
month = jan,
pages = {33--56},
pmid = {17925239},
title = {{A quantitative theory of immediate visual recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17925239},
volume = {165},
year = {2007}
}
@article{Lee2011a,
author = {Lee, Yong Jae and Kim, Jaechul and Grauman, Kristen},
doi = {10.1109/ICCV.2011.6126471},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lee, Kim, Grauman/Lee, Kim, Grauman - 2011 - Key-segments for video object segmentation - 2011 International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4577-1102-2},
journal = {2011 International Conference on Computer Vision},
month = nov,
number = {Iccv},
pages = {1995--2002},
publisher = {Ieee},
title = {{Key-segments for video object segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126471},
year = {2011}
}
@article{Humphrey1924,
author = {Humphrey, George},
file = {:Users/pkmital/Documents/Mendeley Desktop/Humphrey/Humphrey - 1924 - The Psychology of the Gestalt - Journal of Educational Psychology.pdf:pdf},
journal = {Journal of Educational Psychology},
number = {7},
pages = {401--412},
title = {{The Psychology of the Gestalt}},
url = {http://psycnet.apa.org/journals/edu/15/7/401/},
volume = {XV},
year = {1924}
}
@article{Rekimoto1995a,
author = {Rekimoto, Jun and Nagao, Katashi},
file = {::},
journal = {Proc. 8th Ann. ACM Symp. User Interface and Software Technology (UIST), ACM Press},
pages = {29--36},
title = {{The World through the Computer: Computer Augmented Interaction with Real World Environments}},
year = {1995}
}
@book{Findlay2003,
author = {Findlay, John M. and Gilchrist, Iain D.},
isbn = {019852479X},
pages = {240},
publisher = {Oxford University Press, USA},
title = {{Active Vision: The Psychology of Looking and Seeing (Oxford Psychology)}},
url = {http://www.amazon.com/Active-Vision-Psychology-Looking-Seeing/dp/019852479X},
year = {2003}
}
@article{Nitta2010,
author = {Nitta, Naoko and Babaguchi, Noboru},
doi = {10.1007/s11042-010-0633-9},
file = {:Users/pkmital/Documents/Mendeley Desktop/Nitta, Babaguchi/Nitta, Babaguchi - 2010 - Example-based video remixing - Multimedia Tools and Applications.pdf:pdf},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
keywords = {audio clips,examples,expressive quality,structural patterns,transition effects,video clips,video remixing},
month = oct,
number = {2},
pages = {649--673},
title = {{Example-based video remixing}},
url = {http://link.springer.com/10.1007/s11042-010-0633-9},
volume = {51},
year = {2010}
}
@article{Wen2004,
author = {Wen, Xue and Shi, Yuan-yuan and She, Bin},
doi = {10.1109/ICASSP.2004.1326362},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wen, Shi, She/Wen, Shi, She - 2004 - Separation of impulsive acoustical events - 2004 IEEE International Conference on Acoustics, Speech, and Signal P.pdf:pdf},
isbn = {0-7803-8484-9},
journal = {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {ii--733--6},
publisher = {Ieee},
title = {{Separation of impulsive acoustical events}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1326362},
volume = {2},
year = {2004}
}
@article{Simons1999,
abstract = {With each eye fixation, we experience a richly detailed visual world. Yet recent work on visual integration and change direction reveals that we are surprisingly unaware of the details of our environment from one view to the next: we often do not detect large changes to objects and scenes ('change blindness'). Furthermore, without attention, we may not even perceive objects ('inattentional blindness'). Taken together, these findings suggest that we perceive and remember only those objects and details that receive focused attention. In this paper, we briefly review and discuss evidence for these cognitive forms of 'blindness'. We then present a new study that builds on classic studies of divided visual attention to examine inattentional blindness for complex objects and events in dynamic scenes. Our results suggest that the likelihood of noticing an unexpected object depends on the similarity of that object to other objects in the display and on how difficult the priming monitoring task is. Interestingly, spatial proximity of the critical unattended object to attended locations does not appear to affect detection, suggesting that observers attend to objects and events, not spatial positions. We discuss the implications of these results for visual representations and awareness of our visual environment.},
author = {Simons, D J and Chabris, C F},
file = {:Users/pkmital/Documents/Mendeley Desktop/Simons, Chabris/Simons, Chabris - 1999 - Gorillas in our midst sustained inattentional blindness for dynamic events. - Perception.pdf:pdf},
issn = {0301-0066},
journal = {Perception},
keywords = {Attention,Fixation, Ocular,Humans,Psychological Tests,Visual Perception,Visual Perception: physiology},
month = jan,
number = {9},
pages = {1059--74},
pmid = {10694957},
title = {{Gorillas in our midst: sustained inattentional blindness for dynamic events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10694957},
volume = {28},
year = {1999}
}
@article{Kuhn2008,
author = {Kuhn, Gustav and Tatler, Benjamin and Findlay, John and Cole, Geoff},
doi = {10.1080/13506280701479750},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kuhn et al/Kuhn et al. - 2008 - Misdirection in magic Implications for the relationship between eye gaze and attention - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {2},
pages = {391--405},
title = {{Misdirection in magic: Implications for the relationship between eye gaze and attention}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280701479750\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2008}
}
@article{Rasamimanana2010,
author = {Rasamimanana, Nicolas and Schnell, Norbert and Flety, Emmanuel and Zamborlin, Bruno and Stms, Ircam Cnrs and Stavinsky, Igor},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasamimanana et al/Rasamimanana et al. - 2010 - Modular Musical Objects Towards Embodied Control Of Digital Music Real Time Interaction Team - Design.pdf:pdf},
journal = {Design},
pages = {1--5},
title = {{Modular Musical Objects Towards Embodied Control Of Digital Music Real Time Interaction Team}},
year = {2010}
}
@article{Nam2012,
author = {Nam, Juhan and Mysore, Gautham and Smaragdis, Paris},
file = {:Users/pkmital/Documents/Mendeley Desktop/Nam, Mysore, Smaragdis/Nam, Mysore, Smaragdis - 2012 - Sound Recognition in Mixtures - Latent Variable Analysis and Signal, Lecture Notes in Computer Science.pdf:pdf},
journal = {Latent Variable Analysis and Signal, Lecture Notes in Computer Science},
pages = {405--413},
title = {{Sound Recognition in Mixtures}},
url = {http://www.springerlink.com/index/R73150046L5K5MR3.pdf},
volume = {7191},
year = {2012}
}
@incollection{BretonRemembers,
address = {La Dragonne, Galerie Nina Dausset, Paris},
author = {Breton, Andre},
booktitle = {Exhibition Catalog},
pages = {5--7, 9--11},
title = {{"Le Cadavre Exquis: Son Exaltation"}},
year = {1948}
}
@article{Everingham2006,
author = {Everingham, Mark and Williams, Chris and Zisserman, Andrew},
file = {:Users/pkmital/Documents/Mendeley Desktop/Everingham, Williams, Zisserman/Everingham, Williams, Zisserman - 2006 - The Pascal Visual Object Classes Challenge 2006 ( VOC2006 ) Results - Challenge.pdf:pdf},
journal = {Challenge},
title = {{The Pascal Visual Object Classes Challenge 2006 ( VOC2006 ) Results}},
volume = {2006},
year = {2006}
}
@article{Boyce1992,
abstract = {Research with brief presentations of scenes has indicated that scene context facilitates object identification. In the present experiments we used a paradigm in which an object in a scene is "wiggled"--drawing both attention and an eye fixation to itself--and then named. Thus the effect of scene context on object identification can be examined in a situation in which the target object is fixated and hence is fully visible. Experiment 1 indicated that a scene background that was episodically consistent with a target object facilitated the speed of naming. In Experiments 2 and 3, we investigated the time course of scene background information acquisition using display changes contingent on eye movements to the target object. The results from Experiment 2 were inconclusive; however, Experiment 3 demonstrated that scene background information present only on either the first or second fixation on a scene significantly affected naming time. Thus background information appears to be both extracted and able to affect object identification continuously during scene viewing.},
author = {Boyce, S J and Pollatsek, a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Boyce, Pollatsek/Boyce, Pollatsek - 1992 - Identification of objects in scenes the role of scene background in object naming. - Journal of experimental psychology. Learning, memory, and cognition.pdf:pdf},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Adult,Attention,Discrimination Learning,Female,Humans,Male,Mental Recall,Pattern Recognition, Visual,Perceptual Masking,Reaction Time,Verbal Learning},
month = may,
number = {3},
pages = {531--43},
pmid = {1534354},
title = {{Identification of objects in scenes: the role of scene background in object naming.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1534354},
volume = {18},
year = {1992}
}
@article{Hertzmann1998,
address = {New York, New York, USA},
author = {Hertzmann, Aaron},
doi = {10.1145/280814.280951},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hertzmann/Hertzmann - 1998 - Painterly rendering with curved brush strokes of multiple sizes - Proceedings of the 25th annual conference on Comput.pdf:pdf},
isbn = {0897919998},
journal = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques - SIGGRAPH '98},
pages = {453--460},
publisher = {ACM Press},
title = {{Painterly rendering with curved brush strokes of multiple sizes}},
url = {http://portal.acm.org/citation.cfm?doid=280814.280951},
year = {1998}
}
@article{Kusunoki2000,
abstract = {Neurons in the lateral intraparietal area (LIP) of the monkey represent salient stimuli. They respond to recently flashed stimuli that enter their receptive fields by virtue of saccades better than they respond to stable, behaviorally irrelevant stimuli brought into their receptive fields by saccades. They respond transiently to abrupt motion onsets, but have no directional selectivity. They respond to stable stimuli that are the targets for saccadic eye movements, but far less before the same saccades without stimuli. LIP is important in the attentional mechanisms preceding the choice of saccade target rather than in the intention to generate the saccade itself.},
author = {Kusunoki, M and Gottlieb, J and Goldberg, M E},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kusunoki, Gottlieb, Goldberg/Kusunoki, Gottlieb, Goldberg - 2000 - The lateral intraparietal area as a salience map the representation of abrupt onset, stimulus moti.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Animals,Attention,Attention: physiology,Cues,Macaca mulatta,Motion Perception,Motion Perception: physiology,Parietal Lobe,Parietal Lobe: physiology,Photic Stimulation,Photic Stimulation: methods,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
number = {10-12},
pages = {1459--68},
pmid = {10788652},
title = {{The lateral intraparietal area as a salience map: the representation of abrupt onset, stimulus motion, and task relevance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10788652},
volume = {40},
year = {2000}
}
@article{Shotton2008,
author = {Shotton, Jamie and Johnson, Matthew and Cipolla, Roberto},
doi = {10.1109/CVPR.2008.4587503},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shotton, Johnson, Cipolla/Shotton, Johnson, Cipolla - 2008 - Semantic texton forests for image categorization and segmentation - 2008 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1--8},
publisher = {Ieee},
title = {{Semantic texton forests for image categorization and segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587503},
year = {2008}
}
@article{Vedaldi,
author = {Vedaldi, Andrea and Zisserman, Andrew},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vedaldi, Zisserman/Vedaldi, Zisserman - Unknown - Self-Similar Sketch - vlfeat.org.pdf:pdf},
journal = {vlfeat.org},
keywords = {feature detector,self-similarity,vanishing point estimation},
pages = {1--14},
title = {{Self-Similar Sketch}},
url = {http://www.vlfeat.org/~vedaldi/assets/pubs/vedaldi12self.pdf}
}
@article{Cowan1988,
author = {Cowan, Nelson},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cowan/Cowan - 1988 - Evolving conceptions of memory storage, selective attention, and their mutual constraints within the human information-pr.pdf:pdf},
journal = {Psychological bulletin},
number = {2},
pages = {163--191},
title = {{Evolving conceptions of memory storage, selective attention, and their mutual constraints within the human information-processing system.}},
url = {http://psycnet.apa.org/journals/bul/104/2/163/},
volume = {104},
year = {1988}
}
@article{Schwarz2006,
author = {Schwarz, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2006 - Concatenative Sound Synthesis The Early Years - J. New Music Research.pdf:pdf},
journal = {J. New Music Research},
keywords = {CSS},
number = {1},
title = {{Concatenative Sound Synthesis: The Early Years}},
volume = {35},
year = {2006}
}
@article{Hubel1968,
author = {Hubel, DH and Wiesel, TN},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hubel, Wiesel/Hubel, Wiesel - 1968 - Receptive fields and functional architecture of monkey striate cortex - The Journal of physiology.pdf:pdf},
journal = {The Journal of physiology},
pages = {215--243},
title = {{Receptive fields and functional architecture of monkey striate cortex}},
url = {http://jp.physoc.org/content/195/1/215.short},
year = {1968}
}
@article{Lee2010,
author = {Lee, Hochang and Seo, S and Ryoo, S and Yoon, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lee et al/Lee et al. - 2010 - Directional texture transfer - NPAR '10 Proceedings of the 8th International Symposium on Non-Photorealistic Animati.pdf:pdf},
isbn = {9781450301244},
journal = {NPAR '10 Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
keywords = {difference of direction,example-based rendering,non-photorealistic rendering,npr,texture transfer},
number = {212},
pages = {43--50},
title = {{Directional texture transfer}},
url = {http://dl.acm.org/citation.cfm?id=1809945},
volume = {1},
year = {2010}
}
@article{Acik2009,
abstract = {During viewing of natural scenes, do low-level features guide attention, and if so, does this depend on higher-level features? To answer these questions, we studied the image category dependence of low-level feature modification effects. Subjects fixated contrast-modified regions often in natural scene images, while smaller but significant effects were observed for urban scenes and faces. Surprisingly, modifications in fractal images did not influence fixations. Further analysis revealed an inverse relationship between modification effects and higher-level, phase-dependent image features. We suggest that high- and mid-level features--such as edges, symmetries, and recursive patterns--guide attention if present. However, if the scene lacks such diagnostic properties, low-level features prevail. We posit a hierarchical framework, which combines aspects of bottom-up and top-down theories and is compatible with our data.},
author = {A\c{c}ik, Alper and Onat, Selim and Schumann, Frank and Einh\"{a}user, Wolfgang and K\"{o}nig, Peter},
doi = {10.1016/j.visres.2009.03.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/A\c{c}ik et al/A\c{c}ik et al. - 2009 - Effects of luminance contrast and its modifications on fixation behavior during free viewing of images from different categories. - Vision research.pdf:pdf},
issn = {1878-5646},
journal = {Vision research},
keywords = {Adult,Attention,Attention: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Eye Movements,Eye Movements: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Psychophysics,Time Factors,Young Adult},
month = jun,
number = {12},
pages = {1541--53},
pmid = {19306892},
publisher = {Elsevier Ltd},
title = {{Effects of luminance contrast and its modifications on fixation behavior during free viewing of images from different categories.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19306892},
volume = {49},
year = {2009}
}
@phdthesis{Jensen2010,
author = {Jensen, JH},
booktitle = {Processing},
file = {:Users/pkmital/Documents/Mendeley Desktop/Jensen/Jensen - 2010 - Feature Extraction for Music Information Retrieval - Processing.pdf:pdf},
title = {{Feature Extraction for Music Information Retrieval}},
url = {http://www.eletrica.ufpr.br/ufpr2/professor/36/TE808/featureextraction/MIRFeatureExtraction.pdf},
year = {2010}
}
@article{Purwins2008,
author = {Purwins, Hendrik and Herrera, Perfecto and Grachten, Maarten and Hazan, Amaury and Marxer, Ricard and Serra, Xavier},
doi = {10.1016/j.plrev.2008.03.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Purwins et al/Purwins et al. - 2008 - Computational models of music perception and cognition I The perceptual and cognitive processing chain - Physics.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {auditory system,music cognition,music perception,musical expectancy},
month = sep,
number = {3},
pages = {151--168},
publisher = {Elsevier B.V.},
title = {{Computational models of music perception and cognition I: The perceptual and cognitive processing chain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571064508000158},
volume = {5},
year = {2008}
}
@article{Dobashi2003a,
author = {Dobashi, Yoshinori and Yamamoto, Tsuyoshi and Nishita, Tomoyuki},
doi = {10.1145/882262.882339},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {--------------------------------------------------,aerodynamic sound,animation,computational fluid dynamics,simulation,sound synthesis},
month = jul,
number = {3},
pages = {732},
title = {{Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics}},
url = {http://portal.acm.org/citation.cfm?doid=882262.882339},
volume = {22},
year = {2003}
}
@inproceedings{Fels2001a,
abstract = {We describe a system that maps the interaction between two people to control a genetic process for generating music. We start with a population of melodies encoded genetically. This population is allowed to breed every biological cycle creating new members of the population based upon the semantics of the spatial relationship between two people moving in a large, physical space. A pre-specified hidden melody is used to select a melody from the population to play every musical cycle. The overlapping of selected melodies provides an intriguing textured musical space.},
address = {Manchester, UK.},
author = {Fels, Sidney and Manzolli, Jonatas},
booktitle = {Multimedia 2001: proceedings of the Eurographics Workshop.},
file = {::},
isbn = {3211837698},
pages = {153},
publisher = {Springer Verlag Wien},
title = {{Interactive, evolutionary textured sound composition}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=2ueyZAG32KUC\&amp;oi=fnd\&amp;pg=PA153\&amp;dq=Interactive,+Evolutionary+Textured+Sound+Composition\&amp;ots=0A7Y-im7Tw\&amp;sig=k174uajYy6boHONbFp4asuISI10},
year = {2001}
}
@article{Kimura2013,
author = {Kimura, Akisato and Yonetani, Ryo and Hirayama, Takatsugu},
doi = {10.1587/transinf.E96.D.562},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Yonetani, Hirayama/Kimura, Yonetani, Hirayama - 2013 - Computational Models of Human Visual Attention and Their Implementations A Survey - IEICE Transactio.pdf:pdf},
issn = {0916-8532},
journal = {IEICE Transactions on Information and Systems},
keywords = {computational model,human visual attention,saliency},
number = {3},
pages = {562--578},
title = {{Computational Models of Human Visual Attention and Their Implementations: A Survey}},
url = {http://jlc.jst.go.jp/DN/JST.JSTAGE/transinf/E96.D.562?lang=en\&from=CrossRef\&type=abstract},
volume = {E96.D},
year = {2013}
}
@article{Fagerlund2003,
abstract = {For humans bird song is as natural phenomena as speech or human singing. However organization and generation of bird song is not so well-known as one for speech. In this paper we take short review to the basic stuctures of sounds birds can produce and also to principles of sound producing mech- anism in birds. Birds have unique organ for sound production among all animals in the world. Both organ itself and also sounds it can produce have large diversity between different species. We also introduce how popular speech and audio modelling methods can be used to model sound production in birds.},
author = {Fagerlund, Seppo},
file = {::},
journal = {Laboratory of Acoustics and Signal Processing, HUT, Finland},
publisher = {Citeseer},
title = {{Acoustics and physical models of bird sounds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.6303\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{Kajii2001,
abstract = {The present study examines the landing-site distributions of the eyes during natural reading of Japanese script: a script that mixes three different writing systems (Kanji, Hiragana, and Katakana) and that misses regular spacing between words. The results show a clear preference of the eyes to land at the beginning rather than the center of the word. In addition, it was found that the eyes land on Kanji characters more frequently than on Hiragana or Katakana characters. Further analysis for two- and three-character words indicated that the eye's landing-site distribution differs depending on type of the characters in the word: the eyes prefer to land at the word beginning only when the initial character of the word is a Kanji character. For pure Hiragana words, the proportion of initial fixations did not differ between character positions. Thus, as already indicated by Kambe (National Institute of Japanese Language Report 85 (1986) 29), the visual distinctiveness of the three Japanese scripts plays a role in guiding eye movements in reading Japanese.},
author = {Kajii, N and Nazir, T a and Osaka, N},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kajii, Nazir, Osaka/Kajii, Nazir, Osaka - 2001 - Eye movement control in reading unspaced text the case of the Japanese script. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Analysis of Variance,Cues,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Japan,Reading,Saccades,Saccades: physiology,Space Perception,Space Perception: physiology},
month = sep,
number = {19},
pages = {2503--10},
pmid = {11483180},
title = {{Eye movement control in reading unspaced text: the case of the Japanese script.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11483180},
volume = {41},
year = {2001}
}
@article{Sussman2005,
author = {Sussman, Elyse S.},
doi = {10.1121/1.1854312},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman/Sussman - 2005 - Integration and segregation in auditory scene analysis - The Journal of the Acoustical Society of America.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {3},
pages = {1285},
title = {{Integration and segregation in auditory scene analysis}},
url = {http://link.aip.org/link/JASMAN/v117/i3/p1285/s1\&Agg=doi},
volume = {117},
year = {2005}
}
@article{Wickelmaier2003,
author = {Wickelmaier, Florian},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wickelmaier/Wickelmaier - 2003 - An introduction to MDS - Reports from the Sound Quality Research Unit.pdf:pdf},
journal = {Reports from the Sound Quality Research Unit},
title = {{An introduction to MDS}},
url = {http://steep.inrialpes.fr/~Arnaud/indexation/mds03.pdf},
year = {2003}
}
@article{Geisler2008,
abstract = {The environments in which we live and the tasks we must perform to survive and reproduce have shaped the design of our perceptual systems through evolution and experience. Therefore, direct measurement of the statistical regularities in natural environments (scenes) has great potential value for advancing our understanding of visual perception. This review begins with a general discussion of the natural scene statistics approach, of the different kinds of statistics that can be measured, and of some existing measurement techniques. This is followed by a summary of the natural scene statistics measured over the past 20 years. Finally, there is a summary of the hypotheses, models, and experiments that have emerged from the analysis of natural scene statistics.},
author = {Geisler, Wilson S},
doi = {10.1146/annurev.psych.58.110405.085632},
file = {:Users/pkmital/Documents/Mendeley Desktop/Geisler/Geisler - 2008 - Visual perception and the statistical properties of natural scenes. - Annual review of psychology.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Bayes Theorem,Color Perception,Color Perception: physiology,Data Interpretation, Statistical,Eye Movements,Eye Movements: physiology,Humans,Motion Perception,Motion Perception: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
pages = {167--92},
pmid = {17705683},
title = {{Visual perception and the statistical properties of natural scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17705683},
volume = {59},
year = {2008}
}
@misc{Kastbauer2010,
author = {Kastbauer, Damian},
booktitle = {Gamasutra.com},
file = {::},
pages = {1--6},
publisher = {Gamasutra},
title = {{The Next Big Steps in Game Sound Design}},
year = {2010}
}
@book{Koffka1935,
abstract = {Routledge is now re-issuing this prestigious series of 204 volumes originally published between 1910 and 1965. The titles include works by key figures such asC.G. Jung, Sigmund Freud, Jean Piaget, Otto Rank, James Hillman, Erich Fromm, Karen Horney and Susan Isaacs. Each volume is available on its own, as part of a themed mini-set, or as part of a specially-priced 204-volume set. A brochure listing each title in the International Library of Psychology series is available upon request.},
author = {Koffka, Kurt},
pages = {720},
publisher = {Harcourt, Brace and Company},
title = {{Principles of gestalt psychology}},
url = {http://books.google.co.uk/books/about/Principles\_of\_gestalt\_psychology.html?id=PV5-AAAAMAAJ\&pgis=1},
year = {1935}
}
@article{Candlin2000,
author = {Candlin, Fiona},
doi = {10.1111/1468-5949.00206},
file = {:Users/pkmital/Documents/Mendeley Desktop/Candlin/Candlin - 2000 - Practice-based Doctorates and Questions of Academic Legitimacy - Journal of Art \& Design Education.pdf:pdf},
issn = {02609991},
journal = {Journal of Art \& Design Education},
month = feb,
number = {1},
pages = {96--101},
title = {{Practice-based Doctorates and Questions of Academic Legitimacy}},
url = {http://doi.wiley.com/10.1111/1468-5949.00206},
volume = {19},
year = {2000}
}
@article{Cootes2001,
author = {Cootes, T.F. and Edwards, G.J. and Taylor, C.J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cootes, Edwards, Taylor/Cootes, Edwards, Taylor - 2001 - Active appearance models - Pattern Analysis and Machine Intelligence, IEEE Transactions on.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {6},
pages = {681--685},
publisher = {IEEE},
title = {{Active appearance models}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=927467},
volume = {23},
year = {2001}
}
@article{Aslin2007,
author = {Aslin, RN},
file = {:Users/pkmital/Documents/Mendeley Desktop/Aslin/Aslin - 2007 - What's in a look - Developmental Science.pdf:pdf},
journal = {Developmental Science},
number = {1},
pages = {48--53},
title = {{What's in a look?}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00563.x/full},
volume = {10},
year = {2007}
}
@article{Fidler2012,
author = {Fidler, S. and Urtasun, R.},
doi = {10.1109/CVPR.2012.6247739},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fidler, Urtasun/Fidler, Urtasun - 2012 - Describing the scene as a whole Joint object detection, scene classification and semantic segmentation - 2012 I.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {702--709},
publisher = {Ieee},
title = {{Describing the scene as a whole: Joint object detection, scene classification and semantic segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247739},
year = {2012}
}
@article{Kaneva2011,
author = {Kaneva, Biliana and Torralba, Antonio and Freeman, William T.},
doi = {10.1109/ICCV.2011.6126508},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kaneva, Torralba, Freeman/Kaneva, Torralba, Freeman - 2011 - Evaluation of image features using a photorealistic virtual world - 2011 International Conference on.pdf:pdf},
isbn = {978-1-4577-1102-2},
journal = {2011 International Conference on Computer Vision},
month = nov,
pages = {2282--2289},
publisher = {Ieee},
title = {{Evaluation of image features using a photorealistic virtual world}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126508},
year = {2011}
}
@article{Hausner2001,
author = {Hausner, Alejo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hausner/Hausner - 2001 - Simulating decorative mosaics - Proceedings of the 28th annual conference on Computer graphics and interactive techniqu.pdf:pdf},
isbn = {158113374X},
journal = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques - SIGGRAPH '01},
number = {August},
pages = {12--17},
title = {{Simulating decorative mosaics}},
url = {http://dl.acm.org/citation.cfm?id=383327},
year = {2001}
}
@article{Eitz2009a,
author = {Eitz, Mathias and Hildebrand, Kristian and Boubekeur, Tamy and Alexa, Marc},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eitz et al/Eitz et al. - 2009 - Photosketch A sketch based image query and compositing system - SIGGRAPH 2009 talks.pdf:pdf},
journal = {SIGGRAPH 2009: talks},
pages = {1--4},
title = {{Photosketch: A sketch based image query and compositing system}},
url = {http://dl.acm.org/citation.cfm?id=1598050},
year = {2009}
}
@article{Howe2008,
abstract = {Mitochondria and their relatives constitute a wide range of organelles, only some of which function in aerobic respiration. Mitochondrial remnants from different anaerobic lineages show a striking degree of functional convergence.},
author = {Howe, Christopher J},
doi = {10.1016/j.cub.2008.04.007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Howe/Howe - 2008 - Cellular evolution what's in a mitochondrion - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Aerobiosis,Aerobiosis: physiology,Anaerobiosis,Anaerobiosis: physiology,Animals,Biological Evolution,Blastocystis,Blastocystis: cytology,Blastocystis: genetics,Blastocystis: physiology,Eukaryota,Eukaryota: cytology,Eukaryota: genetics,Eukaryota: physiology,Mitochondria,Mitochondria: genetics,Mitochondria: physiology,Symbiosis,Symbiosis: physiology},
month = may,
number = {10},
pages = {R429--31},
pmid = {18492476},
title = {{Cellular evolution: what's in a mitochondrion?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18492476},
volume = {18},
year = {2008}
}
@inproceedings{Wang2004,
address = {New York, New York, USA},
author = {Wang, Jue and Xu, Yingqing and Shum, Heung-Yeung and Cohen, Michael F.},
booktitle = {SIGGRAPH '04 ACM SIGGRAPH 2004 Papers},
doi = {10.1145/1186562.1015763},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang et al/Wang et al. - 2004 - Video tooning - SIGGRAPH '04 ACM SIGGRAPH 2004 Papers.pdf:pdf},
pages = {574--583},
publisher = {ACM Press},
title = {{Video tooning}},
url = {http://portal.acm.org/citation.cfm?doid=1186562.1015763},
year = {2004}
}
@article{Birmingham2009,
author = {Birmingham, Elina and Bischof, Walter and Kingstone, Alan},
doi = {10.1080/13506280902758044},
file = {:Users/pkmital/Documents/Mendeley Desktop/Birmingham, Bischof, Kingstone/Birmingham, Bischof, Kingstone - 2009 - Get real! Resolving the debate about equivalent social stimuli - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {904--924},
title = {{Get real! Resolving the debate about equivalent social stimuli}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902758044\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@book{Arnheim1971,
author = {Arnheim, Rudolf},
file = {:Users/pkmital/Documents/Mendeley Desktop/Arnheim/Arnheim - 1971 - Entropy and art An essay on disorder and order - Unknown.pdf:pdf},
pages = {1--50},
publisher = {University of California Press, Berkeley 1971},
title = {{Entropy and art: An essay on disorder and order}},
url = {http://books.google.com/books?hl=en\&lr=\&id=kL75af7hbXsC\&oi=fnd\&pg=PA2\&dq=ENTROPY+AND+ART+AN+ESSAY+ON+DISORDER+AND+ORDER\&ots=f\_BW5Z4en5\&sig=kuzXI2Qn89whAQwVmR7QF42s1N4 http://books.google.com/books?hl=en\&lr=\&id=kL75af7hbXsC\&oi=fnd\&pg=PA2\&dq=Entropy+and+art:+An+essay+on+disorder+and+order\&ots=f\_BW5Z55e1\&sig=N2D0tWmsoZRpV0PqQ3JUXqM9Tlk},
year = {1971}
}
@article{Heeger1995,
author = {Heeger, D.J. and Bergen, J.R.},
doi = {10.1109/ICIP.1995.537718},
file = {:Users/pkmital/Documents/Mendeley Desktop/Heeger, Bergen/Heeger, Bergen - 1995 - Pyramid-based texture analysissynthesis - Proceedings., International Conference on Image Processing.pdf:pdf},
isbn = {0-7803-3122-2},
journal = {Proceedings., International Conference on Image Processing},
pages = {648--651},
publisher = {IEEE Comput. Soc. Press},
title = {{Pyramid-based texture analysis/synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=537718},
volume = {3},
year = {1995}
}
@article{Smith2006,
abstract = {Transient periods of synchronized oscillating neuronal discharges in the brain have been proposed to support the discrete perceptual moments underlying conscious visual experience. However, the information content of these perceptual moments remains a critical challenge to the understanding of consciousness. We uncovered this information content in four observers who consciously perceived each interpretation of the ambiguous Dali painting Slave Market with the Disappearing Bust of Voltaire. For each individual observer, we isolated the stimulus spatial frequency (SF) features underlying their overt judgments of the input as "the nuns" and "Voltaire". Every 2 ms between stimulus onset and overt response, we derived the sensitivity of the observer's oscillatory brain activity (in the theta, alpha, and beta bandwidths) to these SF features. Then, in each bandwidth, we estimated the moments (between stimulus onset and perceptual judgment) when perception-specific SF features were maximally integrated, corresponding to perceptual moments. We show that the centroparietal beta oscillations support perceptual moments underlying the conscious perception of the nuns, whereas theta oscillations support the perception of Voltaire. For both perceptions, we reveal the specific information content of these perceptual moments.},
author = {Smith, Marie L and Gosselin, Fr\'{e}d\'{e}ric and Schyns, Philippe G},
doi = {10.1073/pnas.0508972103},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Gosselin, Schyns/Smith, Gosselin, Schyns - 2006 - Perceptual moments of conscious visual experience inferred from oscillatory brain activity. - Proceedings of the National Academy of Sciences of the United States of America.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Behavior,Brain,Brain: physiology,Electrodes,Electroencephalography,Humans,Visual Perception},
month = apr,
number = {14},
pages = {5626--31},
pmid = {16567643},
title = {{Perceptual moments of conscious visual experience inferred from oscillatory brain activity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1459404\&tool=pmcentrez\&rendertype=abstract},
volume = {103},
year = {2006}
}
@article{Young2008,
author = {Young, MW and Drever, JL and Grierson, Mick and Stonehouse, Ian},
file = {:Users/pkmital/Documents/Mendeley Desktop/Young et al/Young et al. - 2008 - Goldsmiths Electronic Music Studios 40 Years - In Proceedings of the 2008 International Computer Music Conference.pdf:pdf},
journal = {In Proceedings of the 2008 International Computer Music Conference},
pages = {8--11},
title = {{Goldsmiths Electronic Music Studios: 40 Years}},
url = {http://eprints.gold.ac.uk/5609/},
year = {2008}
}
@article{Parikh2007,
author = {Parikh, Devi and Chen, Tsuhan},
doi = {10.1109/ICCV.2007.4408960},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Chen/Parikh, Chen - 2007 - Hierarchical Semantics of Objects (hSOs) - 2007 IEEE 11th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-1630-1},
journal = {2007 IEEE 11th International Conference on Computer Vision},
pages = {1--8},
publisher = {Ieee},
title = {{Hierarchical Semantics of Objects (hSOs)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4408960},
year = {2007}
}
@article{Meur2007,
author = {Meur, Olivier Le and Le, Patrick and Barba, Dominique},
doi = {10.1016/j.visres.2007.06.015},
file = {:Users/pkmital/Documents/Mendeley Desktop/Meur, Le, Barba/Meur, Le, Barba - 2007 - Predicting visual fixations on video based on low-level visual features - Vision Research.pdf:pdf},
journal = {Vision Research},
keywords = {bottom,down,eye movements,salience,top,up,visual attention},
pages = {2483--2498},
title = {{Predicting visual fixations on video based on low-level visual features}},
volume = {47},
year = {2007}
}
@misc{Kirn2009,
author = {Kirn, Peter},
booktitle = {Createdigitalmotion.com},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kirn/Kirn - 2009 - How to Datamosh with Free Video Tools, “Datamosh” is the Wrong Word, David O’Reilly is Also Wrong - Createdigitalmo.html:html},
title = {{How to Datamosh with Free Video Tools, “Datamosh” is the Wrong Word, David O’Reilly is Also Wrong}},
url = {http://createdigitalmotion.com/2009/03/how-to-datamosh-with-free-video-tools-datamosh-is-the-wrong-word-david-oreilly-is-also-wrong/},
urldate = {16/09/13},
year = {2009}
}
@article{Bechtel,
author = {Bechtel, William and Wright, C.D.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bechtel, Wright/Bechtel, Wright - Unknown - What is psychological explanation - Routledge Companion to philosophy of psychology, London Routledge.pdf:pdf},
journal = {Routledge Companion to philosophy of psychology, London: Routledge},
title = {{What is psychological explanation}},
url = {http://mechanism.ucsd.edu/research/What is Psychological Explanation.web.pdf}
}
@article{Lang2012,
abstract = {This paper addresses the problem of detecting salient areas within natural images. We shall mainly study the problem under unsupervised setting, i.e., saliency detection without learning from labeled images. A solution of multitask sparsity pursuit is proposed to integrate multiple types of features for detecting saliency collaboratively. Given an image described by multiple features, its saliency map is inferred by seeking the consistently sparse elements from the joint decompositions of multiple-feature matrices into pairs of low-rank and sparse matrices. The inference process is formulated as a constrained nuclear norm and as an l(2, 1)-norm minimization problem, which is convex and can be solved efficiently with an augmented Lagrange multiplier method. Compared with previous methods, which usually make use of multiple features by combining the saliency maps obtained from individual features, the proposed method seamlessly integrates multiple features to produce jointly the saliency map with a single inference step and thus produces more accurate and reliable results. In addition to the unsupervised setting, the proposed method can be also generalized to incorporate the top-down priors obtained from supervised environment. Extensive experiments well validate its superiority over other state-of-the-art methods.},
author = {Lang, Congyan and Liu, Guangcan and Yu, Jian and Yan, Shuicheng},
doi = {10.1109/TIP.2011.2169274},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lang et al/Lang et al. - 2012 - Saliency detection by multitask sparsity pursuit. - IEEE transactions on image processing a publication of the IEEE Signal Processing Society.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
month = mar,
number = {3},
pages = {1327--38},
pmid = {21947527},
title = {{Saliency detection by multitask sparsity pursuit.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22255418},
volume = {21},
year = {2012}
}
@book{Taylor2006b,
author = {Taylor, Brandon},
isbn = {0500286094},
pages = {224},
publisher = {Thames \& Hudson},
title = {{Collage: The Making of Modern Art}},
url = {http://www.amazon.com/Collage-The-Making-Modern-Art/dp/0500286094},
year = {2006}
}
@article{Kuhn2009,
author = {Kuhn, Gustav and Tatler, Benjamin and Cole, Geoff},
doi = {10.1080/13506280902826775},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kuhn, Tatler, Cole/Kuhn, Tatler, Cole - 2009 - You look where I look! Effect of gaze cues on overt and covert attention in misdirection - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {925--944},
title = {{You look where I look! Effect of gaze cues on overt and covert attention in misdirection}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902826775\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@misc{Mital2011c,
author = {Mital, Parag K},
booktitle = {(video)},
title = {{Harry Smith Vs. Dumbo}},
url = {http://vimeo.com/32825674},
urldate = {1 May 2012},
year = {2011}
}
@article{Fischer2009,
abstract = {When attention is directed to a region of space, visual resolution at that location flexibly adapts, becoming sharper to resolve fine-scale details or coarser to reflect large-scale texture and surface properties. By what mechanism does attention improve spatial resolution? An improved signal-to-noise ratio (SNR) at the attended location contributes, because of retinotopically specific signal gain. Additionally, attention could sharpen position tuning at the neural population level, so that adjacent objects activate more distinct regions of the visual cortex. A dual mechanism involving both signal gain and sharpened position tuning would be highly efficient at improving visual resolution, but there is no direct evidence that attention can narrow the position tuning of population responses. Here, we compared the spatial spread of the fMRI BOLD response for attended versus ignored stimuli. The activity produced by adjacent stimuli overlapped less when subjects were attending at their locations versus attending elsewhere, despite a stronger peak response with attention. Our results show that even as early as primary visual cortex (V1), spatially directed attention narrows the tuning of population-coded position representations.},
author = {Fischer, Jason and Whitney, David},
doi = {10.1016/j.cub.2009.06.059},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fischer, Whitney/Fischer, Whitney - 2009 - Attention narrows position tuning of population responses in V1. - Current biology CB.pdf:pdf},
issn = {1879-0445},
journal = {Current biology : CB},
keywords = {Attention,Attention: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Magnetic Resonance Imaging,Models, Neurological,Monte Carlo Method,Neurons,Neurons: physiology,Photic Stimulation,Random Allocation,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
month = aug,
number = {16},
pages = {1356--61},
pmid = {19631540},
publisher = {Elsevier Ltd},
title = {{Attention narrows position tuning of population responses in V1.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2757109\&tool=pmcentrez\&rendertype=abstract},
volume = {19},
year = {2009}
}
@article{Schodl2000,
author = {Sch\"{o}dl, A and Szeliski, Richard and Salesin, DH and Essa, Irfan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sch\"{o}dl et al/Sch\"{o}dl et al. - 2000 - Video textures - Proceedings of the 27th annual \ldots.pdf:pdf},
journal = {Proceedings of the 27th annual \ldots},
keywords = {animation,image-based rendering,morphing,multimedia,natural phe-,nomena,texture synthesis,video sprites,video-based animation,video-based rendering},
title = {{Video textures}},
url = {http://dl.acm.org/citation.cfm?id=345012},
year = {2000}
}
@article{Tang2008,
abstract = {Functional magnetic resonance imaging (fMRI) has become the method of choice for mapping brain activity in human subjects and detects changes in regional blood oxygenation and volume associated with local changes in neuronal activity. While imaging based on blood oxygenation level dependent (BOLD) contrast has good spatial resolution and sensitivity, the hemodynamic signal develops relatively slowly and is only indirectly related to neuronal activity. An alternative approach termed magnetic source magnetic resonance imaging (msMRI) is based on the premise that neural activity may be mapped by magnetic resonance imaging (MRI) with greater temporal resolution by detecting the local magnetic field perturbations associated with local neuronal electric currents. We used a hybrid ms/BOLD MRI method to investigate whether msMRI could detect signal changes that occur simultaneously at the time of the production of well-defined event-related potentials, the P300 and N170, in regions that previously have been identified as generators of these electrical signals. Robust BOLD activations occurred after some seconds, but we were unable to detect any significant changes in the T2*-weighted signal in these locations that correlated temporally with the timings of the evoked response potentials (ERPs).},
author = {Tang, Lin and Avison, Malcolm J and Gatenby, James C and Gore, John C},
doi = {10.1016/j.mri.2007.09.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tang et al/Tang et al. - 2008 - Failure to direct detect magnetic field dephasing corresponding to ERP generation. - Magnetic resonance imaging.pdf:pdf},
issn = {0730-725X},
journal = {Magnetic resonance imaging},
keywords = {Adult,Brain,Brain Mapping,Brain: pathology,Contrast Media,Electricity,Electromagnetic Fields,Evoked Potentials,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Neurons,Neurons: metabolism,Neurons: pathology,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Time Factors},
month = may,
number = {4},
pages = {484--9},
pmid = {18180125},
title = {{Failure to direct detect magnetic field dephasing corresponding to ERP generation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2459244\&tool=pmcentrez\&rendertype=abstract},
volume = {26},
year = {2008}
}
@article{Kwatra2005,
address = {New York, New York, USA},
author = {Kwatra, Vivek and Essa, Irfan and Bobick, Aaron and Kwatra, Nipun},
doi = {10.1145/1186822.1073263},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kwatra et al/Kwatra et al. - 2005 - Texture optimization for example-based synthesis - ACM SIGGRAPH 2005 Papers on - SIGGRAPH '05.pdf:pdf},
journal = {ACM SIGGRAPH 2005 Papers on - SIGGRAPH '05},
keywords = {energy minimization,flow visual-,image-based rendering,ization,texture animation,texture synthesis},
pages = {795},
publisher = {ACM Press},
title = {{Texture optimization for example-based synthesis}},
url = {http://portal.acm.org/citation.cfm?doid=1186822.1073263},
year = {2005}
}
@article{Feuerstein1998,
author = {Feuerstein, PL},
file = {:Users/pkmital/Documents/Mendeley Desktop/Feuerstein/Feuerstein - 1998 - Collage, Technology, and Creative Process Collage, tecnologia e processo creativo - International Conference on Gene.pdf:pdf},
journal = {International Conference on Generative Art},
title = {{Collage, Technology, and Creative Process Collage, tecnologia e processo creativo}},
url = {http://generativeart.com/on/cic/ga98/book/12.pdf},
year = {1998}
}
@article{Seiden1996,
author = {Seiden, Steve},
doi = {10.1145/242581.242585},
file = {:Users/pkmital/Documents/Mendeley Desktop/Seiden/Seiden - 1996 - Theoretical computer science cheat sheet - ACM SIGACT News.pdf:pdf},
issn = {01635700},
journal = {ACM SIGACT News},
month = dec,
number = {4},
pages = {52--61},
title = {{Theoretical computer science cheat sheet}},
url = {http://portal.acm.org/citation.cfm?doid=242581.242585},
volume = {27},
year = {1996}
}
@misc{Fassler2011,
author = {Fassler, Joe},
booktitle = {The Atlantic},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fassler/Fassler - 2011 - How Copyright Law Hurts Music, From Chuck D to Girl Talk - The Atlantic.html:html},
keywords = {Atlantic,Books,TaNehisi Coates,The Atlantic,The Atlantic Magazine,TheAtlantic.com,analysis,commentary,film,magazines,music,news,opinion,popular culture,television},
month = apr,
title = {{How Copyright Law Hurts Music, From Chuck D to Girl Talk}},
url = {http://www.theatlantic.com/entertainment/archive/2011/04/how-copyright-law-hurts-music-from-chuck-d-to-girl-talk/236975/},
year = {2011}
}
@article{Itti2005b,
author = {Itti, Laurent and Baldi, Pierre},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Baldi/Itti, Baldi - 2005 - A Principled Approach to Detecting Surprising Events in Video - Proceedings of the IEEE International Conference on.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition},
number = {June},
title = {{A Principled Approach to Detecting Surprising Events in Video}},
year = {2005}
}
@article{BankerGhosalkar2011,
author = {{Banker Ghosalkar}, Sinora and A.Bharadi, Vinayak and Sharma, Sanjay and Ansari, Asif},
doi = {10.5120/3401-4738},
file = {:Users/pkmital/Documents/Mendeley Desktop/Banker Ghosalkar et al/Banker Ghosalkar et al. - 2011 - Feature Extraction using Overlap Blocks for Content based Image Retrieval - International Journal of Co.pdf:pdf},
issn = {09758887},
journal = {International Journal of Computer Applications},
month = aug,
number = {7},
pages = {14--20},
title = {{Feature Extraction using Overlap Blocks for Content based Image Retrieval}},
url = {http://www.ijcaonline.org/volume28/number7/pxc3874738.pdf},
volume = {28},
year = {2011}
}
@article{Hollingworth2001,
abstract = {What is the nature of the representation formed during the viewing of natural scenes? We tested two competing hypotheses regarding the accumulation of visual information during scene viewing. The first holds that coherent visual representations disintegrate as soon as attention is withdrawn from an object and thus that the visual representation of a scene is exceedingly impoverished. The second holds that visual representations do not necessarily decay upon the withdrawal of attention, but instead can be accumulated in memory from previously attended regions. Target objects in line drawings of natural scenes were changed during a saccadic eye movement away from those objects. Three findings support the second hypothesis. First, changes to the visual form of target objects (token substitution) were successfully detected, as indicated by both explicit and implicit measures, even though the target object was not attended when the change occurred. Second, these detections were often delayed until well after the change. Third, changes to semantically inconsistent target objects were detected better than changes to semantically consistent objects.},
author = {Hollingworth, a and Williams, C C and Henderson, J M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Williams, Henderson/Hollingworth, Williams, Henderson - 2001 - To see and remember visually specific information is retained in memory from previously attended objects in natural scenes. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Eye Movements,Humans,Memory,Random Allocation,Semantics,Signal Detection, Psychological,Visual Perception},
month = dec,
number = {4},
pages = {761--8},
pmid = {11848597},
title = {{To see and remember: visually specific information is retained in memory from previously attended objects in natural scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11848597},
volume = {8},
year = {2001}
}
@article{Brunye2009,
abstract = {Recent work has demonstrated that horizontal saccadic eye movements enhance verbal episodic memory retrieval, particularly in strongly right-handed individuals. The present experiments test three primary assumptions derived from this research. First, horizontal eye movements should facilitate episodic memory for both verbal and non-verbal information. Second, the benefits of horizontal eye movements should only be seen when they immediately precede tasks that demand right and left-hemisphere processing towards successful performance. Third, the benefits of horizontal eye movements should be most pronounced in the strongly right-handed. Two experiments confirmed these hypotheses: horizontal eye movements increased recognition sensitivity and decreased response times during a spatial memory test relative to both vertical eye movements and fixation. These effects were only seen when horizontal eye movements preceded episodic memory retrieval, and not when they preceded encoding (Experiment 1). Further, when eye movements preceded retrieval, they were only beneficial with recognition tests demanding a high degree of right and left-hemisphere activity (Experiment 2). In both experiments the beneficial effects of horizontal eye movements were greatest for strongly right-handed individuals. These results support recent work suggesting increased interhemispheric brain activity induced by bilateral horizontal eye movements, and extend this literature to the encoding and retrieval of landmark shape and location information.},
author = {Bruny\'{e}, Tad T and Mahoney, Caroline R and Augustyn, Jason S and Taylor, Holly a},
doi = {10.1016/j.bandc.2009.03.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bruny\'{e} et al/Bruny\'{e} et al. - 2009 - Horizontal saccadic eye movements enhance the retrieval of landmark shape and location information. - Brain and cognition.pdf:pdf},
issn = {1090-2147},
journal = {Brain and cognition},
keywords = {Female,Fixation, Ocular,Functional Laterality,Humans,Male,Memory,Neuropsychological Tests,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Reaction Time,Recognition (Psychology),Saccades,Spatial Behavior,Verbal Behavior,Young Adult},
month = aug,
number = {3},
pages = {279--88},
pmid = {19346050},
publisher = {Elsevier Inc.},
title = {{Horizontal saccadic eye movements enhance the retrieval of landmark shape and location information.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19346050},
volume = {70},
year = {2009}
}
@article{Nishimoto2011,
author = {Nishimoto, Shinji and Vu, An T. and Naselaris, Thomas and Benjamini, Yuval and Yu, Bin and Gallant, Jack L.},
doi = {10.1016/j.cub.2011.08.031},
file = {:Users/pkmital/Documents/Mendeley Desktop/Nishimoto et al/Nishimoto et al. - 2011 - Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies - Current Biology.pdf:pdf},
issn = {09609822},
journal = {Current Biology},
month = sep,
pages = {1641--1646},
title = {{Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982211009377},
year = {2011}
}
@article{Allamanche2001,
author = {Allamanche, Eric and Herre, J and Hellmuth, Oliver},
file = {:Users/pkmital/Documents/Mendeley Desktop/Allamanche, Herre, Hellmuth/Allamanche, Herre, Hellmuth - 2001 - Content-based identification of audio material using MPEG-7 low level description - Proceedings of the International Symposium on Music Information Retrieval.pdf:pdf},
journal = {Proceedings of the International Symposium on Music Information Retrieval},
title = {{Content-based identification of audio material using MPEG-7 low level description}},
url = {http://pages.cs.brandeis.edu/~dilant/cs175/\%5BAlexander-Friedlander\%5D.pdf},
year = {2001}
}
@article{Yuille2006,
abstract = {We argue that the study of human vision should be aimed at determining how humans perform natural tasks with natural images. Attempts to understand the phenomenology of vision from artificial stimuli, although worthwhile as a starting point, can lead to faulty generalizations about visual systems, because of the enormous complexity of natural images. Dealing with this complexity is daunting, but Bayesian inference on structured probability distributions offers the ability to design theories of vision that can deal with the complexity of natural images, and that use 'analysis by synthesis' strategies with intriguing similarities to the brain. We examine these strategies using recent examples from computer vision, and outline some important implications for cognitive science.},
author = {Yuille, Alan and Kersten, Daniel},
doi = {10.1016/j.tics.2006.05.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yuille, Kersten/Yuille, Kersten - 2006 - Vision as Bayesian inference analysis by synthesis - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Algorithms,Bayes Theorem,Brain,Brain Mapping,Brain: physiology,Field Dependence-Independence,Humans,Markov Chains,Models, Statistical,Monte Carlo Method,Orientation,Orientation: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Probability Theory,Signal Detection, Psychological,Vision, Ocular,Vision, Ocular: physiology,Visual Pathways,Visual Pathways: physiology},
month = jul,
number = {7},
pages = {301--8},
pmid = {16784882},
title = {{Vision as Bayesian inference: analysis by synthesis?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16784882},
volume = {10},
year = {2006}
}
@article{Woods1995,
author = {Woods, D L},
issn = {0424-8155},
journal = {Electroencephalography and clinical neurophysiology. Supplement},
keywords = {Acoustic Stimulation,Brain,Brain Mapping,Brain: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Reaction Time,Reaction Time: physiology},
month = jan,
pages = {102--9},
pmid = {7649012},
title = {{The component structure of the N1 wave of the human auditory evoked potential.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7649012},
volume = {44},
year = {1995}
}
@book{Comer2008,
author = {Comer, Stuart},
isbn = {1854376071},
pages = {144},
publisher = {Tate Publishing},
title = {{Film and Video Art}},
url = {http://www.amazon.co.uk/Film-Video-Art-Stuart-Comer/dp/1854376071},
year = {2008}
}
@article{Kimura,
author = {Kimura, a. and Kashino, K. and Kurozumi, T. and Murase, H.},
doi = {10.1109/ICASSP.2003.1199539},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - Unknown - Dynamic-segmentation-based feature dimension reduction for quick audiovideo searching - 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).pdf:pdf},
isbn = {0-7803-7663-3},
journal = {2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},
pages = {III--573--6},
publisher = {Ieee},
title = {{Dynamic-segmentation-based feature dimension reduction for quick audio/video searching}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1199539}
}
@article{Berg,
author = {a.C. Berg and Maire, M. and Malik, J.},
doi = {10.1109/CVPR.2006.301},
file = {:Users/pkmital/Documents/Mendeley Desktop/Berg, Maire, Malik/Berg, Maire, Malik - Unknown - SVM-KNN Discriminative Nearest Neighbor Classification for Visual Category Recognition - 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06).pdf:pdf},
isbn = {0-7695-2597-0},
journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06)},
pages = {2126--2136},
publisher = {Ieee},
title = {{SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1641014}
}
@article{Wilson2009a,
author = {Wilson, E.},
doi = {10.1093/screen/hjp020},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wilson/Wilson - 2009 - Cinema and Sensation French Film and the Art of Transgression - Screen.pdf:pdf},
issn = {0036-9543},
journal = {Screen},
month = sep,
number = {3},
pages = {349--351},
title = {{Cinema and Sensation: French Film and the Art of Transgression}},
url = {http://screen.oxfordjournals.org/cgi/doi/10.1093/screen/hjp020},
volume = {50},
year = {2009}
}
@article{Topel2011,
author = {Topel, Spencer and Casey, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Topel, Casey/Topel, Casey - 2011 - ELEMENTARY SOURCES LATENT COMPONENT ANALYSIS FOR MUSIC COMPOSITION - International Symposium on Music Information.pdf:pdf},
journal = {International Symposium on Music Information Retrieval 2011},
number = {Ismir},
pages = {579--584},
title = {{ELEMENTARY SOURCES: LATENT COMPONENT ANALYSIS FOR MUSIC COMPOSITION}},
url = {http://ismir2011.ismir.net/papers/PS4-18.pdf},
year = {2011}
}
@article{Teh2003,
author = {Teh, Y.W. and Roweis, Sam},
file = {:Users/pkmital/Documents/Mendeley Desktop/Teh, Roweis/Teh, Roweis - 2003 - Automatic alignment of local representations - Advances in neural information processing systems.pdf:pdf},
issn = {1049-5258},
journal = {Advances in neural information processing systems},
pages = {865--872},
publisher = {Citeseer},
title = {{Automatic alignment of local representations}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.897\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{Raj2010,
author = {Raj, Bhiksha and Virtanen, Tuomas and Chaudhuri, Sourish and Singh, Rita},
file = {:Users/pkmital/Documents/Mendeley Desktop/Raj et al/Raj et al. - 2010 - Non-negative matrix factorization based compensation of music for automatic speech recognition - Proceedings of the 11th Annual Conference of the International Speech Communication Association.pdf:pdf},
journal = {Proceedings of the 11th Annual Conference of the International Speech Communication Association},
pages = {717--720},
title = {{Non-negative matrix factorization based compensation of music for automatic speech recognition}},
url = {http://www.isca-speech.org/archive/interspeech\_2010/i10\_0717.html},
year = {2010}
}
@article{Hollingworth2000,
author = {Hollingworth, Andrew and Henderson, John},
doi = {10.1080/135062800394775},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Henderson/Hollingworth, Henderson - 2000 - Semantic Informativeness Mediates the Detection of Changes in Natural Scenes - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {1},
pages = {213--235},
title = {{Semantic Informativeness Mediates the Detection of Changes in Natural Scenes}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/135062800394775\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {7},
year = {2000}
}
@article{Amatriain2003a,
author = {Amatriain, Xavier and Bonada, Jordi and Loscos, �Lex and Arcos, Josep Llu�s and Verfaille, Vincent},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = mar,
number = {1},
pages = {95--114},
title = {{Content-based Transformations}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1076/jnmr.32.1.95.16800\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {32},
year = {2003}
}
@techreport{Savioja2010,
abstract = {An efficient algorithm for time-domain solution of the wave equation for the purpose of room acous- tics is presented. Numerical dispersion is controlled by computing an adaptive rectangular decompo- sition of the environment and using analytical solutions within the partitions that rely on spatially invariant speed of sound. Due to the near absence of dispersion, this technique is suitable for au- ralizations and sound field visualizations, even on coarse meshes approaching the Nyquist limit. It is demonstrated that by carefully mapping all components of the algorithm to match the paral- lel processing capabilities of graphics processors, significant improvement in performance is gained compared to the corresponding CPU-based solver, while producing numerically identical results. Substantial performance gain over a high-order finite-difference time-domain (FDTD) method is observed. Using this technique, a 1 second long simulation can be performed on scenes of air vol- ume 7500 m3 till 1650 Hz within 18 minutes compared to the corresponding CPU-based solver that takes five hours and the high-order FDTD solver up to three weeks on a desktop computer. To the best of the authors’ knowledge, this is the fastest time-domain solver for modeling the room acoustics of large, complex-shaped 3D scenes that generates broad-band results for both auralization and visualization.},
address = {Chapel Hill},
author = {Savioja, Lauri and Mehra, Ravish and Raghuvanshi, Nikunj and Lin, Ming C. and Manocha, Dinesh},
booktitle = {Processing},
file = {::},
institution = {University of North Carolina},
title = {{An efficient time-domain solver for the acoustic wave equation on graphics processors}},
year = {2010}
}
@article{Bregman1990,
author = {Bregman, Albert S.},
isbn = {9780262022972},
month = may,
title = {{Auditory Scene Analysis: The Perceptual Organization of Sound}},
url = {http://mitpress.mit.edu/catalog/item/default.asp?ttype=2\&tid=9065},
year = {1990}
}
@article{Tseng2009,
author = {Tseng, Po-he and Cameron, Ian G M and Munoz, Douglas P and Itti, Laurent},
doi = {10.1167/9.7.4.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tseng et al/Tseng et al. - 2009 - Quantifying center bias of observers in free viewing of dynamic natural scenes - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {eye,eye movement,eye position,fixation,head coordination,motor bias,ocular,orbital reserve,photographer bias,saccade,saccade selection,saccadic eye movement,salience,saliency maps,visuo-motor optimizing strategy},
pages = {1--16},
title = {{Quantifying center bias of observers in free viewing of dynamic natural scenes}},
volume = {9},
year = {2009}
}
@article{Ingram2010,
author = {Ingram, Stephen and Munzner, Tamara and Irvine, Veronika and Tory, Melanie and Bergner, Steven and Moller, Torsten},
doi = {10.1109/VAST.2010.5652392},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ingram et al/Ingram et al. - 2010 - DimStiller Workflows for dimensional analysis and reduction - 2010 IEEE Symposium on Visual Analytics Science and.pdf:pdf},
isbn = {978-1-4244-9488-0},
journal = {2010 IEEE Symposium on Visual Analytics Science and Technology},
month = oct,
pages = {3--10},
publisher = {Ieee},
title = {{DimStiller: Workflows for dimensional analysis and reduction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5652392},
year = {2010}
}
@article{DeCarlo2002,
author = {DeCarlo, Doug and Santella, Anthony},
doi = {10.1145/566654.566650},
file = {:Users/pkmital/Documents/Mendeley Desktop/DeCarlo, Santella/DeCarlo, Santella - 2002 - Stylization and abstraction of photographs - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {eye-,image simplification,non-photorealistic rendering,tracking,visual perception},
month = jul,
number = {3},
pages = {1--8},
title = {{Stylization and abstraction of photographs}},
url = {http://portal.acm.org/citation.cfm?doid=566654.566650},
volume = {21},
year = {2002}
}
@misc{Kalloniatis2007,
author = {Kalloniatis, Michael and Luu, Charles},
booktitle = {Webvision: The Organization of the Retina and Visual System},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalloniatis, Luu/Kalloniatis, Luu - 2007 - Visual Acuity - Webvision The Organization of the Retina and Visual System.html:html},
title = {{Visual Acuity}},
url = {http://webvision.med.utah.edu/book/part-viii-gabac-receptors/visual-acuity/},
urldate = {07/09/13},
year = {2007}
}
@article{Slaney2001,
author = {Slaney, Malcolm},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slaney/Slaney - 2001 - Facesync A linear operator for measuring synchronization of video facial images and audio tracks - Advances in Neural In.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--7},
title = {{Facesync: A linear operator for measuring synchronization of video facial images and audio tracks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.9943\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Burdette1986,
abstract = {The influence of visual processing demands on saccade-triggered evoked potentials was investigated at P3, P4 and Oz recording sites during reading and tracking tasks. To maximize the physical similarities between tasks, subjects tracked a series of lights that flashed in a stereotypic reading pattern behind a page of text; eye movements recorded during reading initiated the light sequence. In the first experiment, a significant decrease observed in the latency of the major positive peak recorded from Oz during tracking was attributed to the smaller amplitude of tracking, relative to reading, saccades. To confirm this interpretation, the experiment was repeated with modification to the light display. As anticipated, equating saccade amplitudes across tasks eliminated waveform differences in the second experiment. Although peak latencies and amplitudes were not influenced reliably by visual processing demands, tracking potentials exhibited a negative DC shift relative to reading waveforms that was significant at 174 msec at the Oz site. These data suggest that the saccade-triggered evoked potential components generally are insensitive to task differences within the visual modality when visual configuration and eye movement parameters are controlled.},
author = {Burdette, L J and Walrath, L C and Gross, J and James, B and Stern, J a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Burdette et al/Burdette et al. - 1986 - A comparison of saccade evoked potentials recorded during reading and tracking tasks. - Physiology \& behavior.pdf:pdf},
issn = {0031-9384},
journal = {Physiology \& behavior},
keywords = {Adult,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Evoked Potentials, Visual,Eye Movements,Humans,Male,Pursuit, Smooth,Reaction Time,Reaction Time: physiology,Reading,Saccades},
month = jan,
number = {4},
pages = {527--32},
pmid = {3749314},
title = {{A comparison of saccade evoked potentials recorded during reading and tracking tasks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3749314},
volume = {37},
year = {1986}
}
@article{Henderson2009a,
author = {Henderson, John and Smith, Tim},
doi = {10.1080/13506280802685552},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Smith/Henderson, Smith - 2009 - How are eye fixation durations controlled during scene viewing Further evidence from a scene onset delay paradigm - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1055--1082},
title = {{How are eye fixation durations controlled during scene viewing? Further evidence from a scene onset delay paradigm}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280802685552\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Basovnik,
author = {Obdr\v{z}\'{a}lek, D and Basovn\'{\i}k, S and Mach, Lukas and Mikul\'{\i}k, A},
file = {:Users/pkmital/Documents/Mendeley Desktop/Obdr\v{z}\'{a}lek et al/Obdr\v{z}\'{a}lek et al. - 2010 - Detecting scene elements using maximally stable colour regions - Research and Education in \ldots.pdf:pdf},
journal = {Research and Education in \ldots},
keywords = {autonomous robot,maximally stable colour regions},
title = {{Detecting scene elements using maximally stable colour regions}},
url = {http://www.springerlink.com/index/J43W228Q805P3871.pdf},
year = {2010}
}
@article{Torralba2003,
abstract = {Models of visual attention have focused predominantly on bottom-up approaches that ignored structured contextual and scene information. I propose a model of contextual cueing for attention guidance based onthe global scene configuration. It is shown that the statistics of low-level features across the whole image can be used to prime the presence or absence of objects in the scene and to predict their location, scale, and appearance before exploring the image. In this scheme, visual context information can become available early in the visual processing chain, which allows modulation of the saliency of image regions and provides an efficient shortcut for object detection and recognition.},
author = {Torralba, Antonio},
institution = {Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 400 Technology Square, Cambridge, Massachusetts 02115, USA. torralba@ai.mit.edu},
journal = {Journal of the Optical Society of America A},
keywords = {attention,humans,models,pattern recognition,psychological,visual,visual perception,visual perception physiology},
number = {7},
pages = {1407--1418},
pmid = {12868645},
publisher = {Optical Society of America},
title = {{Modeling global scene factors in attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12868645},
volume = {20},
year = {2003}
}
@inproceedings{Kimura2004b,
author = {Kimura, A. and Kawanishi, T. and Kashino, K.},
booktitle = {Multimedia and Expo, 2004. ICME'04. 2004 IEEE International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Kawanishi, Kashino/Kimura, Kawanishi, Kashino - 2004 - Similarity-based partial image retrieval guaranteeing same accuracy as exhaustive matching - Multimedia and Expo, 2004. ICME'04. 2004 IEEE International Conference on.pdf:pdf},
isbn = {0780386035},
number = {1},
pages = {1895--1898},
publisher = {IEEE},
title = {{Similarity-based partial image retrieval guaranteeing same accuracy as exhaustive matching}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1394629},
volume = {3},
year = {2004}
}
@article{Smeulders2000,
author = {Smeulders, Arnold W M and Member, Senior and Worring, Marcel and Santini, Simone and Gupta, Amarnath and Jain, Ramesh},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smeulders et al/Smeulders et al. - 2000 - Content-Based Image Retrieval at the End of the Early Years - IEEE Transactions on Pattern Analysis and Machine Intelligence.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {12},
pages = {1--32},
title = {{Content-Based Image Retrieval at the End of the Early Years}},
volume = {22},
year = {2000}
}
@book{No\\e2004,
author = {No$\backslash$$\backslash$"e, A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Noe/Noe - 2004 - Action in perception - Unknown.pdf:pdf},
isbn = {0262140888},
publisher = {the MIT Press},
title = {{Action in perception}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=kFKvU2hPhxEC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Action+in+Perception\&amp;ots=FZsJHhVms3\&amp;sig=a6QsvWdgjBDQiq2sxDRQ4ivNlt8},
year = {2004}
}
@article{Lin1991,
author = {Lin, J.},
doi = {10.1109/18.61115},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lin/Lin - 1991 - Divergence measures based on the Shannon entropy - Unknown.pdf:pdf},
issn = {00189448},
number = {1},
pages = {145--151},
title = {{Divergence measures based on the Shannon entropy}},
volume = {37},
year = {1991}
}
@article{Thomas2006,
abstract = {Inhibition of return (IOR) has long been viewed as a foraging facilitator in visual search. We investigated the contribution of IOR in a task that approximates natural foraging more closely than typical visual search tasks. Participants in a fully immersive virtual reality environment manually searched an array of leaves for a hidden piece of fruit, using a wand to select and examine each leaf location. Search was slower than in typical IOR paradigms, taking seconds instead of a few hundred milliseconds. Participants also made a speeded response when they detected a flashing leaf that either was or was not in a previously searched location. Responses were slower when the flashing leaf was in a previously searched location than when it was in an unvisited location. These results generalize IOR to an approximation of a naturalistic visual search setting and support the hypothesis that IOR can facilitate foraging. The experiment also constitutes the first use of a fully immersive virtual reality display in the study of IOR.},
author = {Thomas, Laura E and Ambinder, Michael S and Hsieh, Brendon and Levinthal, Brian and Crowell, James a and Irwin, David E and Kramer, Arthur F and Lleras, Alejandro and Simons, Daniel J and Wang, Ranxiao Frances},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thomas et al/Thomas et al. - 2006 - Fruitful visual search inhibition of return in a virtual foraging task. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Choice Behavior,Discrimination Learning,Humans,Inhibition (Psychology),Memory, Short-Term,Mental Recall,Orientation,Pattern Recognition, Visual,Perceptual Masking,Reaction Time,Social Environment,User-Computer Interface},
month = oct,
number = {5},
pages = {891--5},
pmid = {17328391},
title = {{Fruitful visual search: inhibition of return in a virtual foraging task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17328391},
volume = {13},
year = {2006}
}
@article{Landman2004,
abstract = {Partial report methods have shown that a large-capacity representation exists for a few hundred milliseconds after a picture has disappeared. However, change blindness studies indicate that very limited information remains available when a changed version of the image is presented subsequently. What happens to the large-capacity representation? New input after the first image may interfere, but this is likely to depend on the characteristics of the new input. In our first experiment, we show that a display containing homogeneous image elements between changing images does not render the large-capacity representation unavailable. Interference occurs when these new elements define objects. On that basis we introduce a new method to produce change blindness: The second experiment shows that change blindness can be induced by redefining figure and background, without an interval between the displays. The local features (line segments) that defined figures and background were swapped, while the contours of the figures remained where they were. Normally, changes are easily detected when there is no interval. However, our paradigm results in massive change blindness. We propose that in a change blindness experiment, there is a large-capacity representation of the original image when it is followed by a homogeneous interval display, but that change blindness occurs whenever the changed image forces resegregation of figures from the background.},
author = {Landman, Rogier and Spekreijse, Henk and Lamme, Victor a F},
file = {:Users/pkmital/Documents/Mendeley Desktop/Landman, Spekreijse, Lamme/Landman, Spekreijse, Lamme - 2004 - The role of figure-ground segregation in change blindness. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Cues,Discrimination (Psychology),Humans,Time Factors,Visual Perception},
month = apr,
number = {2},
pages = {254--61},
pmid = {15260190},
title = {{The role of figure-ground segregation in change blindness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15260190},
volume = {11},
year = {2004}
}
@article{Schomaker2012,
abstract = {The effects of novelty on low-level visual perception were investigated in two experiments using a two-alternative forced-choice tilt detection task. A target, consisting of a Gabor patch, was preceded by a cue that was either a novel or a familiar fractal image. Participants had to indicate whether the Gabor stimulus was vertically oriented or slightly tilted. In the first experiment tilt angle was manipulated; in the second contrast of the Gabor patch was varied. In the first, we found that sensitivity was enhanced after a novel compared to a familiar cue, and in the second we found sensitivity to be enhanced for novel cues in later experimental blocks when participants became more and more familiarized with the familiar cue. These effects were not caused by a shift in the response criterion. This shows for the first time that novel stimuli affect low-level characteristics of perception. We suggest that novelty can elicit a transient attentional response, thereby enhancing perception.},
author = {Schomaker, Judith and Meeter, Martijn},
doi = {10.1371/journal.pone.0050599},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schomaker, Meeter/Schomaker, Meeter - 2012 - Novelty enhances visual perception. - PloS one.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Bandages,Humans,Photic Stimulation,Visual Perception},
month = jan,
number = {12},
pages = {e50599},
pmid = {23227190},
title = {{Novelty enhances visual perception.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3515594\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2012}
}
@article{Kling2004a,
author = {Kling, Garry},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kling/Kling - 2004 - Audio analysis, visualization, and transformation with the matching pursuit algorithm - Conference on Digital Audio Effects (DAFx-04).pdf:pdf},
journal = {Conference on Digital Audio Effects (DAFx-04)},
pages = {33--37},
title = {{Audio analysis, visualization, and transformation with the matching pursuit algorithm}},
url = {http://dafx04.na.infn.it/WebProc/Proc/P\_033.pdf},
year = {2004}
}
@phdthesis{Manovich1993,
author = {Manovich, Lev},
file = {:Users/pkmital/Documents/Mendeley Desktop/Manovich/Manovich - 1993 - The Engineering of Vision from Constructivism to Computers - Unknown.PDF:PDF},
school = {University of Rochester},
title = {{The Engineering of Vision from Constructivism to Computers}},
year = {1993}
}
@inproceedings{Mital2012,
author = {Mital, Parag Kumar and Grierson, Mick},
booktitle = {ACM Multimedia 2012 (In Review)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mital, Grierson/Mital, Grierson - 2012 - Separation and Classification of Acoustic Mixtures using Mel-Frequency-based Probabilistic Latent Component Analysis - ACM Multimedia 2012 (In Review).pdf:pdf},
title = {{Separation and Classification of Acoustic Mixtures using Mel-Frequency-based Probabilistic Latent Component Analysis}},
year = {2012}
}
@article{Mould2012,
author = {Mould, David and Mandryk, Regan L. and Li, Hua},
doi = {10.1016/j.cag.2012.03.039},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mould, Mandryk, Li/Mould, Mandryk, Li - 2012 - Emotional response and visual attention to non-photorealistic images - Computers \& Graphics.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Affect,Arousal,Emotion,Eye tracking,Gaze,Valence,non-photorealistic rendering},
month = oct,
number = {6},
pages = {658--672},
publisher = {Elsevier},
title = {{Emotional response and visual attention to non-photorealistic images}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S009784931200088X},
volume = {36},
year = {2012}
}
@article{Evangelopoulos,
author = {Evangelopoulos, Georgios and Rapantzikos, Konstantinos and Maragos, Petros},
file = {:Users/pkmital/Documents/Mendeley Desktop/Evangelopoulos, Rapantzikos, Maragos/Evangelopoulos, Rapantzikos, Maragos - Unknown - Audio-Visual Attention Modeling and Salient Event Detection - Audio.pdf:pdf},
journal = {Audio},
title = {{Audio-Visual Attention Modeling and Salient Event Detection}}
}
@article{Fujiwara2009,
author = {Fujiwara, Yusuke and Miyawaki, Yoichi and Kamitani, Yukiyasu},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fujiwara, Miyawaki, Kamitani/Fujiwara, Miyawaki, Kamitani - 2009 - Estimating image bases for visual image reconstruction from human brain activity - Advances in Neu.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
title = {{Estimating image bases for visual image reconstruction from human brain activity}},
url = {http://machinelearning.wustl.edu/mlpapers/paper\_files/NIPS2009\_0804.pdf},
year = {2009}
}
@article{Rabinowitz2011,
author = {Rabinowitz, Neil C. and King, Andrew J.},
doi = {10.1016/j.cub.2011.10.027},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rabinowitz, King/Rabinowitz, King - 2011 - Auditory Perception Hearing the Texture of Sounds - Current Biology.pdf:pdf},
issn = {09609822},
journal = {Current Biology},
month = dec,
number = {23},
pages = {R967--R968},
title = {{Auditory Perception: Hearing the Texture of Sounds}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982211011882},
volume = {21},
year = {2011}
}
@article{Sudderth2005,
author = {Sudderth, Erik B and Torralba, Antonio and Freeman, William T and Willsky, Alan S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sudderth et al/Sudderth et al. - 2005 - Describing Visual Scenes using Transformed Dirichlet Processes - Unknown.pdf:pdf},
title = {{Describing Visual Scenes using Transformed Dirichlet Processes}},
year = {2005}
}
@article{Inhoff1998a,
author = {Inhoff, Albrecht W and Starr, Mathew and Liu, Weimin and Wang, Jian},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff et al/Inhoff et al. - 1998 - Eye-movement-contingent display changes are not compromised by flicker and phosphor persistence - Psychonomic Bulletin \& Review.pdf:pdf},
journal = {Psychonomic Bulletin \& Review},
number = {1},
pages = {101--106},
title = {{Eye-movement-contingent display changes are not compromised by flicker and phosphor persistence}},
volume = {5},
year = {1998}
}
@article{DeAngelus2009,
author = {DeAngelus, Marianne and Pelz, Jeff},
doi = {10.1080/13506280902793843},
file = {:Users/pkmital/Documents/Mendeley Desktop/DeAngelus, Pelz/DeAngelus, Pelz - 2009 - Top-down control of eye movements Yarbus revisited - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {790--811},
title = {{Top-down control of eye movements: Yarbus revisited}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902793843\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Marius'tHart2009,
author = {{Marius 't Hart}, Bernard and Vockeroth, Johannes and Schumann, Frank and Bartl, Klaus and Schneider, Erich and Konig, Peter and Einhauser, Wolfgang},
doi = {10.1080/13506280902812304},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marius 't Hart et al/Marius 't Hart et al. - 2009 - Gaze allocation in natural stimuli Comparing free exploration to head-fixed viewing conditions - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1132--1158},
title = {{Gaze allocation in natural stimuli: Comparing free exploration to head-fixed viewing conditions}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902812304\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Tatler2007,
author = {Tatler, Benjamin W},
doi = {10.1167/7.14.4.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler/Tatler - 2007 - The central fixation bias in scene viewing Selecting an optimal viewing position independently of motor biases and imag.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,14,17,2007,4,7,b,citation,eye movements,fixation location,http,image feature distributions,in scene viewing,journal of vision,journalofvision,kernel density estimation,natural images,of motor biases and,org,position independently,salience,selecting an optimal viewing,task,tatler,the central fixation bias,w},
pages = {1--17},
title = {{The central fixation bias in scene viewing : Selecting an optimal viewing position independently of motor biases and image feature distributions}},
volume = {7},
year = {2007}
}
@article{Pham2006,
author = {Pham, T V and Smeulders, A},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {4},
pages = {555--567},
title = {{Sparse Representation for Coarse and Fine Object Recognition}},
volume = {28},
year = {2006}
}
@article{Kimura2008c,
author = {Kimura, Akisato and Pang, Derek},
doi = {10.1109/ICPR.2008.4761025},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Pang/Kimura, Pang - 2008 - Dynamic Markov random fields for stochastic modeling of visual attention - 2008 19th International Conference on Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
journal = {2008 19th International Conference on Pattern Recognition},
month = dec,
number = {1},
pages = {1--5},
publisher = {Ieee},
title = {{Dynamic Markov random fields for stochastic modeling of visual attention}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4761025},
year = {2008}
}
@article{Filipe2013,
author = {Filipe, S\'{\i}lvio and Alexandre, Lu\'{\i}s a.},
doi = {10.1007/s10462-012-9385-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Filipe, Alexandre/Filipe, Alexandre - 2013 - From the human visual system to the computational models of visual attention a survey - Artificial Intelligen.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {biologically motivated computer vision,regions of interest,saliency,visual attention},
month = jan,
title = {{From the human visual system to the computational models of visual attention: a survey}},
url = {http://link.springer.com/10.1007/s10462-012-9385-4},
year = {2013}
}
@article{Lichty2000,
author = {Lichty, P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lichty/Lichty - 2000 - The Cybernetics of Performance and New Media Art - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {5},
pages = {351--354},
title = {{The Cybernetics of Performance and New Media Art}},
url = {http://www.mitpressjournals.org/doi/pdf/10.1162/002409400552810},
volume = {33},
year = {2000}
}
@article{Weinberger1998,
abstract = {"Physiological memory" is enduring neuronal change sufficiently specific to represent learned information. It transcends both sensory traces that are detailed but transient and long-term physiological plasticities that are insufficiently specific to actually represent cardinal details of an experience. The specificity of most physiological plasticities has not been comprehensively studied. We adopted receptive field analysis from sensory physiology to seek physiological memory in the primary auditory cortex of adult guinea pigs. Receptive fields for acoustic frequency were determined before and at various retention intervals after a learning experience, typified by single-tone delay classical conditioning, e.g., 30 trials of tone-shock pairing. Subjects rapidly (5-10 trials) acquire behavioral fear conditioned responses, indexing acquisition of an association between the conditioned and the unconditioned stimuli. Such stimulus-stimulus association produces receptive field plasticity in which responses to the conditioned stimulus frequency are increased in contrast to responses to other frequencies which are decreased, resulting in a shift of tuning toward or to the frequency of the conditioned stimulus. This receptive field plasticity is associative, highly specific, acquired within a few trials, and retained indefinitely (tested to 8 weeks). It thus meets criteria for "physiological memory." The acquired importance of the conditioned stimulus is thought to be represented by the increase in tuning to this stimulus during learning, both within cells and across the primary auditory cortex. Further, receptive field plasticity develops in several tasks, one-tone and two-tone discriminative classical and instrumental conditioning (habituation produces a frequency-specific decrease in the receptive field), suggesting it as a general process for representing the acquired meaning of a signal stimulus. We have proposed a two-stage model involving convergence of the conditioned and unconditioned stimuli in the magnocellular medial geniculate of the thalamus followed by activation of the nucleus basalis, which in turn releases acetylcholine that engages muscarinic receptors in the auditory cortex. This model is supported by several recent findings. For example, tone paired with NB stimulation induces associative, specific receptive field plasticity of at least a 24-h duration. We propose that physiological memory in auditory cortex is not "procedural" memory, i.e., is not tied to any behavioral conditioned response, but can be used flexibly.},
author = {Weinberger, N M},
doi = {10.1006/nlme.1998.3850},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weinberger/Weinberger - 1998 - Physiological memory in primary auditory cortex characteristics and mechanisms. - Neurobiology of learning and memor.pdf:pdf},
issn = {1074-7427},
journal = {Neurobiology of learning and memory},
keywords = {Acetylcholine,Acetylcholine: biosynthesis,Animals,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Conditioning, Classical,Conditioning, Classical: physiology,Guinea Pigs,Habituation, Psychophysiologic,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Models, Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Thalamus,Thalamus: metabolism},
number = {1-2},
pages = {226--51},
pmid = {9753599},
title = {{Physiological memory in primary auditory cortex: characteristics and mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9753599},
volume = {70},
year = {1998}
}
@article{Tanaka2001,
abstract = {Traditional theories of object recognition have emphasized the role of shape information in high-level vision. However, the accumulating behavioral, neuroimaging and neuropsychological evidence indicates that the surface color of an object affects its recognition. In this article, we discuss the research that examines the conditions under which color influences the operations of high-level vision and the neural substrates that might mediate these operations. The relationship between object color and object recognition is summarized in the 'Shape+Surface' model of high-level vision.},
author = {Tanaka, J and Weiskopf, D and Williams, P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tanaka, Weiskopf, Williams/Tanaka, Weiskopf, Williams - 2001 - The role of color in high-level vision. - Trends in cognitive sciences.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = may,
number = {5},
pages = {211--215},
pmid = {11323266},
title = {{The role of color in high-level vision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11323266},
volume = {5},
year = {2001}
}
@article{Pylyshyn2001,
author = {Pylyshyn, Zenon W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pylyshyn/Pylyshyn - 2001 - Visual indexes, preconceptual objects, and situated vision - Cognition.pdf:pdf},
journal = {Cognition},
pages = {127--158},
title = {{Visual indexes, preconceptual objects, and situated vision}},
volume = {80},
year = {2001}
}
@article{Maki2000,
author = {Maki, a},
doi = {10.1006/cviu.2000.0840},
file = {:Users/pkmital/Documents/Mendeley Desktop/Maki/Maki - 2000 - Attentional Scene Segmentation Integrating Depth and Motion - Computer Vision and Image Understanding.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {attention,cue integration,image flow,motion,pursuit,saccade,stereoscopic depth,target},
month = jun,
number = {3},
pages = {351--373},
title = {{Attentional Scene Segmentation: Integrating Depth and Motion}},
url = {http://linkinghub.elsevier.com/retrieve/doi/10.1006/cviu.2000.0840},
volume = {78},
year = {2000}
}
@article{Liu1989,
author = {Liu, D.C. and Nocedal, J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu, Nocedal/Liu, Nocedal - 1989 - On the limited memory BFGS method for large scale optimization - Mathematical programming.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical programming},
number = {1},
pages = {503--528},
publisher = {Springer},
title = {{On the limited memory BFGS method for large scale optimization}},
url = {http://www.springerlink.com/index/K5653WT4Q8061176.pdf},
volume = {45},
year = {1989}
}
@article{Torralba2006a,
abstract = {Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes.},
author = {Torralba, Antonio and Oliva, Aude and Castelhano, Monica S and Henderson, John M},
doi = {10.1037/0033-295X.113.4.766},
file = {:Users/pkmital/Documents/Mendeley Desktop/Torralba et al/Torralba et al. - 2006 - Contextual guidance of eye movements and attention in real-world scenes the role of global features in object search. - Psychological review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Attention,Bayes Theorem,Eye Movements,Humans,Models, Psychological,Social Environment,Visual Perception},
month = oct,
number = {4},
pages = {766--86},
pmid = {17014302},
title = {{Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17014302},
volume = {113},
year = {2006}
}
@book{McLeod2011,
author = {McLeod, Kembrew},
isbn = {0822348225},
pages = {376},
publisher = {Duke University Press Books},
title = {{Cutting Across Media: Appropriation Art, Interventionist Collage, and Copyright Law}},
url = {http://www.amazon.com/Cutting-Across-Media-Appropriation-Interventionist/dp/0822348225},
year = {2011}
}
@article{Santella2004a,
author = {Santella, Anthony and DeCarlo, Doug},
file = {:Users/pkmital/Documents/Mendeley Desktop/Santella, DeCarlo/Santella, DeCarlo - 2004 - Visual interest and NPR an evaluation and manifesto - Proceedings of the 3rd international symposium \ldots.pdf:pdf},
journal = {Proceedings of the 3rd international symposium \ldots},
keywords = {abstraction,evaluation,eye tracking,visual perception},
pages = {1--8},
title = {{Visual interest and NPR: an evaluation and manifesto}},
url = {http://dl.acm.org/citation.cfm?id=987669},
year = {2004}
}
@article{Sussman2002a,
abstract = {OBJECTIVE: Our previous study showed that the auditory context could influence whether two successive acoustic changes occurring within the temporal integration window (approximately 200ms) were pre-attentively encoded as a single auditory event or as two discrete events (Cogn Brain Res 12 (2001) 431). The aim of the current study was to assess whether top-down processes could influence the stimulus-driven processes in determining what constitutes an auditory event.

METHODS: Electroencepholagram (EEG) was recorded from 11 scalp electrodes to frequently occurring standard and infrequently occurring deviant sounds. Within the stimulus blocks, deviants either occurred only in pairs (successive feature changes) or both singly and in pairs. Event-related potential indices of change and target detection, the mismatch negativity (MMN) and the N2b component, respectively, were compared with the simultaneously measured performance in discriminating the deviants.

RESULTS: Even though subjects could voluntarily distinguish the two successive auditory feature changes from each other, which was also indicated by the elicitation of the N2b target-detection response, top-down processes did not modify the event organization reflected by the MMN response.

CONCLUSIONS: Top-down processes can extract elemental auditory information from a single integrated acoustic event, but the extraction occurs at a later processing stage than the one whose outcome is indexed by MMN.

SIGNIFICANCE: Initial processes of auditory event-formation are fully governed by the context within which the sounds occur. Perception of the deviants as two separate sound events (the top-down effects) did not change the initial neural representation of the same deviants as one event (indexed by the MMN), without a corresponding change in the stimulus-driven sound organization.},
author = {Sussman, Elyse and Winkler, Istv\'{a}n and Kreuzer, Judith and Saher, Marieke and N\"{a}\"{a}t\"{a}nen, Risto and Ritter, Walter},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman et al/Sussman et al. - 2002 - Temporal integration intentional sound discrimination does not modulate stimulus-driven processes in auditory ev.pdf:pdf},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Analysis of Variance,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male},
month = dec,
number = {12},
pages = {1909--20},
pmid = {12464328},
title = {{Temporal integration: intentional sound discrimination does not modulate stimulus-driven processes in auditory event synthesis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12464328},
volume = {113},
year = {2002}
}
@article{Hendriks1996,
author = {Hendriks, Angelique W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hendriks/Hendriks - 1996 - acta psychologica Vergence eye movements during fixations in reading - Acta Psychologica.pdf:pdf},
journal = {Acta Psychologica},
keywords = {attention,binocular fixation,eye-movement,reading,vergence},
pages = {131--151},
title = {{acta psychologica Vergence eye movements during fixations in reading}},
volume = {92},
year = {1996}
}
@article{Sussman2002,
abstract = {We recorded event-related potentials (ERPs) and magnetic fields (ERFs) of the human brain to determine whether top-down control could modulate the initial organization of sound representations in the auditory cortex. We presented identical sound stimulation and manipulated top-down processes by instructing participants to either ignore the sounds (Ignore condition), to detect pitch changes (Attend-pitch condition), or to detect violations of a repeating tone pattern (Attend-pattern condition). The ERP results obtained in the Attend-pattern condition dramatically differed from those obtained with the other two task instructions. The magnetoencephalogram (MEG) findings were fully compatible, showing that the neural populations involved in detecting pattern violations differed from those involved in detecting pitch changes. The results demonstrate a top-down effect on the sound representation maintained in auditory cortex.},
author = {Sussman, Elyse and Winkler, Istv\'{a}n and Huotilainen, Minna and Ritter, Walter and N\"{a}\"{a}t\"{a}nen, Risto},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman et al/Sussman et al. - 2002 - Top-down effects can modify the initially stimulus-driven auditory organization. - Brain research. Cognitive bra.pdf:pdf},
issn = {0926-6410},
journal = {Brain research. Cognitive brain research},
keywords = {Acoustic Stimulation,Adult,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Evoked Potentials,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Magnetic Resonance Imaging,Magnetoencephalography,Mental Processes,Mental Processes: physiology,Pitch Discrimination,Pitch Discrimination: physiology,Reference Values},
month = may,
number = {3},
pages = {393--405},
pmid = {11919003},
title = {{Top-down effects can modify the initially stimulus-driven auditory organization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11919003},
volume = {13},
year = {2002}
}
@phdthesis{Sturm2009,
address = {Santa Barbara, CA},
author = {Sturm, B L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm/Sturm - 2009 - Sparse Approximation and Atomic Decomposition Considering Atom Interactions in Evaluating and Building Signal Representat.pdf:pdf},
school = {University of California},
title = {{Sparse Approximation and Atomic Decomposition: Considering Atom Interactions in Evaluating and Building Signal Representations}},
year = {2009}
}
@article{Ehinger2009a,
author = {Ehinger, Krista A and Hidalgo-sotelo, Barbara and Torralba, Antonio},
doi = {10.1080/13506280902834720},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ehinger, Hidalgo-sotelo, Torralba/Ehinger, Hidalgo-sotelo, Torralba - 2009 - Modelling search for people in 900 scenes A combined source model of eye guidance - Electrical Engineering.pdf:pdf},
journal = {Electrical Engineering},
number = {0546262},
title = {{Modelling search for people in 900 scenes : A combined source model of eye guidance}},
volume = {17},
year = {2009}
}
@article{Inhoff2005a,
abstract = {Sequential attention shift models of reading predict that an attended (typically fixated) word must be recognized before useful linguistic information can be obtained from the following (parafoveal) word. These models also predict that linguistic information is obtained from a parafoveal word immediately prior to a saccade toward it. To test these assumptions, sentences were constructed with a critical pretarget-target word sequence, and the temporal availability of the (parafoveal) target preview was manipulated while the pretarget word was fixated. Target viewing effects, examined as a function of prior target visibility, revealed that extraction of linguistic target information began 70-140 ms after the onset of pretarget viewing. Critically, acquisition of useful linguistic information from a target was not confined to the ending period of pretarget viewing. These results favor theoretical conceptions in which there is some temporal overlap in the linguistic processing of a fixated and parafoveally visible word during reading.},
author = {Inhoff, Albrecht W and Eiter, Brianna M and Radach, Ralph},
doi = {10.1037/0096-1523.31.5.979},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff, Eiter, Radach/Inhoff, Eiter, Radach - 2005 - Time course of linguistic information extraction from consecutive words during eye fixations in reading. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Attention,Comprehension,Fixation, Ocular,Humans,Practice (Psychology),Reaction Time,Reading,Semantics,Size Perception,Vision, Binocular,Visual Fields},
month = oct,
number = {5},
pages = {979--95},
pmid = {16262493},
title = {{Time course of linguistic information extraction from consecutive words during eye fixations in reading.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2710455\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2005}
}
@article{Schyns1999,
abstract = {Are categorization and visual processing independent, with categorization operating late, on an already perceived input, or are they intertwined, with the act of categorization flexibly changing (i.e. cognitively penetrating) the early perception of the stimulus? We examined this issue in three experiments by applying different categorization tasks (gender, expressive or not, which expression and identity) to identical face stimuli. Stimuli were hybrids: they combined a man or a woman with a particular expression at a coarse spatial scale with a face of the opposite gender with a different expression at the fine spatial scale. Results suggested that the categorization task changes the spatial scales preferentially used and perceived for rapid recognition. A perceptual set effect is shown whereby the scale preference of an important categorization (e.g. identity) transfers to resolve other face categorizations (e.g. expressive or not, which expression). Together, the results suggest that categorization can be closely bound to perception.},
author = {Schyns, P G and Oliva, a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schyns, Oliva/Schyns, Oliva - 1999 - Dr. Angry and Mr. Smile when categorization flexibly modifies the perception of faces in rapid visual presentations. - Cognition.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Adolescent,Adult,Anger,Cognition,Cognition: physiology,Facial Expression,Female,Humans,Male,Sex Factors,Smiling,Visual Perception,Visual Perception: physiology},
month = jan,
number = {3},
pages = {243--65},
pmid = {10193048},
title = {{Dr. Angry and Mr. Smile: when categorization flexibly modifies the perception of faces in rapid visual presentations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10193048},
volume = {69},
year = {1999}
}
@article{Jegou2011,
author = {J\'{e}gou, H and Perronnin, Florent and Douze, Matthijs and Sanchez, Jorge and Perez, Patrick and Schmid, Cordelia},
file = {:Users/pkmital/Documents/Mendeley Desktop/J\'{e}gou et al/J\'{e}gou et al. - 2011 - Aggregating Local Images Descriptors into Compact Codes - Pattern Analysis and Machine Intelligence, IEEE Transactions on.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
pages = {1--12},
title = {{Aggregating Local Images Descriptors into Compact Codes}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6104058},
year = {2011}
}
@article{Newman2006a,
author = {Newman, J. and Schall, G. and Barakonyi, I. and Schurzinger, A. and Schmalstieg, D.},
file = {::},
journal = {Advances in Pervasive Computing},
pages = {3--6},
title = {{Wide-Area Tracking Tools for Augmented Reality}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Wide-Area+Tracking+Tools+for+Augmented+Reality\#0},
volume = {207},
year = {2006}
}
@article{Bajura1995a,
author = {Bajura, M. and Neumann, U.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
keywords = {augmented reality,reality,registration,virtual},
number = {5},
pages = {52--60},
title = {{Dynamic registration correction in video-based augmented reality systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=403828},
volume = {15},
year = {1995}
}
@book{Szeliski2011,
author = {Szeliski, Richard},
file = {:Users/pkmital/Documents/Mendeley Desktop/Szeliski/Szeliski - 2011 - Computer vision algorithms and applications - Unknown.pdf:pdf},
publisher = {Springer Verlag London Limited},
title = {{Computer vision: algorithms and applications}},
url = {http://books.google.com/books?hl=en\&lr=\&id=bXzAlkODwa8C\&oi=fnd\&pg=PR9\&dq=Computer+Vision+:+Algorithms+and+Applications\&ots=gY33b0lyHE\&sig=bMzoE\_wxmmOUzj94KavHIYdK2r4},
year = {2011}
}
@article{Mather2013,
author = {Mather, M. and Cacioppo, J. T. and Kanwisher, N.},
doi = {10.1177/1745691612469037},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mather, Cacioppo, Kanwisher/Mather, Cacioppo, Kanwisher - 2013 - How fMRI Can Inform Cognitive Theories - Perspectives on Psychological Science.pdf:pdf},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {and test theo-,cognition,cognitive theory,fmri,in this commentary,mind works,neuroimaging,psychology is to develop,ries about how the,the goal of cognitive,we},
month = jan,
number = {1},
pages = {108--113},
title = {{How fMRI Can Inform Cognitive Theories}},
url = {http://pps.sagepub.com/lookup/doi/10.1177/1745691612469037},
volume = {8},
year = {2013}
}
@article{Stephenson1994,
author = {Stephenson, Neal},
doi = {10.1016/0016-3287(94)90052-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stephenson/Stephenson - 1994 - Snow crash Neal Stephenson, London, RoC(Pengiun), 1993, 440 pages - Futures.pdf:pdf},
issn = {00163287},
journal = {Futures},
month = sep,
number = {7},
pages = {798--800},
title = {{Snow crash Neal Stephenson, London, RoC(Pengiun), 1993, 440 pages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0016328794900523},
volume = {26},
year = {1994}
}
@article{Watson1985a,
author = {Watson, AB and Ahumada, AJ},
file = {:Users/pkmital/Documents/Mendeley Desktop/Watson, Ahumada/Watson, Ahumada - 1985 - Model of human visual-motion sensing - of America, Journal, A Optics and.pdf:pdf},
journal = {of America, Journal, A: Optics and},
title = {{Model of human visual-motion sensing}},
url = {http://vision.arc.nasa.gov/publications/ModelHumanVisualMotion.pdf},
year = {1985}
}
@article{Member2007a,
author = {Member, Student and Harish, Pawan and Narayanan, P J},
file = {::},
journal = {Computer},
number = {5},
pages = {864--877},
title = {{Garuda: A Scalable Tiled Display Wall Using Commodity PCs}},
volume = {13},
year = {2007}
}
@inproceedings{Kalipsiz2000,
author = {Kalipsiz, Oya},
booktitle = {Proceedings of the IEEE},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalipsiz/Kalipsiz - 2000 - Multimedia Databases - Proceedings of the IEEE.pdf:pdf},
title = {{Multimedia Databases}},
year = {2000}
}
@article{Guo2006,
author = {Guo, Yan-wen and Yu, Jin-hui and Xu, Xiao-dong and Wang, Jin and Peng, Qun-sheng},
doi = {10.1631/jzus.2006.A1152},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo et al/Guo et al. - 2006 - Example based painting generation - Journal of Zhejiang University SCIENCE A.pdf:pdf},
issn = {1009-3095},
journal = {Journal of Zhejiang University SCIENCE A},
keywords = {10,1631,2006,a1152,brush,doi,grounding,jzus,non-photorealistic rendering,npr,painting,van gogh},
month = jun,
number = {7},
pages = {1152--1159},
title = {{Example based painting generation}},
url = {http://www.springerlink.com/index/10.1631/jzus.2006.A1152},
volume = {7},
year = {2006}
}
@article{Hillyard1983,
author = {Hillyard, S a and Kutas, M},
doi = {10.1146/annurev.ps.34.020183.000341},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hillyard, Kutas/Hillyard, Kutas - 1983 - Electrophysiology of cognitive processing. - Annual review of psychology.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Child,Child, Preschool,Cognition,Cognition: physiology,Cues,Evoked Potentials,Evoked Potentials, Auditory,Evoked Potentials, Somatosensory,Humans,Infant,Language,Linguistics,Memory,Memory: physiology,Reaction Time,Semantics,Visual Perception,Visual Perception: physiology},
month = jan,
number = {Haber 1974},
pages = {33--61},
pmid = {6338812},
title = {{Electrophysiology of cognitive processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6338812},
volume = {34},
year = {1983}
}
@inproceedings{Collins2011,
author = {Collins, Nick and Sturm, B},
booktitle = {Proceedings of ICMC 2011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Collins, Sturm/Collins, Sturm - 2011 - Sound cross-synthesis and morphing using dictionary-based methods - Proceedings of ICMC 2011.pdf:pdf},
title = {{Sound cross-synthesis and morphing using dictionary-based methods}},
url = {http://vbn.aau.dk/files/77310007/dbmcrossynth.pdf},
year = {2011}
}
@article{Manovich2013a,
author = {Manovich, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Manovich/Manovich - 2002 - Ten key texts on digital art 1970-2000 - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {5},
pages = {567--569},
title = {{Ten key texts on digital art: 1970-2000}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/002409402320774385},
volume = {35},
year = {2002}
}
@article{Hillyard1973,
author = {Hillyard, SA and Hink, RF and Schwent, VL and Picton, TW},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hillyard et al/Hillyard et al. - 1973 - Electrical signs of selective attention in the human brain - Science.pdf:pdf},
journal = {Science},
number = {4108},
pages = {177--180},
title = {{Electrical signs of selective attention in the human brain}},
url = {http://ling.umd.edu/~ellenlau/courses/nacs642/Hillyard\_1973.pdf},
volume = {182},
year = {1973}
}
@article{Bar1999,
abstract = {Presentations of pictures that are too brief to be recognized, or even guessed above chance on a forced-choice test, nonetheless can facilitate the recognition of the same pictures many trials later. This subliminal visual priming was compared for images translated 4. 8 degrees either Within or Between quadrants of the visual field. Priming was evident only for images that remained within the same quadrant in priming and test trials. Consequently, subliminal visual priming is likely mediated by cortical areas in which cells have receptive fields large enough to respond to both presentations of a stimulus translated almost 5 degrees, yet where the receptive fields are confined to a single quadrant, namely, the human homologue of macaque V4 or TEO (the posterior part of the inferior temporal cortex). Awareness of object identity might therefore be associated exclusively with activity at or beyond the anterior part of the inferior temporal cortex, namely, area TE.},
author = {Bar, M and Biederman, I},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bar, Biederman/Bar, Biederman - 1999 - Localizing the cortical region mediating visual awareness of object identity. - Proceedings of the National Academy of Sciences of the United States of America.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adolescent,Adult,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Choice Behavior,Female,Humans,Male,Pattern Recognition, Visual,Reproducibility of Results,Visual Fields},
month = feb,
number = {4},
pages = {1790--3},
pmid = {9990103},
title = {{Localizing the cortical region mediating visual awareness of object identity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=15596\&tool=pmcentrez\&rendertype=abstract},
volume = {96},
year = {1999}
}
@inproceedings{Cook2002a,
abstract = {This paper presents algorithms and systems for automatic analysis and parametric synthesis of walking and other (gesture-rate) periodically modulated noisy sounds. A recording of walking is analyzed, extracting the gait (tempo and left/right asymmetries), heel-toe events, etc. Linear prediction is used to extract the basic resonances. Wavelet decomposition is performed, and a high frequency-subband is used to calculate statistics for a particle resynthesis model. Control envelopes are extracted from the original sound. A real-time synthesis program allows flexible resynthesis of walking sounds, controlled by a score extracted from a sound file, a graphical user interface, or parameters from game/animation/VR data. Results for the analysis algorithm are presented for synthesisized data, and for hand-crafted real experimental sounds of gravel.},
author = {Cook, P.},
booktitle = {Proceedings of the AES 22nd International Conference on Virtual, Synthetic, and Entertainment Audio},
file = {::},
pages = {73--78},
publisher = {Citeseer},
title = {{Modeling Bill's Gait: Analysis and Parametric Synthesis of Walking Sounds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.1820\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Elhilali2009,
abstract = {The mechanism by which a complex auditory scene is parsed into coherent objects depends on poorly understood interactions between task-driven and stimulus-driven attentional processes. We illuminate these interactions in a simultaneous behavioral-neurophysiological study in which we manipulate participants' attention to different features of an auditory scene (with a regular target embedded in an irregular background). Our experimental results reveal that attention to the target, rather than to the background, correlates with a sustained (steady-state) increase in the measured neural target representation over the entire stimulus sequence, beyond auditory attention's well-known transient effects on onset responses. This enhancement, in both power and phase coherence, occurs exclusively at the frequency of the target rhythm, and is only revealed when contrasting two attentional states that direct participants' focus to different features of the acoustic stimulus. The enhancement originates in auditory cortex and covaries with both behavioral task and the bottom-up saliency of the target. Furthermore, the target's perceptual detectability improves over time, correlating strongly, within participants, with the target representation's neural buildup. These results have substantial implications for models of foreground/background organization, supporting a role of neuronal temporal synchrony in mediating auditory object formation.},
author = {Elhilali, Mounya and Xiang, Juanjuan and Shamma, Shihab a and Simon, Jonathan Z},
doi = {10.1371/journal.pbio.1000129},
file = {:Users/pkmital/Documents/Mendeley Desktop/Elhilali et al/Elhilali et al. - 2009 - Interaction between attention and bottom-up saliency mediates the representation of foreground and background i.pdf:pdf},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Acoustic Stimulation,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Behavior,Female,Humans,Magnetoencephalography,Male,Middle Aged,Nervous System,Time Factors},
month = jun,
number = {6},
pages = {e1000129},
pmid = {19529760},
title = {{Interaction between attention and bottom-up saliency mediates the representation of foreground and background in an auditory scene.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2690434\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2009}
}
@article{Tatler2009a,
author = {Tatler, Benjamin},
doi = {10.1080/13506280902869213},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler/Tatler - 2009 - Current understanding of eye guidance - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {777--789},
title = {{Current understanding of eye guidance}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902869213\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Winkler2009a,
abstract = {Predictive processing of information is essential for goal-directed behavior. We offer an account of auditory perception suggesting that representations of predictable patterns, or 'regularities', extracted from the incoming sounds serve as auditory perceptual objects. The auditory system continuously searches for regularities within the acoustic signal. Primitive regularities may be encoded by neurons adapting their response to specific sounds. Such neurons have been observed in many parts of the auditory system. Representations of the detected regularities produce predictions of upcoming sounds as well as alternative solutions for parsing the composite input into coherent sequences potentially emitted by putative sound sources. Accuracy of the predictions can be utilized for selecting the most likely interpretation of the auditory input. Thus in our view, perception generates hypotheses about the causal structure of the world.},
author = {Winkler, Istv\'{a}n and Denham, Susan L and Nelken, Israel},
doi = {10.1016/j.tics.2009.09.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler, Denham, Nelken/Winkler, Denham, Nelken - 2009 - Modeling the auditory scene predictive regularity representations and perceptual objects. - Trends i(2).pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adaptation, Physiological,Adaptation, Physiological: physiology,Animal Communication,Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Hearing,Hearing: physiology,Humans,Models, Neurological,Predictive Value of Tests},
month = dec,
number = {12},
pages = {532--40},
pmid = {19828357},
title = {{Modeling the auditory scene: predictive regularity representations and perceptual objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19828357},
volume = {13},
year = {2009}
}
@article{Fu2011,
author = {Fu, Tak-chung},
doi = {10.1016/j.engappai.2010.09.007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fu/Fu - 2011 - A review on time series data mining - Engineering Applications of Artificial Intelligence.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Representation,Segmentation,Similarity measure,Visualization,time series data mining},
month = feb,
number = {1},
pages = {164--181},
publisher = {Elsevier},
title = {{A review on time series data mining}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0952197610001727},
volume = {24},
year = {2011}
}
@misc{Kerr2013,
author = {Kerr, James},
booktitle = {2013},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kerr/Kerr - Unknown - scorpion dagger - 2013.html:html},
keywords = {collage,gif,horse,scorpion dagger,vids},
title = {scorpion dagger},
url = {http://scorpiondagger.tumblr.com/},
urldate = {20/09/13}
}
@article{Sudderth2007,
author = {Sudderth, Erik B. and Torralba, Antonio and Freeman, William T. and Willsky, Alan S.},
doi = {10.1007/s11263-007-0069-5},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sudderth et al/Sudderth et al. - 2007 - Describing Visual Scenes Using Transformed Objects and Parts - International Journal of Computer Vision.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = aug,
number = {1-3},
pages = {291--330},
title = {{Describing Visual Scenes Using Transformed Objects and Parts}},
url = {http://www.springerlink.com/index/10.1007/s11263-007-0069-5},
volume = {77},
year = {2007}
}
@article{Yamashita2008,
abstract = {Recent studies have used pattern classification algorithms to predict or decode task parameters from individual fMRI activity patterns. For fMRI decoding, it is important to choose an appropriate set of voxels (or features) as inputs to the decoder, since the presence of many irrelevant voxels could lead to poor generalization performance, a problem known as overfitting. Although individual voxels could be chosen based on univariate statistics, the resulting set of voxels could be suboptimal if correlations among voxels carry important information. Here, we propose a novel linear classification algorithm, called sparse logistic regression (SLR), that automatically selects relevant voxels while estimating their weight parameters for classification. Using simulation data, we confirmed that SLR can automatically remove irrelevant voxels and thereby attain higher classification performance than other methods in the presence of many irrelevant voxels. SLR also proved effective with real fMRI data obtained from two visual experiments, successfully identifying voxels in corresponding locations of visual cortex. SLR-selected voxels often led to better performance than those selected based on univariate statistics, by exploiting correlated noise among voxels to allow for better pattern separation. We conclude that SLR provides a robust method for fMRI decoding and can also serve as a stand-alone tool for voxel selection.},
author = {Yamashita, Okito and Sato, Masa-aki and Yoshioka, Taku and Tong, Frank and Kamitani, Yukiyasu},
doi = {10.1016/j.neuroimage.2008.05.050},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yamashita et al/Yamashita et al. - 2008 - Sparse estimation automatically selects voxels relevant for the decoding of fMRI activity patterns. - NeuroIma.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Algorithms,Bayes Theorem,Brain Mapping,Brain Mapping: methods,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Visual Cortex,Visual Cortex: physiology},
month = oct,
number = {4},
pages = {1414--29},
pmid = {18598768},
title = {{Sparse estimation automatically selects voxels relevant for the decoding of fMRI activity patterns.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3158033\&tool=pmcentrez\&rendertype=abstract},
volume = {42},
year = {2008}
}
@inproceedings{AkisatoKimuraKunioKashino2002,
author = {{Akisato Kimura , Kunio Kashino}, Takayuki Kurozumi and Hiroshi Murase},
booktitle = {Acoustics, Speech, and Signal Processing, 1993. ICASSP-93., 1993 IEEE International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Akisato Kimura , Kunio Kashino/Akisato Kimura , Kunio Kashino - 2002 - A quick search method for multimedia signals using feature compression based on piecewise linear maps - Acoustics, Speech, and Signal Processing, 1993. ICASSP-93., 1993 IEEE International Conference on.pdf:pdf},
isbn = {0780374029},
issn = {1520-6149},
pages = {IV--IV},
publisher = {IEEE},
title = {{A quick search method for multimedia signals using feature compression based on piecewise linear maps}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1004709},
volume = {4},
year = {2002}
}
@article{Ilg2006,
abstract = {Saccades are very fast, ballistic movements, which move the eyes from one target to another. Here, we show that the latency, precision and kinematics of saccades directed toward a target presented on a dark homogeneous background do not differ from the parameters of saccades directed toward a target presented on a structured background. However, if the visual background changed either its luminance or orientation simultaneously with the presentation of the saccade target, a significant increase in saccade latency was observed. The saccade kinematics as well as saccade precision, however, was not affected. Likewise, additional auditory stimulation applied simultaneously with the presentation of the target did not increase saccade latency. The increase in saccade latency and the maintenance of saccade kinematics indicate a sensory channel overload caused by the change in background. As a consequence, execution of the saccade was delayed until the computational resources to program the eye movement were available again.},
author = {Ilg, Uwe J and Jin, Yu and Schumann, Stefan and Schwarz, Urs},
doi = {10.1007/s00221-005-0255-z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ilg et al/Ilg et al. - 2006 - Preparation and execution of saccades the problem of limited capacity of computational resources. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Analysis of Variance,Biomechanics,Contrast Sensitivity,Contrast Sensitivity: physiology,Fixation, Ocular,Humans,Orientation,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology},
month = may,
number = {1},
pages = {7--15},
pmid = {16320043},
title = {{Preparation and execution of saccades: the problem of limited capacity of computational resources.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16320043},
volume = {171},
year = {2006}
}
@inproceedings{Oswald1985,
author = {Oswald, John},
booktitle = {Wired Society Electro-Acoustic Conference},
title = {{Plunderphonics, or Audio Piracy as a Compositional Prerogative}},
year = {1985}
}
@phdthesis{Collins2006,
author = {Collins, Nicholas M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Collins/Collins - 2006 - Towards Autonomous Agents for Live Computer Music Realtime Machine Listening and Interactive Music Systems - Unknown.pdf:pdf},
number = {October 2003},
school = {University of Cambridge},
title = {{Towards Autonomous Agents for Live Computer Music : Realtime Machine Listening and Interactive Music Systems}},
year = {2006}
}
@article{Coutrot2012,
author = {Coutrot, Antoine and Guyader, Nathalie and Ionescu, Gelu and Caplier, Alice},
file = {:Users/pkmital/Documents/Mendeley Desktop/Coutrot et al/Coutrot et al. - 2012 - Influence of soundtrack on eye movements during video exploration - Journal of Eye Movement Research.pdf:pdf},
journal = {Journal of Eye Movement Research},
keywords = {attention,audio-visual,eye movements,multimodal,sound,videos},
number = {4},
pages = {1--10},
title = {{Influence of soundtrack on eye movements during video exploration}},
volume = {5},
year = {2012}
}
@article{Liu2011,
abstract = {While image alignment has been studied in different areas of computer vision for decades, aligning images depicting different scenes remains a challenging problem. Analogous to optical flow, where an image is aligned to its temporally adjacent frame, we propose SIFT flow, a method to align an image to its nearest neighbors in a large image corpus containing a variety of scenes. The SIFT flow algorithm consists of matching densely sampled, pixelwise SIFT features between two images while preserving spatial discontinuities. The SIFT features allow robust matching across different scene/object appearances, whereas the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach robustly aligns complex scene pairs containing significant spatial differences. Based on SIFT flow, we propose an alignment-based large database framework for image analysis and synthesis, where image information is transferred from the nearest neighbors to a query image according to the dense scene correspondence. This framework is demonstrated through concrete applications such as motion field prediction from a single image, motion synthesis via object transfer, satellite image registration, and face recognition.},
author = {Liu, Ce and Yuen, Jenny and Torralba, Antonio},
doi = {10.1109/TPAMI.2010.147},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu, Yuen, Torralba/Liu, Yuen, Torralba - 2011 - SIFT flow dense correspondence across scenes and its applications. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Motion,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Video Recording},
month = may,
number = {5},
pages = {978--94},
pmid = {20714019},
title = {{SIFT flow: dense correspondence across scenes and its applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20714019},
volume = {33},
year = {2011}
}
@article{Macon1996,
author = {Macon, M.W. and Clements, M.a.},
doi = {10.1109/ICASSP.1996.541107},
file = {:Users/pkmital/Documents/Mendeley Desktop/Macon, Clements/Macon, Clements - 1996 - Speech concatenation and synthesis using an overlap-add sinusoidal model - 1996 IEEE International Conference o.pdf:pdf},
isbn = {0-7803-3192-3},
journal = {1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
pages = {361--364},
publisher = {Ieee},
title = {{Speech concatenation and synthesis using an overlap-add sinusoidal model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=541107},
year = {1996}
}
@article{Krauzlis2004,
abstract = {Primates use a combination of smooth pursuit and saccadic eye movements to stabilize the retinal image of selected objects within the high-acuity region near the fovea. Pursuit has traditionally been viewed as a relatively automatic behavior, driven by visual motion signals and mediated by pathways that connect visual areas in the cerebral cortex to motor regions in the cerebellum. However, recent findings indicate that this view needs to be reconsidered. Rather than being controlled primarily by areas in extrastriate cortex specialized for processing visual motion, pursuit involves an extended network of cortical areas, and, of these, the pursuit-related region in the frontal eye fields appears to exert the most direct influence. The traditional pathways through the cerebellum are important, but there are also newly identified routes involving structures previously associated with the control of saccades, including the basal ganglia, the superior colliculus, and nuclei in the brain stem reticular formation. These recent findings suggest that the pursuit system has a functional architecture very similar to that of the saccadic system. This viewpoint provides a new perspective on the processing steps that occur as descending control signals interact with circuits in the brain stem and cerebellum responsible for gating and executing voluntary eye movements. Although the traditional view describes pursuit and saccades as two distinct neural systems, it may be more accurate to consider the two movements as different outcomes from a shared cascade of sensory-motor functions.},
author = {Krauzlis, Richard J},
doi = {10.1152/jn.00801.2003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Krauzlis/Krauzlis - 2004 - Recasting the smooth pursuit eye movement system. - Journal of neurophysiology.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Animals,Brain,Brain: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Neural Pathways,Neural Pathways: physiology,Pursuit, Smooth,Pursuit, Smooth: physiology,Saccades,Saccades: physiology},
month = feb,
number = {2},
pages = {591--603},
pmid = {14762145},
title = {{Recasting the smooth pursuit eye movement system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14762145},
volume = {91},
year = {2004}
}
@article{Tzanetakis2000,
author = {Tzanetakis, George and Cook, Perry},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = dec,
number = {03},
pages = {169--175},
title = {{MARSYAS: a framework for audio analysis}},
url = {http://journals.cambridge.org/abstract\_S1355771800003071},
volume = {4},
year = {2000}
}
@article{Pannasch2009,
author = {Pannasch, Sebastian and Velichkovsky, Boris},
doi = {10.1080/13506280902764422},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pannasch, Velichkovsky/Pannasch, Velichkovsky - 2009 - Distractor effect and saccade amplitudes Further evidence on different modes of processing in free exploration of visual images - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1109--1131},
title = {{Distractor effect and saccade amplitudes: Further evidence on different modes of processing in free exploration of visual images}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902764422\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Witten2005,
abstract = {Vision may dominate our perception of space not because of any inherent physiological advantage of visual over other sensory connections in the brain, but because visual information tends to be more reliable than other sources of spatial information, and the central nervous system integrates information in a statistically optimal fashion. This review discusses recent experiments on audiovisual integration that support this hypothesis. We consider candidate neural codes that would enable optimal integration and the implications of optimal integration for perception and plasticity.},
author = {Witten, Ilana B and Knudsen, Eric I},
doi = {10.1016/j.neuron.2005.10.020},
file = {:Users/pkmital/Documents/Mendeley Desktop/Witten, Knudsen/Witten, Knudsen - 2005 - Why seeing is believing merging auditory and visual worlds. - Neuron.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Hearing,Hearing: physiology,Humans,Models, Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Vision, Ocular,Vision, Ocular: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = nov,
number = {3},
pages = {489--96},
pmid = {16269365},
title = {{Why seeing is believing: merging auditory and visual worlds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16269365},
volume = {48},
year = {2005}
}
@article{Tholl,
author = {Tholl, Andrew},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tholl/Tholl - 2010 - Plunderphonics A Literature Review - Unknown.pdf:pdf},
title = {{Plunderphonics: A Literature Review}},
year = {2010}
}
@inproceedings{Field2004a,
address = {Hobart, Tasmania},
author = {Field, Tom and Bay, Sandy and Vamplew, Peter},
booktitle = {AISAT2004: International Conference on Artificial Intelligence in Science and Technology},
file = {::},
title = {{Generalised Algorithms for Redirected Walking in Virtual Environments}},
url = {http://eprints.utas.edu.au/109/},
year = {2004}
}
@article{Kay2008,
abstract = {A challenging goal in neuroscience is to be able to read out, or decode, mental content from brain activity. Recent functional magnetic resonance imaging (fMRI) studies have decoded orientation, position and object category from activity in visual cortex. However, these studies typically used relatively simple stimuli (for example, gratings) or images drawn from fixed categories (for example, faces, houses), and decoding was based on previous measurements of brain activity evoked by those same stimuli or categories. To overcome these limitations, here we develop a decoding method based on quantitative receptive-field models that characterize the relationship between visual stimuli and fMRI activity in early visual areas. These models describe the tuning of individual voxels for space, orientation and spatial frequency, and are estimated directly from responses evoked by natural images. We show that these receptive-field models make it possible to identify, from a large set of completely novel natural images, which specific image was seen by an observer. Identification is not a mere consequence of the retinotopic organization of visual areas; simpler receptive-field models that describe only spatial tuning yield much poorer identification performance. Our results suggest that it may soon be possible to reconstruct a picture of a person's visual experience from measurements of brain activity alone.},
author = {Kay, Kendrick N and Naselaris, Thomas and Prenger, Ryan J and Gallant, Jack L},
doi = {10.1038/nature06713},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kay et al/Kay et al. - 2008 - Identifying natural images from human brain activity. - Nature.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Nature,Photic Stimulation,Photography,Research Design,Visual Perception,Visual Perception: physiology},
month = mar,
number = {7185},
pages = {352--5},
pmid = {18322462},
title = {{Identifying natural images from human brain activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18322462},
volume = {452},
year = {2008}
}
@article{Rauschecker1998,
author = {Rauschecker, JP},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rauschecker/Rauschecker - 1998 - Cortical processing of complex sounds - Current Opinion in Neurobiology.pdf:pdf},
journal = {Current Opinion in Neurobiology},
pages = {516--521},
title = {{Cortical processing of complex sounds}},
url = {http://www.sciencedirect.com/science/article/pii/S0959438898800408},
volume = {8},
year = {1998}
}
@article{Dick2012,
abstract = {In contrast to vision, where retinotopic mapping alone can define areal borders, primary auditory areas such as A1 are best delineated by combining in vivo tonotopic mapping with postmortem cyto- or myeloarchitectonics from the same individual. We combined high-resolution (800 $\mu$m) quantitative T(1) mapping with phase-encoded tonotopic methods to map primary auditory areas (A1 and R) within the "auditory core" of human volunteers. We first quantitatively characterize the highly myelinated auditory core in terms of shape, area, cortical depth profile, and position, with our data showing considerable correspondence to postmortem myeloarchitectonic studies, both in cross-participant averages and in individuals. The core region contains two "mirror-image" tonotopic maps oriented along the same axis as observed in macaque and owl monkey. We suggest that these two maps within the core are the human analogs of primate auditory areas A1 and R. The core occupies a much smaller portion of tonotopically organized cortex on the superior temporal plane and gyrus than is generally supposed. The multimodal approach to defining the auditory core will facilitate investigations of structure-function relationships, comparative neuroanatomical studies, and promises new biomarkers for diagnosis and clinical studies.},
author = {Dick, Frederic and Tierney, Adam Taylor and Lutti, Antoine and Josephs, Oliver and Sereno, Martin I and Weiskopf, Nikolaus},
doi = {10.1523/JNEUROSCI.1712-12.2012},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dick et al/Dick et al. - 2012 - In vivo functional and myeloarchitectonic mapping of human primary auditory areas. - The Journal of neuroscience t.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Adult,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Brain Mapping,Female,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Middle Aged,Models, Neurological,Models, Statistical,Whole Body Imaging,Young Adult},
month = nov,
number = {46},
pages = {16095--105},
pmid = {23152594},
title = {{In vivo functional and myeloarchitectonic mapping of human primary auditory areas.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23152594},
volume = {32},
year = {2012}
}
@article{Boden2009,
author = {Boden, MA and Edmonds, EA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Boden, Edmonds/Boden, Edmonds - 2009 - What is generative art - Digital Creativity.pdf:pdf},
journal = {Digital Creativity},
pages = {150--166},
title = {{What is generative art?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14626260902867915},
year = {2009}
}
@misc{MickGrierson2013,
author = {Grierson, Mick and Kiefer, Chris},
booktitle = {Personal Website},
file = {:Users/pkmital/Documents/Mendeley Desktop/Grierson, Kiefer/Grierson, Kiefer - 2013 - Maximilian - Personal Website.html:html},
title = {{Maximilian}},
url = {http://maximilian.strangeloop.co.uk/news/},
urldate = {02/10/13},
year = {2013}
}
@article{Vincent2009,
author = {Vincent, Benjamin and Baddeley, Roland and Correani, Alessia and Troscianko, Tom and Leonards, Ute},
doi = {10.1080/13506280902916691},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vincent et al/Vincent et al. - 2009 - Do we look at lights Using mixture modelling to distinguish between low- and high-level factors in natural image viewing - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {856--879},
title = {{Do we look at lights? Using mixture modelling to distinguish between low- and high-level factors in natural image viewing}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902916691\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Itti1998,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Koch, Niebur/Itti, Koch, Niebur - 1998 - A model of saliency-based visual attention for rapid scene analysis - IEEE Transactions on Pattern Analysis and Machine Intelligence.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {{A model of saliency-based visual attention for rapid scene analysis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=730558},
year = {1998}
}
@article{Antonelo2012,
abstract = {This work proposes a hierarchical biologically-inspired architecture for learning sensor-based spatial representations of a robot environment in an unsupervised way. The first layer is comprised of a fixed randomly generated recurrent neural network, the reservoir, which projects the input into a high-dimensional, dynamic space. The second layer learns instantaneous slowly-varying signals from the reservoir states using Slow Feature Analysis (SFA), whereas the third layer learns a sparse coding on the SFA layer using Independent Component Analysis (ICA). While the SFA layer generates non-localized activations in space, the ICA layer presents high place selectivity, forming a localized spatial activation, characteristic of place cells found in the hippocampus area of the rodent's brain. We show that, using a limited number of noisy short-range distance sensors as input, the proposed system learns a spatial representation of the environment which can be used to predict the actual location of simulated and real robots, without the use of odometry. The results confirm that the reservoir layer is essential for learning spatial representations from low-dimensional input such as distance sensors. The main reason is that the reservoir state reflects the recent history of the input stream. Thus, this fading memory is essential for detecting locations, mainly when locations are ambiguous and characterized by similar sensor readings.},
author = {Antonelo, Eric and Schrauwen, Benjamin},
doi = {10.1016/j.neunet.2011.08.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Antonelo, Schrauwen/Antonelo, Schrauwen - 2012 - Learning slow features with reservoir computing for biologically-inspired robot localization. - Neural netw.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Animals,Learning,Learning: physiology,Models, Biological,Neural Networks (Computer),Rats,Robotics,Robotics: methods,Robotics: statistics \& numerical data,Time Factors},
month = jan,
number = {1},
pages = {178--90},
pmid = {21945043},
title = {{Learning slow features with reservoir computing for biologically-inspired robot localization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21945043},
volume = {25},
year = {2012}
}
@article{Usselmann2013,
author = {Usselmann, Rainer},
file = {:Users/pkmital/Documents/Mendeley Desktop/Usselmann/Usselmann - 2003 - The dilemma of media art cybernetic serendipity at the ICA London - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {5},
pages = {389--396},
title = {{The dilemma of media art: cybernetic serendipity at the ICA London}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/002409403771048191},
volume = {36},
year = {2003}
}
@article{Verma2011,
abstract = {Measles is a highly infectious, acute respiratory illness that is caused by a virus of the genus Morbillivirus. The disease infects nearly 30 million children each year, and deaths usually occur from complications related to pneumonia, diarrhea and malnutrition. A systematic review of published Indian literature depicts the median case fatality ratio (CFR) of measles to be 1.6\%. Through immunization, measles deaths dropped a remarkable 78\% from 733,000 in 2000 to 164,000 in 2008. As of 2008, 192 of 193 Member States of WHO use 2 doses of measles vaccine in their national immunization programs, India being the only exception. The Millennium Development Goal (MDG) 4 aims to reduce by two-thirds between 1990 and 2015 the under-five mortality rate (U5MR) in the world. Per the draft comprehensive Multi Year Strategic Plan (cMYP, 2010–17) for immunization of India, the country aims to reduce measles-related mortality by 90\% by 2013 when compared to 2000. As recommended by the National Technical Advisory Group on Immunization (NTAGI), the implementation strategy of the second dose of measles vaccine at the state level is determined by the underlying performance of the routine immunization program. The second dose in the national immunization schedule gives extra immunity against measles infection that renders children more susceptible to secondary pneumonia and diarrheal diseases, which are the primary causes of under-5 child mortality in India.},
author = {DeMenthon, D.F. and Davis, L.S.},
file = {:Users/pkmital/Documents/Mendeley Desktop/DeMenthon, Davis/DeMenthon, Davis - 1995 - Model-based object pose in 25 lines of code - International Journal of Computer Vision.pdf:pdf},
issn = {1554-8619},
journal = {International Journal of Computer Vision},
month = oct,
number = {1},
pages = {123--141},
pmid = {22238787},
publisher = {Springer},
title = {{Model-based object pose in 25 lines of code}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22238787 http://www.springerlink.com/index/K3670132H2815858.pdf},
volume = {15},
year = {1995}
}
@article{Henderson1999a,
author = {Henderson, John M. and Siefert, Amy B. C.},
doi = {10.1037//0096-1523.25.1.243},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Siefert/Henderson, Siefert - 1999 - The influence of enantiomorphic transformation on transsaccadic object integration. - Journal of Experimental Psychology Human Perception and Performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {1},
pages = {243--255},
title = {{The influence of enantiomorphic transformation on transsaccadic object integration.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.25.1.243},
volume = {25},
year = {1999}
}
@article{Barnard2003,
author = {Barnard, Kobus and Duygulu, P and Forsyth, David and de Freitas, Nando and Blei, David and Jordan, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barnard et al/Barnard et al. - 2003 - Matching words and pictures - The Journal of Machine Learning Research.pdf:pdf},
journal = {The Journal of Machine Learning Research},
pages = {1107--1135},
title = {{Matching words and pictures}},
url = {http://dl.acm.org/citation.cfm?id=944965},
volume = {3},
year = {2003}
}
@article{Miranda2010,
author = {Miranda, Eduardo Reck},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = apr,
number = {01},
pages = {13--25},
title = {{Organised Sound, Mental Imageries and the Future of Music Technology: a neuroscience outlook}},
url = {http://journals.cambridge.org/abstract\_S1355771809990227},
volume = {15},
year = {2010}
}
@article{Hinterstoisser2009,
author = {Hinterstoisser, S. and Kutter, O. and Navab, N. and Fua, P. and Lepetit, V.},
doi = {10.1109/CVPR.2009.5206794},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hinterstoisser et al/Hinterstoisser et al. - 2009 - Real-time learning of accurate patch rectification - 2009 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {2945--2952},
publisher = {Ieee},
title = {{Real-time learning of accurate patch rectification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206794},
year = {2009}
}
@article{Inhoff2005,
abstract = {In two experiments, readers' use of spatial memory was examined by asking them to determine whether an individually shown probe word had appeared in a previously read sentence (Experiment 1) or had occupied a right or left sentence location (Experiment 2). Under these conditions, eye movements during the classification task were generally directed toward the right, irrespective of the location of the relevant target in the previously read sentence. In two additional experiments, readers' knowledge of prior sentence content was examined either without (Experiment 3) or with (Experiment 4) an explicit instruction to move the eyes to a target word in that sentence. Although regressions into the prior sentence were generally directed toward the target, they rarely reached it. In the absence of accurate spatial memories, readers reached previously read target words in two distinct steps--one that moved the eyes in the general vicinity of the target, and one that homed in on it.},
author = {Inhoff, Albrecht W and Weger, Ulrich W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff, Weger/Inhoff, Weger - 2005 - Memory for word location during reading eye movements to previously read words are spatially selective but not precise. - Memory \& cognition.pdf:pdf},
issn = {0090-502X},
journal = {Memory \& cognition},
keywords = {Decision Making,Humans,Memory,Reading,Saccades,Saccades: physiology,Space Perception,Vocabulary},
month = apr,
number = {3},
pages = {447--61},
pmid = {16156180},
title = {{Memory for word location during reading: eye movements to previously read words are spatially selective but not precise.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2694611\&tool=pmcentrez\&rendertype=abstract},
volume = {33},
year = {2005}
}
@article{Kimura2004a,
author = {Kimura, a. and Uyematsu, T.},
doi = {10.1109/TIT.2003.821968},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 2004 - Weak Variable-Length Slepian–Wolf Coding With Linked Encoders for Mixed Sources - IEEE Transactions on Information Theory(2).pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = jan,
number = {1},
pages = {183--193},
title = {{Weak Variable-Length Slepian–Wolf Coding With Linked Encoders for Mixed Sources}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262627},
volume = {50},
year = {2004}
}
@article{Capin2008b,
author = {Capin, Tolga and Pulli, Kari and Akenine-M\"{o}ller, Tomas},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {74--84},
title = {{The State of the Art in Mobile Graphics Research}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557959},
volume = {28},
year = {2008}
}
@article{Goferman2010,
author = {Goferman, Stas and Tal, Ayellet and Zelnik-Manor, Lihi},
doi = {10.1111/j.1467-8659.2009.01615.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Goferman, Tal, Zelnik-Manor/Goferman, Tal, Zelnik-Manor - 2010 - Puzzle-like Collage - Computer Graphics Forum.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
month = jun,
number = {2},
pages = {459--468},
title = {{Puzzle-like Collage}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01615.x},
volume = {29},
year = {2010}
}
@phdthesis{Schwarz2004,
author = {Schwarz, D},
school = {l'Universit\'{e} Paris 6 -- Pierre et Marie Curie},
title = {{Data-Driven Concatenative Sound Synthesis}},
year = {2004}
}
@article{Shepard,
author = {Shepard, R.N.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shepard/Shepard - Unknown - Toward a Universal Law of Generalization for Psychological Science - Science.pdf:pdf},
journal = {Science},
number = {4820},
pages = {1317},
publisher = {American Association for the Advancement of Science},
title = {{Toward a universal law of generalization for psychological science}},
url = {http://www.sciencemag.org/content/237/4820/1317.short},
volume = {237},
year = {1987}
}
@article{Leung2007,
author = {Leung, Clement and Kimura, Akisato and Takeuchi, Tatsuto and Kashino, Kunio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leung et al/Leung et al. - 2007 - A COMPUTATIONAL MODEL OF SALIENCY DEPLETION RECOVERY PHENOMENA FOR THE SALIENT REGION EXTRACTION OF VIDEOS NTT Communication Science Laboratories , NTT Corporation , Japan Department of Electrical and Computer Engineering , Uni.pdf:pdf},
journal = {Structure},
pages = {300--303},
title = {{A COMPUTATIONAL MODEL OF SALIENCY DEPLETION / RECOVERY PHENOMENA FOR THE SALIENT REGION EXTRACTION OF VIDEOS NTT Communication Science Laboratories , NTT Corporation , Japan Department of Electrical and Computer Engineering , University of British Columbi}},
year = {2007}
}
@article{Torralba2008,
abstract = {With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.},
author = {Torralba, Antonio and Fergus, Rob and Freeman, William T},
doi = {10.1109/TPAMI.2008.128},
file = {:Users/pkmital/Documents/Mendeley Desktop/Torralba, Fergus, Freeman/Torralba, Fergus, Freeman - 2008 - 80 Million Tiny Images a Large Data Set for Nonparametric Object and Scene Recognition. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Artificial Intelligence,Database Management Systems,Databases, Factual,Documentation,Documentation: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Internet,Pattern Recognition, Automated,Pattern Recognition, Automated: methods},
month = nov,
number = {11},
pages = {1958--70},
pmid = {18787244},
title = {{80 Million Tiny Images: a Large Data Set for Nonparametric Object and Scene Recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18787244},
volume = {30},
year = {2008}
}
@article{Haeberli1990,
author = {Haeberli, Paul},
doi = {10.1145/97880.97902},
file = {:Users/pkmital/Documents/Mendeley Desktop/Haeberli/Haeberli - 1990 - Paint by numbers abstract image representations - ACM SIGGRAPH Computer Graphics.pdf:pdf},
isbn = {0897913442},
issn = {00978930},
journal = {ACM SIGGRAPH Computer Graphics},
month = sep,
number = {4},
pages = {207--214},
title = {{Paint by numbers: abstract image representations}},
url = {http://portal.acm.org/citation.cfm?doid=97880.97902},
volume = {24},
year = {1990}
}
@article{Muja2009a,
author = {Muja, Marius and Lowe, David},
file = {:Users/pkmital/Documents/Mendeley Desktop/Muja, Lowe/Muja, Lowe - 2009 - FLANN - Fast Library for Approximate Nearest Neighbors User Manual - Writing.pdf:pdf},
journal = {Writing},
title = {{FLANN - Fast Library for Approximate Nearest Neighbors User Manual}},
year = {2009}
}
@article{Lallemand2011,
author = {Lallemand, Ianis and Schwarz, Diemo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lallemand, Schwarz/Lallemand, Schwarz - 2011 - Interaction-Optimized Sound Database Representation - Proceedings of the 14th International Conference on Di.pdf:pdf},
journal = {Proceedings of the 14th International Conference on Digital Audio Effects (DAFx-11)},
pages = {1--8},
title = {{Interaction-Optimized Sound Database Representation}},
year = {2011}
}
@article{RuiHuTinghuaiWang,
author = {Hu, R and Wang, T and Collomosse, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hu, Wang, Collomosse/Hu, Wang, Collomosse - 2011 - A bag-of-regions approach to sketch-based image retrieval - Image Processing (ICIP), 2011 \ldots.pdf:pdf},
journal = {Image Processing (ICIP), 2011 \ldots},
title = {{A bag-of-regions approach to sketch-based image retrieval}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6116513},
year = {2011}
}
@article{Tabachneck-Schijf1997,
author = {Tabachneck-Schijf, Hermina J.M. and Leonardo, Anthony M. and Simon, Herbert a.},
doi = {10.1207/s15516709cog2103\_3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tabachneck-Schijf, Leonardo, Simon/Tabachneck-Schijf, Leonardo, Simon - 1997 - CaMeRa A Computational Model of Multiple Representations - Cognitive Science.PDF:PDF},
issn = {03640213},
journal = {Cognitive Science},
month = jul,
number = {3},
pages = {305--350},
title = {{CaMeRa: A Computational Model of Multiple Representations}},
url = {http://doi.wiley.com/10.1207/s15516709cog2103\_3},
volume = {21},
year = {1997}
}
@article{Breton1924,
author = {Breton, Andr\'{e}},
file = {:Users/pkmital/Documents/Mendeley Desktop/Breton/Breton - 1924 - Manifeste du surr\'{e}alisme - Unknown.pdf:pdf},
keywords = {Manifeste, surr\'{e}alisme, Breton, surr\'{e}alistes, r\'{e}vo},
title = {{Manifeste du surr\'{e}alisme}},
year = {1924}
}
@article{Kaplan2000,
address = {New York, New York, USA},
author = {Kaplan, Matthew and Gooch, Bruce and Cohen, Elaine},
doi = {10.1145/340916.340925},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kaplan, Gooch, Cohen/Kaplan, Gooch, Cohen - 2000 - Interactive artistic rendering - Proceedings of the first international symposium on Non-photorealistic an.pdf:pdf},
isbn = {1581132778},
journal = {Proceedings of the first international symposium on Non-photorealistic animation and rendering - NPAR '00},
keywords = {illustration,interaction,lighting models,non-photorealistic rendering,silhouettes},
pages = {67--74},
publisher = {ACM Press},
title = {{Interactive artistic rendering}},
url = {http://portal.acm.org/citation.cfm?doid=340916.340925},
year = {2000}
}
@article{Carlyon2004,
abstract = {In everyday life we often listen to one sound, such as someone's voice, in a background of competing sounds. To do this, we must assign simultaneously occurring frequency components to the correct source, and organize sounds appropriately over time. The physical cues that we exploit to do so are well-established; more recent research has focussed on the underlying neural bases, where most progress has been made in the study of a form of sequential organization known as "auditory streaming". Listeners' sensitivity to streaming cues can be captured in the responses of neurons in the primary auditory cortex, and in EEG wave components with a short latency (< 200ms). However, streaming can be strongly affected by attention, suggesting that this early processing either receives input from non-auditory areas, or feeds into processes that do.},
author = {Carlyon, Robert P},
doi = {10.1016/j.tics.2004.08.008},
file = {:Users/pkmital/Documents/Mendeley Desktop/Carlyon/Carlyon - 2004 - How the brain separates sounds. - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Cognition,Cognition: physiology,Cues,Electroencephalography,Humans},
month = oct,
number = {10},
pages = {465--71},
pmid = {15450511},
title = {{How the brain separates sounds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15450511},
volume = {8},
year = {2004}
}
@article{Kollar,
author = {Kollar, Thomas and Roy, Nicholas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kollar, Roy/Kollar, Roy - Unknown - when planning to find things - English.pdf:pdf},
journal = {English},
title = {when planning to find things}
}
@inproceedings{Grierson2009,
author = {Grierson, Mick},
booktitle = {EVA 2009 London Conference},
file = {:Users/pkmital/Documents/Mendeley Desktop/Grierson/Grierson - 2009 - Plundermatics Real-time Interactive Media Segmentation for Audiovisual Analysis, Composition and Performance - EVA 200.pdf:pdf},
pages = {276--284},
title = {{Plundermatics: Real-time Interactive Media Segmentation for Audiovisual Analysis, Composition and Performance}},
year = {2009}
}
@inproceedings{Hertzmann2002,
author = {Hertzmann, Aaron and Oliver, Nuria and Curless, Brian and Seitz, Steven M.},
booktitle = {EGRW '02 Proceedings of the 13th Eurographics workshop on Rendering},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hertzmann et al/Hertzmann et al. - 2002 - Curve analogies - EGRW '02 Proceedings of the 13th Eurographics workshop on Rendering.pdf:pdf},
pages = {233--246},
title = {{Curve analogies}},
url = {http://www.dgp.utoronto.ca/papers/ahertzmann\_EWR2002.pdf},
year = {2002}
}
@misc{Stefik1985,
author = {Stefik, M},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(85)90057-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stefik/Stefik - 1985 - Vehicles Experiments in synthetic psychology V. Braitenberg, (MIT, Cambridge, MA, 1984) 152 pages, \$14.95. - Artificial Intelligence.pdf:pdf},
issn = {00043702},
month = nov,
number = {2},
pages = {246--248},
title = {{Vehicles: Experiments in synthetic psychology V. Braitenberg, (MIT, Cambridge, MA, 1984); 152 pages, \$14.95.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0004370285900578},
volume = {27},
year = {1985}
}
@article{Belopolsky2006,
abstract = {Previous research has shown that salient events have a powerful effect on our covert (attentional capture) and overt (oculomotor capture) behavior. The goal of the present study was to examine whether oculomotor capture errors, which are purely stimulus-driven, meaning that they are not in any way defined by the task-set, elicit the error-related negativity (ERN). Using a hybrid of antisaccade and oculomotor capture tasks, we showed that erroneous prosaccades and irrelevant onset capture errors elicited the ERN of similar amplitude. The results suggest that participants adopted an internal standard for a direct eye movement to the target (optimal performance) and any eye movement that deviated from this path was detected by a performance-monitoring system and indexed by the error-related negativity.},
author = {Belopolsky, Artem V and Kramer, Arthur F},
doi = {10.1016/j.brainres.2006.01.082},
file = {:Users/pkmital/Documents/Mendeley Desktop/Belopolsky, Kramer/Belopolsky, Kramer - 2006 - Error-processing of oculomotor capture. - Brain research.pdf:pdf},
issn = {0006-8993},
journal = {Brain research},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Electroretinography,Electroretinography: methods,Evoked Potentials,Evoked Potentials: physiology,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Orientation,Orientation: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Visual Perception,Visual Perception: physiology},
month = apr,
number = {1},
pages = {171--8},
pmid = {16499886},
title = {{Error-processing of oculomotor capture.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16499886},
volume = {1081},
year = {2006}
}
@article{Mondor1994,
abstract = {Three experiments were conducted to determine whether attention may be allocated to a specific frequency region. On each trial, a frequency cue was presented and was followed by a target tone. The cue indicated the most likely frequency of the forthcoming target about which the listeners were required to make a duration judgment. It was reasoned that if listeners are able to allocate attention to the cued frequency region, then judgments of any characteristic of a tone of the cued frequency should be facilitated relative to tones of different frequencies. Results indicated that duration judgements were made more quickly and accurately when the cue provided accurate frequency information than when it did not. In addition, performance generally declined as the frequency separation between cue and target increased. These effects are interpreted as an indication that listeners may use a frequency cue to allocate attention to a specific frequency region and that, under these conditions, the shape of the attentional focus conforms to a gradient. The possible similarities of covert orienting mechanisms in vision and audition are discussed.},
author = {Mondor, T a and Bregman, a S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mondor, Bregman/Mondor, Bregman - 1994 - Allocating attention to frequency regions. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Acoustic Stimulation,Attention,Auditory Perception,Cues,Humans,Orientation,Visual Perception},
month = sep,
number = {3},
pages = {268--76},
pmid = {7971127},
title = {{Allocating attention to frequency regions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7971127},
volume = {56},
year = {1994}
}
@incollection{Posner1984,
author = {Posner, MI and Cohen, Y},
booktitle = {Attention and Performance X: Control of Language Processes.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Posner, Cohen/Posner, Cohen - 1984 - Components of visual orienting - Attention and Performance X Control of Language Processes.pdf:pdf},
pages = {551--556},
title = {{Components of visual orienting}},
url = {http://psy2.ucsd.edu/~dhuber/Posner+Cohen1984.pdf},
year = {1984}
}
@article{Barlow1990,
author = {Barlow, John Perry and Dyson, Esther and Leary, Timothy and Jacobson, Bob and Bricken, Willian and Robinett, Warren},
journal = {SIGGRAPH 90 Panel Proceedings},
pages = {1--29},
title = {{Hip , Hype and Hope: The Three Faces of Virtual Worlds}},
year = {1990}
}
@article{Hyv\\arinen2000,
author = {Hyv$\backslash$$\backslash$"arinen, A. and Oja, Erkki},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hyvarinen, Oja/Hyvarinen, Oja - 2000 - Independent component analysis algorithms and applications - Neural networks.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {analysis,blind signal separation,factor,independent component analysis,projection pursuit,representation,source separation},
number = {4-5},
pages = {411--430},
publisher = {Elsevier},
title = {{Independent component analysis: algorithms and applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608000000265},
volume = {13},
year = {2000}
}
@article{Yuen2009,
author = {Yuen, Jenny and Russell, Bryan and Torralba, Antonio},
doi = {10.1109/ICCV.2009.5459289},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yuen, Russell, Torralba/Yuen, Russell, Torralba - 2009 - LabelMe video Building a video database with human annotations - 2009 IEEE 12th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {1451--1458},
publisher = {Ieee},
title = {{LabelMe video: Building a video database with human annotations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459289},
year = {2009}
}
@article{Hunt2007,
abstract = {Eye movements are often misdirected toward a distractor when it appears abruptly, an effect known as oculomotor capture. Fundamental differences between eye movements and attention have led to questions about the relationship of oculomotor capture to the more general effect of sudden onsets on performance, known as attentional capture. This study explores that issue by examining the time course of eye movements and manual localization responses to targets in the presence of sudden-onset distractors. The results demonstrate that for both response types, the proportion of trials on which responses are erroneously directed to sudden onsets reflects the quality of information about the visual display at a given point in time. Oculomotor capture appears to be a specific instance of a more general attentional capture effect. Differences and similarities between the two types of capture can be explained by the critical idea that the quality of information about a visual display changes over time and that different response systems tend to access this information at different moments in time.},
author = {Hunt, Amelia R and von M\"{u}hlenen, Adrian and Kingstone, Alan},
doi = {10.1037/0096-1523.33.2.271},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hunt, von M\"{u}hlenen, Kingstone/Hunt, von M\"{u}hlenen, Kingstone - 2007 - The time course of attentional and oculomotor capture reveals a common cause. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Attention,Attention: physiology,Eye Movements,Eye Movements: physiology,Humans,Reaction Time,Reflex,Reflex: physiology,Visual Perception,Visual Perception: physiology},
month = apr,
number = {2},
pages = {271--84},
pmid = {17469968},
title = {{The time course of attentional and oculomotor capture reveals a common cause.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17469968},
volume = {33},
year = {2007}
}
@article{Li2002,
author = {Li, Zhaoping},
doi = {10.1016/S1364-6613(00)01817-9},
file = {:Users/pkmital/Documents/Mendeley Desktop/Li/Li - 2002 - A saliency map in primary visual cortex - Trends in Cognitive Sciences.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = jan,
number = {1},
pages = {9--16},
title = {{A saliency map in primary visual cortex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661300018179},
volume = {6},
year = {2002}
}
@book{Yarbus1967,
author = {Yarbus, Alfred},
booktitle = {Institute for Problems of Information Transmission},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yarbus/Yarbus - 1967 - Eye movements and vision - Institute for Problems of Information Transmission.pdf:pdf},
pages = {1--222},
title = {{Eye movements and vision}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Eye+Movements+and+Vision\#0},
year = {1967}
}
@article{Hooge1996,
abstract = {To obtain insight into the control of fixation duration during visual search, we had 4 subjects perform simple search tasks in which we systematically varied the discriminability of the target. The experiment was carried out under two conditions. Under the first condition (blocked), the discriminability of the target was kept constant during a session. Under the second condition (mixed), the discriminability of the target varied per trial. Under the blocked condition, fixation duration increased with decreasing discriminability. For 2 subjects, we found much shorter fixation durations in difficult trials with the mixed condition than in difficult trials with the blocked condition. Overall, the subjects fixated the target, continued to search, and then went back to the target in 5\%-55\% of the correct trials. In these trials, the result of the analysis of the foveal target was not used for preparing the next saccade. The results support a preprogramming model of the control of fixation duration. In a simple search task, control of fixation duration appears to be indirect.},
author = {Hooge, I T and Erkelens, C J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hooge, Erkelens/Hooge, Erkelens - 1996 - Control of fixation duration in a simple search task. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adult,Attention,Discrimination Learning,Fixation, Ocular,Humans,Male,Middle Aged,Orientation,Pattern Recognition, Visual,Psychophysics,Reaction Time,Saccades},
month = oct,
number = {7},
pages = {969--76},
pmid = {8920834},
title = {{Control of fixation duration in a simple search task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8920834},
volume = {58},
year = {1996}
}
@article{Hays2007,
author = {Hays, James and Efros, AA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hays, Efros/Hays, Efros - 2007 - Scene completion using millions of photographs - ACM Transactions on Graphics (TOG).pdf:pdf},
journal = {ACM Transactions on Graphics (TOG)},
keywords = {as accurately as possible,com-,different strategies for image,hole filling,image com-,image completion,image database,inpainting,pletion,positing,reconstruct,the first aims to,there are two fundamentally},
number = {212},
pages = {1--7},
title = {{Scene completion using millions of photographs}},
url = {http://dl.acm.org/citation.cfm?id=1276382},
volume = {1},
year = {2007}
}
@article{Yuen2009a,
author = {Yuen, J. and Torralba, a.},
doi = {10.1109/CVPR.2009.5206536},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yuen, Torralba/Yuen, Torralba - 2009 - Nonparametric scene parsing Label transfer via dense scene alignment - 2009 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1972--1979},
publisher = {Ieee},
title = {{Nonparametric scene parsing: Label transfer via dense scene alignment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206536},
year = {2009}
}
@article{Bay2006,
author = {Bay, Herbert and Tuytelaars, Tinne and Gool, Luc Van},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bay, Tuytelaars, Gool/Bay, Tuytelaars, Gool - 2006 - Surf Speeded up robust features - Unknown.pdf:pdf},
title = {{Surf: Speeded up robust features}},
url = {http://www.springerlink.com/index/E580H2K58434P02K.pdf},
year = {2006}
}
@incollection{Battermann2009,
author = {Battermann, Michael and Heise, Sebastian and Loviscach, J\"{o}rn},
booktitle = {Audio Engineering Society Convention 126},
file = {:Users/pkmital/Documents/Mendeley Desktop/Battermann, Heise, Loviscach/Battermann, Heise, Loviscach - 2009 - Sonosketch Querying sound effect databases through painting - Audio Engineering Society Convention.pdf:pdf},
title = {{Sonosketch: Querying sound effect databases through painting}},
url = {http://www.aes.org/e-lib/browse.cfm?conv=126\&papernum=7794},
year = {2009}
}
@article{Sussman2007a,
abstract = {There is controversy over whether stream segregation is an attention-dependent process. Part of the argument is related to the initial formation of auditory streams. It has been suggested that attention is needed only to form the streams, but not to maintain them once they have been segregated. The question of whether covert attention at the beginning of a to-be-ignored set of sounds will be enough to initiate the segregation process remains open. Here, we investigate this question by (1) using a methodology that does not require the participant to make an overt response to assess how the unattended sounds are organized and (2) structuring the test sound sequence to account for the covert attention explanation. The results of four experiments provide evidence to support the view that attention is not always required for the formation of auditory streams.},
author = {Sussman, Elyse S and Horv\'{a}th, J\'{a}nos and Winkler, Istv\'{a}n and Orr, Mark},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman et al/Sussman et al. - 2007 - The role of attention in the formation of auditory streams. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Loudness Perception,Loudness Perception: physiology,Male,Pitch Perception,Pitch Perception: physiology,Psychoacoustics,Speech Perception,Speech Perception: physiology},
month = jan,
number = {1},
pages = {136--52},
pmid = {17515223},
title = {{The role of attention in the formation of auditory streams.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17515223},
volume = {69},
year = {2007}
}
@article{Borst2011,
abstract = {Traditionally, characterizations of the macrolevel functional organization of the human cerebral cortex have focused on the left and right cerebral hemispheres. However, the idea of left brain versus right brain functions has been shown to be an oversimplification. We argue here that a top-bottom divide, rather than a left-right divide, is a more fruitful way to organize human cortical brain functions. However, current characterizations of the functions of the dorsal (top) and ventral (bottom) systems have rested on dichotomies, namely where versus what and how versus what. We propose that characterizing information-processing systems leads to a better macrolevel organization of cortical function; specifically, we hypothesize that the dorsal system is driven by expectations and processes sequences, relations, and movement, whereas the ventral system categorizes stimuli in parallel, focuses on individual events, and processes object properties (such as shape in vision and pitch in audition). To test this hypothesis, we reviewed over 100 relevant studies in the human neuroimaging and neuropsychological literatures and coded them relative to 11 variables, some of which characterized our hypothesis and some of which characterized the previous dichotomies. The results of forward stepwise logistic regressions supported our characterization of the 2 systems and showed that this model predicted the empirical findings better than either the traditional dichotomies or a left-right difference.},
author = {Borst, Gr\'{e}goire and Thompson, William L and Kosslyn, Stephen M},
doi = {10.1037/a0024038},
file = {:Users/pkmital/Documents/Mendeley Desktop/Borst, Thompson, Kosslyn/Borst, Thompson, Kosslyn - 2011 - Understanding the dorsal and ventral systems of the human cerebral cortex beyond dichotomies. - The Am.pdf:pdf},
issn = {1935-990X},
journal = {The American psychologist},
keywords = {Cerebral Cortex,Cerebral Cortex: physiology,Humans,Models, Neurological,Neural Pathways,Neural Pathways: physiology,Neuroimaging},
month = oct,
number = {7},
pages = {624--32},
pmid = {21707128},
title = {{Understanding the dorsal and ventral systems of the human cerebral cortex: beyond dichotomies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21707128},
volume = {66},
year = {2011}
}
@book{Fischer2005a,
author = {Fischer, Jan and Bartz, Dirk},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fischer, Bartz/Fischer, Bartz - 2005 - Real-time Cartoon-like Stylization of AR Video Streams on the GPU - Unknown.pdf:pdf},
title = {{Real-time Cartoon-like Stylization of AR Video Streams on the GPU}},
url = {http://www.gris.uni-tuebingen.de/~fischer/janfischer.com/publications/Fischer05\_Tooning\_TechRep\_elec.pdf},
year = {2005}
}
@inproceedings{Menzies,
address = {Graz},
author = {Menzies, Dylan},
booktitle = {Ambisonics Symposium 2009},
file = {::},
title = {{HRTFs from Point Source Representations}}
}
@misc{WaynePort2007,
author = {Porter, Wayne},
booktitle = {www.revenews.com},
title = {{GOOG to Outsource YouTube Filtering to AudibleMagic | ReveNewsReveNews}},
url = {http://www.revenews.com/search-engine-marketing/goog-to-outsource-youtube-filtering-to-audiblemagic/},
year = {2007}
}
@article{Pasley2012,
author = {Pasley, Brian N. and David, Stephen V. and Mesgarani, Nima and Flinker, Adeen and Shamma, Shihab a. and Crone, Nathan E. and Knight, Robert T. and Chang, Edward F.},
doi = {10.1371/journal.pbio.1001251},
editor = {Zatorre, Robert},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pasley et al/Pasley et al. - 2012 - Reconstructing Speech from Human Auditory Cortex - PLoS Biology.pdf:pdf},
issn = {1545-7885},
journal = {PLoS Biology},
month = jan,
number = {1},
pages = {e1001251},
title = {{Reconstructing Speech from Human Auditory Cortex}},
url = {http://dx.plos.org/10.1371/journal.pbio.1001251},
volume = {10},
year = {2012}
}
@article{Greeno1993,
author = {Greeno, James G. and Moore, Joyce L.},
doi = {10.1207/s15516709cog1701\_3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Greeno, Moore/Greeno, Moore - 1993 - Situativity and Symbols Response to Vera and Simon - Cognitive Science.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
month = jan,
number = {1},
pages = {49--59},
title = {{Situativity and Symbols: Response to Vera and Simon}},
url = {http://doi.wiley.com/10.1207/s15516709cog1701\_3},
volume = {17},
year = {1993}
}
@article{Itti2002,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Koch, Niebur/Itti, Koch, Niebur - 2002 - Short Papers Meeting, Royal Society of Medicine, London, Section of Coloproctology, 28 November 2001. - Colorectal disease the official journal of the Association of Coloproctology of Great Britain and Ireland.pdf:pdf},
issn = {1463-1318},
journal = {Colorectal disease : the official journal of the Association of Coloproctology of Great Britain and Ireland},
month = mar,
number = {2},
pages = {147--149},
pmid = {12780641},
title = {{Short Papers Meeting, Royal Society of Medicine, London, Section of Coloproctology, 28 November 2001.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20740439},
volume = {4},
year = {2002}
}
@article{Fletcher1940,
author = {Fletcher, Harvey},
doi = {10.1103/RevModPhys.12.47},
issn = {0034-6861},
journal = {Reviews of Modern Physics},
month = jan,
number = {1},
pages = {47--65},
publisher = {American Physical Society},
shorttitle = {Rev. Mod. Phys.},
title = {{Auditory Patterns}},
url = {http://link.aps.org/doi/10.1103/RevModPhys.12.47},
volume = {12},
year = {1940}
}
@article{Averbuch2006,
author = {Averbuch, a. and Coifman, R.R. and Donoho, D.L. and Elad, M. and Israeli, M.},
doi = {10.1016/j.acha.2005.11.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Averbuch et al/Averbuch et al. - 2006 - Fast and accurate Polar Fourier transform - Applied and Computational Harmonic Analysis.pdf:pdf},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {cartesian coordinates,fast fourier transform,interpolation,polar coordinates,pseudo-polar coordinates,unequally-sampled fft},
month = sep,
number = {2},
pages = {145--167},
title = {{Fast and accurate Polar Fourier transform}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520305001065},
volume = {21},
year = {2006}
}
@article{Baddeley2003,
author = {Baddeley, Alan},
doi = {10.1038/nrn1201},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baddeley/Baddeley - 2003 - Working memory looking back and looking forward. - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Brain,Brain: anatomy \& histology,Brain: physiology,Humans,Imagination,Imagination: physiology,Memory,Memory, Short-Term,Memory, Short-Term: physiology,Memory: physiology,Models, Neurological,Phonetics,Spatial Behavior,Spatial Behavior: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {10},
pages = {829--39},
pmid = {14523382},
title = {{Working memory: looking back and looking forward.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14523382},
volume = {4},
year = {2003}
}
@article{Zhuang2010,
author = {Zhuang, Xiaodan and Zhou, Xi and Hasegawa-Johnson, M.A. and Huang, T.S.},
doi = {10.1016/j.patrec.2010.02.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhuang et al/Zhuang et al. - 2010 - Real-world acoustic event detection - Pattern Recognition Letters.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {acoustic event detection},
number = {12},
pages = {1543--1551},
publisher = {Elsevier},
title = {{Real-world acoustic event detection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000620},
volume = {31},
year = {2010}
}
@article{Trukenbrod2007,
abstract = {Using a serial search paradigm, we observed several effects of within-object fixation position on spatial and temporal control of eye movements: the preferred viewing location, launch site effect, the optimal viewing position, and the inverted optimal viewing position of fixation duration. While these effects were first identified by eye-movement studies in reading, our approach permits an analysis of the functional relationships between the effects in a different paradigm. Our results demonstrate that the fixation position is an important predictor of the subsequent saccade by influencing both fixation duration and the selection of the next saccade target.},
author = {Trukenbrod, Hans a and Engbert, Ralf},
doi = {10.1016/j.visres.2007.05.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Trukenbrod, Engbert/Trukenbrod, Engbert - 2007 - Oculomotor control in a sequential search task. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Reading,Saccades,Saccades: physiology,Time Factors},
month = aug,
number = {18},
pages = {2426--43},
pmid = {17662332},
title = {{Oculomotor control in a sequential search task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17662332},
volume = {47},
year = {2007}
}
@article{Krauskopf1960,
author = {Krauskopf, J and Cornsweet, T N and Riggs, L a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Krauskopf, Cornsweet, Riggs/Krauskopf, Cornsweet, Riggs - 1960 - Analysis of eye movements during monocular and binocular fixation. - Journal of the Optical Society of America.pdf:pdf},
issn = {0030-3941},
journal = {Journal of the Optical Society of America},
keywords = {Vision, Ocular,Vision, Ocular: physiology},
month = jun,
number = {6},
pages = {572--8},
pmid = {14411808},
title = {{Analysis of eye movements during monocular and binocular fixation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14411808},
volume = {50},
year = {1960}
}
@article{RobinKirk2005,
author = {{Robin Kirk}, Jan Newmarch},
file = {::},
journal = {Second IEEE Consumer Communications and Networking Conference, 2005. CCNC. 2005},
keywords = {- home networks,interoperability,location-based services,middleware,mobility,multimedia distribution protocols,multimedia technologies,network architecture,pervasive computing,session user and device},
number = {C},
pages = {343--347},
publisher = {Ieee},
title = {{A location-aware, service-based audio system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1405194},
volume = {00},
year = {2005}
}
@inproceedings{Liu2008,
author = {Liu, Ce and Yuen, J. and Torralba, A. and Sivic, J. and Freeman, W.T.},
booktitle = {Proceedings of the 10th European Conference on Computer Vision: Part III},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu et al/Liu et al. - 2008 - SIFT flow dense correspondence across different scenes - Proceedings of the 10th European Conference on Computer Vision Part III.pdf:pdf},
number = {1},
pages = {28--42},
publisher = {Springer-Verlag},
title = {{SIFT flow: dense correspondence across different scenes}},
url = {http://portal.acm.org/citation.cfm?id=1835239 http://portal.acm.org/citation.cfm?id=1478176},
volume = {1},
year = {2008}
}
@article{Gibson1998,
author = {Gibson, Bradley S. and Jiang, Yuhong},
doi = {10.1111/1467-9280.00034},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gibson, Jiang/Gibson, Jiang - 1998 - Surprise! An Unexpected Color Singleton Does Not Capture Attention in Visual Search - Psychological Science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = may,
number = {3},
pages = {176--182},
title = {{Surprise! An Unexpected Color Singleton Does Not Capture Attention in Visual Search}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.00034},
volume = {9},
year = {1998}
}
@book{Rabiner1993a,
author = {Rabiner, L and Juang, BH},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rabiner, Juang/Rabiner, Juang - 1993 - Fundamentals of speech recognition - Unknown.pdf:pdf},
publisher = {Prentice Hall International, Inc.},
title = {{Fundamentals of speech recognition}},
url = {http://www.citeulike.org/group/10577/article/308923},
year = {1993}
}
@unpublished{Menziesb,
abstract = {A system is described for simulating environmental sound in interactive virtual worlds, using the physical state of objects as control parameters. It contains a unified framework for integration with physics simulation engines, and synthesis algorithms that are tailored to work within the framework. A range of behaviours can be simulated, including diffuse and non-linear resonators, and loose surfaces. The overall aim has been to produce a flexible and practical system with intuitive controls that will appeal to sound design professionals. This could be valuable for computer game design, and in other areas where realistic environmental audio is required. A review of previous work is included, and discussion of the issues which influence the overall design of the system.},
author = {Menzies, Dylan},
booktitle = {Technology},
file = {::},
keywords = {environmental sound,sound synthesis,virtual reality,virtual world},
mendeley-tags = {environmental sound,sound synthesis,virtual reality,virtual world},
pages = {1--23},
title = {{Physically Motivated Environmental Sound Synthesis for Virtual Worlds}}
}
@article{Papandreou2011,
author = {Papandreou, George and Yuille, Alan L.},
doi = {10.1109/ICCVW.2011.6130406},
file = {:Users/pkmital/Documents/Mendeley Desktop/Papandreou, Yuille/Papandreou, Yuille - 2011 - Efficient variational inference in large-scale Bayesian compressed sensing - 2011 IEEE International Confere.pdf:pdf},
isbn = {978-1-4673-0063-6},
journal = {2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)},
month = nov,
pages = {1332--1339},
publisher = {Ieee},
title = {{Efficient variational inference in large-scale Bayesian compressed sensing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6130406},
year = {2011}
}
@article{Alain2003,
author = {Alain, Claude and Theunissen, Eef L. and Chevalier, H\'{e}l\`{e}ne and Batty, Magali and Taylor, Margot J.},
doi = {10.1016/S0926-6410(02)00275-6},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alain et al/Alain et al. - 2003 - Developmental changes in distinguishing concurrent auditory objects - Cognitive Brain Research.pdf:pdf},
issn = {09266410},
journal = {Cognitive Brain Research},
keywords = {auditory cortex,children,evoked potentials,perception},
month = apr,
number = {2},
pages = {210--218},
title = {{Developmental changes in distinguishing concurrent auditory objects}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926641002002756},
volume = {16},
year = {2003}
}
@article{Watsen1999a,
author = {Watsen, K and Darken, R and Capps, M},
file = {::},
journal = {3rd International Immersive Projection Technology Workshop (IPTW'},
publisher = {Citeseer},
title = {{A Handheld Computer as an Interaction Device to a Virtual Environment}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Handheld+Computer+as+an+Interaction+Device+to+a+Virtual+Environment\#0},
volume = {99},
year = {1999}
}
@article{Beauvois1991,
abstract = {A computer model is described which simulates some aspects of auditory stream segregation. The model emphasizes the explanatory power of simple physiological principles operating at a peripheral rather than a central level. The model consists of a multi-channel bandpass-filter bank with a "noisy" output and an attentional mechanism that responds selectively to the channel with the greatest activity. A "leaky integration" principle allows channel excitation to accumulate and dissipate over time. The model produces similar results to two experimental demonstrations of streaming phenomena, which are presented in detail. These results are discussed in terms of the "emergent properties" of a system governed by simple physiological principles. As such the model is contrasted with higher-level Gestalt explanations of the same phenomena while accepting that they may constitute complementary kinds of explanation.},
author = {Beauvois, M W and Meddis, R},
issn = {0272-4987},
journal = {The Quarterly journal of experimental psychology. A, Human experimental psychology},
keywords = {Attention,Attention: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Threshold,Auditory Threshold: physiology,Computer Simulation,Humans,Models, Neurological,Perceptual Masking,Perceptual Masking: physiology,Pitch Discrimination,Pitch Discrimination: physiology,Psychoacoustics,Sound Localization,Sound Localization: physiology,Time Perception,Time Perception: physiology},
month = aug,
number = {3},
pages = {517--41},
pmid = {1775655},
title = {{A computer model of auditory stream segregation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1775655},
volume = {43},
year = {1991}
}
@article{Crossland2004,
abstract = {Patients with scotomas due to macular disease may use more than one preferred retinal locus (PRL) for fixation. We have developed and evaluated an objective, quantitative technique to determine the number of PRLs used during an episode of fixation and the extent of each locus. In five of eight adults with macular disease our techniques consistently indicated the presence of multiple PRLs. Patients with multiple PRLs were more likely to have suffered recent vision loss in the tested eye. Our technique describes fixation more fully than the traditional method of calculating a single bivariate contour ellipse area.},
author = {Crossland, M D and Sims, M and Galbraith, R F and Rubin, G S},
doi = {10.1016/j.visres.2004.01.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Crossland et al/Crossland et al. - 2004 - Evaluation of a new quantitative technique to assess the number and extent of preferred retinal loci in macula.pdf:pdf},
isbn = {4420760869},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Aged,Analysis of Variance,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Macular Degeneration,Macular Degeneration: physiopathology,Male,Regression Analysis,Retina,Retina: physiopathology,Vision Tests},
month = jan,
number = {13},
pages = {1537--46},
pmid = {15126063},
title = {{Evaluation of a new quantitative technique to assess the number and extent of preferred retinal loci in macular disease.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15126063},
volume = {44},
year = {2004}
}
@article{Tanaka2011,
author = {Tanaka, Atau and Altavilla, Alessandro and Spowage, Neal},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tanaka, Altavilla, Spowage/Tanaka, Altavilla, Spowage - 2011 - Gestural Musical Affordances - Unknown.pdf:pdf},
title = {{Gestural Musical Affordances}},
url = {http://nealspowage.com/publications/SMC-Gestural Musical Affordance (paper 231).pdf},
year = {2011}
}
@inproceedings{Hyv\\arinen2006,
author = {Hyv$\backslash$$\backslash$"arinen, A. and K\"{o}ster, U.},
booktitle = {Proc. of ESANN},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hyvarinen, K\"{o}ster/Hyvarinen, K\"{o}ster - 2006 - FastISA A fast fixed-point algorithm for independent subspace analysis - Proc. of ESANN.pdf:pdf},
number = {1},
pages = {371--376},
publisher = {Citeseer},
title = {{FastISA: A fast fixed-point algorithm for independent subspace analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.131.165\&amp;rep=rep1\&amp;type=pdf},
year = {2006}
}
@article{Naatanen2007,
abstract = {In the present article, the basic research using the mismatch negativity (MMN) and analogous results obtained by using the magnetoencephalography (MEG) and other brain-imaging technologies is reviewed. This response is elicited by any discriminable change in auditory stimulation but recent studies extended the notion of the MMN even to higher-order cognitive processes such as those involving grammar and semantic meaning. Moreover, MMN data also show the presence of automatic intelligent processes such as stimulus anticipation at the level of auditory cortex. In addition, the MMN enables one to establish the brain processes underlying the initiation of attention switch to, conscious perception of, sound change in an unattended stimulus stream.},
author = {N\"{a}\"{a}t\"{a}nen, R and Paavilainen, P and Rinne, T and Alho, K},
doi = {10.1016/j.clinph.2007.04.026},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen et al/N\"{a}\"{a}t\"{a}nen et al. - 2007 - The mismatch negativity (MMN) in basic research of central auditory processing a review. - Clinical neuro(2).pdf:pdf},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Cerebral Cortex,Cerebral Cortex: anatomy \& histology,Cerebral Cortex: physiology,Dominance, Cerebral,Dominance, Cerebral: physiology,Evoked Potentials,Evoked Potentials: physiology,Humans,Magnetoencephalography,Magnetoencephalography: methods,Pitch Discrimination,Pitch Discrimination: physiology,Reaction Time,Reaction Time: physiology,Speech Perception,Speech Perception: physiology},
month = dec,
number = {12},
pages = {2544--90},
pmid = {17931964},
title = {{The mismatch negativity (MMN) in basic research of central auditory processing: a review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17931964},
volume = {118},
year = {2007}
}
@article{Thier2005,
abstract = {Smooth-pursuit eye movements are used to stabilize the image of a moving object of interest on the fovea, thus guaranteeing its high-acuity scrutiny. Such movements are based on a phylogenetically recent cerebro-ponto-cerebellar pathway that has evolved in parallel with foveal vision. Recent work has shown that a network of several cerebrocortical areas directs attention to objects of interest moving in three dimensions and reconstructs the trajectory of the target in extrapersonal space, thereby integrating various sources of multimodal sensory and efference copy information, as well as cognitive influences such as prediction. This cortical network is the starting point of a set of parallel cerebrofugal projections that use different parts of the dorsal pontine nuclei and the neighboring rostral nucleus reticularis tegmenti pontis as intermediate stations to feed two areas of the cerebellum, the flocculus-paraflocculus and the posterior vermis, which make mainly complementary contributions to the control of smooth pursuit.},
author = {Thier, Peter and Ilg, Uwe J},
doi = {10.1016/j.conb.2005.10.013},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thier, Ilg/Thier, Ilg - 2005 - The neural basis of smooth-pursuit eye movements. - Current opinion in neurobiology.pdf:pdf},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animals,Cerebellum,Cerebellum: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Efferent Pathways,Efferent Pathways: physiology,Humans,Learning,Learning: physiology,Pons,Pons: physiology,Pursuit, Smooth,Pursuit, Smooth: physiology},
month = dec,
number = {6},
pages = {645--52},
pmid = {16271460},
title = {{The neural basis of smooth-pursuit eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271460},
volume = {15},
year = {2005}
}
@article{Tatler2003,
author = {Tatler, Benjamin W and Gilchrist, Iain D and Rusted, Jenny},
doi = {10.1068/p3396},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Gilchrist, Rusted/Tatler, Gilchrist, Rusted - 2003 - The time course of abstract visual representation - Perception.pdf:pdf},
issn = {0301-0066},
journal = {Perception},
number = {5},
pages = {579--592},
title = {{The time course of abstract visual representation}},
url = {http://www.perceptionweb.com/abstract.cgi?id=p3396},
volume = {32},
year = {2003}
}
@article{Speer2007,
abstract = {Readers structure narrative text into a series of events in order to understand and remember the text. In this study, subjects read brief narratives describing everyday activities while brain activity was recorded with functional magnetic resonance imaging. Subjects later read the stories again to divide them into large and small events. During the initial reading, points later identified as boundaries between events were associated with transient increases in activity in a number of brain regions whose activity was mediated by changes in the narrated situation, such as changes in characters' goals. These results indicate that the segmentation of narrated activities into events is a spontaneous part of reading, and that this process of segmentation is likely dependent on neural responses to changes in the narrated situation.},
author = {Speer, Nicole K and Zacks, Jeffrey M and Reynolds, Jeremy R},
doi = {10.1111/j.1467-9280.2007.01920.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Speer, Zacks, Reynolds/Speer, Zacks, Reynolds - 2007 - Human brain activity time-locked to narrative event boundaries. - Psychological science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science},
keywords = {Adult,Analysis of Variance,Behavior,Behavior: physiology,Brain,Brain Mapping,Brain Mapping: methods,Brain: anatomy \& histology,Brain: physiology,Concept Formation,Concept Formation: physiology,Cues,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Mental Recall,Mental Recall: physiology,Odds Ratio,Predictive Value of Tests,Reading,Time,Time Factors,Visual Perception,Visual Perception: physiology},
month = may,
number = {5},
pages = {449--55},
pmid = {17576286},
title = {{Human brain activity time-locked to narrative event boundaries.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17576286},
volume = {18},
year = {2007}
}
@inproceedings{Smaragdis2003,
author = {Smaragdis, Paris and Casey, Michael},
booktitle = {Proc. ICA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Casey/Smaragdis, Casey - 2003 - Audiovisual independent components - Proc. ICA.pdf:pdf},
pages = {709--714},
publisher = {Citeseer},
title = {{Audio/visual independent components}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.3577\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{Treisman1980,
author = {Treisman, AM and Gelade, Garry},
file = {:Users/pkmital/Documents/Mendeley Desktop/Treisman, Gelade/Treisman, Gelade - 1980 - A feature-integration theory of attention - Cognitive psychology.pdf:pdf},
journal = {Cognitive psychology},
pages = {97--136},
title = {{A feature-integration theory of attention}},
url = {http://www.sciencedirect.com/science/article/pii/0010028580900055},
volume = {12},
year = {1980}
}
@article{Levinshtein2009,
abstract = {We describe a geometric-flow-based algorithm for computing a dense oversegmentation of an image, often referred to as superpixels. It produces segments that, on one hand, respect local image boundaries, while, on the other hand, limiting undersegmentation through a compactness constraint. It is very fast, with complexity that is approximately linear in image size, and can be applied to megapixel sized images with high superpixel densities in a matter of minutes. We show qualitative demonstrations of high-quality results on several complex images. The Berkeley database is used to quantitatively compare its performance to a number of oversegmentation algorithms, showing that it yields less undersegmentation than algorithms that lack a compactness constraint while offering a significant speedup over N-cuts, which does enforce compactness.},
author = {Levinshtein, Alex and Stere, Adrian and Kutulakos, Kiriakos N and Fleet, David J and Dickinson, Sven J and Siddiqi, Kaleem},
doi = {10.1109/TPAMI.2009.96},
file = {:Users/pkmital/Documents/Mendeley Desktop/Levinshtein et al/Levinshtein et al. - 2009 - TurboPixels fast superpixels using geometric flows. - IEEE transactions on pattern analysis and machine inte.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
number = {12},
pages = {2290--7},
pmid = {19834148},
title = {{TurboPixels: fast superpixels using geometric flows.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19834148},
volume = {31},
year = {2009}
}
@article{Lyon1983,
author = {Lyon, R.},
doi = {10.1109/ICASSP.1983.1171927},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lyon/Lyon - 1983 - A computational model of binaural localization and separation - ICASSP '83. IEEE International Conference on Acoustics, Sp.pdf:pdf},
journal = {ICASSP '83. IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {1148--1151},
publisher = {Institute of Electrical and Electronics Engineers},
title = {{A computational model of binaural localization and separation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1171927},
volume = {8},
year = {1983}
}
@article{Greeno1994,
author = {Greeno, James G.},
doi = {10.1037//0033-295X.101.2.336},
file = {:Users/pkmital/Documents/Mendeley Desktop/Greeno/Greeno - 1994 - Gibson's affordances. - Psychological Review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
number = {2},
pages = {336--342},
title = {{Gibson's affordances.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.101.2.336},
volume = {101},
year = {1994}
}
@inproceedings{VandenDoel2001,
abstract = {We describe algorithms for real-time synthesis of realistic sound effects for interactive simulations (e.g., games) and animation. These sound effects are produced automatically, from 3D models using dynamic simulation and user interac- tion. We develop algorithms that are efficient, physically- based, and can be controlled by users in natural ways. We develop effective techniques for producing high quality con- tinuous contact sounds from dynamic simulations running at video rates which are slow relative to audio synthesis. We ac- complish this using modal models driven by contact forces modeled at audio rates, which are much higher than the graphics frame rate. The contact forces can be computed from simulations or can be custom designed. We demon- strate the effectiveness with complex realistic simulations.},
address = {New York, New York, USA},
author = {van den Doel, Kees and Kry, Paul G. and Pai, Dinesh K.},
booktitle = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques - SIGGRAPH '01},
doi = {10.1145/383259.383322},
file = {::},
isbn = {158113374X},
keywords = {Animation Systems,Computer Games,Head Mounted Displays.,Multimedia,Physically Based Animation,Physically BasedModeling,Sound Visualization,Virtual Reality},
mendeley-tags = {Animation Systems,Computer Games,Head Mounted Displays.,Multimedia,Physically Based Animation,Physically BasedModeling,Sound Visualization,Virtual Reality},
pages = {537--544},
publisher = {ACM Press},
title = {{FoleyAutomatic: Physically-based Sound Effects for Interactive Simulation and Animation}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383322},
year = {2001}
}
@inproceedings{Donaldson2007,
author = {Donaldson, Justin and Knopke, Ian and Raphael, Chris},
booktitle = {Proceedings of the 7th international Conference on New Interfaces for Musical Expression (NIME'07)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donaldson, Knopke, Raphael/Donaldson, Knopke, Raphael - 2007 - Chroma Palette chromatic maps of sound as granular synthesis interface - Proceedings of the 7th inte.pdf:pdf},
pages = {213--219},
title = {{Chroma Palette: chromatic maps of sound as granular synthesis interface}},
url = {http://dl.acm.org/citation.cfm?id=1279782},
year = {2007}
}
@article{Bolter1996,
author = {Bolter, J. David and Grusin, Richard a.},
doi = {10.1353/con.1996.0018},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bolter, Grusin/Bolter, Grusin - 1996 - Remediation - Configurations.pdf:pdf},
issn = {1080-6520},
journal = {Configurations},
number = {3},
pages = {311--358},
title = {{Remediation}},
url = {http://muse.jhu.edu/content/crossref/journals/configurations/v004/4.3bolter.html},
volume = {4},
year = {1996}
}
@book{Manovich2001,
author = {Manovich, Lev},
file = {:Users/pkmital/Documents/Mendeley Desktop/Manovich/Manovich - 2001 - The language of new media - Unknown.pdf:pdf},
publisher = {MIT Press},
title = {{The language of new media}},
url = {http://www.media.uoa.gr/lectures/linguistic\_archives/mda0405/notes/Bell\_Media\_and\_Language.pdf},
year = {2001}
}
@article{Lee2009b,
author = {Lee, Jong-Seok and {De Simone}, Francesca and Ebrahimi, Touradj},
doi = {10.1109/ICME.2009.5202435},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lee, De Simone, Ebrahimi/Lee, De Simone, Ebrahimi - 2009 - Video coding based on audio-visual attention - 2009 IEEE International Conference on Multimedia and Ex.pdf:pdf},
isbn = {978-1-4244-4290-4},
journal = {2009 IEEE International Conference on Multimedia and Expo},
month = jun,
number = {July},
pages = {57--60},
publisher = {Ieee},
title = {{Video coding based on audio-visual attention}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5202435},
year = {2009}
}
@article{Csiszar2008,
abstract = {Axiomatic characterizations of Shannon entropy, Kullback I-divergence, and some
generalized information measures are surveyed. Three directions are treated: (A) Characterization of functions of probability distributions suitable as information measures. (B) Characterization of set functions on the subsets of \{1,... ,N\} representable by joint entropies of components of an N-dimensional random vector. (C) Axiomatic characterization of MaxEnt and related inference rules. The paper concludes with a brief discussion of the relevance of the axiomatic approach for information theory.},
author = {Csisz\'{a}r, Imre},
doi = {10.3390/e10030261},
file = {:Users/pkmital/Documents/Mendeley Desktop/Csisz\'{a}r/Csisz\'{a}r - 2008 - Axiomatic Characterizations of Information Measures - Entropy.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {bregman distance,divergence,f -,f -entropy,f-divergence,f-entropy,ference rule,functional equation,kullback i-divergence,maximum entropy,proper score,r\'{e}nyi information measures,shannon entropy,transitive in-,transitive inference rule},
month = sep,
number = {3},
pages = {261--273},
title = {{Axiomatic Characterizations of Information Measures}},
url = {http://www.mdpi.org/entropy/papers/e10030261.pdf},
volume = {10},
year = {2008}
}
@article{Wang2011a,
author = {Wang, Tinghuai and Collomosse, John and Hu, Rui and Slatter, David and Greig, Darryl and Cheatle, Phil},
doi = {10.1016/j.cag.2010.11.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang et al/Wang et al. - 2011 - Stylized ambient displays of digital media collections - Computers \& Graphics.pdf:pdf},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Ambient displays,Artistic rendering,Composition,Graph cut,Segmentation,Temporal coherence},
month = feb,
number = {1},
pages = {54--66},
publisher = {Elsevier},
title = {{Stylized ambient displays of digital media collections}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849310001731},
volume = {35},
year = {2011}
}
@book{Richardson2010,
author = {Richardson, Iain E},
edition = {2nd Editio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Richardson/Richardson - 2010 - The H.264 Advanced Video Compression Standard - Unknown.pdf:pdf},
isbn = {9780470516928},
publisher = {John Wiley and Sons},
title = {{The H.264 Advanced Video Compression Standard}},
year = {2010}
}
@misc{LevManovich1996,
author = {Manovich, Lev},
booktitle = {Personal Website},
file = {:Users/pkmital/Documents/Mendeley Desktop/Manovich/Manovich - 1996 - Essays What is Digital Cinema - Personal Website.html:html},
title = {{Essays : What is Digital Cinema?}},
url = {http://www.manovich.net/TEXT/digital-cinema.html},
urldate = {03/10/13},
year = {1996}
}
@article{TURATTO2008,
author = {Pavani, F},
doi = {10.3758/PP},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pavani/Pavani - 2008 - Change perception in complex auditory scenes - Attention, Perception, \&amp Psychophysics.pdf:pdf},
journal = {Attention, Perception, \&amp; Psychophysics},
number = {4},
pages = {619--629},
title = {{Change perception in complex auditory scenes}},
url = {http://www.springerlink.com/index/K51J719KP5026131.pdf},
volume = {70},
year = {2008}
}
@article{Bregler1997,
author = {Bregler, Christoph and Covell, Michele},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bregler, Covell/Bregler, Covell - 1997 - Video rewrite Driving visual speech with audio - of the 24th annual conference on.pdf:pdf},
journal = {of the 24th annual conference on},
pages = {1--8},
title = {{Video rewrite: Driving visual speech with audio}},
url = {http://portal.acm.org/citation.cfm?id=258880},
year = {1997}
}
@article{Puri2009,
author = {Puri, Manika and Lubin, Jeffrey},
doi = {10.1117/12.805997},
editor = {{Delp III}, Edward J. and Dittmann, Jana and Memon, Nasir D. and Wong, Ping Wah},
file = {:Users/pkmital/Documents/Mendeley Desktop/Puri, Lubin/Puri, Lubin - 2009 - titleRobust efficient video fingerprintingtitle - Unknown.pdf:pdf},
keywords = {duplicate detection,video fingerprint},
month = feb,
pages = {725406--725406--8},
title = {{<title>Robust efficient video fingerprinting</title>}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.805997},
volume = {7254},
year = {2009}
}
@article{Rauss2011,
abstract = {An increasing number of human electroencephalography (EEG) studies examining the earliest component of the visual evoked potential, the so-called C1, have cast doubts on the previously prevalent notion that this component is impermeable to top-down effects. This article reviews the original studies that (i) described the C1, (ii) linked it to primary visual cortex (V1) activity, and (iii) suggested that its electrophysiological characteristics are exclusively determined by low-level stimulus attributes, particularly the spatial position of the stimulus within the visual field. We then describe conflicting evidence from animal studies and human neuroimaging experiments and provide an overview of recent EEG and magnetoencephalography (MEG) work showing that initial V1 activity in humans may be strongly modulated by higher-level cognitive factors. Finally, we formulate a theoretical framework for understanding top-down effects on early visual processing in terms of predictive coding.},
author = {Rauss, Karsten and Schwartz, Sophie and Pourtois, Gilles},
doi = {10.1016/j.neubiorev.2010.12.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rauss, Schwartz, Pourtois/Rauss, Schwartz, Pourtois - 2011 - Top-down effects on early visual processing in humans a predictive coding framework. - Neuroscience a.pdf:pdf},
issn = {1873-7528},
journal = {Neuroscience and biobehavioral reviews},
keywords = {Animals,Attention,Attention: physiology,Brain Mapping,Electroencephalography,Electromyography,Humans,Learning,Learning: physiology,Magnetoencephalography,Models, Biological,Vision, Ocular,Vision, Ocular: physiology,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology},
month = apr,
number = {5},
pages = {1237--53},
pmid = {21185860},
publisher = {Elsevier Ltd},
title = {{Top-down effects on early visual processing in humans: a predictive coding framework.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21185860},
volume = {35},
year = {2011}
}
@article{Shanken2000,
author = {Shanken, EA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shanken/Shanken - 2000 - Tele-agency Telematics, telerobotics, and the art of meaning - Art Journal.pdf:pdf},
journal = {Art Journal},
number = {2},
pages = {64--77},
title = {{Tele-agency: Telematics, telerobotics, and the art of meaning}},
url = {http://www.jstor.org/stable/10.2307/778102},
volume = {59},
year = {2000}
}
@article{Pampalk2006a,
author = {Pampalk, Elias},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pampalk/Pampalk - 2006 - Audio-based music similarity and retrieval Combining a spectral similarity model with information extracted from fluctuation patterns - International Symposium on Music Information Retrieval.pdf:pdf},
journal = {International Symposium on Music Information Retrieval},
title = {{Audio-based music similarity and retrieval: Combining a spectral similarity model with information extracted from fluctuation patterns}},
url = {http://www.music-ir.org/mirex/abstracts/2006/AS\_pampalk.pdf},
year = {2006}
}
@article{Pele2009,
author = {Pele, Ofir and Werman, Michael},
doi = {10.1109/ICCV.2009.5459199},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pele, Werman/Pele, Werman - 2009 - Fast and robust Earth Mover's Distances - 2009 IEEE 12th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {460--467},
publisher = {Ieee},
title = {{Fast and robust Earth Mover's Distances}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459199},
year = {2009}
}
@article{Bidet-Caulet2009,
abstract = {In our complex acoustic environment, we are confronted with a mixture of sounds produced by several simultaneous sources. However, we rarely perceive these sounds as incomprehensible noise. Our brain uses perceptual organization processes to independently follow the emission of each sound source over time. If the acoustic properties exploited in these processes are well-established, the neurophysiological mechanisms involved in auditory scene analysis remain unclear and have recently raised more interest. Here, we review the studies investigating these mechanisms using electrophysiological recordings from the cochlear nucleus to the auditory cortex, in animals and humans. Their findings reveal that basic mechanisms such as frequency selectivity, forward suppression and multi-second habituation shape the automatic brain responses to sounds in a way that can account for several important characteristics of perceptual organization of both simultaneous and successive sounds. One challenging question remains unresolved: how are the resulting activity patterns integrated to yield the corresponding conscious percepts?},
author = {Bidet-Caulet, Aurelie and Bertrand, Olivier},
doi = {10.3389/neuro.01.025.2009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bidet-Caulet, Bertrand/Bidet-Caulet, Bertrand - 2009 - Neurophysiological mechanisms involved in auditory perceptual organization. - Frontiers in neuroscience.pdf:pdf},
issn = {1662-453X},
journal = {Frontiers in neuroscience},
keywords = {auditory scene analysis,concurrent sound,electrophysiology,neurophysiology,stream segregation},
month = sep,
number = {2},
pages = {182--91},
pmid = {20011140},
title = {{Neurophysiological mechanisms involved in auditory perceptual organization.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2751619\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2009}
}
@article{Klein2007a,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces - 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@article{Goble2008,
author = {Goble, Brian and Price, Garrett and Hipsoft},
file = {::},
journal = {Casual Games Quarterly},
number = {1},
pages = {16},
title = {{Build-A-Lot Post Mortem}},
volume = {3},
year = {2008}
}
@article{Chu2009a,
author = {Chu, Selina and Narayanan, Shrikanth and Kuo, C.C.J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chu, Narayanan, Kuo/Chu, Narayanan, Kuo - 2009 - Environmental sound recognition with time–frequency audio features - Audio, Speech, and Language Processing, IEEE Transactions on.pdf:pdf},
journal = {Audio, Speech, and Language Processing, IEEE Transactions on},
number = {6},
pages = {1142--1158},
publisher = {IEEE},
title = {{Environmental sound recognition with time–frequency audio features}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5109766},
volume = {17},
year = {2009}
}
@article{Salvucci2001,
author = {Salvucci, Dario D},
doi = {10.1016/S1389-0417(00)00015-2},
file = {:Users/pkmital/Documents/Mendeley Desktop/Salvucci/Salvucci - 2001 - An integrated model of eye movements and visual encoding - Cognitive Systems Research.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
month = feb,
number = {4},
pages = {201--220},
title = {{An integrated model of eye movements and visual encoding}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041700000152},
volume = {1},
year = {2001}
}
@article{Bendixen2010,
abstract = {The auditory system continuously parses the acoustic environment into auditory objects, usually representing separate sound sources. Sound sources typically show characteristic emission patterns. These regular temporal sound patterns are possible cues for distinguishing sound sources. The present study was designed to test whether regular patterns are used as cues for source distinction and to specify the role that detecting these regularities may play in the process of auditory stream segregation. Participants were presented with tone sequences, and they were asked to continuously indicate whether they perceived the tones in terms of a single coherent sequence of sounds (integrated) or as two concurrent sound streams (segregated). Unknown to the participant, in some stimulus conditions, regular patterns were present in one or both putative streams. In all stimulus conditions, participants' perception switched back and forth between the two sound organizations. Importantly, regular patterns occurring in either one or both streams prolonged the mean duration of two-stream percepts, whereas the duration of one-stream percepts was unaffected. These results suggest that temporal regularities are utilized in auditory scene analysis. It appears that the role of this cue lies in stabilizing streams once they have been formed on the basis of simpler acoustic cues.},
author = {Bendixen, Alexandra and Denham, Susan L and Gyimesi, Kinga and Winkler, Istv\'{a}n},
doi = {10.1121/1.3500695},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bendixen et al/Bendixen et al. - 2010 - Regular patterns stabilize auditory streams. - The Journal of the Acoustical Society of America.pdf:pdf},
issn = {1520-8524},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Audiometry,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Threshold,Cues,Female,Humans,Male,Pattern Recognition, Physiological,Psychoacoustics,Signal Detection, Psychological,Time Factors,Time Perception,Young Adult},
month = dec,
number = {6},
pages = {3658--66},
pmid = {21218898},
title = {{Regular patterns stabilize auditory streams.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21218898},
volume = {128},
year = {2010}
}
@article{Menzies2007a,
abstract = {Exterior expansions of complex sound sources are presented as flexible objects for producing Ambisonic soundfield encodings. The sources can be synthesized or recorded directly, rotated and positioned in space. Related techniques can also be used to efficiently add high quality reverberation depending on the orientation and location of the source and listener.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--28},
title = {{Ambisonic Synthesis of Complex Sources}},
year = {2007}
}
@article{Picard-Limpens2009,
author = {Picard-Limpens, C\'{e}cile},
journal = {Environments},
title = {{Expressive Sound Synthesis for Animation}},
url = {http://www-sop.inria.fr/members/Cecile.Picard/index.html},
year = {2009}
}
@article{Mustovic2003,
author = {Mustovic, Henrietta and Scheffler, Klaus and {Di Salle}, Francesco and Esposito, Fabrizio and Neuhoff, John G and Hennig, J\"{u}rgen and Seifritz, Erich},
doi = {10.1016/S1053-8119(03)00293-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mustovic et al/Mustovic et al. - 2003 - Temporal integration of sequential auditory events silent period in sound pattern activates human planum tempor.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
month = sep,
number = {1},
pages = {429--434},
title = {{Temporal integration of sequential auditory events: silent period in sound pattern activates human planum temporale}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811903002933},
volume = {20},
year = {2003}
}
@article{Kerne2013,
author = {Kerne, Andruid},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kerne/Kerne - 2013 - CollageMachine An Interactive Agent of Web Recombination - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {5},
pages = {347--350},
title = {{CollageMachine: An Interactive Agent of Web Recombination}},
volume = {33},
year = {2013}
}
@article{Smaragdis2007,
author = {Smaragdis, Paris and Raj, B.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Raj/Smaragdis, Raj - 2007 - Shift-invariant probabilistic latent component analysis - Journal of Machine Learning Research.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {composition,convolutive bases,factorization,latent de-,non-negative,positive deconvolution,shift invariance},
number = {5},
title = {{Shift-invariant probabilistic latent component analysis}},
url = {http://www.merl.com/reports/docs/TR2007-009.pdf},
year = {2007}
}
@article{Elhilali2009a,
abstract = {Just as the visual system parses complex scenes into identifiable objects, the auditory system must organize sound elements scattered in frequency and time into coherent "streams." Current neurocomputational theories of auditory streaming rely on tonotopic organization of the auditory system to explain the observation that sequential spectrally distant sound elements tend to form separate perceptual streams. Here, we show that spectral components that are well separated in frequency are no longer heard as separate streams if presented synchronously rather than consecutively. In contrast, responses from neurons in primary auditory cortex of ferrets show that both synchronous and asynchronous tone sequences produce comparably segregated responses along the tonotopic axis. The results argue against tonotopic separation per se as a neural correlate of stream segregation. Instead we propose a computational model of stream segregation that can account for the data by using temporal coherence as the primary criterion for predicting stream formation.},
author = {Elhilali, Mounya and Ma, Ling and Micheyl, Christophe and Oxenham, Andrew J and Shamma, Shihab a},
doi = {10.1016/j.neuron.2008.12.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Elhilali et al/Elhilali et al. - 2009 - Temporal coherence in the perceptual organization and cortical representation of auditory scenes. - Neuron.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: anatomy \& histology,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Computer Simulation,Electrophysiology,Ferrets,Humans,Neurons,Neurons: physiology,Neuropsychological Tests,Signal Processing, Computer-Assisted,Time Factors},
month = jan,
number = {2},
pages = {317--29},
pmid = {19186172},
publisher = {Elsevier Inc.},
title = {{Temporal coherence in the perceptual organization and cortical representation of auditory scenes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2673083\&tool=pmcentrez\&rendertype=abstract},
volume = {61},
year = {2009}
}
@article{Hinterstoisser2008,
author = {Hinterstoisser, Stefan and Benhimane, Selim and Navab, Nassir and Fua, Pascal and Lepetit, Vincent},
doi = {10.1109/CVPR.2008.4587514},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hinterstoisser et al/Hinterstoisser et al. - 2008 - Online learning of patch perspective rectification for efficient object detection - 2008 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1--8},
publisher = {Ieee},
title = {{Online learning of patch perspective rectification for efficient object detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587514},
year = {2008}
}
@article{ShaoboHou2008,
author = {{Shaobo Hou}},
doi = {10.1109/CVPR.2008.4587467},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shaobo Hou/Shaobo Hou - 2008 - Robust estimation of gaussian mixtures from noisy input data - Unknown.pdf:pdf},
isbn = {978-1-4244-2242-5},
month = jun,
pages = {1--8},
title = {{Robust estimation of gaussian mixtures from noisy input data}},
year = {2008}
}
@article{Kragic,
author = {Kragic, Danica},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kragic/Kragic - Unknown - Active 3D scene segmentation and detection of unknown objects - Image (Rochester, N.Y.).pdf:pdf},
journal = {Image (Rochester, N.Y.)},
title = {{Active 3D scene segmentation and detection of unknown objects}}
}
@article{Keech2010,
author = {Keech, TD and Resca, L},
doi = {10.3758/APP},
file = {:Users/pkmital/Documents/Mendeley Desktop/Keech, Resca/Keech, Resca - 2010 - Eye movements in active visual search A computable phenomenological model - Attention, Perception, \& Psychophysics.pdf:pdf},
journal = {Attention, Perception, \& Psychophysics},
number = {2},
pages = {285--307},
title = {{Eye movements in active visual search: A computable phenomenological model}},
url = {http://www.springerlink.com/index/A7603424676GM396.pdf},
volume = {72},
year = {2010}
}
@misc{Alfishawi2012,
author = {Alfishawi, Thabet},
booktitle = {YouTube.com's Official Blog},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alfishawi/Alfishawi - 2012 - Improving Content ID - YouTube.com's Official Blog.html:html},
title = {{Improving Content ID}},
url = {http://youtube-global.blogspot.co.uk/2012/10/improving-content-id.html},
urldate = {27/08/13},
year = {2012}
}
@article{Kennedy2008,
abstract = {Adjective-Noun and Noun-Adjective sequences inspected with single fixations in the French part of the Dundee Corpus were examined. Violations to canonical reading order produced significant effects on average inspection time, but only for fixations on the two words concerned and the immediately following fixation. Extended analyses on both English and French data sets also show local consequences of violations to reading order, but only very limited evidence of longer-lasting effects on wrap-up. The fact that a failure to maintain a strict left-right serial reading order seems not to result in significant processing disruption poses a challenge to current models of eye movement control in reading.},
author = {Kennedy, Alan and Pynte, Jo\"{e}l},
doi = {10.1016/j.visres.2008.07.007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kennedy, Pynte/Kennedy, Pynte - 2008 - The consequences of violations to reading order an eye movement analysis. - Vision research.pdf:pdf},
issn = {1878-5646},
journal = {Vision research},
keywords = {Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,France,Humans,Linguistics,Psychomotor Performance,Psychomotor Performance: physiology,Reading,Semantics},
month = sep,
number = {21},
pages = {2309--20},
pmid = {18680761},
title = {{The consequences of violations to reading order: an eye movement analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18680761},
volume = {48},
year = {2008}
}
@article{Barber2007,
abstract = {In this article, we discuss the relevance of electrophysiological data to the enterprise of analyzing and understanding the reading process. Specifically, we detail how the event-related brain potential (ERP) technique (and its magnetic counterpart) can aid in development of models of visual word recognition. Any viable and accurate account of reading must take into account the temporal and anatomical constraints imposed by the fact that reading is a human brain function. We believe that neurophysiological (especially, although not limited to electrophysiological) data can serve an essential reference in the development of biologically realistic models of reading. We assess just how well extant electrophysiological data comport with specific predictions of existing computational models and offer some suggestions for the kinds of research that can address some of the remaining open questions.},
author = {Barber, Horacio a and Kutas, Marta},
doi = {10.1016/j.brainresrev.2006.07.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barber, Kutas/Barber, Kutas - 2007 - Interplay between computational models and cognitive electrophysiology in visual word recognition. - Brain research reviews.pdf:pdf},
issn = {0165-0173},
journal = {Brain research reviews},
keywords = {Brain,Brain: anatomy \& histology,Brain: physiology,Computer Simulation,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Humans,Magnetoencephalography,Magnetoencephalography: methods,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reading,Statistics as Topic,Verbal Behavior,Verbal Behavior: physiology},
month = jan,
number = {1},
pages = {98--123},
pmid = {16905196},
title = {{Interplay between computational models and cognitive electrophysiology in visual word recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16905196},
volume = {53},
year = {2007}
}
@article{Hertzmann2000,
address = {New York, New York, USA},
author = {Hertzmann, Aaron and Perlin, Ken},
doi = {10.1145/340916.340917},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hertzmann, Perlin/Hertzmann, Perlin - 2000 - Painterly rendering for video and interaction - Proceedings of the first international symposium on Non-photo.pdf:pdf},
isbn = {1581132778},
journal = {Proceedings of the first international symposium on Non-photorealistic animation and rendering - NPAR '00},
keywords = {a,a viewer interacting with,animation,dering,figure 1,living,non-photorealistic rendering,painterly ren-,painting,video processing},
pages = {7--12},
publisher = {ACM Press},
title = {{Painterly rendering for video and interaction}},
url = {http://portal.acm.org/citation.cfm?doid=340916.340917},
year = {2000}
}
@article{Peli1990,
abstract = {The physical contrast of simple images such as sinusoidal gratings or a single patch of light on a uniform background is well defined and agrees with the perceived contrast, but this is not so for complex images. Most definitions assign a single contrast value to the whole image, but perceived contrast may vary greatly across the image. Human contrast sensitivity is a function of spatial frequency; therefore the spatial frequency content of an image should be considered in the definition of contrast. In this paper a definition of local band-limited contrast in images is proposed that assigns a contrast value to every point in the image as a function of the spatial frequency band. For each frequency band, the contrast is defined as the ratio of the bandpass-filtered image at the frequency to the low-pass image filtered to an octave below the same frequency (local luminance mean). This definition raises important implications regarding the perception of contrast in complex images and is helpful in understanding the effects of image-processing algorithms on the perceived contrast. A pyramidal image-contrast structure based on this definition is useful in simulating nonlinear, threshold characteristics of spatial vision in both normal observers and the visually impaired.},
author = {Peli, E},
file = {:Users/pkmital/Documents/Mendeley Desktop/Peli/Peli - 1990 - Contrast in complex images. - Journal of the Optical Society of America. A, Optics and image science.pdf:pdf},
issn = {0740-3232},
journal = {Journal of the Optical Society of America. A, Optics and image science},
keywords = {Contrast Sensitivity,Form Perception,Humans,Image Processing, Computer-Assisted,Light,Mathematics,Sensory Thresholds,Visual Perception},
month = oct,
number = {10},
pages = {2032--40},
pmid = {2231113},
title = {{Contrast in complex images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2231113},
volume = {7},
year = {1990}
}
@article{VanZuijen2006,
abstract = {Implicit knowledge has been proposed to be the substrate of intuition because intuitive judgments resemble implicit processes. We investigated whether the automatically elicited mismatch negativity (MMN) component of the auditory event-related potentials (ERPs) can reflect implicit knowledge and whether this knowledge can be utilized for intuitive sound discrimination. We also determined the sensitivity of the attention-and task-dependent P3 component to intuitive versus explicit knowledge. We recorded the ERPs elicited in an "abstract" oddball paradigm. Tone pairs roving over different frequencies but with a constant ascending inter-pair interval, were presented as frequent standard events. The standards were occasionally replaced by deviating, descending tone pairs. The ERPs were recorded under both ignore and attend conditions. Subjects were interviewed and classified on the basis of whether or not they could datect the deviants. The deviants elicited an MMN even in subjects who subsequent to the MMN recording did not express awareness of the deviants. This suggests that these subjects possessed implicit knowledge of the sound-sequence structure. Some of these subjects learned, in an associative training session, to detect the deviants intuitively, that is, they could detect the deviants but did not give a correct description of how the deviants differed from the standards. Intuitive deviant detection was not accompanied by P3 elicitation whereas subjects who developed explicit knowledge of the sound sequence during the training did show a P3 to the detected deviants.},
author = {van Zuijen, Titia L and Simoens, Veerle L and Paavilainen, Petri and N\"{a}\"{a}t\"{a}nen, Risto and Tervaniemi, Mari},
doi = {10.1162/jocn.2006.18.8.1292},
file = {:Users/pkmital/Documents/Mendeley Desktop/van Zuijen et al/van Zuijen et al. - 2006 - Implicit, intuitive, and explicit knowledge of abstract regularities in a sound sequence an event-related bra.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Perception,Auditory Perception: physiology,Brain,Brain Mapping,Brain: physiology,Contingent Negative Variation,Contingent Negative Variation: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Knowledge,Male,Mental Processes,Mental Processes: physiology,Reaction Time,Reaction Time: physiology,Sound},
month = aug,
number = {8},
pages = {1292--303},
pmid = {16859415},
title = {{Implicit, intuitive, and explicit knowledge of abstract regularities in a sound sequence: an event-related brain potential study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16859415},
volume = {18},
year = {2006}
}
@article{Donoho2006c,
author = {Donoho, DL},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donoho/Donoho - 2006 - Compressed sensing - IEEE Transactions on Information Theory.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
keywords = {adaptive sampling,almost-spherical sections of banach,and phrases,based complexity,basis pursuit,equations,fand n -widths,gel,information-,integrated sensing and processing,minimum 1 norm decomposition,optimal recovery,spaces,sparse solution of linear},
number = {4},
pages = {1289 -- 1306},
title = {{Compressed sensing}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1614066},
volume = {52},
year = {2006}
}
@article{Barrett1990,
abstract = {Event-related potentials (ERPs) were recorded from one midline and three pairs of lateral electrodes while subjects determined whether pairs of sequentially presented pictures were semantically associated. The ERPs evoked by the second picture of each pair differed as a consequence of whether it was associated with its predecessor, such that ERPs to nonassociated pictures were more negative-going than those to associated items. These differences resulted from the modulation of two ERP components, one frontally distributed and centered on an N300 deflection, the other distributed more widely over the scalp and encompassing an N450 deflection. The modulation of N450 is interpreted as further evidence that the "N400" ERP component is sensitive to semantic relationships between nonverbal stimuli. The earlier N300 effects, which do not appear to occur when ERPs are evoked by semantically primed and unprimed words, could suggest that the semantic processing of pictorial stimuli involves neural systems different from those associated with the semantic processing of words.},
author = {Barrett, S E and Rugg, M D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barrett, Rugg/Barrett, Rugg - 1990 - Event-related potentials and the semantic matching of pictures. - Brain and cognition.pdf:pdf},
issn = {0278-2626},
journal = {Brain and cognition},
keywords = {Adolescent,Adult,Arousal,Arousal: physiology,Attention,Attention: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Electroencephalography,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Paired-Associate Learning,Paired-Associate Learning: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Semantics},
month = nov,
number = {2},
pages = {201--12},
pmid = {2285513},
title = {{Event-related potentials and the semantic matching of pictures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2285513},
volume = {14},
year = {1990}
}
@article{Casey2008b,
author = {Casey, MA and Veltkamp, Remco and Goto, Masataka},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey, Veltkamp, Goto/Casey, Veltkamp, Goto - 2008 - Content-based music information retrieval current directions and future challenges - Proceedings of the I.pdf:pdf},
journal = {Proceedings of the IEEE},
number = {4},
title = {{Content-based music information retrieval: current directions and future challenges}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4472077},
volume = {96},
year = {2008}
}
@article{Mattern2008,
author = {Mattern, Matthew and Gerard, Perry S and Geller, Matthew D},
doi = {10.1016/j.amjmed.2008.08.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mattern, Gerard, Geller/Mattern, Gerard, Geller - 2008 - Synchronicity. - The American journal of medicine.pdf:pdf},
issn = {1555-7162},
journal = {The American journal of medicine},
keywords = {Carcinoma, Papillary,Carcinoma, Papillary: radiography,Fluorodeoxyglucose F18,Fluorodeoxyglucose F18: diagnostic use,Head and Neck Neoplasms,Head and Neck Neoplasms: radiography,Humans,Male,Melanoma,Melanoma: radiography,Middle Aged,Neoplasms, Multiple Primary,Neoplasms, Multiple Primary: radiography,Neoplasms, Squamous Cell,Neoplasms, Squamous Cell: radiography,Positron-Emission Tomography,Scalp,Scalp: radiography,Skin Neoplasms,Skin Neoplasms: radiography,Thyroid Neoplasms,Thyroid Neoplasms: radiography},
month = oct,
number = {10},
pages = {868--9},
pmid = {18823857},
title = {{Synchronicity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18823857},
volume = {121},
year = {2008}
}
@article{Schmalstieg2007e,
author = {Schmalstieg, Dieter and Wagner, Daniel},
file = {::},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality games,cultural heritage,mobile augmented reality,wearable computing},
month = nov,
pages = {1--13},
publisher = {Ieee},
title = {{Experiences with Handheld Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538819},
year = {2007}
}
@article{Itti2005,
author = {Itti, Laurent},
doi = {10.1080/13506280444000661},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti/Itti - 2005 - Quantifying the contribution of low‐level saliency to human eye movements in dynamic scenes - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1093--1123},
title = {{Quantifying the contribution of low‐level saliency to human eye movements in dynamic scenes}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280444000661\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {12},
year = {2005}
}
@article{Kim2002,
author = {Kim, Junhwan and Pellacini, Fabio},
doi = {10.1145/566654.566633},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kim, Pellacini/Kim, Pellacini - 2002 - Jigsaw image mosaics - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {morphing,mosaics,optimization},
month = jul,
number = {3},
title = {{Jigsaw image mosaics}},
url = {http://portal.acm.org/citation.cfm?doid=566654.566633},
volume = {21},
year = {2002}
}
@article{Sprague2007,
author = {Sprague, Nathan and Ballard, Dana and Robinson, Al},
doi = {10.1145/1265957.1265960},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sprague, Ballard, Robinson/Sprague, Ballard, Robinson - 2007 - Modeling embodied visual behaviors - ACM Transactions on Applied Perception.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
month = jul,
number = {2},
pages = {11--es},
title = {{Modeling embodied visual behaviors}},
url = {http://portal.acm.org/citation.cfm?doid=1265957.1265960},
volume = {4},
year = {2007}
}
@article{Seiffert2003,
abstract = {Motion of an object is thought to be perceived independently of the object's surface properties. However, theoretical, neuropsychological and psychophysical observations have suggested that motion of textures, called 'second-order motion', may be processed by a separate system from luminance-based, or 'first-order', motion. Functional magnetic resonance imaging (fMRI) responses during passive viewing, attentional modulation and post-adaptation motion after-effects (MAE) of these stimuli were measured in seven retinotopic visual areas (labeled V1, V2, V3, VP, V4v, V3A and LO) and the motion-sensitive area MT/MST (V5). In all visual areas, responses were strikingly similar to motion of first- and second-order stimuli. These results differ from a prior investigation, because here the motion-specific responses were isolated. Directing attention towards and away from the motion elicited equivalent response modulation for the two types. Dramatic post-adaptation (MAE) differences in perception of the two stimuli were observed and fMRI activation mimicked perceptual changes, but did not reveal the processing differences. In fact, no visual area was found to respond selectively to the motion of second-order stimuli, suggesting that motion perception arises from a unified motion detection system.},
author = {Seiffert, Adriane E and Somers, David C and Dale, Anders M and Tootell, Roger B H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Seiffert et al/Seiffert et al. - 2003 - Functional MRI studies of human visual motion perception texture, luminance, attention and after-effects. - Cerebral cortex (New York, N.Y. 1991).pdf:pdf},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Brain,Brain: physiology,Female,Humans,Lighting,Lighting: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Motion Perception,Motion Perception: physiology,Photic Stimulation,Photic Stimulation: methods,Visual Fields,Visual Fields: physiology},
month = apr,
number = {4},
pages = {340--9},
pmid = {12631563},
title = {{Functional MRI studies of human visual motion perception: texture, luminance, attention and after-effects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12631563},
volume = {13},
year = {2003}
}
@misc{Stewart2010,
author = {Stewart, Margaret Gould},
booktitle = {TED.com},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stewart/Stewart - 2010 - How YouTube thinks about copyright Video on TED.com - TED.com.html:html},
keywords = {TED,Talks,art,arts,business,creativity,culture,entertainment,law,technology,video},
title = {{How YouTube thinks about copyright | Video on TED.com}},
url = {http://www.ted.com/talks/margaret\_stewart\_how\_youtube\_thinks\_about\_copyright.html},
urldate = {27/08/13},
year = {2010}
}
@article{Targher2011,
author = {Targher, Stefano},
file = {:Users/pkmital/Documents/Mendeley Desktop/Targher/Targher - 2011 - Spatiotemporal aspects in audiovisual interaction - eprints-phd.biblio.unitn.it.pdf:pdf},
journal = {eprints-phd.biblio.unitn.it},
title = {{Spatiotemporal aspects in audiovisual interaction}},
url = {http://eprints-phd.biblio.unitn.it/634/1/Stefano\_Targher\_PhD\_Thesis.pdf},
year = {2011}
}
@article{Dobashi2004,
author = {Dobashi, Yoshinori and Yamamoto, Tsuyoshi and Nishita, Tomoyuki},
doi = {10.1111/j.1467-8659.2004.00785.x},
file = {::},
issn = {0167-7055},
journal = {Computer Graphics Forum},
month = sep,
number = {3},
pages = {539--545},
title = {{Synthesizing Sound from Turbulent Field using Sound Textures for Interactive Fluid Simulation}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2004.00785.x},
volume = {23},
year = {2004}
}
@article{Yen2008,
abstract = {We introduce a novel technique to generate painterly art map (PAM) for 3D non-photorealistic rendering. Our technique can automatically transfer brush stroke textures and color changes to 3D models from samples of a painted image. Therefore, the generation of stylized images/animation in the style of a given artwork can be achieved. This new approach works particularly well for a rich variety of brush strokes ranging from simple 1D and 2D line-art strokes to very complicated ones with significant variations in stroke characteristics. During the rendering/animation process, the coherence of brush stroke textures and color changes over 3D surfaces can be well maintained. With PAM, we can also easily generate the illusion of flow animation over a 3D surface to convey the shape of a model.},
author = {Yen, Chung-Ren and Chi, Ming-Te and Lee, Tong-Yee and Lin, Wen-Chieh},
doi = {10.1109/TVCG.2007.70440},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yen et al/Yen et al. - 2008 - Stylized rendering using samples of a painted image. - IEEE transactions on visualization and computer graphics.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
number = {2},
pages = {468--80},
pmid = {18192723},
title = {{Stylized rendering using samples of a painted image.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18192723},
volume = {14},
year = {2008}
}
@article{Sejnowski1992,
author = {Sejnowski, T J},
doi = {10.1126/science.257.5070.687},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sejnowski/Sejnowski - 1992 - Models of vision. - Science (New York, N.Y.).pdf:pdf},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = jul,
number = {5070},
pages = {687--8},
pmid = {17740735},
title = {{Models of vision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17740735},
volume = {257},
year = {1992}
}
@article{Eronen2006,
author = {Eronen, AJ and Peltonen, VT and Tuomi, JT},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eronen, Peltonen, Tuomi/Eronen, Peltonen, Tuomi - 2006 - Audio-based context recognition - Audio, Speech, and Language Processing, IEEE Transactions on.pdf:pdf},
journal = {Audio, Speech, and Language Processing, IEEE Transactions on},
number = {1},
pages = {321--329},
title = {{Audio-based context recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1561288},
volume = {14},
year = {2006}
}
@article{Ji2003,
author = {Ji, Xiaowen and Kato, Z and Huang, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ji, Kato, Huang/Ji, Kato, Huang - 2003 - Non-photorealistic rendering and content-based image retrieval - Computer Graphics and Applications, \ldots.pdf:pdf},
journal = {Computer Graphics and Applications, \ldots},
number = {Section 2},
title = {{Non-photorealistic rendering and content-based image retrieval}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1238257},
year = {2003}
}
@article{Kennedy2004,
author = {Kennedy, Alan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kennedy/Kennedy - 2004 - Parafoveal-on-foveal effects are not an artifact of mis-located saccades - Neurosciences.pdf:pdf},
journal = {Neurosciences},
keywords = {fixation duration,foveal processing time,mislocated,oculomotor error,parafoveal-on-foveal effects,saccades},
number = {1},
pages = {1--10},
title = {{Parafoveal-on-foveal effects are not an artifact of mis-located saccades}},
volume = {2},
year = {2004}
}
@article{Czigler2002,
author = {Czigler, Istvan and Balazs, Laszlo and Winkler, Istvan},
doi = {10.1111/1469-8986.3960869},
issn = {0048-5772},
journal = {Psychophysiology},
month = nov,
number = {6},
pages = {869--873},
title = {{Memory-based detection of task-irrelevant visual changes}},
url = {http://doi.wiley.com/10.1111/1469-8986.3960869},
volume = {39},
year = {2002}
}
@article{Escera2003,
author = {Escera, Carles and Yago, Elena and Corral, Maria-Jose and Corbera, Silvia and Nunez, M. Isabel},
doi = {10.1046/j.1460-9568.2003.02937.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Escera et al/Escera et al. - 2003 - Attention capture by auditory significant stimuli semantic analysis follows attention switching - European Journa.pdf:pdf},
issn = {0953-816X},
journal = {European Journal of Neuroscience},
keywords = {evoked potentials,exogenous attention,humans,involuntary,novelty,stimulus-driven},
month = oct,
number = {8},
pages = {2408--2412},
title = {{Attention capture by auditory significant stimuli: semantic analysis follows attention switching}},
url = {http://doi.wiley.com/10.1046/j.1460-9568.2003.02937.x},
volume = {18},
year = {2003}
}
@article{Torralba2006,
abstract = {Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes.},
author = {Torralba, Antonio and Oliva, Aude and Castelhano, Monica S and Henderson, John M},
doi = {10.1037/0033-295X.113.4.766},
file = {:Users/pkmital/Documents/Mendeley Desktop/Torralba et al/Torralba et al. - 2006 - Contextual guidance of eye movements and attention in real-world scenes the role of global features in object s.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Attention,Bayes Theorem,Eye Movements,Humans,Models, Psychological,Social Environment,Visual Perception},
month = oct,
number = {4},
pages = {766--86},
pmid = {17014302},
title = {{Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17014302},
volume = {113},
year = {2006}
}
@article{Klinec1988a,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
number = {19-20},
pages = {xiii},
title = {{Positioning and Location Services for Infoor Areas in neXus}},
volume = {7},
year = {1988}
}
@article{Bonneel2008,
author = {Bonneel, Nicolas and Drettakis, George and Tsingos, Nicolas and Viaud-Delmon, Isabelle and James, Doug},
doi = {10.1145/1360612.1360623},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {dering,modal synthesis,physically based animation,real-time audio ren-,sound synthesis,time-domain modal synthesis},
month = aug,
number = {3},
pages = {1},
title = {{Fast modal sounds with scalable frequency-domain synthesis}},
url = {http://portal.acm.org/citation.cfm?doid=1360612.1360623},
volume = {27},
year = {2008}
}
@misc{Hochman2013,
abstract = {How are users’  experiences  of production, sharing, and interaction with the media they create mediated by the  interfaces  of particular social media platforms? How can we use computational analysis and visualizations of the  content of visual social media  ( e.g. , user photos, as opposed to upload dates, locations, tags and other metadata) to study social and cultural patterns? How can we visualize this media on  multiple spatial and temporal scales?  In this paper, we examine these questions through the analysis of the popular mobile photo–sharing application Instagram. First, we analyze the affordances provided by the Instagram interface and the ways this interface and the application’s tools structure users’ understanding and use of the “Instagram medium.” Next, we compare the visual signatures of 13 different global cities using 2.3 million Instagram photos from these cities. Finally, we use spatio–temporal visualizations of over 200,000 Instagram photos uploaded in Tel Aviv, Israel over three months to show how they can offer social, cultural and political insights about people’s activities in particular locations and time periods.},
author = {Hochman, Nadav and Manovich, Lev},
booktitle = {First Monday},
issn = {13960466},
keywords = {Instagram,cultural analytics,data visualization,social media},
language = {en},
month = jun,
number = {7},
title = {{Zooming into an Instagram City: Reading the local through social media}},
url = {http://firstmonday.org/ojs/index.php/fm/article/view/4711/3698},
volume = {18},
year = {2013}
}
@article{Kimura2006g,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 2006 - Multiterminal source coding with complementary delivering • Investigate a coding problem for correlated information reproduce the other message - Science.pdf:pdf},
journal = {Science},
pages = {1--20},
title = {{Multiterminal source coding with complementary delivering • Investigate a coding problem for correlated information reproduce the other message}},
year = {2006}
}
@article{Henderson2007a,
author = {Henderson, John M.},
doi = {10.1111/j.1467-8721.2007.00507.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson/Henderson - 2007 - Regarding Scenes - Current Directions in Psychological Science.pdf:pdf},
issn = {0963-7214},
journal = {Current Directions in Psychological Science},
keywords = {be apprehended very rapidly,eye movements,for at least 30,gaze control,it has been known,of a scene can,of a single,real-world scene,saliency,scene perception,visual,visual context,well within the duration,years that the gist},
month = aug,
number = {4},
pages = {219--222},
title = {{Regarding Scenes}},
url = {http://cdp.sagepub.com/lookup/doi/10.1111/j.1467-8721.2007.00507.x},
volume = {16},
year = {2007}
}
@article{Pang2008b,
author = {Pang, Derek and Kimura, Akisato and Takeuchi, Tatsuto and Yamato, Junji and Kashino, Kunio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pang et al/Pang et al. - 2008 - A Stochastic Model of Selective Visual Attention with a Dynamic Bayesian Network Where would you focus - Media.pdf:pdf},
journal = {Media},
number = {1},
title = {{A Stochastic Model of Selective Visual Attention with a Dynamic Bayesian Network Where would you focus ?}},
year = {2008}
}
@article{Zimmer2003,
abstract = {The relationship between people and art is complex and intriguing. Of course, artworks are our creations; but in interesting and important ways, we are also created by our artworks. Our sense of the world is informed by the art we make and by the art we inherit and value, works that, in themselves, encode others' world views. This two-way effect is deeply rooted and art encodes and affects both a culture's ways of perceiving the world and its ways of remaking the world it perceives. The purpose of this paper is to indicate ways in which a study of abstraction in art can be used to discover insights into, to quote the call for papers for this issue, 'our perception of the world, acquired through experience' and 'the way concepts are formed and manipulated to achieve goals'.},
author = {Zimmer, Robert},
doi = {10.1098/rstb.2003.1307},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zimmer/Zimmer - 2003 - Abstraction in art with implications for perception. - Philosophical transactions of the Royal Society of London. Series.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Art,Concept Formation,Humans,Neurology,Problem Solving,Psychology,Visual Perception},
month = jul,
number = {1435},
pages = {1285--91},
pmid = {12903671},
title = {{Abstraction in art with implications for perception.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1693220\&tool=pmcentrez\&rendertype=abstract},
volume = {358},
year = {2003}
}
@incollection{McLeod2011a,
author = {McLeod, Kembrew and Kuenzli, Rudolf},
booktitle = {Cutting Across Media. Appropriation Art, Interventionist Collage, and Copyright Law},
editor = {McLeod, Kembrew and Kuenzli, Rudolf},
pages = {1--23},
publisher = {Duke University Press},
title = {{I Collage, Therefore I Am}},
year = {2011}
}
@article{Himmel1998,
author = {Himmel, Dave and Greaves, Mark and Kao, Anne and Poteet, Steve},
file = {:Users/pkmital/Documents/Mendeley Desktop/Himmel et al/Himmel et al. - 1998 - Visualization for large collections of multimedia information - Content Visualization and Intermedia Representations.pdf:pdf},
journal = {Content Visualization and Intermedia Representations},
title = {{Visualization for large collections of multimedia information}},
url = {http://acl.ldc.upenn.edu/W/W98/W98-0205.pdf},
year = {1998}
}
@article{Marsh2009,
author = {Marsh, Kerry L. and Richardson, Michael J. and Schmidt, R. C.},
doi = {10.1111/j.1756-8765.2009.01022.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marsh, Richardson, Schmidt/Marsh, Richardson, Schmidt - 2009 - Social Connection Through Joint Action and Interpersonal Coordination - Topics in Cognitive Science.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {cooperation,dynamical,ecological,embodiment,joint action,social affordance,social coordination,social embedding,synchrony},
month = apr,
number = {2},
pages = {320--339},
title = {{Social Connection Through Joint Action and Interpersonal Coordination}},
url = {http://doi.wiley.com/10.1111/j.1756-8765.2009.01022.x},
volume = {1},
year = {2009}
}
@article{Kurths,
archivePrefix = {arXiv},
arxivId = {arXiv:0802.2201v2},
author = {Kurths, J},
eprint = {arXiv:0802.2201v2},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kurths/Kurths - Unknown - Reconstruction of eye movements during blinks - Unknown.pdf:pdf},
pages = {1--16},
title = {{Reconstruction of eye movements during blinks}}
}
@book{Ascott2003,
abstract = {Long before e-mail and the Internet permeated society, Roy Ascott, a pioneering British artist and theorist, coined the term "telematic art" to describe the use of online computer networks as an artistic medium. In Telematic Embrace Edward A. Shanken gathers, for the first time, an impressive compilation of more than three decades of Ascott's philosophies on aesthetics, interactivity, and the sense of self and community in the telematic world of cyberspace. This book explores Ascott's ideas on how networked communication has shaped behavior and consciousness within and beyond the realm of what is conventionally defined as art.Telematics, a powerful marriage of computers and telecommunication, made technologies we now take for granted-such as e-mail and automated teller machines (ATMs)-part of our daily life, and made art a more interactive form of expression. Telematic art challenges traditional relationships between artist, artwork, and audience by allowing nonlocal audiences to influence the emergent qualities of the artwork, which consists of the ebb and flow of electronic information. These essays constitute a unique archaeology of ideas, tracing Ascott's meditations on the formation of consciousness through the intertwined cultural histories of art and technology from the 1960s to the present.Shanken's introduction situates Ascott's work within a history of ideas in art, technology, and philosophy. Given the increasing role of the Internet and the World Wide Web in the creation of commerce and community at the dawn of this new millennium, scholars, students, laypeople, policymakers, and artists will find this collection informative and thought-provoking.},
author = {Ascott, Roy and Shanken, Edward A},
booktitle = {University of California Press},
editor = {Shanken, Edward A},
isbn = {0520218035},
pages = {427},
publisher = {University of California Press},
series = {BFI Modern Classics},
title = {{Telematic Embrace: Visionary Theories of Art, Technology, and Consciousness}},
url = {http://books.google.com/books?id=zN85LrAoDwUC\&pgis=1},
year = {2003}
}
@article{Alain2001,
author = {Alain, C and Arnott, SR and Picton, TW},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alain, Arnott, Picton/Alain, Arnott, Picton - 2001 - Bottom–up and top–down influences on auditory scene analysis Evidence from event-related brain potent.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {5},
pages = {1072--1089},
title = {{Bottom–up and top–down influences on auditory scene analysis: Evidence from event-related brain potentials.}},
url = {http://psycnet.apa.org/psycinfo/2001-18525-004},
volume = {27},
year = {2001}
}
@article{Shams2010,
abstract = {Vision is generally considered the dominant sensory modality; self-contained and independent of other senses. In this article, we will present recent results that contradict this view, and show that visual perception can be strongly altered by sound and touch, and such alterations can occur even at early stages of processing, as early as primary visual cortex. We will first review the behavioral evidence demonstrating modulation of visual perception by other modalities. As extreme examples of such modulations, we will describe two visual illusions induced by sound, and a visual illusion induced by touch. Next, we will discuss studies demonstrating modulation of activity in visual areas by stimulation of other modalities, and discuss possible pathways that could underpin such interactions. This will be followed by a discussion of how crossmodal interactions can affect visual learning and adaptation. We will review several studies showing crossmodal effects on visual learning. We will conclude with a discussion of computational principles governing these crossmodal interactions, and review several recent studies that demonstrate that these interactions are statistically optimal.},
author = {Shams, Ladan and Kim, Robyn},
doi = {10.1016/j.plrev.2010.04.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shams, Kim/Shams, Kim - 2010 - Crossmodal influences on visual perception. - Physics of life reviews.pdf:pdf},
issn = {1873-1457},
journal = {Physics of life reviews},
keywords = {multisensory integration,multisensory perception,visual learning,visual perception},
month = apr,
pages = {1--16},
pmid = {20447880},
publisher = {Elsevier B.V.},
title = {{Crossmodal influences on visual perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20447880},
volume = {1},
year = {2010}
}
@article{Borst2012,
abstract = {Although few studies have systematically investigated the relationship between visual mental imagery and visual working memory, work on the effects of passive visual interference has generally demonstrated a dissociation between the two functions. In four experiments, we investigated a possible commonality between the two functions: We asked whether both rely on depictive representations. Participants judged the visual properties of letters using visual mental images or pictures of unfamiliar letters stored in short-term memory. Participants performed both tasks with two different types of interference: sequences of unstructured visual masks (consisting of randomly changing white and black dots) or sequences of structured visual masks (consisting of fragments of letters). The structured visual noise contained elements of depictive representations (i.e., shape fragments arrayed in space), and hence should interfere with stored depictive representations; the unstructured visual noise did not contain such elements, and thus should not interfere as much with such stored representations. Participants did in fact make more errors in both tasks with sequences of structured visual masks. Various controls converged in demonstrating that in both tasks participants used representations that depicted the shapes of the letters. These findings not only constrain theories of visual mental imagery and visual working memory, but also have direct implications for why some studies have failed to find that dynamic visual noise interferes with visual working memory.},
author = {Borst, Gregoire and Ganis, Giorgio and Thompson, William L and Kosslyn, Stephen M},
doi = {10.3758/s13421-011-0143-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Borst et al/Borst et al. - 2012 - Representations in mental imagery and working memory evidence from different types of visual masks. - Memory \& cog.pdf:pdf},
issn = {1532-5946},
journal = {Memory \& cognition},
keywords = {Adult,Auditory Perception,Auditory Perception: physiology,Female,Humans,Imagination,Imagination: classification,Imagination: physiology,Male,Memory, Short-Term,Memory, Short-Term: classification,Memory, Short-Term: physiology,Neuropsychological Tests,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = feb,
number = {2},
pages = {204--17},
pmid = {21948349},
title = {{Representations in mental imagery and working memory: evidence from different types of visual masks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21948349},
volume = {40},
year = {2012}
}
@article{Mei2008,
author = {Mei, Tao and Yang, Bo and Yang, Shi-Qiang and Hua, Xian-Sheng},
doi = {10.1007/s00371-008-0282-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mei et al/Mei et al. - 2008 - Video collage presenting a video sequence using a single image - The Visual Computer.pdf:pdf},
issn = {0178-2789},
journal = {The Visual Computer},
keywords = {energy minimization,video,video collage},
month = aug,
number = {1},
pages = {39--51},
title = {{Video collage: presenting a video sequence using a single image}},
url = {http://link.springer.com/10.1007/s00371-008-0282-4},
volume = {25},
year = {2008}
}
@article{A2007,
author = {Serre, T and Kreiman, Gabriel and Kouh, Minjoon and Cadieu, Charles},
doi = {10.1016/S0079-6123(06)65004-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Serre et al/Serre et al. - 2007 - A quantitative theory of immediate visual recognition - Progress in brain.pdf:pdf},
journal = {Progress in brain},
keywords = {feedforward,hierarchical models,ventral stream,visual object recognition},
pages = {33--56},
title = {{A quantitative theory of immediate visual recognition}},
url = {http://www.sciencedirect.com/science/article/pii/S0079612306650048},
volume = {165},
year = {2007}
}
@article{Franconeri2005a,
abstract = {The visual system relies on several heuristics to direct attention to important locations and objects. One of these mechanisms directs attention to sudden changes in the environment. Although a substantial body of research suggests that this capture of attention occurs only for the abrupt appearance of a new perceptual object, more recent evidence shows that some luminance-based transients (e.g., motion and looming) and some types of brightness change also capture attention. These findings show that new objects are not necessary for attention capture. The present study tested whether they are even sufficient. That is, does a new object attract attention because the visual system is sensitive to new objects or because it is sensitive to the transients that new objects create? In two experiments using a visual search task, new objects did not capture attention unless they created a strong local luminance transient.},
author = {Franconeri, Steven L and Hollingworth, Andrew and Simons, Daniel J},
doi = {10.1111/j.0956-7976.2005.01528.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Franconeri, Hollingworth, Simons/Franconeri, Hollingworth, Simons - 2005 - Do new objects capture attention - Psychological science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science},
keywords = {Attention,Depth Perception,Discrimination Learning,Habituation, Psychophysiologic,Humans,Light,Orientation,Pattern Recognition, Visual,Perceptual Masking,Psychomotor Performance,Reaction Time,Reference Values,Size Perception},
month = apr,
number = {4},
pages = {275--81},
pmid = {15828974},
title = {{Do new objects capture attention?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3163077\&tool=pmcentrez\&rendertype=abstract},
volume = {16},
year = {2005}
}
@article{Canny1986,
abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
author = {Canny, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Canny/Canny - 1986 - A computational approach to edge detection. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = jun,
number = {6},
pages = {679--98},
pmid = {21869365},
title = {{A computational approach to edge detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21869365},
volume = {8},
year = {1986}
}
@phdthesis{Milvich2004b,
author = {Milvich, Michael Lazar},
file = {::},
number = {July},
title = {{JavaCave: A 3D Immersive Environment in Java}},
year = {2004}
}
@article{Kirkby2008,
abstract = {The goal of this review is to evaluate the literature on binocular coordination during reading and non-reading tasks in adult, child, and dyslexic populations. The review begins with a description of the basic characteristics of eye movements during reading. Then, reading and non-reading studies investigating binocular coordination are evaluated. Areas of future research in the field are identified and discussed. Finally, some general conclusions are made regarding binocular coordination. The review demonstrates that findings from traditionally independent areas of research are largely consistent and complementary. Throughout the review, theoretical and methodological commonalities are identified and clarified in order to advance current understanding of this fundamental aspect of human visual processing.},
author = {Kirkby, Julie a and Webster, Lisa a D and Blythe, Hazel I and Liversedge, Simon P},
doi = {10.1037/a0012979},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kirkby et al/Kirkby et al. - 2008 - Binocular coordination during reading and non-reading tasks. - Psychological bulletin.pdf:pdf},
issn = {0033-2909},
journal = {Psychological bulletin},
keywords = {Adult,Child,Dyslexia,Dyslexia: physiopathology,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Humans,Photic Stimulation,Photic Stimulation: methods,Reading,Task Performance and Analysis,Vision, Binocular},
month = sep,
number = {5},
pages = {742--63},
pmid = {18729571},
title = {{Binocular coordination during reading and non-reading tasks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18729571},
volume = {134},
year = {2008}
}
@article{Itti2000,
abstract = {Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a saliency map, that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment. Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target. Inhibiting this location automatically allows the system to attend to the next most salient location. We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner. The model is applied to common psychophysical stimuli as well as to a very demanding visual search task. Its successful performance is used to address the extent to which the primate visual system carries out visual search via one or more such saliency maps and how this can be tested.},
author = {Itti, L and Koch, C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Koch/Itti, Koch - 2000 - A saliency-based search mechanism for overt and covert shifts of visual attention. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Female,Humans,Male,Middle Aged,Models, Neurological,Models, Psychological,Psychophysics,Visual Perception,Visual Perception: physiology},
month = jan,
number = {10-12},
pages = {1489--506},
pmid = {10788654},
title = {{A saliency-based search mechanism for overt and covert shifts of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10788654},
volume = {40},
year = {2000}
}
@article{Simons1998,
abstract = {Recent research on change detection has documented surprising failures to detect visual changes occurring between views of a scene, suggesting the possibility that visual representations contain few details. Although these studies convincingly demonstrate change blindness for objects in still images and motion pictures, they may not adequately assess the capacity to represent objects in the real world. Here we examine and reject the possibility that change blindness in previous studies resulted from passive viewing of 2-D displays. In one experiment, an experimenter initiated a conversation with a pedestrian,, and during the interaction, he was surreptitiously replaced by a different experimenter. Only half of the pedestrians detected the change. Furthermore, successful detection depended on social group membership; pedestrians from the same social group as the experimenters detected the change but those from a different social group did not. A second experiment further examined the importance of this effect of social group. Provided that the meaning of the scene is unchanged, changes to attended objects can escape detection even when they occur during a natural, real-world interaction. The discussion provides a set of guidelines and suggestions for future research on change blindness.},
author = {Simons, Daniel J and Levin, Daniel T},
doi = {10.3758/BF03208840},
issn = {10699384},
journal = {Psychonomic Bulletin \& Review},
number = {4},
pages = {644--649},
pmid = {1550},
publisher = {Springer},
title = {{Failure to detect changes to people during a real-world interaction}},
url = {http://www.springerlink.com/index/10.3758/BF03208840},
volume = {5},
year = {1998}
}
@article{Schmalstieg2007d,
author = {Schmalstieg, Dieter and Schall, Gerhard and Wagner, Daniel and Barakonyi, Istv\'{a}n and Reitmayr, Gerhard and Newman, Joseph and Ledermann, Florian},
file = {::},
journal = {IEEE computer graphics and applications},
keywords = {Algorithms,Artificial Intelligence,Computer Graphics,Database Management Systems,Databases, Factual,Ecosystem,Geographic Information Systems,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Theoretical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,User-Computer Interface},
number = {4},
pages = {48--57},
title = {{Managing complex augmented reality models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17713234},
volume = {27},
year = {2007}
}
@article{O'Regan2001,
abstract = {Many current neurophysiological, psychophysical, and psychological approaches to vision rest on the idea that when we see, the brain produces an internal representation of the world. The activation of this internal representation is assumed to give rise to the experience of seeing. The problem with this kind of approach is that it leaves unexplained how the existence of such a detailed internal representation might produce visual consciousness. An alternative proposal is made here. We propose that seeing is a way of acting. It is a particular way of exploring the environment. Activity in internal representations does not generate the experience of seeing. The outside world serves as its own, external, representation. The experience of seeing occurs when the organism masters what we call the governing laws of sensorimotor contingency. The advantage of this approach is that it provides a natural and principled way of accounting for visual consciousness, and for the differences in the perceived quality of sensory experience in the different sensory modalities. Several lines of empirical evidence are brought forward in support of the theory, in particular: evidence from experiments in sensorimotor adaptation, visual "filling in," visual stability despite eye movements, change blindness, sensory substitution, and color perception.},
author = {O'Regan, J K and No\"{e}, a},
file = {:Users/pkmital/Documents/Mendeley Desktop/O'Regan, No\"{e}/O'Regan, No\"{e} - 2001 - A sensorimotor account of vision and visual consciousness. - The Behavioral and brain sciences.pdf:pdf},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {Brain,Brain: physiology,Consciousness,Consciousness: physiology,Environment,Humans,Mental Processes,Vision, Ocular,Vision, Ocular: physiology},
month = oct,
number = {5},
pages = {939--73; discussion 973--1031},
pmid = {12239892},
title = {{A sensorimotor account of vision and visual consciousness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12239892},
volume = {24},
year = {2001}
}
@article{Dalal2005,
author = {Dalal, N. and Triggs, B.},
doi = {10.1109/CVPR.2005.177},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dalal, Triggs/Dalal, Triggs - 2005 - Histograms of Oriented Gradients for Human Detection - 2005 IEEE Computer Society Conference on Computer Vision a.pdf:pdf},
isbn = {0-7695-2372-2},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
pages = {886--893},
publisher = {Ieee},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467360},
volume = {1},
year = {2005}
}
@article{Salzmann2007,
abstract = {Three-dimensional detection and shape recovery of a nonrigid surface from video sequences require deformation models to effectively take advantage of potentially noisy image data. Here, we introduce an approach to creating such models for deformable 3D surfaces. We exploit the fact that the shape of an inextensible triangulated mesh can be parameterized in terms of a small subset of the angles between its facets. We use this set of angles to create a representative set of potential shapes, which we feed to a simple dimensionality reduction technique to produce low-dimensional 3D deformation models. We show that these models can be used to accurately model a wide range of deforming 3D surfaces from video sequences acquired under realistic conditions.},
author = {Salzmann, Mathieu and Pilet, Julien and Ilic, Slobodan and Fua, Pascal},
doi = {10.1109/TPAMI.2007.1080},
file = {:Users/pkmital/Documents/Mendeley Desktop/Salzmann et al/Salzmann et al. - 2007 - Surface deformation models for nonrigid 3D shape recovery. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = aug,
number = {8},
pages = {1481--7},
pmid = {17568151},
title = {{Surface deformation models for nonrigid 3D shape recovery.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17568151},
volume = {29},
year = {2007}
}
@article{Kimura2007c,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2007 - Universal coding for correlated sources over generalized - Communication.pdf:pdf},
journal = {Communication},
keywords = {complementary delivery,ing,lossless coding,methods of types,multiterminal source coding,universal cod-,vertex color-},
pages = {274--279},
title = {{Universal coding for correlated sources over generalized}},
year = {2007}
}
@article{Nakazato,
author = {Nakazato, M. and Huang, T.S.},
doi = {10.1109/ICME.2001.1237651},
file = {:Users/pkmital/Documents/Mendeley Desktop/Nakazato, Huang/Nakazato, Huang - Unknown - 3D MARS immersive virtual reality for content-based image retrieval - IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.pdf:pdf},
isbn = {0-7695-1198-8},
journal = {IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.},
keywords = {content-based image retrieval,in addition to this,information visualization,our system dynamically reorganizes,reality,relevance feedback,the visual-,virtual},
pages = {44--47},
publisher = {Ieee},
title = {{3D MARS: immersive virtual reality for content-based image retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1237651}
}
@inproceedings{Pfeiffer1997,
address = {Boston, MA},
author = {Pfeiffer, S and Fischer, S and Effelsberg, W},
booktitle = {Proc. Int. Multimedia Conf.},
pages = {21--30},
title = {{Automatic Audio Content Analysis}},
year = {1997}
}
@article{Hamker2005,
abstract = {Attention is known to play a key role in perception, including action selection, object recognition and memory. Despite findings revealing competitive interactions among cell populations, attention remains difficult to explain. The central purpose of this paper is to link up a large number of findings in a single computational approach. Our simulation results suggest that attention can be well explained on a network level involving many areas of the brain. We argue that attention is an emergent phenomenon that arises from reentry and competitive interactions. We hypothesize that guided visual search requires the usage of an object-specific template in prefrontal cortex to sensitize V4 and IT cells whose preferred stimuli match the target template. This induces a feature-specific bias and provides guidance for eye movements. Prior to an eye movement, a spatially organized reentry from occulomotor centers, specifically the movement cells of the frontal eye field, occurs and modulates the gain of V4 and IT cells. The processes involved are elucidated by quantitatively comparing the time course of simulated neural activity with experimental data. Using visual search tasks as an example, we provide clear and empirically testable predictions for the participation of IT, V4 and the frontal eye field in attention. Finally, we explain a possible physiological mechanism that can lead to non-flat search slopes as the result of a slow, parallel discrimination process.},
author = {Hamker, Fred H},
doi = {10.1093/cercor/bhh146},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hamker/Hamker - 2005 - The reentry hypothesis the putative interaction of the frontal eye field, ventrolateral prefrontal cortex, and areas V4,.pdf:pdf},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Algorithms,Attention,Attention: physiology,Computer Simulation,Cues,Discrimination (Psychology),Discrimination (Psychology): physiology,Eye Movements,Eye Movements: physiology,Memory,Memory: physiology,Neural Networks (Computer),Neurons,Neurons, Afferent,Neurons, Afferent: cytology,Neurons, Afferent: physiology,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Saccades,Saccades: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = apr,
number = {4},
pages = {431--47},
pmid = {15749987},
title = {{The reentry hypothesis: the putative interaction of the frontal eye field, ventrolateral prefrontal cortex, and areas V4, IT for attention and eye movement.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15749987},
volume = {15},
year = {2005}
}
@book{Leman2007,
author = {Leman, M},
booktitle = {Processing},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leman/Leman - 2007 - Embodied music cognition and mediation technology - Processing.pdf:pdf},
isbn = {9780262122931},
title = {{Embodied music cognition and mediation technology}},
url = {http://books.google.com/books?hl=en\&lr=\&id=s70oAeq3XYMC\&oi=fnd\&pg=PR11\&dq=Embodied+Music+Cognition+and+Mediation+Technology\&ots=gCq7ep2tm4\&sig=HfRKuD6hzZzO3rZ6NbLDs-c1kMY},
year = {2007}
}
@article{Wang2011,
author = {Wang, JC and Lee, HS and Wang, HM},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang, Lee, Wang/Wang, Lee, Wang - 2011 - Learning the Similarity of Audio Music in Bag-of-Frames Representation from Tagged Music Data - International Symposium on Music Information Retrieval.pdf:pdf},
journal = {International Symposium on Music Information Retrieval},
title = {{Learning the Similarity of Audio Music in Bag-of-Frames Representation from Tagged Music Data}},
url = {http://ismir2011.ismir.net/papers/PS1-8.pdf},
year = {2011}
}
@article{Zhang2011,
author = {Zhang, Song-Hai and Li, Xian-Ying and Hu, Shi-Min and Martin, Ralph R.},
doi = {10.1109/TMM.2011.2165052},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang et al/Zhang et al. - 2011 - Online Video Stream Abstraction and Stylization - IEEE Transactions on Multimedia.pdf:pdf},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
month = dec,
number = {6},
pages = {1286--1294},
title = {{Online Video Stream Abstraction and Stylization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5986719},
volume = {13},
year = {2011}
}
@article{Shamma2011,
abstract = {Humans and other animals can attend to one of multiple sounds and follow it selectively over time. The neural underpinnings of this perceptual feat remain mysterious. Some studies have concluded that sounds are heard as separate streams when they activate well-separated populations of central auditory neurons, and that this process is largely pre-attentive. Here, we argue instead that stream formation depends primarily on temporal coherence between responses that encode various features of a sound source. Furthermore, we postulate that only when attention is directed towards a particular feature (e.g. pitch) do all other temporally coherent features of that source (e.g. timbre and location) become bound together as a stream that is segregated from the incoherent features of other sources.},
author = {Shamma, Shihab a and Elhilali, Mounya and Micheyl, Christophe},
doi = {10.1016/j.tins.2010.11.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shamma, Elhilali, Micheyl/Shamma, Elhilali, Micheyl - 2011 - Temporal coherence and attention in auditory scene analysis. - Trends in neurosciences.pdf:pdf},
issn = {1878-108X},
journal = {Trends in neurosciences},
month = mar,
number = {3},
pages = {114--23},
pmid = {21196054},
publisher = {Elsevier Ltd},
title = {{Temporal coherence and attention in auditory scene analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3073558\&tool=pmcentrez\&rendertype=abstract},
volume = {34},
year = {2011}
}
@phdthesis{Bogart2008,
author = {Bogart, Benjamin},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bogart/Bogart - 2008 - Memory Association Machine An Account of the Realization and Interpretation of an Autonomous Responsive Site-Specific Ar.pdf:pdf},
title = {{Memory Association Machine: An Account of the Realization and Interpretation of an Autonomous Responsive Site-Specific Artwork}},
year = {2008}
}
@article{Gamble2011,
abstract = {Humans must often focus attention onto relevant sensory signals in the presence of simultaneous irrelevant signals. This type of attention has been explored in vision with the N2pc component, and the present study sought to find an analogous auditory effect. In Experiment 1, two 750-ms sounds were presented simultaneously, one from each of two lateral speakers. On each trial, participants indicated whether one of the two sounds was a pre-defined target. We found that targets elicited an N2ac component: a negativity in the N2 latency range at anterior contralateral electrodes. We also observed a later and more posterior contralateral positivity. Experiment 2 replicated these effects and demonstrated that they arose from competition between attended and unattended tones rather than reflecting lateralized effects of attention for individual tones. The N2ac component may provide a useful tool for studying selective attention within auditory scenes.},
author = {Gamble, Marissa L and Luck, Steven J},
doi = {10.1111/j.1469-8986.2010.01172.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gamble, Luck/Gamble, Luck - 2011 - N2ac an ERP component associated with the focusing of attention within an auditory scene. - Psychophysiology.pdf:pdf},
issn = {1540-5958},
journal = {Psychophysiology},
month = aug,
number = {8},
pages = {1057--68},
pmid = {21261633},
title = {{N2ac: an ERP component associated with the focusing of attention within an auditory scene.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21261633},
volume = {48},
year = {2011}
}
@inproceedings{Wang2005,
author = {Wang, Beiming and Plumbley, M.D.},
booktitle = {Proc. DMRN Summer Conf},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang, Plumbley/Wang, Plumbley - 2005 - Musical audio stream separation by non-negative matrix factorization - Proc. DMRN Summer Conf.pdf:pdf},
keywords = {automatic music transcription,blind source separation,non-negative ma-,trix factorization},
pages = {23--24},
title = {{Musical audio stream separation by non-negative matrix factorization}},
url = {http://www.elec.qmul.ac.uk/people/markp/2005/WangPlumbley05-dmrn.pdf},
year = {2005}
}
@book{Thiran2009,
author = {Thiran, JP and Bourlard, H},
booktitle = {Journal on Multimodal},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thiran, Bourlard/Thiran, Bourlard - 2009 - Multimodal Signal Processing Theory and applications for human-computer interaction - Journal on Multimodal.pdf:pdf},
isbn = {9780123744494},
title = {{Multimodal Signal Processing: Theory and applications for human-computer interaction}},
url = {http://www.springerlink.com/index/N3713702546V4712.pdf http://books.google.com/books?hl=en\&amp;lr=\&amp;id=mNSduMPXZy4C\&amp;oi=fnd\&amp;pg=PP1\&amp;dq=Multimodal+signal+processing+theory+and+applications+for+human-computer+interaction\&amp;ots=3LAPW4ID60\&amp;sig=lwTfG2CDO5\_JeT3AqcvbEKcAQXw},
year = {2009}
}
@article{Temko2007,
author = {Temko, Andrey and Malkin, Robert and Zieger, Christian and Macho, Dusan and Nadeu, Climent and Omologo, Maurizio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Temko et al/Temko et al. - 2007 - CLEAR evaluation of acoustic event detection and classification systems - Multimodal Technologies for Perception of Humans.pdf:pdf},
journal = {Multimodal Technologies for Perception of Humans},
pages = {311--322},
publisher = {Springer},
title = {{CLEAR evaluation of acoustic event detection and classification systems}},
url = {http://www.springerlink.com/index/x208wp120056207k.pdf},
year = {2007}
}
@article{Bains1992,
abstract = {Binocular measurements of instantaneous velocity vectors in normal human subjects during saccades showed: (1) considerable trial to trial variation in peak velocity, saccade duration, and saccade curvature despite saccade accuracy; (2) variations in one eye were mirrored by similar variations in the other eye, with a high positive correlation. The high correlation between the peak velocities suggest that saccades in the two eyes are driven by a common saccade generator. Assuming that a local feedback loop guides saccades, the high correlation between saccade durations and between saccade curvatures suggests that both eyes are guided by common feedback. If so, monocular adaptation must occur downstream from the saccade generator.},
author = {Bains, R a and Crawford, J D and Cadera, W and Vilis, T},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bains et al/Bains et al. - 1992 - The conjugacy of human saccadic eye movements. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Humans,Oculomotor Muscles,Oculomotor Muscles: innervation,Saccades,Saccades: physiology,Time Factors,Vision, Binocular,Vision, Binocular: physiology},
month = sep,
number = {9},
pages = {1677--84},
pmid = {1455739},
title = {{The conjugacy of human saccadic eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1455739},
volume = {32},
year = {1992}
}
@article{Ahissar2009,
abstract = {Revealing the relationships between perceptual representations in the brain and mechanisms of adult perceptual learning is of great importance, potentially leading to significantly improved training techniques both for improving skills in the general population and for ameliorating deficits in special populations. In this review, we summarize the essentials of reverse hierarchy theory for perceptual learning in the visual and auditory modalities and describe the theory's implications for designing improved training procedures, for a variety of goals and populations.},
author = {Ahissar, Merav and Nahum, Mor and Nelken, Israel and Hochstein, Shaul},
doi = {10.1098/rstb.2008.0253},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ahissar et al/Ahissar et al. - 2009 - Reverse hierarchies and sensory learning. - Philosophical transactions of the Royal Society of London. Series B, Biological sciences.pdf:pdf},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Humans,Learning,Learning: physiology,Models, Neurological,Psychophysics,Visual Perception,Visual Perception: physiology},
month = feb,
number = {1515},
pages = {285--99},
pmid = {18986968},
title = {{Reverse hierarchies and sensory learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2674477\&tool=pmcentrez\&rendertype=abstract},
volume = {364},
year = {2009}
}
@article{Henderson1990,
abstract = {Two experiments were conducted to examine the effects of foveal processing difficulty on the perceptual span in reading. Subjects read sentences while their eye movements were recorded. By changing the text contingent on the reader's current point of fixation, foveal processing difficulty and the availability of parafoveal word information were independently manipulated. In Experiment 1, foveal processing difficulty was manipulated by lexical frequency, and in Experiment 2 foveal difficulty was manipulated by syntactic complexity. In both experiments, less parafoveal information was acquired when processing in the fovea was difficult. We conclude that the perceptual span is variable and attentionally constrained. We also discuss the implications of the results for current models of the relation between covert visual-spatial attention and eye movement control in reading.},
author = {Henderson, J M and Ferreira, F},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Ferreira/Henderson, Ferreira - 1990 - Effects of foveal processing difficulty on the perceptual span in reading implications for attention and eye movement control. - Journal of experimental psychology. Learning, memory, and cognition.pdf:pdf},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Adult,Attention,Eye Movements,Fixation, Ocular,Humans,Mental Recall,Reading,Saccades,Semantics,Visual Fields},
month = may,
number = {3},
pages = {417--29},
pmid = {2140401},
title = {{Effects of foveal processing difficulty on the perceptual span in reading: implications for attention and eye movement control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2140401},
volume = {16},
year = {1990}
}
@article{Henderson1996,
abstract = {In 2 earlier sets of experiments, the author reported that shape discrimination in an otherwise empty visual field is facilitated when the target shape is preceded by a valid spatial precue (J. M. Henderson, 1991; J. M. Henderson \& A. D. Macquistan, 1993). L. Shiu and H. Pashler (1994) recently suggested that these earlier results were due to the presence of multiple posttarget pattern masks. They concluded that precue effects are observed only when visual noise is present. The author reviews the existing evidence and presents new data supporting the view that spatial precues influence shape discrimination in the absence of visual noise, consistent with a limited capacity conception of visual-spatial attention.},
author = {Henderson, J M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson/Henderson - 1996 - Spatial precues affect target discrimination in the absence of visual noise. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adult,Attention,Cues,Discrimination Learning,Female,Humans,Male,Mental Recall,Orientation,Pattern Recognition, Visual,Perceptual Masking,Psychophysics,Visual Fields},
month = jun,
number = {3},
pages = {780--7},
pmid = {8666963},
title = {{Spatial precues affect target discrimination in the absence of visual noise.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8666963},
volume = {22},
year = {1996}
}
@article{Tropp2004,
author = {Tropp, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tropp/Tropp - 2004 - Greed is good Algorithmic results for sparse approximation - IEEE Trans. Info. Theory.pdf:pdf},
journal = {IEEE Trans. Info. Theory},
number = {10},
pages = {2231--2242},
title = {{Greed is good: Algorithmic results for sparse approximation}},
volume = {50},
year = {2004}
}
@article{Vedaldi2012,
author = {Vedaldi, Andrea and Zisserman, A},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vedaldi, Zisserman/Vedaldi, Zisserman - 2012 - Sparse kernel approximations for efficient classification and detection - Computer Vision and Pattern \ldots.pdf:pdf},
journal = {Computer Vision and Pattern \ldots},
title = {{Sparse kernel approximations for efficient classification and detection}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6247943},
year = {2012}
}
@article{Effros2004,
author = {Effros, M. and Dugatkin, D.},
doi = {10.1109/TIT.2004.838381},
file = {:Users/pkmital/Documents/Mendeley Desktop/Effros, Dugatkin/Effros, Dugatkin - 2004 - Multiresolution Vector Quantization - IEEE Transactions on Information Theory.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = dec,
number = {12},
pages = {3130--3145},
title = {{Multiresolution Vector Quantization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1362902},
volume = {50},
year = {2004}
}
@inproceedings{Muja2009,
author = {Muja, Marius and Lowe, D.G.},
booktitle = {International Conference on Computer Vision Theory and Applications (VISAPP'09)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Muja, Lowe/Muja, Lowe - 2009 - Fast approximate nearest neighbors with automatic algorithm configuration - International Conference on Computer Vis.pdf:pdf},
publisher = {Citeseer},
title = {{Fast approximate nearest neighbors with automatic algorithm configuration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.160.1721\&amp;rep=rep1\&amp;type=pdf http://people.cs.ubc.ca/~lowe/papers/09muja.pdf},
volume = {340},
year = {2009}
}
@article{Bevilacqua2010,
author = {Bevilacqua, F. and Zamborlin, Bruno and Sypniewski, Anthony and Schnell, Norbert and Gu\'{e}dy, F. and Rasamimanana, Nicolas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bevilacqua et al/Bevilacqua et al. - 2010 - Continuous realtime gesture following and recognition - Gesture in Embodied Communication and Human-Computer Interaction.pdf:pdf},
journal = {Gesture in Embodied Communication and Human-Computer Interaction},
keywords = {gesture following,gesture recognition,hidden markov model,interactive systems,mu-,sic},
pages = {73--84},
publisher = {Springer},
title = {{Continuous realtime gesture following and recognition}},
url = {http://www.springerlink.com/index/V8PN885111256625.pdf},
year = {2010}
}
@article{Henderson2008a,
author = {Henderson, J. M. and Pierce, G. L.},
doi = {10.3758/PBR.15.3.566},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Pierce/Henderson, Pierce - 2008 - Eye movements during scene viewing Evidence for mixed control of fixation durations - Psychonomic Bulletin \& Review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin \& Review},
month = jun,
number = {3},
pages = {566--573},
title = {{Eye movements during scene viewing: Evidence for mixed control of fixation durations}},
url = {http://pbr.psychonomic-journals.org/cgi/doi/10.3758/PBR.15.3.566},
volume = {15},
year = {2008}
}
@article{Arnold2010a,
author = {Arnold, DH and Tear, Morgan and Schindel, Ryan},
doi = {10.1371/journal.pone.0010217},
file = {:Users/pkmital/Documents/Mendeley Desktop/Arnold, Tear, Schindel/Arnold, Tear, Schindel - 2010 - Audio-visual speech cue combination - PLoS One.pdf:pdf},
journal = {PLoS One},
number = {4},
title = {{Audio-visual speech cue combination}},
url = {http://dx.plos.org/10.1371/journal.pone.0010217},
volume = {5},
year = {2010}
}
@article{Mairal2012,
abstract = {Modeling data with linear combinations of a few elements from a learned dictionary has been the focus of much recent research in machine learning, neuroscience, and signal processing. For signals such as natural images that admit such sparse representations, it is now well established that these models are well suited to restoration tasks. In this context, learning the dictionary amounts to solving a large-scale matrix factorization problem, which can be done efficiently with classical optimization tools. The same approach has also been used for learning features from data for other purposes, e.g., image classification, but tuning the dictionary in a supervised way for these tasks has proven to be more difficult. In this paper, we present a general formulation for supervised dictionary learning adapted to a wide variety of tasks, and present an efficient algorithm for solving the corresponding optimization problem. Experiments on handwritten digit classification, digital art identification, nonlinear inverse image problems, and compressed sensing demonstrate that our approach is effective in large-scale settings, and is well suited to supervised and semi-supervised classification, as well as regression tasks for data that admit sparse representations.},
author = {Mairal, Julien and Bach, Francis and Ponce, Jean},
doi = {10.1109/TPAMI.2011.156},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mairal, Bach, Ponce/Mairal, Bach, Ponce - 2012 - Task-driven dictionary learning. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = apr,
number = {4},
pages = {791--804},
pmid = {21808090},
title = {{Task-driven dictionary learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21808090},
volume = {34},
year = {2012}
}
@misc{J2013,
author = {Oswald, John},
booktitle = {Personal website},
file = {:Users/pkmital/Documents/Mendeley Desktop/Oswald/Oswald - 2013 - Plunderphonics - Essay - Personal website.html:html},
title = {{Plunderphonics - Essay}},
url = {http://www.plunderphonics.com/xhtml/xplunder.html},
urldate = {31/07/13},
year = {2013}
}
@article{Tatler2006,
abstract = {We recorded over 90,000 saccades while observers viewed a diverse collection of natural images and measured low level visual features at fixation. The features that discriminated between where observers fixated and where they did not varied considerably with task, and the length of the preceding saccade. Short saccades (<8 degrees) are image feature dependent, long are less so. For free viewing, short saccades target high frequency information, long saccades are scale-invariant. When searching for luminance targets, saccades of all lengths are scale-invariant. We argue that models of saccade behaviour must account not only for task but also for saccade length and that long and short saccades are targeted differently.},
author = {Tatler, Benjamin W and Baddeley, Roland J and Vincent, Benjamin T},
doi = {10.1016/j.visres.2005.12.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Baddeley, Vincent/Tatler, Baddeley, Vincent - 2006 - The long and the short of it spatial statistics at fixation vary with saccade amplitude and task. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Middle Aged,Photic Stimulation,Photic Stimulation: methods,Saccades,Saccades: physiology,Time Factors,Visual Perception,Visual Perception: physiology},
month = jun,
number = {12},
pages = {1857--62},
pmid = {16469349},
title = {{The long and the short of it: spatial statistics at fixation vary with saccade amplitude and task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16469349},
volume = {46},
year = {2006}
}
@article{Boot2004,
abstract = {Previous research has indicated that saccade target selection during visual search is influenced by scanning history. Already inspected items are less likely to be chosen as saccade targets as long as the number intervening saccades is small. Here, we adapted Jacoby's (1991) process dissociation procedure to assess the role of intentional and automatic processes in saccade target selection. Results indicate a large automatic component biasing participants to move their eyes to unexamined locations. However, an intentional component allowed participants to both reinspect old items and aid their selection of new items. A second experiment examined inhibition of return (IOR) as a candidate for the observed automatic component. IOR was found for items that had been previously examined. It is concluded that both automatic and intentional memory traces are available to guide the eyes during search.},
author = {Boot, Walter R and McCarley, Jason S and Kramer, Arthur F and Peterson, Mathew S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Boot et al/Boot et al. - 2004 - Automatic and intentional memory processes in visual search. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Automatism,Humans,Intention,Memory,Visual Perception},
month = oct,
number = {5},
pages = {854--61},
pmid = {15732694},
title = {{Automatic and intentional memory processes in visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15732694},
volume = {11},
year = {2004}
}
@article{Kornhuber1972,
author = {Kornhuber, Hans H and Rlichen, V O R Willk},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kornhuber, Rlichen/Kornhuber, Rlichen - 1972 - BEREITSCHAFTSPOTENTIAL , POSITIVIERUNG SAKKADISCHEN - Unknown.pdf:pdf},
pages = {421--436},
title = {{BEREITSCHAFTSPOTENTIAL , POSITIVIERUNG SAKKADISCHEN}},
volume = {12},
year = {1972}
}
@article{Goldstein2007,
abstract = {Magnification around the most important point of a movie scene (center of interest-COI) might aid people with visual impairments that cause resolution loss. This will be effective only if most people look at the same place when watching a movie. We recorded the eye movements of 20 normally sighted subjects as each watched six movie clips, totaling 37.5 min. More than half of the time the distribution of subject gaze points fell within an area statistic that was less than 12\% of the movie scene. Male and older subjects were more likely to look in the same place than female and younger subjects, respectively. We conclude that the between-subject agreement is sufficient to make the approach practical.},
author = {Goldstein, Robert B and Woods, Russell L and Peli, Eli},
doi = {10.1016/j.compbiomed.2006.08.018},
file = {:Users/pkmital/Documents/Mendeley Desktop/Goldstein, Woods, Peli/Goldstein, Woods, Peli - 2007 - Where people look when watching movies do all viewers look at the same place - Computers in biology and.pdf:pdf},
issn = {0010-4825},
journal = {Computers in biology and medicine},
keywords = {Audiovisual Aids,Computers,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Motion Pictures as Topic,Vision, Low,Vision, Low: physiopathology,Visual Perception,Visual Perception: physiology},
month = jul,
number = {7},
pages = {957--64},
pmid = {17010963},
title = {{Where people look when watching movies: do all viewers look at the same place?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1945220\&tool=pmcentrez\&rendertype=abstract},
volume = {37},
year = {2007}
}
@article{Harris1988,
author = {Harris, C. and Stephens, M.},
doi = {10.5244/C.2.23},
file = {:Users/pkmital/Documents/Mendeley Desktop/Harris, Stephens/Harris, Stephens - 1988 - A Combined Corner and Edge Detector - Procedings of the Alvey Vision Conference 1988.pdf:pdf},
journal = {Procedings of the Alvey Vision Conference 1988},
pages = {23.1--23.6},
publisher = {Alvey Vision Club},
title = {{A Combined Corner and Edge Detector}},
url = {http://www.bmva.org/bmvc/1988/avc-88-023.html},
year = {1988}
}
@article{VanderBurg2010,
abstract = {A prevailing view is that audiovisual integration requires temporally coincident signals. However, a recent study failed to find any evidence for audiovisual integration in visual search even when using synchronized audiovisual events. An important question is what information is critical to observe audiovisual integration.},
author = {{Van der Burg}, Erik and Cass, John and Olivers, Christian N L and Theeuwes, Jan and Alais, David},
doi = {10.1371/journal.pone.0010664},
file = {:Users/pkmital/Documents/Mendeley Desktop/Van der Burg et al/Van der Burg et al. - 2010 - Efficient visual search from synchronized auditory signals requires transient audiovisual events. - PloS on.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Acoustic Stimulation,Adult,Auditory Perception,Female,Humans,Male,Sound Localization,Sound Localization: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = jan,
number = {5},
pages = {e10664},
pmid = {20498844},
title = {{Efficient visual search from synchronized auditory signals requires transient audiovisual events.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2871056\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2010}
}
@article{Scientific1986,
author = {Scientific, Elsevier and Ireland, Publishers},
file = {:Users/pkmital/Documents/Mendeley Desktop/Scientific, Ireland/Scientific, Ireland - 1986 - Short communication PRESACCADIC SPIKE POTENTIAL. RELATION TO EYE MOVEMENT DIRECTION - Unknown.pdf:pdf},
keywords = {10-40 msec prior to,amplitude which is recorded,becker et al,blinn 1955,horizontal saccadic eye movements,is a potential of,k e - eye,large,movement - direction,presaceadic s p i,sp,the onset of,the presaccadic spike potential},
pages = {3--6},
title = {{Short communication PRESACCADIC SPIKE POTENTIAL. RELATION TO EYE MOVEMENT DIRECTION}},
year = {1986}
}
@article{Becker2007,
abstract = {The authors investigated whether anomalous information in the periphery of a scene attracts saccades when the anomaly is not distinctive in its low-level visual properties. Subjects viewed color photographs for 8 s while their eye movements were monitored. Each subject saw 2 photographs of different scenes. One photograph was a control scene in which familiar objects appeared in their canonical form. In the other picture, objects were altered in a way that rendered them deviant without introducing any obvious changes in low-level visual saliency. In Experiment 1, these alterations involved rotating an object in an unnatural fashion (e.g., an inverted head on a portrait, a truck parked on its front end). In Experiment 2, colors were distributed over objects in a way that was either reasonable or anomalous (e.g., a green cup vs. a green hand). Subjects fixated the anomalous items earlier (both in time and in order of fixations) than the nondistorted objects, suggesting that violations of canonical form are detected peripherally and can affect the likelihood of fixating an item.},
author = {Becker, Mark W and Pashler, Harold and Lubin, Jeffrey},
doi = {10.1037/0096-1523.33.1.20},
file = {:Users/pkmital/Documents/Mendeley Desktop/Becker, Pashler, Lubin/Becker, Pashler, Lubin - 2007 - Object-intrinsic oddities draw early saccades. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Attention,Color Perception,Discrimination Learning,Fixation, Ocular,Humans,Orientation,Pattern Recognition, Visual,Psychophysics,Reaction Time,Saccades},
month = feb,
number = {1},
pages = {20--30},
pmid = {17311476},
title = {{Object-intrinsic oddities draw early saccades.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17311476},
volume = {33},
year = {2007}
}
@article{Rabinovich2007,
author = {Rabinovich, Andrew and Vedaldi, Andrea and Galleguillos, Carolina and Wiewiora, Eric and Belongie, Serge},
doi = {10.1109/ICCV.2007.4408986},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rabinovich et al/Rabinovich et al. - 2007 - Objects in Context - 2007 IEEE 11th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-1630-1},
journal = {2007 IEEE 11th International Conference on Computer Vision},
pages = {1--8},
publisher = {Ieee},
title = {{Objects in Context}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4408986},
year = {2007}
}
@article{Kimura2004c,
author = {Kimura, a. and Uyematsu, T.},
doi = {10.1109/TIT.2003.821968},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 2004 - Weak Variable-Length Slepian–Wolf Coding With Linked Encoders for Mixed Sources - IEEE Transactions on Information Theory.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = jan,
number = {1},
pages = {183--193},
title = {{Weak Variable-Length Slepian–Wolf Coding With Linked Encoders for Mixed Sources}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262627},
volume = {50},
year = {2004}
}
@article{Ratha1996,
author = {Ratha, NK and Karu, K and Chen, S and Jain, Anil K.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ratha et al/Ratha et al. - 1996 - A real-time matching system for large fingerprint databases - Pattern Analysis and Machine Intelligence, IEEE Transactions on.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {8},
title = {{A real-time matching system for large fingerprint databases}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=531800},
volume = {18},
year = {1996}
}
@article{Kimurah,
author = {Kimura, Akisato and Uyematsu, Tomohiko and Kuzuoka, Shigeaki},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Kuzuoka/Kimura, Uyematsu, Kuzuoka - Unknown - Universal coding for correlated sources over generalized complementary delivery networks • Universal coding problem for a class of - East.pdf:pdf},
journal = {East},
title = {{Universal coding for correlated sources over generalized complementary delivery networks • Universal coding problem for a class of}}
}
@inproceedings{Russell2007,
author = {Russell, B.C. and Torralba, Antonio and Liu, Ce and Fergus, Rob and Freeman, W.T.},
booktitle = {In NIPS},
file = {:Users/pkmital/Documents/Mendeley Desktop/Russell et al/Russell et al. - 2007 - Object recognition by scene alignment - In NIPS.pdf:pdf},
publisher = {Citeseer},
title = {{Object recognition by scene alignment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.7045},
year = {2007}
}
@article{Szeliski2003,
author = {Szeliski, RS and Salesin, D and Schdl, A},
file = {:Users/pkmital/Documents/Mendeley Desktop/Szeliski, Salesin, Schdl/Szeliski, Salesin, Schdl - 2003 - Video-based rendering - US Patent 6,636,220.pdf:pdf},
journal = {US Patent 6,636,220},
title = {{Video-based rendering}},
url = {http://www.google.com/patents?hl=en\&lr=\&vid=USPAT6636220\&id=aEIOAAAAEBAJ\&oi=fnd\&dq=video+based+rendering\&printsec=abstract},
year = {2003}
}
@article{Alho1994,
author = {Alho, K and Woods, DL and Algazi, A},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alho, Woods, Algazi/Alho, Woods, Algazi - 1994 - Processing of auditory stimuli during auditory and visual attention as revealed by event‐related potentia.pdf:pdf},
journal = {Psychophysiology},
pages = {469--479},
title = {{Processing of auditory stimuli during auditory and visual attention as revealed by event‐related potentials}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1469-8986.1994.tb01050.x/full},
volume = {31},
year = {1994}
}
@article{Micheyl2010,
address = {New York, NY},
author = {Micheyl, Christophe and Shamma, Shihab and Elhilali, Mounya and Oxenham, Andrew J},
doi = {10.1007/978-1-4419-5686-6},
editor = {Lopez-Poveda, Enrique A. and Palmer, Alan R. and Meddis, Ray},
file = {:Users/pkmital/Documents/Mendeley Desktop/Micheyl et al/Micheyl et al. - 2010 - The Neurophysiological Bases of Auditory Perception - Unknown.pdf:pdf},
isbn = {978-1-4419-5685-9},
keywords = {auditory scene analysis,performance measures,stream segregation,synchrony,timing},
pages = {489--496},
publisher = {Springer New York},
title = {{The Neurophysiological Bases of Auditory Perception}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-5686-6},
year = {2010}
}
@article{Henderson2009,
abstract = {We investigated whether the deployment of attention in scenes is better explained by visual salience or by cognitive relevance. In two experiments, participants searched for target objects in scene photographs. The objects appeared in semantically appropriate locations but were not visually salient within their scenes. Search was fast and efficient, with participants much more likely to look to the targets than to the salient regions. This difference was apparent from the first fixation and held regardless of whether participants were familiar with the visual form of the search targets. In the majority of trials, salient regions were not fixated. The critical effects were observed for all 24 participants across the two experiments. We outline a cognitive relevance framework to account for the control of attention and fixation in scenes.},
author = {Henderson, John M and Malcolm, George L and Schandl, Charles},
doi = {10.3758/PBR.16.5.850},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Malcolm, Schandl/Henderson, Malcolm, Schandl - 2009 - Searching in the dark cognitive relevance drives attention in real-world scenes. - Psychonomic bulletin \& review.pdf:pdf},
issn = {1531-5320},
journal = {Psychonomic bulletin \& review},
keywords = {Attention,Cognition,Fixation, Ocular,Form Perception,Humans,Visual Perception},
month = oct,
number = {5},
pages = {850--6},
pmid = {19815788},
title = {{Searching in the dark: cognitive relevance drives attention in real-world scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19815788},
volume = {16},
year = {2009}
}
@article{Fanelli2010,
author = {Fanelli, Gabriele and Gall, Juergen and Romsdorfer, Harald and Weise, Thibaut and Gool, Luc Van},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fanelli et al/Fanelli et al. - 2010 - Acquisition of a 3d audio-visual corpus of affective speech - BIWI Technical Report 270.pdf:pdf},
journal = {BIWI Technical Report 270},
title = {{Acquisition of a 3d audio-visual corpus of affective speech}},
url = {http://people.ee.ethz.ch/~gfanelli/pubs/eth270.pdf},
year = {2010}
}
@article{Davison2007,
abstract = {We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub MonoSLAM, is the ﬁrst successful application of the SLAM methodology from mobile robotics to the ‘pure vision’ domain of a single uncontrolled camera, achieving real-time but drift-free performance inaccessible to Structure from Motion approaches. The core of the approach is the on-line creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efﬁcient and robust algorithm which runs at 30Hz with standard PC and camera hardware. This work extends the range of robotic systems in which SLAM can be usefully applied, but also opens up new areas. We present applications of MonoSLAM to real-time 3D localization and mapping for a high-performance full-size humanoid robot, and live augmented reality with a hand-held camera.},
author = {Davison, Andrew J and Reid, Ian D and Molton, Nicholas D and Stasse, Olivier},
file = {:Users/pkmital/Documents/Mendeley Desktop/Davison et al/Davison et al. - 2007 - MonoSLAM Real-Time Single Camera SLAM - Pattern Analysis and Machine Intelligence.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence},
keywords = {I.2.10.a 3D/stereo scene analysis,I.2.9.a Autonomous vehicles,I.4.8.n Tracking,autonomous,scene analysis,slam,stereo,tracking},
mendeley-tags = {autonomous,scene analysis,slam,stereo,tracking},
pages = {1--24},
title = {{MonoSLAM : Real-Time Single Camera SLAM}},
year = {2007}
}
@article{Snyder2008,
abstract = {The authors examined the effect of preceding context on auditory stream segregation. Low tones (A), high tones (B), and silences (-) were presented in an ABA- pattern. Participants indicated whether they perceived 1 or 2 streams of tones. The A tone frequency was fixed, and the B tone was the same as the A tone or had 1 of 3 higher frequencies. Perception of 2 streams in the current trial increased with greater frequency separation between the A and B tones (Delta f). Larger Delta f in previous trials modified this pattern, causing less streaming in the current trial. This occurred even when listeners were asked to bias their perception toward hearing 1 stream or 2 streams. The effect of previous Delta f was not due to response bias because simply perceiving 2 streams in the previous trial did not cause less streaming in the current trial. Finally, the effect of previous ?f was diminished, though still present, when the silent duration between trials was increased to 5.76 s. The time course of this context effect on streaming implicates the involvement of auditory sensory memory or neural adaptation.},
author = {Snyder, Joel S and Carter, Olivia L and Lee, Suh-Kyung and Hannon, Erin E and Alain, Claude},
doi = {10.1037/0096-1523.34.4.1007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Snyder et al/Snyder et al. - 2008 - Effects of context on auditory stream segregation. - Journal of experimental psychology. Human perception and per.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Auditory Threshold: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Female,Humans,Male,Memory,Memory: physiology,Middle Aged,Models, Neurological,Perceptual Masking,Perceptual Masking: physiology,Pitch Discrimination,Pitch Discrimination: physiology,Psychoacoustics,Psychomotor Performance,Psychomotor Performance: physiology,Time Factors},
month = aug,
number = {4},
pages = {1007--16},
pmid = {18665741},
title = {{Effects of context on auditory stream segregation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18665741},
volume = {34},
year = {2008}
}
@article{Seitz2006,
abstract = {Numerous studies show that practice can result in performance improvements on low-level visual perceptual tasks [1-5]. However, such learning is characteristically difficult and slow, requiring many days of training [6-8]. Here, we show that a multisensory audiovisual training procedure facilitates visual learning and results in significantly faster learning than unisensory visual training. We trained one group of subjects with an audiovisual motion-detection task and a second group with a visual motion-detection task, and compared performance on trials containing only visual signals across ten days of training. Whereas observers in both groups showed improvements of visual sensitivity with training, subjects trained with multisensory stimuli showed significantly more learning both within and across training sessions. These benefits of multisensory training are particularly surprising given that the learning of visual motion stimuli is generally thought to be mediated by low-level visual brain areas [6, 9, 10]. Although crossmodal interactions are ubiquitous in human perceptual processing [11-13], the contribution of crossmodal information to perceptual learning has not been studied previously. Our results show that multisensory interactions can be exploited to yield more efficient learning of sensory information and suggest that multisensory training programs would be most effective for the acquisition of new skills.},
author = {Seitz, Aaron R and Kim, Robyn and Shams, Ladan},
doi = {10.1016/j.cub.2006.05.048},
file = {:Users/pkmital/Documents/Mendeley Desktop/Seitz, Kim, Shams/Seitz, Kim, Shams - 2006 - Sound facilitates visual learning. - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Acoustic Stimulation,Adult,Auditory Perception,Humans,Learning,Learning: physiology,Photic Stimulation,Sound,Visual Perception},
month = jul,
number = {14},
pages = {1422--7},
pmid = {16860741},
title = {{Sound facilitates visual learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16860741},
volume = {16},
year = {2006}
}
@article{Klein2007c,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces - 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality(3).pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@article{Feng2012,
abstract = {This paper is concerned with the task of automatically generating captions for images, which is important for many image-related applications. Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned and co-located with thematically related documents. Our model learns to create captions from a database of news articles, the pictures embedded in them, and their captions and consists of two stages. Content selection identifies what the image and accompanying article are about, whereas surface realization determines how to verbalize the chosen content. We approximate content selection with a probabilistic image annotation model that suggests keywords for an image. The model postulates that images and their textual descriptions are generated by a shared set of latent variables (topics), and is trained on a weakly-labeled dataset (which treats the captions and associated news articles as image labels). Inspired by recent work in summarization, we propose extractive and abstractive surface realization models. Experimental results show that it is viable to generate captions that are pertinent to the specific content of an image and its associated article, while permitting creativity in the description. Indeed, the output of our abstractive model compares favorably to hand-written captions and is often superior to extractive methods.},
author = {Feng, Yansong and Lapata, Mirella},
doi = {10.1109/TPAMI.2012.118},
file = {:Users/pkmital/Documents/Mendeley Desktop/Feng, Lapata/Feng, Lapata - 2012 - Automatic Caption Generation for News Images. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = may,
pmid = {22641700},
title = {{Automatic Caption Generation for News Images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22641700},
year = {2012}
}
@article{Isotalo2005,
abstract = {We have investigated the effects of mental set on predictive capabilities using a saccade square-wave tracking paradigm with ten normal subjects, comparing three amplitudes (10, 20, and 40 degrees ) and five inter-stimulus intervals (ISIs) (400, 500, 625, 1000, and 2000 ms). Subjects were instructed simply to "follow the lights" (passive, reflexive instruction) or explicitly "move your eyes in time with the lights" (active, volitional instruction). Saccades were defined as reflexive (latency>100 ms), predictive (-200 ms<latency<100 ms), or anticipatory (latency<-200 ms). We also calculated arrival time (saccade latency+saccade duration). Instructions had a striking effect on predictive performance. The effects were greatest with the longest ISIs (1000 and 2000 ms) and the largest target displacement (40 degrees ). With the active instruction there were more predictive and anticipatory saccades and with the passive instruction more reflexive saccades. Furthermore, with the active instruction subjects could take into account the duration of the impending saccade so that the eyes would arrive closer to the appearance of the target no matter what the amplitude of the required saccade. In sum, cognitive set, as determined by the specific instructions given to the subject, has a striking effect on predictive saccade behavior, which has important implications for interpreting physiological and imaging correlates of predictive behavior in normals and in patients with neurological disease.},
author = {Isotalo, E and Lasker, a G and Zee, D S},
doi = {10.1007/s00221-005-2317-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Isotalo, Lasker, Zee/Isotalo, Lasker, Zee - 2005 - Cognitive influences on predictive saccadic tracking. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adult,Cognition,Cognition: physiology,Data Interpretation, Statistical,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Saccades,Saccades: physiology},
month = sep,
number = {4},
pages = {461--9},
pmid = {16025290},
title = {{Cognitive influences on predictive saccadic tracking.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16025290},
volume = {165},
year = {2005}
}
@misc{Neuromancer1984,
author = {Neuromancer, William Gibson},
booktitle = {City},
publisher = {Ace},
title = {{William Gibson - Neuromancer}},
url = {http://www.amazon.com/dp/B00327KDIC},
year = {1984}
}
@article{DiCarlo2012a,
abstract = {Mounting evidence suggests that 'core object recognition,' the ability to rapidly recognize objects despite substantial appearance variation, is solved in the brain via a cascade of reflexive, largely feedforward computations that culminate in a powerful neuronal representation in the inferior temporal cortex. However, the algorithm that produces this solution remains poorly understood. Here we review evidence ranging from individual neurons and neuronal populations to behavior and computational models. We propose that understanding this algorithm will require using neuronal and psychophysical data to sift through many computational models, each based on building blocks of small, canonical subnetworks with a common functional goal.},
author = {DiCarlo, James J and Zoccolan, Davide and Rust, Nicole C},
doi = {10.1016/j.neuron.2012.01.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/DiCarlo, Zoccolan, Rust/DiCarlo, Zoccolan, Rust - 2012 - How does the brain solve visual object recognition - Neuron(2).pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Attention,Attention: physiology,Brain,Brain: cytology,Brain: physiology,Cognition,Cognition: physiology,Humans,Models, Neurological,Neurons,Neurons: physiology,Pattern Recognition, Visual,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology},
month = feb,
number = {3},
pages = {415--34},
pmid = {22325196},
publisher = {Elsevier Inc.},
title = {{How does the brain solve visual object recognition?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3306444\&tool=pmcentrez\&rendertype=abstract},
volume = {73},
year = {2012}
}
@article{Nister,
author = {Nister, D. and Stewenius, H.},
doi = {10.1109/CVPR.2006.264},
file = {:Users/pkmital/Documents/Mendeley Desktop/Nister, Stewenius/Nister, Stewenius - Unknown - Scalable Recognition with a Vocabulary Tree - 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06).pdf:pdf},
isbn = {0-7695-2597-0},
journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06)},
pages = {2161--2168},
publisher = {Ieee},
title = {{Scalable Recognition with a Vocabulary Tree}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1641018}
}
@article{Oliva1997,
author = {Oliva, Aude and Schyns, Philippe G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Oliva, Schyns/Oliva, Schyns - 1997 - Coarse blobs or fine edges Evidence that information diagnosticity changes the perception of complex visual stimuli - Cognitive psychology.pdf:pdf},
journal = {Cognitive psychology},
pages = {72--107},
title = {{Coarse blobs or fine edges? Evidence that information diagnosticity changes the perception of complex visual stimuli}},
url = {http://cogprints.org/707},
volume = {107},
year = {1997}
}
@article{Irwin1996,
author = {Irwin, David E.},
doi = {10.1111/1467-8721.ep10772833},
file = {:Users/pkmital/Documents/Mendeley Desktop/Irwin/Irwin - 1996 - Integrating Information Across Saccadic Eye Movements. - Current Directions in Psychological Science.pdf:pdf},
issn = {0963-7214},
journal = {Current Directions in Psychological Science},
month = jun,
number = {3},
pages = {94--100},
title = {{Integrating Information Across Saccadic Eye Movements.}},
url = {http://cdp.sagepub.com/lookup/doi/10.1111/1467-8721.ep10772833},
volume = {5},
year = {1996}
}
@article{Pinker2003,
author = {Pinker, Steven and Ullman, Michael T.},
doi = {10.1016/S1364-6613(03)00021-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pinker, Ullman/Pinker, Ullman - 2003 - Beyond one model per phenomenon - Trends in Cognitive Sciences.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = mar,
number = {3},
pages = {108--109},
title = {{Beyond one model per phenomenon}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661303000214},
volume = {7},
year = {2003}
}
@article{Kimura2006d,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2006 - Information-theoretical analysis of index searching Revised - Search.pdf:pdf},
journal = {Search},
keywords = {cascading,feedback,index searching,multiterminal source coding,rate-distortion theory},
title = {{Information-theoretical analysis of index searching : Revised}},
year = {2006}
}
@article{Pfeiffer1996,
address = {New York, New York, USA},
author = {Pfeiffer, Silvia and Fischer, Stephan and Effelsberg, Wolfgang},
journal = {Proceedings of the fourth ACM international conference on Multimedia - MULTIMEDIA '96},
pages = {21--30},
publisher = {ACM Press},
title = {{Automatic audio content analysis}},
url = {http://portal.acm.org/citation.cfm?doid=244130.244139},
year = {1996}
}
@inproceedings{Kahrs2001,
author = {Kahrs, M. and Avanzini, F.},
booktitle = {Proc. COST G6 Conf. on Digital Audio Effects (Limerick, Ireland, December 2001},
file = {::},
pages = {23--7},
publisher = {Citeseer},
title = {{Computer Synthesis of Bird Songs and Calls}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.3169\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Steinicke2008a,
author = {Steinicke, Frank and Bruder, Gerd and Ropinski, Timo and Hinrichs, Klaus},
file = {::},
journal = {Proceedings of IEEE VRIC 2008 : 10th International Conference on Virtual Reality},
title = {{Moving Towards Generally Applicable Redirected Walking}},
url = {http://viscg.uni-muenster.de/publications/2008/SBRH08/},
year = {2008}
}
@article{Thorpe2001,
abstract = {It is generally believed that the acuity of the peripheral visual field is too poor to allow accurate object recognition and, that to be identified, most objects need to be brought into foveal vision by using saccadic eye movements. However, most measures of form vision in the periphery have been done at eccentricities below 10 degrees and have used relatively artificial stimuli such as letters, digits and compound Gabor patterns. Little is known about how such data would apply in the case of more naturalistic stimuli. Here humans were required to categorize briefly flashed (28 ms) unmasked photographs of natural scenes (39 degrees high, and 26 degrees across) on the basis of whether or not they contained an animal. The photographs appeared randomly in nine locations across virtually the entire extent of the horizontal visual field. Accuracy was 93.3\% for central vision and decreased almost linearly with increasing eccentricity (89.8\% at 13 degrees, 76.1\% at 44.5 degrees and 71.2\% at 57.5 degrees ). Even at the most extreme eccentricity, where the images were centred at 70.5 degrees, subjects scored 60.5\% correct. No evidence was found for hemispheric specialization. This level of performance was achieved despite the fact that the position of the image was unpredictable, ruling out the use of precued attention to target locations. The results demonstrate that even high-level visual tasks involving object vision can be performed using the relatively coarse information provided by the peripheral retina.},
author = {Thorpe, S J and Gegenfurtner, K R and Fabre-Thorpe, M and B\"{u}lthoff, H H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thorpe et al/Thorpe et al. - 2001 - Detection of animals in natural images using far peripheral vision. - The European journal of neuroscience.pdf:pdf},
issn = {0953-816X},
journal = {The European journal of neuroscience},
keywords = {Adult,Animals,Female,Form Perception,Form Perception: physiology,Humans,Male,Photic Stimulation,Photic Stimulation: methods,Retina,Retina: physiology,Visual Fields,Visual Fields: physiology},
month = sep,
number = {5},
pages = {869--76},
pmid = {11576191},
title = {{Detection of animals in natural images using far peripheral vision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11576191},
volume = {14},
year = {2001}
}
@inproceedings{Jacob1995,
author = {Jacob, B.L.},
booktitle = {Proceedings of the 1995 International Computer Music Conference},
file = {::},
number = {September},
pages = {452--455},
publisher = {Citeseer},
title = {{Composing with genetic algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.4011\&amp;rep=rep1\&amp;type=pdf},
year = {1995}
}
@article{Fernandez2006,
abstract = {An achromatizing lens has been designed for the human eye in the near infrared range, from 700 to 900 nm, for retinal imaging purposes. Analysis of the performance of the lens, including tolerance to misalignments, has been mathematically accomplished by using an existing eye model. The calculations have shown a virtually perfect correction of the ocular longitudinal chromatic aberration, while still keeping a high optical quality. Ocular aberrations in five subjects have been measured with and without the achromatizing lens by using a Hartmann-Shack wavefront sensor and a broad bandwidth femtosecond Ti:sapphire laser in the spectral range of interest with a set of interference filters, studying the benefits and limits in the use of the achromatizing lens. Ocular longitudinal chromatic aberration has been experimentally demonstrated to be fully corrected by the proposed lens, with no induction of any other parasitic aberration. The practical implementation of the achromatizing lens for Ophthalmoscopy, specifically for optical coherence tomography where the use of polychromatic light sources in the near infrared portion of the spectrum is mandatory, has been considered. The potential benefits of using this lens in combination with adaptive optics to achieve a full aberration correction of the human eye for retinal imaging have also been discussed.},
author = {Fern\'{a}ndez, Enrique J and Unterhuber, Angelika and Povazay, Boris and Hermann, Boris and Artal, Pablo and Drexler, Woflgang},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fern\'{a}ndez et al/Fern\'{a}ndez et al. - 2006 - Chromatic aberration correction of the human eye for retinal imaging in the near infrared. - Optics express.pdf:pdf},
issn = {1094-4087},
journal = {Optics express},
month = jun,
number = {13},
pages = {6213--25},
pmid = {19516794},
title = {{Chromatic aberration correction of the human eye for retinal imaging in the near infrared.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19516794},
volume = {14},
year = {2006}
}
@article{Hayhoe1998,
abstract = {This paper examines the nature of visual representations that direct ongoing performance in sensorimotor tasks. Performance of such natural tasks requires relating visual information from different gaze positions. To explore this we used the technique of making task relevant display changes during saccadic eye movements. Subjects copied a pattern of colored blocks on a computer monitor, using the mouse to drag the blocks across the screen. Eye position was monitored using a dual-purkinje eye tracker, and the color of blocks in the pattern was changed at different points in task performance. When the target of the saccade changed color during the saccade, the duration of fixations on the model pattern increased, depending on the point in the task that the change was made. Thus different fixations on the same visual stimulus served a different purpose. The results also indicated that the visual information that is retained across successive fixations depends on moment by moment task demands. This is consistent with previous suggestions that visual representations are limited and task dependent. Changes in blocks in addition to the saccade target led to greater increases in fixation duration. This indicated that some global aspect of the pattern was retained across different fixations. Fixation durations revealed effects of the display changes that were not revealed in perceptual report. This can be understood by distinguishing between processes that operate at different levels of description and different time scales. Our conscious experience of the world may reflect events over a longer time scale than those underlying the substructure of the perceptuo-motor machinery.},
author = {Hayhoe, M M and Bensinger, D G and Ballard, D H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hayhoe, Bensinger, Ballard/Hayhoe, Bensinger, Ballard - 1998 - Task constraints in visual working memory. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Color Perception,Fixation, Ocular,Humans,Memory,Memory: physiology,Saccades,Time Factors},
month = jan,
number = {1},
pages = {125--37},
pmid = {9474383},
title = {{Task constraints in visual working memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9474383},
volume = {38},
year = {1998}
}
@inproceedings{SmaragdisRajShashanka,
author = {Smaragdis, Paris and Raj, Bhiksha and Shashanka, Madhusudana},
booktitle = {In Workshop on Advances in Models for Acoustic Processing at NIPS},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Raj, Shashanka/Smaragdis, Raj, Shashanka - 2006 - A Probabilistic Latent Variable Model for Acoustic Modeling - In Workshop on Advances in Models for Acoustic Processing at NIPS.pdf:pdf},
number = {1},
title = {{A Probabilistic Latent Variable Model for Acoustic Modeling}},
year = {2006}
}
@article{Lagendijk,
author = {Lagendijk, R L and Biemond, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lagendijk, Biemond/Lagendijk, Biemond - Unknown - SPATIO-TEMPORAL MODEL OF HUMAN VISION FOR DIGITAL VIDEO COMPRESSION - Unknown.pdf:pdf},
title = {{SPATIO-TEMPORAL MODEL OF HUMAN VISION FOR DIGITAL VIDEO COMPRESSION}}
}
@article{Snyder2012,
abstract = {Auditory perception and cognition entails both low-level and high-level processes, which are likely to interact with each other to create our rich conscious experience of soundscapes. Recent research that we review has revealed numerous influences of high-level factors, such as attention, intention, and prior experience, on conscious auditory perception. And recently, studies have shown that auditory scene analysis tasks can exhibit multistability in a manner very similar to ambiguous visual stimuli, presenting a unique opportunity to study neural correlates of auditory awareness and the extent to which mechanisms of perception are shared across sensory modalities. Research has also led to a growing number of techniques through which auditory perception can be manipulated and even completely suppressed. Such findings have important consequences for our understanding of the mechanisms of perception and also should allow scientists to precisely distinguish the influences of different higher-level influences.},
author = {Snyder, Joel S and Gregg, Melissa K and Weintraub, David M and Alain, Claude},
doi = {10.3389/fpsyg.2012.00015},
file = {:Users/pkmital/Documents/Mendeley Desktop/Snyder et al/Snyder et al. - 2012 - Attention, awareness, and the perception of auditory scenes. - Frontiers in psychology.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {attentional,auditory scene analysis,auditory scene analysis, multistability, change de,change deafness,informational masking,multistability,priming},
month = jan,
number = {February},
pages = {15},
pmid = {22347201},
title = {{Attention, awareness, and the perception of auditory scenes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3273855\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@inproceedings{Grill2012,
author = {Grill, Thomas and Flexer, Arthur},
booktitle = {Proceedings of the International Computer Music Conference},
file = {:Users/pkmital/Documents/Mendeley Desktop/Grill, Flexer/Grill, Flexer - 2012 - Visualization of perceptual qualities in textural sounds - Proceedings of the International Computer Music Confer.pdf:pdf},
title = {{Visualization of perceptual qualities in textural sounds}},
url = {http://grrrr.org/pub/grill-2012-icmc.pdf},
year = {2012}
}
@article{Camargo2009,
author = {Camargo, Jorge and Gonz\'{a}lez, Fabio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Camargo, Gonz\'{a}lez/Camargo, Gonz\'{a}lez - 2009 - Visualization, Summarization and Exploration of Large Collections of Images State Of The Art - Latin America.pdf:pdf},
journal = {Latin American Conference On Networked and Electronic Media (LACNEM)},
pages = {1--9},
title = {{Visualization, Summarization and Exploration of Large Collections of Images: State Of The Art}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.8288\&rep=rep1\&type=pdf},
year = {2009}
}
@book{Kesey1963,
author = {Kesey, Ken},
isbn = {0451163966},
publisher = {Signet},
title = {{One Flew Over the Cuckoo's Nest}},
url = {http://www.amazon.com/One-Flew-Over-Cuckoos-Nest/dp/0451163966},
year = {1963}
}
@article{Franconeri2005,
abstract = {We recently demonstrated that, contrary to previous findings, some types of irrelevant motion are capable of capturing our attention (Franconeri \& Simons, 2003). Strikingly, whereas sitmulated looming (a dynamic increase in object size) captured attention, simulated receding (a decrease in object size) did not. Abrams and Christ (2003, 2005) have provided a different interpretation of this evidence, arguing that in each case attention was captured by the onset of motion rather than by motion per se. They argued that the only published finding inconsistent with their motion onset account is our evidence that simulated receding motion failed to capture attention. Abrams and Christ (2005) presented a receding object stereoscopically and found that it did capture attention, leading them to conclude that the motion onset account explains existing data more parsimoniously than our account does. Our reply has three parts. First, we argue that evidence of capture by receding motion is interesting but irrelevant to the debate over whether capture by motion requires a motion onset. Second, we show that the original empirical evidence in support of the motion onset claim (Abrams \& Christ, 2003) put the motion-only condition at a critical disadvantage. We present a new experiment that demonstrates strong capture by motion in the absence of a motion onset, showing that motion onsets are not necessary for attention capture by dynamic events. Finally, we outline what is known about the set of dynamic events that capture attention.},
author = {Franconeri, Steven L and Simons, Daniel J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Franconeri, Simons/Franconeri, Simons - 2005 - The dynamic events that capture visual attention A reply to Abrams and Christ (2005). - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Humans,Visual Perception},
month = aug,
number = {6},
pages = {962--6},
pmid = {16396005},
title = {{The dynamic events that capture visual attention: A reply to Abrams and Christ (2005).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16396005},
volume = {67},
year = {2005}
}
@article{Overgaard2011,
abstract = {In a recent paper, Brogaard (2011) presents counter-arguments to the conclusions of an experiment with blindsight subject GR. She argues that contrary to the apparent findings that GR's preserved visual abilities relate to degraded visual experiences, she is in fact fully unconscious of the stimuli she correctly identifies. In this paper, we present arguments and evidence why Brogaard's argument does not succeed in its purpose. We suggest that not only is relevant empirical evidence in opposition to Brogaard's argument, her argument misconstrues necessary criteria to decide whether a conscious experience is visual or not visual.},
author = {Overgaard, Morten and Gr\"{u}nbaum, Thor},
doi = {10.1016/j.concog.2011.08.016},
file = {:Users/pkmital/Documents/Mendeley Desktop/Overgaard, Gr\"{u}nbaum/Overgaard, Gr\"{u}nbaum - 2011 - Consciousness and modality on the possible preserved visual consciousness in blindsight subjects. - Consci.pdf:pdf},
issn = {1090-2376},
journal = {Consciousness and cognition},
keywords = {Humans,Unconsciousness,Unconsciousness: physiopathology,Visual Perception},
month = dec,
number = {4},
pages = {1855--9},
pmid = {21930399},
publisher = {Elsevier Inc.},
title = {{Consciousness and modality: on the possible preserved visual consciousness in blindsight subjects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21930399},
volume = {20},
year = {2011}
}
@article{DeSanctis2008,
abstract = {Segregation of auditory inputs into meaningful acoustic groups is a key element of auditory scene analysis. Previously, we showed that two interwoven sets of tones differing widely along multiple feature dimensions (duration, pitch and location) were pre-attentively separated into different groups, and that tones separated in this manner did not elicit the mismatch negativity component with respect to each other. Grouping was studied with human subjects using a stimulus rate too slow to induce streaming. Here, we varied the separation of tone sequences along a single feature dimension, i.e. frequency. Frequency differences were either 24 Hz (small) or 1054 Hz (large). Two relatively slow stimulus rates were used (2.7 or 1 tone/s) to explicitly investigate grouping outside the so-called 'streaming effect', which requires rates of about 4 tones/s or faster. Two tones were presented in a quasi-random manner with embedded trains of one to four identical tones in a row. Deviants were defined as frequency switches after trains of four identical tones. Mismatch negativity was only elicited for small frequency switches at the slower stimulation rate. The data indicate that pre-attentive grouping of tones occurred when the frequency difference that separated them was large, regardless of stimulation rate. For small frequency differences, inputs were only grouped separately when the stimulation rate was relatively fast.},
author = {{De Sanctis}, Pierfilippo and Ritter, Walter and Molholm, Sophie and Kelly, Simon P and Foxe, John J},
doi = {10.1111/j.1460-9568.2008.06080.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/De Sanctis et al/De Sanctis et al. - 2008 - Auditory scene analysis the interaction of stimulation rate and frequency separation on pre-attentive groupin.pdf:pdf},
issn = {1460-9568},
journal = {The European journal of neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male},
month = mar,
number = {5},
pages = {1271--6},
pmid = {18364041},
title = {{Auditory scene analysis: the interaction of stimulation rate and frequency separation on pre-attentive grouping.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3073558\&tool=pmcentrez\&rendertype=abstract},
volume = {27},
year = {2008}
}
@article{Kimura2009a,
author = {Kimura, Akisato and Uyematsu, Tomohiko and Kuzuoka, Shigeaki and Watanabe, Shun},
doi = {10.1109/TIT.2008.2011438},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - 2009 - Universal Source Coding Over Generalized Complementary Delivery Networks - IEEE Transactions on Information Theory.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = mar,
number = {3},
pages = {1360--1373},
title = {{Universal Source Coding Over Generalized Complementary Delivery Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4787593},
volume = {55},
year = {2009}
}
@misc{Ltd,
author = {Ltd., N3krozoft},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ltd/Ltd. - 2013 - WALTER RUTTMANN - Unknown.html:html},
title = {{// WALTER RUTTMANN}},
url = {http://www.n3krozoft.com/\_xxbcf67373.TMP/doc/ruttman.html},
urldate = {27/08/13},
year = {2013}
}
@article{Apter1969,
author = {Apter, MJ},
file = {:Users/pkmital/Documents/Mendeley Desktop/Apter/Apter - 1969 - Cybernetics and art - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {3},
pages = {257--265},
title = {{Cybernetics and art}},
url = {http://www.jstor.org/stable/10.2307/1572155},
volume = {2},
year = {1969}
}
@article{Darrell2000,
author = {Darrell, Trevor and Fisher, J. and Viola, Paul},
file = {:Users/pkmital/Documents/Mendeley Desktop/Darrell, Fisher, Viola/Darrell, Fisher, Viola - 2000 - Audio-visual Segmentation and “The Cocktail Party Effect” - Advances in Multimodal Interfaces—ICMI 2000.pdf:pdf},
journal = {Advances in Multimodal Interfaces—ICMI 2000},
pages = {32--40},
publisher = {Springer},
title = {{Audio-visual Segmentation and “The Cocktail Party Effect”}},
url = {http://www.springerlink.com/index/6t3plfy64na6hmrj.pdf},
year = {2000}
}
@article{Li,
author = {Li, Bing and Xiong, W and Hu, W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Li, Xiong, Hu/Li, Xiong, Hu - 2012 - Visual Saliency Map from Tensor Analysis - Twenty-Sixth AAAI Conference on Artificial \ldots.pdf:pdf},
journal = {Twenty-Sixth AAAI Conference on Artificial \ldots},
keywords = {Multidisciplinary Topics (Main Track)},
number = {1},
pages = {1585--1591},
title = {{Visual Saliency Map from Tensor Analysis}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewFile/4864/5305},
year = {2012}
}
@article{Hooge2000,
abstract = {Tasks such as reading or visual search consist of series of saccades. We have investigated to what extent saccades that are made within a series of self-paced movements are influenced by preceding movements. The present paper concerns an analysis of the duration of the fixations preceding saccades. We tested human subjects in a paradigm where they had to fixate two to four targets in a fixed order as fast as they could. We found that fixations before so-called 'return saccades' (saccades returning to the previously fixated position) are considerably longer (up to 40\%) than other fixations. This phenomenon, which we call 'Inhibition of Saccade Return' (ISR), is present when return and regular saccades are mixed in one trial, and seems to be reset after each saccade. ISR is strongest at the previously fixated target, and decreases gradually from there. The radius of the area where ISR is found is about 4 degrees. The relation between ISR and 'Inhibition of Return' of spatial attention [Posner \& Cohen, 1984] is discussed, as well as the neurophysiological basis of ISR.},
author = {Hooge, I T and Frens, M a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hooge, Frens/Hooge, Frens - 2000 - Inhibition of saccade return (ISR) spatio-temporal properties of saccade programming. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Male,Neural Inhibition,Neural Inhibition: physiology,Psychophysics,Saccades,Saccades: physiology,Time Factors},
month = jan,
number = {24},
pages = {3415--26},
pmid = {11058738},
title = {{Inhibition of saccade return (ISR): spatio-temporal properties of saccade programming.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11058738},
volume = {40},
year = {2000}
}
@article{Raghuvanshi2007,
abstract = {Simulating the complete process of sound synthesis and propagation by exploiting aural perception makes the experience of playing games much more realistic and immersive.},
author = {Raghuvanshi, Nikunj and Lauterbach, Christian and Chandak, Anish and Manocha, Dinesh and Lin, Ming C},
doi = {10.1145/1272516.1272541},
issn = {00010782},
journal = {Communications of the ACM},
number = {7},
pages = {66--73},
publisher = {ACM},
title = {{Real-time sound synthesis and propagation for games}},
url = {http://portal.acm.org/citation.cfm?id=1272516.1272541},
volume = {50},
year = {2007}
}
@article{Gao2009,
author = {Gao, Jizhou and Hu, Yin and Liu, Jinze and Yang, Ruigang},
doi = {10.1109/ICCV.2009.5459465},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gao et al/Gao et al. - 2009 - Unsupervised learning of high-order structural semantics from images - 2009 IEEE 12th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {2122--2129},
publisher = {Ieee},
title = {{Unsupervised learning of high-order structural semantics from images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459465},
year = {2009}
}
@article{Klein1999,
author = {Klein, Raymond M and Macinnes, W Joseph},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Macinnes/Klein, Macinnes - 1999 - Research Article INHIBITION OF RETURN IS A FORAGING FACILITATOR IN VISUAL SEARCH - Psychological Science.pdf:pdf},
journal = {Psychological Science},
pages = {346--352},
title = {{Research Article INHIBITION OF RETURN IS A FORAGING FACILITATOR IN VISUAL SEARCH}},
year = {1999}
}
@article{Hibbard2007,
author = {Hibbard, Paul},
doi = {10.1080/13506280600648018},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hibbard/Hibbard - 2007 - A statistical model of binocular disparity - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
number = {2},
pages = {149--165},
title = {{A statistical model of binocular disparity}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280600648018\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {15},
year = {2007}
}
@article{Mairal2010,
author = {Mairal, Julien and Bach, Francis and Ponce, J and Sapiro, Guillermo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mairal et al/Mairal et al. - 2010 - Online learning for matrix factorization and sparse coding - The Journal of Machine Learning \ldots.pdf:pdf},
journal = {The Journal of Machine Learning \ldots},
keywords = {basis pursuit,dictionary learning,ing,matrix factorization,negative matrix factorization,non-,online learning,sparse cod-,sparse principal component analysis,stochastic approximations,stochastic optimization},
pages = {19--60},
title = {{Online learning for matrix factorization and sparse coding}},
url = {http://dl.acm.org/citation.cfm?id=1756008},
volume = {11},
year = {2010}
}
@article{Hutchison1973,
author = {Hutchison, David and Mitchell, John C and Forsyth, David and Torr, Philip},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hutchison et al/Hutchison et al. - 1973 - Computer Vision – ECCV 2008 10th European Conference on Computer Vision - New York(2).pdf:pdf},
journal = {New York},
title = {{Computer Vision – ECCV 2008 10th European Conference on Computer Vision}},
year = {1973}
}
@article{Liu,
author = {Liu, Qian},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu/Liu - Unknown - TUIO, Touchlib, reacTIVision and Community Core Vision - mat.ucsb.edu.pdf:pdf},
journal = {mat.ucsb.edu},
keywords = {community core vision,multi-touch,reactivision,touchlib,tuio},
title = {{TUIO, Touchlib, reacTIVision and Community Core Vision}},
url = {http://mat.ucsb.edu/~ryan/200C\_site/Qian/QianLiu\_200C\_TUIO.pdf}
}
@misc{OswaldInterviews,
author = {Oswald, John},
booktitle = {Personal website},
file = {:Users/pkmital/Documents/Mendeley Desktop/Oswald/Oswald - 2013 - Plunderphonics Interviews - Personal website.html:html},
title = {{Plunderphonics: Interviews}},
url = {http://www.plunderphonics.com/xhtml/xinterviews.html},
urldate = {31/07/13},
year = {2013}
}
@article{Peck2013,
address = {New York, New York, USA},
author = {Peck, Evan M M. and Yuksel, Beste F. and Ottley, Alvitta and Jacob, Robert J.K. and Chang, Remco},
doi = {10.1145/2470654.2470723},
file = {:Users/pkmital/Documents/Mendeley Desktop/Peck et al/Peck et al. - 2013 - Using fNIRS brain sensing to evaluate information visualization interfaces - Proceedings of the SIGCHI Conference o.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
pages = {473},
publisher = {ACM Press},
title = {{Using fNIRS brain sensing to evaluate information visualization interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2470723},
year = {2013}
}
@article{Kalinli2009,
author = {Kalinli, Ozlem and Sundaram, Shiva and Narayanan, Shrikanth},
doi = {10.1109/MMSP.2009.5293267},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kalinli, Sundaram, Narayanan/Kalinli, Sundaram, Narayanan - 2009 - Saliency-driven unstructured acoustic scene classification using latent perceptual indexing - 2(2).pdf:pdf},
isbn = {978-1-4244-4463-2},
journal = {2009 IEEE International Workshop on Multimedia Signal Processing},
month = oct,
pages = {1--6},
publisher = {Ieee},
title = {{Saliency-driven unstructured acoustic scene classification using latent perceptual indexing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5293267},
year = {2009}
}
@article{Lloyd2011,
author = {Lloyd, D Brandon and Raghuvanshi, Nikunj and Govindaraju, Naga K.},
journal = {ACM},
keywords = {interactive audio,sound synthesis},
pages = {55--62},
title = {{Sound Synthesis for Impact Sounds in Video Games}},
year = {2011}
}
@article{Filimowicz2010a,
author = {Filimowicz, M. and Stockholm, J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Filimowicz, Stockholm/Filimowicz, Stockholm - 2010 - Towards a phenomenology of the acoustic image - Organised Sound.pdf:pdf},
issn = {1469-8153},
journal = {Organised Sound},
number = {01},
pages = {5--12},
publisher = {Cambridge Univ Press},
title = {{Towards a phenomenology of the acoustic image}},
url = {http://journals.cambridge.org/abstract\_S1355771809990215},
volume = {15},
year = {2010}
}
@article{Brockmann2000,
author = {Brockmann, D},
doi = {10.1016/S0925-2312(00)00227-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmann/Brockmann - 2000 - The ecology of gaze shifts - Neurocomputing.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {gaze shift,h vy,ight,le,saccade,vision,visual salience},
month = jun,
number = {1-4},
pages = {643--650},
title = {{The ecology of gaze shifts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231200002277},
volume = {32-33},
year = {2000}
}
@book{DanielleOSteen2007,
author = {{Danielle O'Steen} and O'Steen, Danielle},
publisher = {ART+AUCTION},
title = {{Artist Dossier: Joseph Cornell}},
url = {http://www.artinfo.com/news/story/24307/artist-dossier-joseph-cornell/},
year = {2007}
}
@article{Klin2002a,
abstract = {Genetic and neurofunctional research in autism has highlighted the need for improved characterization of the core social disorder defining the broad spectrum of syndrome manifestations.},
author = {Klin, Ami and Jones, Warren and Schultz, Robert and Volkmar, Fred and Cohen, Donald},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klin et al/Klin et al. - 2002 - Defining and quantifying the social phenotype in autism. - The American journal of psychiatry.pdf:pdf},
issn = {0002-953X},
journal = {The American journal of psychiatry},
keywords = {Adult,Autistic Disorder,Autistic Disorder: diagnosis,Autistic Disorder: genetics,Cues,Eye Movements,Eye Movements: genetics,Eye Movements: physiology,Eye Movements: radiation effects,Female,Fixation, Ocular,Fixation, Ocular: genetics,Fixation, Ocular: physiology,Forecasting,Humans,Interpersonal Relations,Male,Motion Pictures as Topic,Neurosciences,Neurosciences: methods,Neurosciences: trends,Nonverbal Communication,Phenotype,Research Design,Research Design: trends,Social Behavior Disorders,Social Behavior Disorders: diagnosis,Social Behavior Disorders: genetics,Social Perception,Visual Perception,Visual Perception: genetics,Visual Perception: physiology},
month = jun,
number = {6},
pages = {895--908},
pmid = {12042174},
title = {{Defining and quantifying the social phenotype in autism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12042174},
volume = {159},
year = {2002}
}
@inproceedings{Menziesa,
address = {Graz},
author = {Menzies, Dylan},
booktitle = {Ambisonics Symposium 2009},
file = {::},
title = {{HRTFs from Point Source Representations}}
}
@book{Fuller2005,
author = {Fuller, M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fuller/Fuller - 2005 - Media ecologies Materialist energies in art and technoculture - Unknown.pdf:pdf},
isbn = {026206247X},
publisher = {The MIT Press},
title = {{Media ecologies: Materialist energies in art and technoculture}},
url = {http://books.google.com/books?hl=en\&lr=\&id=1FLIHNPucroC\&oi=fnd\&pg=PT10\&dq=Media+Ecologies:+Materialist+Energies+in+Art+and+Technoculture\&ots=081zoyqJDS\&sig=wvgvgvmY0PvMxii2qty8fHtrly4},
year = {2005}
}
@article{Roma2010,
author = {Roma, Gerard and Janer, Jordi and Kersten, Stefan and Schirosa, Mattia and Herrera, Perfecto and Serra, Xavier},
issn = {1687-4714},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
pages = {1--11},
title = {{Ecological Acoustics Perspective for Content-Based Retrieval of Environmental Sounds}},
url = {http://www.hindawi.com/journals/asmp/2010/960863.html},
volume = {2010},
year = {2010}
}
@article{Harold2004,
author = {Harold, Christine},
doi = {10.1080/0739318042000212693},
file = {:Users/pkmital/Documents/Mendeley Desktop/Harold/Harold - 2004 - Pranking rhetoric “culture jamming” as media activism - Critical Studies in Media Communication.pdf:pdf},
issn = {1529-5036},
journal = {Critical Studies in Media Communication},
month = sep,
number = {3},
pages = {189--211},
title = {{Pranking rhetoric: “culture jamming” as media activism}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0739318042000212693},
volume = {21},
year = {2004}
}
@article{Barreiro2010,
author = {Barreiro, Daniel L.},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = apr,
number = {01},
pages = {35--42},
title = {{Sonic Image and Acousmatic Listening}},
url = {http://journals.cambridge.org/abstract\_S1355771809990240},
volume = {15},
year = {2010}
}
@article{Kaya2012,
author = {Kaya, Emine Merve and Elhilali, Mounya},
doi = {10.1109/CISS.2012.6310945},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kaya, Elhilali/Kaya, Elhilali - 2012 - A temporal saliency map for modeling auditory attention - 2012 46th Annual Conference on Information Sciences an.pdf:pdf},
isbn = {978-1-4673-3140-1},
journal = {2012 46th Annual Conference on Information Sciences and Systems (CISS)},
month = mar,
pages = {1--6},
publisher = {Ieee},
title = {{A temporal saliency map for modeling auditory attention}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6310945},
year = {2012}
}
@inproceedings{Schwarz2000,
abstract = {In speech synthesis, concatenative data-driven synthesis methods
prevail. They use a database of recorded speech and a unit selection
algorithm that selects the segments that match best the utterance
to be synthesized. Transferring these ideas to musical sound
synthesis allows a new method of high quality sound synthesis.
Usual synthesis methods are based on a model of the sound signal.
It is very difficult to build a model that would preserve the entire
fine details of sound. Concatenative synthesis achieves this by using
actual recordings. This data-driven approach (as opposed to a
rule-based approach) takes advantage of the information contained
in the many sound recordings. For example, very naturally sounding
transitions can be synthesized, since unit selection is aware
of the context of the database units. The CATERPILLAR software
system has been developed to allow data-driven concatenative unit
selection sound synthesis. It allows high-quality instrument synthesis
with high level control, explorative free synthesis from arbitrary
sound databases, or resynthesis of a recording with sounds
from the database. It is based on the new software-engineering
concept of component-oriented software, increasing flexibility and
facilitating reuse.},
address = {Verona, Italy},
author = {Schwarz, D},
booktitle = {Proc. COST G-6 Conf. on Digital Audio Effects},
keywords = {CSS},
title = {{A System for Data-Driven Concatenative Sound Synthesis}},
year = {2000}
}
@article{Vacchetti,
author = {Vacchetti, L. and Lepetit, V. and Fua, P.},
doi = {10.1109/ISMAR.2004.24},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vacchetti, Lepetit, Fua/Vacchetti, Lepetit, Fua - Unknown - Combining Edge and Texture Information for Real-Time Accurate 3D Camera Tracking - Third IEEE and ACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {0-7695-2191-6},
journal = {Third IEEE and ACM International Symposium on Mixed and Augmented Reality},
pages = {48--57},
publisher = {Ieee},
title = {{Combining Edge and Texture Information for Real-Time Accurate 3D Camera Tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1383042}
}
@article{Niebles2008,
author = {Niebles, J.C. and Wang, Hongcheng and Fei-Fei, L.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Niebles, Wang, Fei-Fei/Niebles, Wang, Fei-Fei - 2008 - Unsupervised learning of human action categories using spatial-temporal words - International Journal of Computer Vision.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
number = {3},
pages = {299--318},
publisher = {Springer},
title = {{Unsupervised learning of human action categories using spatial-temporal words}},
url = {http://www.springerlink.com/index/b456l4x7ktrk7073.pdf},
volume = {79},
year = {2008}
}
@inproceedings{Gooch2002,
author = {Gooch, Bruce and Coombe, Greg and Shirley, Peter},
booktitle = {NPAR '02 Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gooch, Coombe, Shirley/Gooch, Coombe, Shirley - 2002 - Artistic vision painterly rendering using computer vision techniques - NPAR '02 Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering.pdf:pdf},
keywords = {image moments,image processing,medial axis,non-,painting,photorealistic rendering},
pages = {83},
title = {{Artistic vision: painterly rendering using computer vision techniques}},
url = {http://dl.acm.org/citation.cfm?id=508545},
year = {2002}
}
@article{Leo2010,
author = {Leo, Justin and Loong, Cheang and Subari, Khazaimatol S and Abdullah, Muhammad Kamil and Ahmad, Nurul Nadia},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leo et al/Leo et al. - 2010 - Comparison of MFCC and Cepstral Coefficients as a Feature Set for PCG Biometric Systems - Engineering and Technology.pdf:pdf},
journal = {Engineering and Technology},
keywords = {biometric,cepstral coefficients,phonocardiogram},
pages = {754--758},
title = {{Comparison of MFCC and Cepstral Coefficients as a Feature Set for PCG Biometric Systems}},
year = {2010}
}
@article{Behrens1992,
abstract = {An algorithm is described to discriminate automatically between saccades and slow eye movements. Sampled data of the eye position have been used to calculate the momentary acceleration of the eye. The higher acceleration values of the saccadic eye movements as opposed to the slow compensatory or pursuit eye movements served to differentiate between the two. The method is demonstrated by search-coil data in squirrel monkeys.},
author = {Behrens, F and Weiss, L R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Behrens, Weiss/Behrens, Weiss - 1992 - An algorithm separating saccadic from nonsaccadic eye movements automatically by use of the acceleration signal. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Algorithms,Animals,Eye Movements,Eye Movements: physiology,Nystagmus, Physiologic,Nystagmus, Physiologic: physiology,Pursuit, Smooth,Pursuit, Smooth: physiology,Saccades,Saccades: physiology,Saimiri,Time Factors},
month = may,
number = {5},
pages = {889--93},
pmid = {1604857},
title = {{An algorithm separating saccadic from nonsaccadic eye movements automatically by use of the acceleration signal.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1604857},
volume = {32},
year = {1992}
}
@book{Navas2012,
author = {Navas, Eduardo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Navas/Navas - 2012 - Remix theory the aesthetics of sampling - Unknown.pdf:pdf},
isbn = {9783709112625},
publisher = {Springer-Verlag/Wien},
title = {{Remix theory: the aesthetics of sampling}},
url = {http://www.lavoisier.fr/livre/notice.asp?id=2LOW6RAR3X3OWF},
year = {2012}
}
@article{Bello2011,
author = {Bello, Juan P.},
doi = {10.1109/TASL.2011.2108287},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bello/Bello - 2011 - Measuring Structural Similarity in Music - IEEE Transactions on Audio, Speech, and Language Processing.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
month = sep,
number = {7},
pages = {2013--2025},
title = {{Measuring Structural Similarity in Music}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5711645},
volume = {19},
year = {2011}
}
@article{Cox2011,
author = {Cox, C.},
doi = {10.1177/1470412911402880},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cox/Cox - 2011 - Beyond Representation and Signification Toward a Sonic Materialism - Journal of Visual Culture.pdf:pdf},
issn = {1470-4129},
journal = {Journal of Visual Culture},
month = aug,
number = {2},
pages = {145--161},
title = {{Beyond Representation and Signification: Toward a Sonic Materialism}},
url = {http://vcu.sagepub.com/cgi/doi/10.1177/1470412911402880},
volume = {10},
year = {2011}
}
@article{Sivic2005,
author = {Sivic, J. and Russell, B.C. and a.a. Efros and Zisserman, a. and Freeman, W.T.},
doi = {10.1109/ICCV.2005.77},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sivic et al/Sivic et al. - 2005 - Discovering objects and their location in images - Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1.pdf:pdf},
isbn = {0-7695-2334-X},
journal = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
pages = {370--377 Vol. 1},
publisher = {Ieee},
title = {{Discovering objects and their location in images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1541280},
year = {2005}
}
@article{Wolfe2011,
abstract = {How efficient is visual search in real scenes? In searches for targets among arrays of randomly placed distractors, efficiency is often indexed by the slope of the reaction time (RT) × Set Size function. However, it may be impossible to define set size for real scenes. As an approximation, we hand-labeled 100 indoor scenes and used the number of labeled regions as a surrogate for set size. In Experiment 1, observers searched for named objects (a chair, bowl, etc.). With set size defined as the number of labeled regions, search was very efficient (\~{}5 ms/item). When we controlled for a possible guessing strategy in Experiment 2, slopes increased somewhat (\~{}15 ms/item), but they were much shallower than search for a random object among other distinctive objects outside of a scene setting (Exp. 3: \~{}40 ms/item). In Experiments 4-6, observers searched repeatedly through the same scene for different objects. Increased familiarity with scenes had modest effects on RTs, while repetition of target items had large effects (>500 ms). We propose that visual search in scenes is efficient because scene-specific forms of attentional guidance can eliminate most regions from the "functional set size" of items that could possibly be the target.},
author = {Wolfe, Jeremy M and Alvarez, George a and Rosenholtz, Ruth and Kuzmova, Yoana I and Sherman, Ashley M},
doi = {10.3758/s13414-011-0153-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wolfe et al/Wolfe et al. - 2011 - Visual search for arbitrary objects in real scenes. - Attention, perception \& psychophysics.pdf:pdf},
issn = {1943-393X},
journal = {Attention, perception \& psychophysics},
keywords = {Attention,Color Perception,Cues,Discrimination (Psychology),Field Dependence-Independence,Humans,Orientation,Pattern Recognition, Visual,Reaction Time},
month = aug,
number = {6},
pages = {1650--71},
pmid = {21671156},
title = {{Visual search for arbitrary objects in real scenes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3153571\&tool=pmcentrez\&rendertype=abstract},
volume = {73},
year = {2011}
}
@article{Magas2008,
author = {Magas, Michela and Casey, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Magas, Casey/Magas, Casey - 2008 - mHashup fast visual music discovery via locality sensitive hashing - ACM SIGGRAPH 2008 new tech.pdf:pdf},
journal = {ACM SIGGRAPH 2008 new tech},
pages = {2008},
title = {{mHashup: fast visual music discovery via locality sensitive hashing}},
url = {http://dl.acm.org/citation.cfm?id=1401615.1401641},
year = {2008}
}
@article{Jaramillo2011,
abstract = {When events occur at predictable instants, anticipation improves performance. Knowledge of event timing modulates motor circuits and thereby improves response speed. By contrast, the neuronal mechanisms that underlie changes in sensory perception resulting from expectation are not well understood. We developed a behavioral procedure for rats in which we manipulated expectations about sound timing. Valid expectations improved both the speed and the accuracy of the subjects' performance, indicating not only improved motor preparedness but also enhanced perception. Single-neuron recordings in primary auditory cortex showed enhanced representation of sounds during periods of heightened expectation. Furthermore, we found that activity in auditory cortex was causally linked to the performance of the task and that changes in the neuronal representation of sounds predicted performance on a trial-by-trial basis. Our results indicate that changes in neuronal representation as early as primary sensory cortex mediate the perceptual advantage conferred by temporal expectation.},
author = {Jaramillo, Santiago and Zador, Anthony M},
doi = {10.1038/nn.2688},
file = {:Users/pkmital/Documents/Mendeley Desktop/Jaramillo, Zador/Jaramillo, Zador - 2011 - The auditory cortex mediates the perceptual effects of acoustic temporal expectation. - Nature neuroscience.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Acoustic Stimulation,Animals,Auditory Cortex,Auditory Cortex: drug effects,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: drug effects,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: drug effects,Auditory Perception: physiology,Choice Behavior,Choice Behavior: drug effects,Choice Behavior: physiology,Discrimination (Psychology),Discrimination (Psychology): drug effects,Discrimination (Psychology): physiology,Electrophysiology,GABA-A Receptor Agonists,GABA-A Receptor Agonists: pharmacology,Muscimol,Muscimol: pharmacology,Neurons,Neurons: drug effects,Neurons: physiology,Rats,Reaction Time,Reaction Time: drug effects,Reaction Time: physiology,Time Factors,Time Perception,Time Perception: drug effects,Time Perception: physiology},
month = feb,
number = {2},
pages = {246--51},
pmid = {21170056},
publisher = {Nature Publishing Group},
title = {{The auditory cortex mediates the perceptual effects of acoustic temporal expectation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3152437\&tool=pmcentrez\&rendertype=abstract},
volume = {14},
year = {2011}
}
@article{Bischof2007,
author = {Bischof, W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bischof/Bischof - 2007 - Why do we look at people's eyes - Journal of Eye Movement Research.pdf:pdf},
journal = {Journal of Eye Movement Research},
number = {1},
pages = {1e6},
title = {{Why do we look at people's eyes}},
url = {http://web.mac.com/alan.kingstone/Site/Publications\_files/birmingham.07.pdf},
volume = {1},
year = {2007}
}
@article{Sturm2009b,
author = {Sturm, B L and Roads, C and McLeran, A and Shynk, J J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm et al/Sturm et al. - 2009 - Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods - J. New Music Researc.pdf:pdf},
journal = {J. New Music Research},
number = {4},
pages = {325--341},
title = {{Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods}},
volume = {38},
year = {2009}
}
@article{Langlotz2011a,
abstract = {A common goal of outdoor augmented reality (AR) is the presentation of annotations that are registered to anchor points in the real world. We present an enhanced approach for registering and tracking such anchor points, which is suitable for current generation mobile phones and can also successfully deal with the wide variety of viewing conditions encountered in real life outdoor use. The approach is based on on-the-fly generation of panoramic images by sweeping the camera over the scene. The panoramas are then used for stable orientation tracking, while the user is performing only rotational movements. This basic approach is improved by several new techniques for the re-detection and tracking of anchor points. For the re-detection, specifically after temporal variations, we first compute a panoramic image with extended dynamic range, which can better represent varying illumination conditions. The panorama is then searched for known anchor points, while orientation tracking continues uninterrupted. We then use information from an internal orientation sensor to prime an active search scheme for the anchor points, which improves matching results. Finally, global consistency is enhanced by statistical estimation of a global rotation that minimizes the overall position error of anchor points when transforming them from the source panorama in which they were created, to the current view represented by a new panorama. Once the anchor points are redetected, we track the user's movement using a novel 3-degree-of-freedom orientation tracking approach that combines vision tracking with the absolute orientation from inertial and magnetic sensors. We tested our system using an AR campus guide as an example application and provide detailed results for our approach using an off-the-shelf smartphone. Results show that the re-detection rate is improved by a factor of 2 compared to previous work and reaches almost 90\% for a wide variety of test cases while still keeping the ability to run at interactive frame rates.},
author = {Langlotz, Tobias and Degendorfer, Claus and Mulloni, Alessandro and Schall, Gerhard and Reitmayr, Gerhard and Schmalstieg, Dieter},
doi = {10.1016/j.cag.2011.04.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Langlotz et al/Langlotz et al. - 2011 - Robust detection and tracking of annotations for outdoor augmented reality browsing. - Computers \& graphics.pdf:pdf},
issn = {0097-8493},
journal = {Computers \& graphics},
keywords = {annotation,augmented reality,be found at the,com,elsevier,home page of nima,homepacs,homepage,htm,http,left column,mobile phone,pacs,sak,the pacs codes can,tracking,under contents services,www1},
month = aug,
number = {4},
pages = {831--840},
pmid = {21976781},
title = {{Robust detection and tracking of annotations for outdoor augmented reality browsing.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3149669\&tool=pmcentrez\&rendertype=abstract},
volume = {35},
year = {2011}
}
@article{Mill2013,
abstract = {Many sound sources can only be recognised from the pattern of sounds they emit, and not from the individual sound events that make up their emission sequences. Auditory scene analysis addresses the difficult task of interpreting the sound world in terms of an unknown number of discrete sound sources (causes) with possibly overlapping signals, and therefore of associating each event with the appropriate source. There are potentially many different ways in which incoming events can be assigned to different causes, which means that the auditory system has to choose between them. This problem has been studied for many years using the auditory streaming paradigm, and recently it has become apparent that instead of making one fixed perceptual decision, given sufficient time, auditory perception switches back and forth between the alternatives-a phenomenon known as perceptual bi- or multi-stability. We propose a new model of auditory scene analysis at the core of which is a process that seeks to discover predictable patterns in the ongoing sound sequence. Representations of predictable fragments are created on the fly, and are maintained, strengthened or weakened on the basis of their predictive success, and conflict with other representations. Auditory perceptual organisation emerges spontaneously from the nature of the competition between these representations. We present detailed comparisons between the model simulations and data from an auditory streaming experiment, and show that the model accounts for many important findings, including: the emergence of, and switching between, alternative organisations; the influence of stimulus parameters on perceptual dominance, switching rate and perceptual phase durations; and the build-up of auditory streaming. The principal contribution of the model is to show that a two-stage process of pattern discovery and competition between incompatible patterns can account for both the contents (perceptual organisations) and the dynamics of human perception in auditory streaming.},
author = {Mill, Robert W and Bőhm, Tam\'{a}s M and Bendixen, Alexandra and Winkler, Istv\'{a}n and Denham, Susan L},
doi = {10.1371/journal.pcbi.1002925},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mill et al/Mill et al. - 2013 - Modelling the emergence and dynamics of perceptual organisation in auditory streaming. - PLoS computational biology.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
month = jan,
number = {3},
pages = {e1002925},
pmid = {23516340},
title = {{Modelling the emergence and dynamics of perceptual organisation in auditory streaming.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3597549\&tool=pmcentrez\&rendertype=abstract},
volume = {9},
year = {2013}
}
@article{Rensink2002,
abstract = {Five aspects of visual change detection are reviewed. The first concerns the concept of change itself, in particular the ways it differs from the related notions of motion and difference. The second involves the various methodological approaches that have been developed to study change detection; it is shown that under a variety of conditions observers are often unable to see large changes directly in their field of view. Next, it is argued that this "change blindness" indicates that focused attention is needed to detect change, and that this can help map out the nature of visual attention. The fourth aspect concerns how these results affect our understanding of visual perception-for example, the implication that a sparse, dynamic representation underlies much of our visual experience. Finally, a brief discussion is presented concerning the limits to our current understanding of change detection.},
author = {Rensink, RA},
doi = {10.1146/annurev.psych.53.100901.135125},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rensink/Rensink - 2002 - Change detection - Annual review of psychology.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Attention,Attention: physiology,Eye Movements,Eye Movements: physiology,Humans,Memory,Memory: physiology,Motion,Psychological,Psychological Theory,Signal Detection,Visual Perception,Visual Perception: physiology},
month = jan,
pages = {245--77},
pmid = {11752486},
title = {{Change detection}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508591 http://www.annualreviews.org/doi/pdf/10.1146/annurev.psych.53.100901.135125},
volume = {53},
year = {2002}
}
@article{Marois2005,
abstract = {Despite the impressive complexity and processing power of the human brain, it is severely capacity limited. Behavioral research has highlighted three major bottlenecks of information processing that can cripple our ability to consciously perceive, hold in mind, and act upon the visual world, illustrated by the attentional blink (AB), visual short-term memory (VSTM), and psychological refractory period (PRP) phenomena, respectively. A review of the neurobiological literature suggests that the capacity limit of VSTM storage is primarily localized to the posterior parietal and occipital cortex, whereas the AB and PRP are associated with partly overlapping fronto-parietal networks. The convergence of these two networks in the lateral frontal cortex points to this brain region as a putative neural locus of a common processing bottleneck for perception and action.},
author = {Marois, Ren\'{e} and Ivanoff, Jason},
doi = {10.1016/j.tics.2005.04.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marois, Ivanoff/Marois, Ivanoff - 2005 - Capacity limits of information processing in the brain. - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Attention,Attention: physiology,Blinking,Blinking: physiology,Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Memory, Short-Term,Memory, Short-Term: physiology},
month = jun,
number = {6},
pages = {296--305},
pmid = {15925809},
title = {{Capacity limits of information processing in the brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15925809},
volume = {9},
year = {2005}
}
@article{Pang2008c,
author = {Pang, Derek and Kimura, Akisato and Takeuchi, Tatsuto and Yamato, Junji and Kashino, Kunio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pang et al/Pang et al. - 2008 - A STOCHASTIC MODEL OF SELECTIVE VISUAL ATTENTION WITH A DYNAMIC BAYESIAN NETWORK NTT Communication Science Laboratories , NTT Corporation , Japan - Engineering.pdf:pdf},
journal = {Engineering},
pages = {1073--1076},
title = {{A STOCHASTIC MODEL OF SELECTIVE VISUAL ATTENTION WITH A DYNAMIC BAYESIAN NETWORK NTT Communication Science Laboratories , NTT Corporation , Japan}},
year = {2008}
}
@article{Hamker2006,
abstract = {Visual attention is generally considered to facilitate the processing of the attended stimulus. Its mechanisms, however, are still under debate. We have developed a systems-level model of visual attention which predicts that attentive effects emerge by the interactions between different brain areas. Recent physiological studies have provided evidence that attention also alters the receptive field structure. For example, V4 receptive fields typically shrink and shift towards the saccade target around saccade onset. We show that receptive field dynamics are inherently predicted by the mechanism of feedback in our model. According to the model an oculomotor feedback signal from an area involved in the competition for the saccade target location, e.g. the frontal eye field, enhances the gain of V4 cells. V4 receptive field dynamics can be observed after pooling the gain modulated responses to obtain a certain degree of spatial invariance. The time course of the receptive field dynamics in the model resemble those obtained from macaque V4.},
author = {Hamker, Fred H and Zirnsak, Marc},
doi = {10.1016/j.neunet.2006.08.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hamker, Zirnsak/Hamker, Zirnsak - 2006 - V4 receptive field dynamics as predicted by a systems-level model of visual attention using feedback from the f.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Animals,Attention,Attention: physiology,Eye,Feedback,Humans,Models, Biological,Neurons,Neurons: physiology,Nonlinear Dynamics,Photic Stimulation,Photic Stimulation: methods,Predictive Value of Tests,Saccades,Time Factors,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = nov,
number = {9},
pages = {1371--82},
pmid = {17014990},
title = {{V4 receptive field dynamics as predicted by a systems-level model of visual attention using feedback from the frontal eye field.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17014990},
volume = {19},
year = {2006}
}
@article{Mallat1993,
author = {Mallat, S and Zhang, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mallat, Zhang/Mallat, Zhang - 1993 - Matching Pursuits with Time-Frequency Dictionaries - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
keywords = {MP},
number = {12},
pages = {3397--3415},
title = {{Matching Pursuits with Time-Frequency Dictionaries}},
volume = {41},
year = {1993}
}
@article{Tomasi,
author = {Tomasi, Carlo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tomasi/Tomasi - Unknown - Estimating Gaussian Mixture Densities with EM – A Tutorial - Unknown.pdf:pdf},
number = {i},
pages = {1--8},
title = {{Estimating Gaussian Mixture Densities with EM – A Tutorial}}
}
@article{Wolfe2000,
author = {Wolfe, J M and Alvarez, G a and Horowitz, T S},
doi = {10.1038/35021132},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wolfe, Alvarez, Horowitz/Wolfe, Alvarez, Horowitz - 2000 - Attention is fast but volition is slow. - Nature.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Attention,Attention: physiology,Fixation, Ocular,Humans,Reaction Time,Visual Perception,Visual Perception: physiology,Volition,Volition: physiology},
month = aug,
number = {6797},
pages = {691},
pmid = {10963584},
title = {{Attention is fast but volition is slow.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10963584},
volume = {406},
year = {2000}
}
@article{Slotnick2005,
abstract = {There is a long-standing debate as to whether visual mental imagery relies entirely on symbolic (language-like) representations or also relies on depictive (picture-like) representations. We sought to discover whether visual mental imagery could evoke cortical activity with precise visual field topography (retinotopy). Participants received three conditions: the perception condition consisted of a standard retinotopic mapping procedure, where two flickering checkerboard wedges rotated around a central fixation point. The imagery and attention conditions consisted of the same stimulus, but only the outer arcs of the wedges were visible. During imagery, participants mentally reproduced the stimulus wedges, using the stimulus arcs as a guide. The attention condition required either distributed attention or focused attention to where the stimulus wedges would have been. Event-related analysis revealed that the imagery (greater than either form of attention) retinotopic maps were similar to the perception maps. Moreover, blocked analysis revealed similar perception and imagery effects in human motion processing region MT+. These results support the depictive view of visual mental imagery.},
author = {Slotnick, Scott D and Thompson, William L and Kosslyn, Stephen M},
doi = {10.1093/cercor/bhi035},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slotnick, Thompson, Kosslyn/Slotnick, Thompson, Kosslyn - 2005 - Visual mental imagery induces retinotopically organized activation of early visual areas. - Cerebra.pdf:pdf},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Cerebrovascular Circulation,Cerebrovascular Circulation: physiology,Data Interpretation, Statistical,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Imagination,Imagination: physiology,Magnetic Resonance Imaging,Male,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Retina,Retina: physiology,Signal Detection, Psychological,Signal Detection, Psychological: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {10},
pages = {1570--83},
pmid = {15689519},
title = {{Visual mental imagery induces retinotopically organized activation of early visual areas.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15689519},
volume = {15},
year = {2005}
}
@article{May2010,
abstract = {The current review constitutes the first comprehensive look at the possibility that the mismatch negativity (MMN, the deflection of the auditory ERP/ERF elicited by stimulus change) might be generated by so-called fresh-afferent neuronal activity. This possibility has been repeatedly ruled out for the past 30 years, with the prevailing theoretical accounts relying on a memory-based explanation instead. We propose that the MMN is, in essence, a latency- and amplitude-modulated expression of the auditory N1 response, generated by fresh-afferent activity of cortical neurons that are under nonuniform levels of adaptation.},
author = {May, Patrick J C and Tiitinen, Hannu},
doi = {10.1111/j.1469-8986.2009.00856.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/May, Tiitinen/May, Tiitinen - 2010 - Mismatch negativity (MMN), the deviance-elicited auditory deflection, explained. - Psychophysiology.pdf:pdf},
issn = {1540-5958},
journal = {Psychophysiology},
keywords = {Acoustic Stimulation,Adaptation, Psychological,Adaptation, Psychological: physiology,Affect,Affect: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Electroencephalography,Electroencephalography: psychology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Memory,Memory: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology},
month = jan,
number = {1},
pages = {66--122},
pmid = {19686538},
title = {{Mismatch negativity (MMN), the deviance-elicited auditory deflection, explained.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19686538},
volume = {47},
year = {2010}
}
@article{Kimura2001b,
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - 2001 - Very quick audio searching Time-series active search ( TAS ) - Science.pdf:pdf},
journal = {Science},
number = {May},
pages = {1--11},
title = {{Very quick audio searching Time-series active search ( TAS )}},
year = {2001}
}
@article{Rasmussen2000a,
author = {Rasmussen, Carl Edward},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasmussen/Rasmussen - 2000 - The Infinite Gaussian Mixture Model - Processing.pdf:pdf},
journal = {Processing},
pages = {554--560},
title = {{The Infinite Gaussian Mixture Model}},
year = {2000}
}
@article{Lepetit,
author = {Lepetit, V. and Pilet, J. and Fua, P.},
doi = {10.1109/CVPR.2004.1315170},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lepetit, Pilet, Fua/Lepetit, Pilet, Fua - Unknown - Point matching as a classification problem for fast and robust object pose estimation - Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.pdf:pdf},
isbn = {0-7695-2158-4},
journal = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
pages = {244--250},
publisher = {Ieee},
title = {{Point matching as a classification problem for fast and robust object pose estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1315170}
}
@article{Atiani2009,
abstract = {Attention is essential for navigating complex acoustic scenes, when the listener seeks to extract a foreground source while suppressing background acoustic clutter. This study explored the neural correlates of this perceptual ability by measuring rapid changes of spectrotemporal receptive fields (STRFs) in primary auditory cortex during detection of a target tone embedded in noise. Compared with responses in the passive state, STRF gain decreased during task performance in most cells. By contrast, STRF shape changes were excitatory and specific, and were strongest in cells with best frequencies near the target tone. The net effect of these adaptations was to accentuate the representation of the target tone relative to the noise by enhancing responses of near-target cells to the tone during high-signal-to-noise ratio (SNR) tasks while suppressing responses of far-from-target cells to the masking noise in low-SNR tasks. These adaptive STRF changes were largest in high-performance sessions, confirming a close correlation with behavior.},
author = {Atiani, Serin and Elhilali, Mounya and David, Stephen V and Fritz, Jonathan B and Shamma, Shihab a},
doi = {10.1016/j.neuron.2008.12.027},
file = {:Users/pkmital/Documents/Mendeley Desktop/Atiani et al/Atiani et al. - 2009 - Task difficulty and performance induce diverse adaptive patterns in gain and shape of primary auditory cortical r.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Adaptation, Physiological,Adaptation, Physiological: physiology,Animals,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Behavior, Animal,Behavior, Animal: physiology,Ferrets,Habituation, Psychophysiologic,Habituation, Psychophysiologic: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Neuropsychological Tests},
month = feb,
number = {3},
pages = {467--80},
pmid = {19217382},
publisher = {Elsevier Ltd},
title = {{Task difficulty and performance induce diverse adaptive patterns in gain and shape of primary auditory cortical receptive fields.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19217382},
volume = {61},
year = {2009}
}
@article{Janer2008,
author = {Janer, Jordi and Boer, Maarten De},
file = {:Users/pkmital/Documents/Mendeley Desktop/Janer, Boer/Janer, Boer - 2008 - Extending voice-driven synthesis to audio mosaicing - 5th Sound and Music Computing \ldots.pdf:pdf},
journal = {5th Sound and Music Computing \ldots},
title = {{Extending voice-driven synthesis to audio mosaicing}},
url = {http://www.smc-conference.org/smc08/images/proceedings/session10\_number3\_paper22.pdf},
year = {2008}
}
@article{Allusse2008,
author = {Allusse, Yannick},
doi = {10.1007/978-3-540-89646-3\_42},
file = {:Users/pkmital/Documents/Mendeley Desktop/Allusse/Allusse - 2008 - GpuCV A GPU-Accelerated Framework for Image Processing and Computer Vision - Unknown.pdf:pdf},
isbn = {978-3-540-89645-6},
issn = {0302-9743},
keywords = {computer vision,cuda,glsl,gpgpu,image processing},
pages = {430--439},
title = {{GpuCV: A GPU-Accelerated Framework for Image Processing and Computer Vision}},
volume = {5359},
year = {2008}
}
@inproceedings{O'Brien2001,
address = {New York, New York, USA},
author = {O'Brien, James F. and Cook, Perry R. and Essl, Georg},
booktitle = {SIGGRAPH 2001: Proceedings of the 28th annual conference on Computer graphics and interactive techniques.},
doi = {10.1145/383259.383321},
file = {::},
isbn = {158113374X},
keywords = {animation techniques,dynamics,finite,physically based modeling,sim-,sound modeling,surface vibrations,ulation},
pages = {529--536},
publisher = {ACM Press},
title = {{Synthesizing sounds from physically based motion}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383321},
year = {2001}
}
@article{Stefanics2011,
abstract = {Sequential regularities are abstract rules based on repeating sequences of environmental events, which are useful to make predictions about future events. Here, we tested whether the visual system is capable to detect sequential regularity in unattended stimulus sequences. The visual mismatch negativity (vMMN) component of the event-related potentials is sensitive to the violation of complex regularities (e.g., object-related characteristics, temporal patterns). We used the vMMN component as an index of violation of conditional (if, then) regularities. In the first experiment, to investigate emergence of vMMN and other change-related activity to the violation of conditional rules, red and green disk patterns were delivered in pairs. The majority of pairs comprised of disk patterns with identical colors, whereas in deviant pairs the colors were different. The probabilities of the two colors were equal. The second member of the deviant pairs elicited a vMMN with longer latency and more extended spatial distribution to deviants with lower probability (10 vs. 30\%). In the second (control) experiment the emergence of vMMN to violation of a simple, feature-related rule was studied using oddball sequences of stimulus pairs where deviant colors were presented with 20\% probabilities. Deviant colored patterns elicited a vMMN, and this component was larger for the second member of the pair, i.e., after a shorter inter-stimulus interval. This result corresponds to the SOA/(v)MMN relationship, expected on the basis of a memory-mismatch process. Our results show that the system underlying vMMN is sensitive to abstract, conditional rules. Representation of such rules implicates expectation of a subsequent event, therefore vMMN can be considered as a correlate of violated predictions about the characteristics of environmental events.},
author = {Stefanics, G\'{a}bor and Kimura, Motohiro and Czigler, Istv\'{a}n},
doi = {10.3389/fnhum.2011.00046},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stefanics, Kimura, Czigler/Stefanics, Kimura, Czigler - 2011 - Visual mismatch negativity reveals automatic detection of sequential regularity violation. - Frontie.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {1997,an increased,body of studies shows,event-related potential,event-related potential, oddball, predictive model,focal attention even large,however,in the absence of,is capable of detect-,oddball,predictive models,probability,remain unnoticed,sequential regularity,simons and levin,that the human brain,visual changes may,visual mismatch negativity},
month = jan,
number = {May},
pages = {46},
pmid = {21629766},
title = {{Visual mismatch negativity reveals automatic detection of sequential regularity violation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3099311\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Kimura2006,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2006 - Multiterminal source coding for cascading and feedback refinement systems - Science.pdf:pdf},
journal = {Science},
keywords = {152-8552 japan,2-12-1 ookayama,akisato kimura,cascading,department of communications and,feedback,integrated systems,meguro-ku,multiterminal source coding,refinement,scalable coding,side informa-,stitute of technology,the authors are with,tion,tokyo,tokyo in-},
pages = {2--12},
title = {{Multiterminal source coding for cascading and feedback refinement systems}},
year = {2006}
}
@article{Kayser2005,
abstract = {Our nervous system is confronted with a barrage of sensory stimuli, but neural resources are limited and not all stimuli can be processed to the same extent. Mechanisms exist to bias attention toward the particularly salient events, thereby providing a weighted representation of our environment. Our understanding of these mechanisms is still limited, but theoretical models can replicate such a weighting of sensory inputs and provide a basis for understanding the underlying principles. Here, we describe such a model for the auditory system-an auditory saliency map. We experimentally validate the model on natural acoustical scenarios, demonstrating that it reproduces human judgments of auditory saliency and predicts the detectability of salient sounds embedded in noisy backgrounds. In addition, it also predicts the natural orienting behavior of naive macaque monkeys to the same salient stimuli. The structure of the suggested model is identical to that of successfully used visual saliency maps. Hence, we conclude that saliency is determined either by implementing similar mechanisms in different unisensory pathways or by the same mechanism in multisensory areas. In any case, our results demonstrate that different primate sensory systems rely on common principles for extracting relevant sensory events.},
author = {Kayser, Christoph and Petkov, Christopher I and Lippert, Michael and Logothetis, Nikos K},
doi = {10.1016/j.cub.2005.09.040},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kayser et al/Kayser et al. - 2005 - Mechanisms for allocating auditory attention an auditory saliency map. - Current biology CB(2).pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Acoustic Stimulation,Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Macaca mulatta,Macaca mulatta: physiology,Models, Neurological,Orientation,Orientation: physiology,Species Specificity},
month = nov,
number = {21},
pages = {1943--7},
pmid = {16271872},
title = {{Mechanisms for allocating auditory attention: an auditory saliency map.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271872},
volume = {15},
year = {2005}
}
@article{Losada2009,
author = {Losada, CC},
file = {:Users/pkmital/Documents/Mendeley Desktop/Losada/Losada - 2009 - Between Modernism and Postmodernism Strands of Continuity in Collage Compositions by Rochberg, Berio, and Zimmermann - M.pdf:pdf},
journal = {Music Theory Spectrum},
keywords = {berio,chromatic comple-,chromatic saturation,collage,contrasting styles has cre-,gap-fill,mentation,n the last forty,of musical,postmodernism,quotation,quotation and juxtaposition of,rochberg,significant gap,sinfonia,years the extensive use,zimmermann},
number = {1},
pages = {57--100},
title = {{Between Modernism and Postmodernism: Strands of Continuity in Collage Compositions by Rochberg, Berio, and Zimmermann}},
url = {http://www.jstor.org/stable/10.1525/mts.2011.33.1.cover http://www.jstor.org/stable/10.1525/mts.2009.31.1.57},
volume = {31},
year = {2009}
}
@article{Maaten2011,
author = {Maaten, Laurens and Hinton, Geoffrey},
doi = {10.1007/s10994-011-5273-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Maaten, Hinton/Maaten, Hinton - 2011 - Visualizing non-metric similarities in multiple maps - Machine Learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {data visualization,embedding,multidimensional scaling,non-metric},
month = dec,
number = {November},
title = {{Visualizing non-metric similarities in multiple maps}},
url = {http://www.springerlink.com/index/10.1007/s10994-011-5273-4},
year = {2011}
}
@article{Rother2006,
address = {New York, New York, USA},
author = {Rother, Carsten and Bordeaux, Lucas and Hamadi, Youssef and Blake, Andrew},
doi = {10.1145/1179352.1141965},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rother et al/Rother et al. - 2006 - AutoCollage - ACM SIGGRAPH 2006 Papers on - SIGGRAPH '06.pdf:pdf},
isbn = {1595933646},
journal = {ACM SIGGRAPH 2006 Papers on - SIGGRAPH '06},
keywords = {2006 by the association,ablake,carrot,com,constraint satisfaction,copyright,energy min-,for computing machinery,graph cut,image editing,imization,inc,lucasb,microsoft,photomontage,poisson blending,youssefh},
pages = {847},
publisher = {ACM Press},
title = {{AutoCollage}},
url = {http://portal.acm.org/citation.cfm?doid=1179352.1141965},
year = {2006}
}
@article{Bello2005,
abstract = {Note onset detection and localization is useful in a number of analysis and indexing techniques for musical signals. The usual way to detect onsets is to look for \&8220;transient\&8221; regions in the signal, a notion that leads to many definitions: a sudden burst of energy, a change in the short-time spectrum of the signal or in the statistical properties, etc. The goal of this paper is to review, categorize, and compare some of the most commonly used techniques for onset detection, and to present possible enhancements. We discuss methods based on the use of explicitly predefined signal features: the signal's amplitude envelope, spectral magnitudes and phases, time-frequency representations; and methods based on probabilistic signal models: model-based change point detection, surprise signals, etc. Using a choice of test cases, we provide some guidelines for choosing the appropriate method for a given application.},
author = {Bello, J P and Daudet, L and Abdallah, S and Duxbury, C and Davies, M and Sandler, M B},
doi = {10.1109/TSA.2005.851998},
issn = {10636676},
journal = {Ieee Transactions On Speech And Audio Processing},
number = {5},
pages = {1035--1047},
publisher = {INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS},
title = {{A tutorial on onset detection in music signals}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1495485},
volume = {13},
year = {2005}
}
@article{Alvarez2011,
abstract = {The visual system can only accurately represent a handful of objects at once. How do we cope with this severe capacity limitation? One possibility is to use selective attention to process only the most relevant incoming information. A complementary strategy is to represent sets of objects as a group or ensemble (e.g. represent the average size of items). Recent studies have established that the visual system computes accurate ensemble representations across a variety of feature domains and current research aims to determine how these representations are computed, why they are computed and where they are coded in the brain. Ensemble representations enhance visual cognition in many ways, making ensemble coding a crucial mechanism for coping with the limitations on visual processing.},
author = {Alvarez, George a},
doi = {10.1016/j.tics.2011.01.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alvarez/Alvarez - 2011 - Representing multiple objects as an ensemble enhances visual cognition. - Trends in cognitive sciences.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Animals,Attention,Attention: physiology,Brain,Brain Mapping,Brain: physiology,Cognition,Cognition: physiology,Humans,Photic Stimulation,Set (Psychology),Visual Perception,Visual Perception: physiology},
month = mar,
number = {3},
pages = {122--31},
pmid = {21292539},
title = {{Representing multiple objects as an ensemble enhances visual cognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21292539},
volume = {15},
year = {2011}
}
@article{Kubovy2001,
abstract = {Notions of objecthood have traditionally been cast in visuocentric terminology. As a result, theories of auditory and cross-modal perception have focused more on the differences between modalities than on the similarities. In this paper we re-examine the concept of an object in a way that overcomes the limitations of the traditional perspective. We propose a new, cross-modal conception of objecthood which focuses on the similarities between modalities instead of the differences. Further, we propose that the auditory system might consist of two parallel streams of processing (the 'what' and 'where' subsystems) in a manner analogous to current conceptions of the visual system. We suggest that the 'what' subsystems in each modality are concerned with objecthood. Finally, we present evidence for - and elaborate on - the hypothesis that the auditory 'where' subsystem is in the service of the visual-motor 'where' subsystem.},
author = {Kubovy, M and {Van Valkenburg}, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kubovy, Van Valkenburg/Kubovy, Van Valkenburg - 2001 - Auditory and visual objects. - Cognition.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Auditory Perception,Auditory Perception: physiology,Concept Formation,Humans,Models, Psychological,Neurophysiology,Sound Localization,Sound Localization: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {1-2},
pages = {97--126},
pmid = {11245841},
title = {{Auditory and visual objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11245841},
volume = {80},
year = {2001}
}
@article{Rensink2000,
author = {Rensink, Ronald a.},
doi = {10.1080/135062800394667},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rensink/Rensink - 2000 - The Dynamic Representation of Scenes - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {1-3},
pages = {17--42},
title = {{The Dynamic Representation of Scenes}},
url = {http://www.tandfonline.com/doi/abs/10.1080/135062800394667},
volume = {7},
year = {2000}
}
@article{Kimura1999a,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 1999 - Large Deviations Performance of Interval Algorithm for Random Number Generation - Source.pdf:pdf},
journal = {Source},
pages = {2--12},
title = {{Large Deviations Performance of Interval Algorithm for Random Number Generation}},
year = {1999}
}
@article{Thura2008,
abstract = {In daily life, activities requiring the hand and eye to work separately are as frequent as activities requiring tight eye-hand coordination, and we effortlessly switch from one type of activity to the other. Such flexibility is unlikely to be achieved without each effector "knowing" where the other one is at all times, even when it is static. Here, we provide behavioral evidence that the mere position of the static hand affects one eye movement parameter: saccadic reaction time. Two monkeys were trained and 11 humans instructed to perform nondelayed or delayed visually guided saccades to either a right or a left target while holding their hand at a location either near or far from the eye target. From trial to trial, target locations and hand positions varied pseudorandomly. Subjects were tested both when they could and when they could not see their hand. The main findings are 1) the presence of the static hand in the workspace did affect saccade initiation; 2) this interaction persisted when the hand was invisible; 3) it was strongly influenced by the delay duration: hand-target proximity retarded immediate saccades, whereas it could hasten delayed saccades; and 4) this held true both for humans and for each of the two monkeys. We propose that both visual and nonvisual hand position signals are used by the primates' oculomotor system for the planning and execution of saccades, and that this may result in a hand-eye competition for spatial attentional resources that explains the delay-dependent reversal observed.},
author = {Thura, David and Boussaoud, Driss and Meunier, Martine},
doi = {10.1152/jn.01271.2007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thura, Boussaoud, Meunier/Thura, Boussaoud, Meunier - 2008 - Hand position affects saccadic reaction times in monkeys and humans. - Journal of neurophysiology.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Adult,Animals,Data Interpretation, Statistical,Female,Functional Laterality,Functional Laterality: physiology,Hand,Hand: innervation,Hand: physiology,Humans,Macaca fascicularis,Macaca mulatta,Male,Middle Aged,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Species Specificity},
month = may,
number = {5},
pages = {2194--202},
pmid = {18337364},
title = {{Hand position affects saccadic reaction times in monkeys and humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18337364},
volume = {99},
year = {2008}
}
@article{Azzopardi2012,
abstract = {Simple cells in primary visual cortex are believed to extract local contour information from a visual scene. The 2D Gabor function (GF) model has gained particular popularity as a computational model of a simple cell. However, it short-cuts the LGN, it cannot reproduce a number of properties of real simple cells, and its effectiveness in contour detection tasks has never been compared with the effectiveness of alternative models. We propose a computational model that uses as afferent inputs the responses of model LGN cells with center-surround receptive fields (RFs) and we refer to it as a Combination of Receptive Fields (CORF) model. We use shifted gratings as test stimuli and simulated reverse correlation to explore the nature of the proposed model. We study its behavior regarding the effect of contrast on its response and orientation bandwidth as well as the effect of an orthogonal mask on the response to an optimally oriented stimulus. We also evaluate and compare the performances of the CORF and GF models regarding contour detection, using two public data sets of images of natural scenes with associated contour ground truths. The RF map of the proposed CORF model, determined with simulated reverse correlation, can be divided in elongated excitatory and inhibitory regions typical of simple cells. The modulated response to shifted gratings that this model shows is also characteristic of a simple cell. Furthermore, the CORF model exhibits cross orientation suppression, contrast invariant orientation tuning and response saturation. These properties are observed in real simple cells, but are not possessed by the GF model. The proposed CORF model outperforms the GF model in contour detection with high statistical confidence (RuG data set: p<10(-4), and Berkeley data set: p<10(-4)). The proposed CORF model is more realistic than the GF model and is more effective in contour detection, which is assumed to be the primary biological role of simple cells.},
author = {Azzopardi, George and Petkov, Nicolai},
doi = {10.1007/s00422-012-0486-6},
file = {:Users/pkmital/Documents/Mendeley Desktop/Azzopardi, Petkov/Azzopardi, Petkov - 2012 - A CORF computational model of a simple cell that relies on LGN input outperforms the Gabor function model. -.pdf:pdf},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {Models, Theoretical,Neurons,Neurons: cytology,Visual Cortex,Visual Cortex: cytology},
month = mar,
number = {3},
pages = {177--89},
pmid = {22526357},
title = {{A CORF computational model of a simple cell that relies on LGN input outperforms the Gabor function model.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22526357},
volume = {106},
year = {2012}
}
@article{Hauk2004,
abstract = {OBJECTIVE: We investigated the influence of the length and frequency of printed words on the amplitude and peak latencies of event-related potentials (ERPs). This served two goals, namely (I) to clarify their possible effects as confounds in ERP experiments employing word-stimuli, and (II) to determine the point in time of lexical access in visual word recognition. METHODS: EEG was recorded from 64 scalp sites while subjects (n=12) performed a lexical decision task. Word length and frequency were orthogonally varied between stimulus groups, whereas variables including regularity of spelling and orthographic tri-gram frequency were kept constant. RESULTS: Long words produced the strongest brain response early on (approximately 100 ms after stimulus onset), whereas those to short words became strongest later (150-360 ms). Lower ERP amplitudes were elicited by words with high frequency compared with low frequency words in the latency ranges 150-190 ms and 320-360 ms. However, we did not find evidence for a robust alteration of peak latencies with word frequency. CONCLUSIONS: Length and frequency of word stimuli have independent and additive effects on the amplitude of the ERP. Studies on the precise time course of cognitive processes should consider their potentially confounding character. Our data support the view that lexical access takes place as early as 150 ms after onset of written word stimuli.},
author = {Hauk, O and Pulverm\"{u}ller, F},
doi = {10.1016/j.clinph.2003.12.020},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hauk, Pulverm\"{u}ller/Hauk, Pulverm\"{u}ller - 2004 - Effects of word length and frequency on the human event-related potential. - Clinical neurophysiology official journal of the International Federation of Clinical Neurophysiology.pdf:pdf},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Adult,Brain,Brain: physiology,Electroencephalography,Evoked Potentials,Female,Humans,Language,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reaction Time,Reading,Scalp,Scalp: physiology},
month = may,
number = {5},
pages = {1090--103},
pmid = {15066535},
title = {{Effects of word length and frequency on the human event-related potential.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15066535},
volume = {115},
year = {2004}
}
@article{Kimura2010,
abstract = {For our adaptive behavior in a dynamically changing environment, an essential task of the brain is to automatically encode sequential regularities inherent in the environment into a memory representation. Recent studies in neuroscience have suggested that sequential regularities embedded in discrete sensory events are automatically encoded into a memory representation at the level of the sensory system. This notion is largely supported by evidence from investigations using auditory mismatch negativity (auditory MMN), an event-related brain potential (ERP) correlate of an automatic memory-mismatch process in the auditory sensory system. However, it is still largely unclear whether or not this notion can be generalized to other sensory modalities. The purpose of the present study was to investigate the contribution of the visual sensory system to the automatic encoding of sequential regularities using visual mismatch negativity (visual MMN), an ERP correlate of an automatic memory-mismatch process in the visual sensory system. To this end, we conducted a sequential analysis of visual MMN in an oddball sequence consisting of infrequent deviant and frequent standard stimuli, and tested whether the underlying memory representation of visual MMN generation contains only a sensory memory trace of standard stimuli (trace-mismatch hypothesis) or whether it also contains sequential regularities extracted from the repetitive standard sequence (regularity-violation hypothesis). The results showed that visual MMN was elicited by first deviant (deviant stimuli following at least one standard stimulus), second deviant (deviant stimuli immediately following first deviant), and first standard (standard stimuli immediately following first deviant), but not by second standard (standard stimuli immediately following first standard). These results are consistent with the regularity-violation hypothesis, suggesting that the visual sensory system automatically encodes sequential regularities. In combination with a wide range of auditory MMN studies, the present study highlights the critical role of sensory systems in automatically encoding sequential regularities when modeling the world.},
author = {Kimura, Motohiro and Schr\"{o}ger, Erich and Czigler, Istv\'{a}n and Ohira, Hideki},
doi = {10.1162/jocn.2009.21299},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
keywords = {Adult,Analysis of Variance,Attention,Attention: physiology,Brain Mapping,Electroencephalography,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Memory,Memory: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Serial Learning,Serial Learning: physiology,Signal Processing, Computer-Assisted,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {6},
pages = {1124--39},
pmid = {19583466},
title = {{Human visual system automatically encodes sequential regularities of discrete events.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19583466},
volume = {22},
year = {2010}
}
@article{Bundesen1990,
abstract = {A unified theory of visual recognition and attentional selection is developed by integrating the biased-choice model for single-stimulus recognition (Luce, 1963; Shepard, 1957) with a choice model for selection from multielement displays (Bundesen, Pedersen, \& Larsen, 1984) in a race model framework. Mathematically, the theory is tractable, and it specifies the computations necessary for selection. The theory is applied to extant findings from a broad range of experimental paradigms. The findings include effects of object integrality in selective report, number and spatial position of targets in divided-attention paradigms, selection criterion and number of distracters in focused-attention paradigms, delay of selection cue in partial report, and consistent practice in search. On the whole, the quantitative fits are encouraging.},
author = {Bundesen, C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bundesen/Bundesen - 1990 - A theory of visual attention. - Psychological review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Attention,Discrimination Learning,Humans,Models, Theoretical,Orientation,Pattern Recognition, Visual,Psychophysics,Reaction Time},
month = oct,
number = {4},
pages = {523--47},
pmid = {2247540},
title = {{A theory of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21146554},
volume = {97},
year = {1990}
}
@article{Meier1996,
address = {New York, New York, USA},
author = {Meier, Barbara J.},
doi = {10.1145/237170.237288},
file = {:Users/pkmital/Documents/Mendeley Desktop/Meier/Meier - 1996 - Painterly rendering for animation - Proceedings of the 23rd annual conference on Computer graphics and interactive techni.pdf:pdf},
isbn = {0897917464},
journal = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques - SIGGRAPH '96},
keywords = {abstract images,non-photorealistic rendering,painterly rendering,painting,particle systems},
pages = {477--484},
publisher = {ACM Press},
title = {{Painterly rendering for animation}},
url = {http://portal.acm.org/citation.cfm?doid=237170.237288},
year = {1996}
}
@article{Palmeri2004,
author = {Palmeri, Thomas J and Gauthier, Isabel},
doi = {10.1038/nrn1364},
file = {:Users/pkmital/Documents/Mendeley Desktop/Palmeri, Gauthier/Palmeri, Gauthier - 2004 - Visual object understanding. - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Comprehension,Comprehension: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Form Perception,Form Perception: physiology,Humans,Learning,Learning: physiology,Models, Neurological,Visual Perception,Visual Perception: physiology},
month = apr,
number = {4},
pages = {291--303},
pmid = {15034554},
title = {{Visual object understanding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15034554},
volume = {5},
year = {2004}
}
@misc{Mital2011d,
author = {Mital, Parag K},
booktitle = {(video)},
title = {{The Simpsons vs The Family Guy}},
url = {http://vimeo.com/30444762},
urldate = {1 May 2012},
year = {2011}
}
@article{Balota1985,
author = {Balota, D a and Pollatsek, a and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Balota, Pollatsek, Rayner/Balota, Pollatsek, Rayner - 1985 - The interaction of contextual constraints and parafoveal visual information in reading. - Cognitive psychology.pdf:pdf},
issn = {0010-0285},
journal = {Cognitive psychology},
keywords = {Eye Movements,Fixation, Ocular,Form Perception,Form Perception: physiology,Humans,Models, Psychological,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reading,Retina,Retina: physiology,Semantics},
month = jul,
number = {3},
pages = {364--90},
pmid = {4053565},
title = {{The interaction of contextual constraints and parafoveal visual information in reading.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/4053565},
volume = {17},
year = {1985}
}
@article{Attneave1954,
author = {Attneave, F},
file = {:Users/pkmital/Documents/Mendeley Desktop/Attneave/Attneave - 1954 - Some informational aspects of visual perception. - Psychological review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Perception,Vision, Ocular},
month = may,
number = {3},
pages = {183--93},
pmid = {13167245},
title = {{Some informational aspects of visual perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/13167245},
volume = {61},
year = {1954}
}
@article{Muller2013,
abstract = {One of the most challenging tasks of our visual systems is to structure and integrate the enormous amount of incoming information into distinct coherent objects. It is an ongoing debate whether or not the formation of visual objects requires attention. Implicit behavioral measures suggest that object formation can occur for task-irrelevant and unattended visual stimuli. The present study investigated pre-attentive visual object formation by combining implicit behavioral measures and an electrophysiological indicator of pre-attentive visual irregularity detection, the visual mismatch negativity (vMMN) of the event-related potential. Our displays consisted of two symmetrically arranged, task-irrelevant ellipses, the objects. In addition, there were two discs of either high or low luminance presented on the objects, which served as targets. Participants had to indicate whether the targets were of the same or different luminance. In separate conditions, the targets either usually were enclosed in the same object or in two different objects (standards). Occasionally, the regular target-to-object assignment was changed (deviants). That is, standards and deviants were exclusively defined on the basis of the task-irrelevant target-to-object assignment but not on the basis of some feature regularity. Although participants did not notice the regularity nor the occurrence of the deviation in the sequences, task-irrelevant deviations resulted in increased reaction times. Moreover, compared with physically identical standard displays deviating target-to-object assignments elicited a negative potential in the 246-280 ms time window over posterio-temporal electrode positions which was identified as vMMN. With variable resolution electromagnetic tomography (VARETA) object-related vMMN was localized to the inferior temporal gyrus. Our results support the notion that the visual system automatically structures even task-irrelevant aspects of the incoming information into objects.},
author = {M\"{u}ller, Dagmar and Widmann, Andreas and Schr\"{o}ger, Erich},
doi = {10.3389/fnhum.2013.00259},
file = {:Users/pkmital/Documents/Mendeley Desktop/M\"{u}ller, Widmann, Schr\"{o}ger/M\"{u}ller, Widmann, Schr\"{o}ger - 2013 - Object-related regularities are processed automatically evidence from the visual mismatch negativit.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {deviance detection,deviance detection, human ERP, prediction error, o,human erp,object formation,prediction error,tomography,vareta,variable resolution electromagnetic,visual mismatch negativity},
month = jan,
number = {June},
pages = {259},
pmid = {23772212},
title = {{Object-related regularities are processed automatically: evidence from the visual mismatch negativity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3677125\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2013}
}
@inproceedings{Saragih,
author = {Saragih, Jason},
booktitle = {Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Saragih/Saragih - 2011 - Principal regression analysis - Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on.pdf:pdf},
pages = {2881--2888},
publisher = {IEEE},
title = {{Principal regression analysis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5995618},
year = {2011}
}
@article{Moore2012,
abstract = {A sequence of sounds may be heard as coming from a single source (called fusion or coherence) or from two or more sources (called fission or stream segregation). Each perceived source is called a 'stream'. When the differences between successive sounds are very large, fission nearly always occurs, whereas when the differences are very small, fusion nearly always occurs. When the differences are intermediate in size, the percept often 'flips' between one stream and multiple streams, a property called 'bistability'. The flips do not generally occur regularly in time. The tendency to hear two streams builds up over time, but can be partially or completely reset by a sudden change in the properties of the sequence or by switches in attention. Stream formation depends partly on the extent to which successive sounds excite different 'channels' in the peripheral auditory system. However, other factors can play a strong role; multiple streams may be heard when successive sounds are presented to the same ear and have essentially identical excitation patterns in the cochlea. Differences between successive sounds in temporal envelope, fundamental frequency, phase spectrum and lateralization can all induce a percept of multiple streams. Regularities in the temporal pattern of elements within a stream can help in stabilizing that stream.},
author = {Moore, Brian C J and Gockel, Hedwig E},
doi = {10.1098/rstb.2011.0355},
file = {:Users/pkmital/Documents/Mendeley Desktop/Moore, Gockel/Moore, Gockel - 2012 - Properties of auditory stream formation. - Philosophical transactions of the Royal Society of London. Series B, B.pdf:pdf},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Acoustic Stimulation,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Auditory Threshold: physiology,Humans,Sound},
month = apr,
number = {1591},
pages = {919--31},
pmid = {22371614},
title = {{Properties of auditory stream formation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3282308\&tool=pmcentrez\&rendertype=abstract},
volume = {367},
year = {2012}
}
@article{Geiger2011,
author = {Geiger, Andreas and Ziegler, Julius and Stiller, Christoph},
doi = {10.1109/IVS.2011.5940405},
file = {:Users/pkmital/Documents/Mendeley Desktop/Geiger, Ziegler, Stiller/Geiger, Ziegler, Stiller - 2011 - StereoScan Dense 3d reconstruction in real-time - 2011 IEEE Intelligent Vehicles Symposium (IV).pdf:pdf},
isbn = {978-1-4577-0890-9},
journal = {2011 IEEE Intelligent Vehicles Symposium (IV)},
month = jun,
pages = {963--968},
publisher = {Ieee},
title = {{StereoScan: Dense 3d reconstruction in real-time}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5940405},
year = {2011}
}
@article{Republic,
author = {Republic, Video},
file = {:Users/pkmital/Documents/Mendeley Desktop/Republic/Republic - Unknown - Video republic - Unknown.pdf:pdf},
title = {{Video republic}}
}
@article{Taaseh2011,
abstract = {Stimulus-specific adaptation (SSA) is the specific decrease in the response to a frequent ('standard') stimulus, which does not generalize, or generalizes only partially, to another, rare stimulus ('deviant'). Stimulus-specific adaptation could result simply from the depression of the responses to the standard. Alternatively, there may be an increase in the responses to the deviant stimulus due to the violation of expectations set by the standard, indicating the presence of true deviance detection. We studied SSA in the auditory cortex of halothane-anesthetized rats, recording local field potentials and multi-unit activity. We tested the responses to pure tones of one frequency when embedded in sequences that differed from each other in the frequency and probability of the tones composing them. The responses to tones of the same frequency were larger when deviant than when standard, even with inter-stimulus time intervals of almost 2 seconds. Thus, SSA is present and strong in rat auditory cortex. SSA was present even when the frequency difference between deviants and standards was as small as 10\%, substantially smaller than the typical width of cortical tuning curves, revealing hyper-resolution in frequency. Strong responses were evoked also by a rare tone presented by itself, and by rare tones presented as part of a sequence of many widely spaced frequencies. On the other hand, when presented within a sequence of narrowly spaced frequencies, the responses to a tone, even when rare, were smaller. A model of SSA that included only adaptation of the responses in narrow frequency channels predicted responses to the deviants that were substantially smaller than the observed ones. Thus, the response to a deviant is at least partially due to the change it represents relative to the regularity set by the standard tone, indicating the presence of true deviance detection in rat auditory cortex.},
author = {Taaseh, Nevo and Yaron, Amit and Nelken, Israel},
doi = {10.1371/journal.pone.0023369},
file = {:Users/pkmital/Documents/Mendeley Desktop/Taaseh, Yaron, Nelken/Taaseh, Yaron, Nelken - 2011 - Stimulus-specific adaptation and deviance detection in the rat auditory cortex. - PloS one.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Acoustic Stimulation,Adaptation, Physiological,Animals,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Female,Male,Models, Biological,Rats},
month = jan,
number = {8},
pages = {e23369},
pmid = {21853120},
title = {{Stimulus-specific adaptation and deviance detection in the rat auditory cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3154435\&tool=pmcentrez\&rendertype=abstract},
volume = {6},
year = {2011}
}
@article{Tervaniemi1994,
abstract = {Investigated in 2 experiments whether the sensory memory traces (SMTs), as reflected by mismatch negativity (MMN), encode a tone pair as 2 individual stimuli or as a single integrated event. Ss were 23 university students and laboratory personnel. The 13 Ss in Exp 2 were experienced in event-related potential (ERP) studies. ERPs to different types of infrequent change in a tone pair composed of 2 closely spaced tones of different frequencies were recorded. MMN was elicited by reversing the order of the 2 tones, by repeating the 1st tone, by replacing the 1st tone with the 2nd tone, or by omitting the 2nd tone. The omission of the 2nd tone elicited the MMN only when the interval between the 2 tones was very short, offset to onset 40 or 140 msec, but did not when this interval was somewhat longer, 240 or 340 msec. Results suggest that SMTs, as reflected by the MMN, integrate information about 2 closely spaced stimuli into a single sensory event.},
author = {Tervaniemi, M. and Saarinen, J. and Paavilainen, P. and Danilova, N. and N\"{a}\"{a}t\"{a}nen, R.},
journal = {Biological Psychology},
number = {2-3},
pages = {157--167},
title = {{Temporal integration of auditory information in sensory memory as reflected by the mismatch negativity}},
url = {http://www.sciencedirect.com/science/article/pii/0301051194900361},
volume = {38},
year = {1994}
}
@article{Kimurae,
author = {Kimura, Akisato and Kashino, Kunio and Fukuchi, Ken and Miyazato, Kouji and Akamine, Kazuma and Takagi, Shigeru},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - Unknown - Cognitive developmental approach towards the realization of human - like visual scene understanding Framework and core technologies Babies naturally acquire the ability to do it . - Science.pdf:pdf},
journal = {Science},
number = {1},
title = {{Cognitive developmental approach towards the realization of human - like visual scene understanding : Framework and core technologies Babies naturally acquire the ability to do it .}}
}
@article{Keller1991,
abstract = {This article reviews the current state of knowledge of the primate smooth-pursuit system. The emphasis is on the neuronal mechanisms and pathways that control pursuit eye movements in the monkey. The review covers the neuronal structures believed to be involved in pursuit generation from striate cortex to the final premotoneuron structures in the brainstem. Information gathered from physiological and anatomical work is stressed.},
author = {Keller, E L and Heinen, S J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Keller, Heinen/Keller, Heinen - 1991 - Generation of smooth-pursuit eye movements neuronal mechanisms and pathways. - Neuroscience research.pdf:pdf},
issn = {0168-0102},
journal = {Neuroscience research},
keywords = {Animals,Brain,Brain: physiology,Motion Perception,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Pursuit, Smooth,Pursuit, Smooth: physiology,Visual Perception,Visual Perception: physiology},
month = jul,
number = {2},
pages = {79--107},
pmid = {1656345},
title = {{Generation of smooth-pursuit eye movements: neuronal mechanisms and pathways.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1656345},
volume = {11},
year = {1991}
}
@article{Tallon-Baudry1996,
abstract = {Considerable interest has been raised by non-phase-locked episodes of synchronization in the gamma-band (30-60 Hz). One of their putative roles in the visual modality is feature-binding. We tested the stimulus specificity of high-frequency oscillations in humans using three types of visual stimuli: two coherent stimuli (a Kanizsa and a real triangle) and a noncoherent stimulus ("no-triangle stimulus"). The task of the subject was to count the occurrences of a curved illusory triangle. A time-frequency analysis of single-trial EEG data recorded from eight human subjects was performed to characterize phase-locked as well as non-phase-locked high-frequency activities. We found in early phase-locked 40 Hz component, maximal at electrodes Cz-C4, which does not vary with stimulation type. We describe a second 40 Hz component, appearing around 280 msec, that is not phase-locked to stimulus onset. This component is stronger in response to a coherent triangle, whether real or illusory: it could reflect, therefore, a mechanism of feature binding based on high-frequency synchronization. Because both the illusory and the real triangle are more target-like, it could also correspond to an oscillatory mechanism for testing the match between stimulus and target. At the same latencies, the low-frequency evoked response components phase-locked to stimulus onset behave differently, suggesting that low- and high-frequency activities have different functional roles.},
author = {Tallon-Baudry, C and Bertrand, O and Delpuech, C and Pernier, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tallon-Baudry et al/Tallon-Baudry et al. - 1996 - Stimulus specificity of phase-locked and non-phase-locked 40 Hz visual responses in human. - The Journal o.pdf:pdf},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Adult,Electroencephalography,Evoked Potentials, Visual,Female,Humans,Male,Photic Stimulation,Photic Stimulation: methods,Visual Perception,Visual Perception: physiology},
month = jul,
number = {13},
pages = {4240--9},
pmid = {8753885},
title = {{Stimulus specificity of phase-locked and non-phase-locked 40 Hz visual responses in human.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8753885},
volume = {16},
year = {1996}
}
@article{Reynolds2009a,
abstract = {Attention has been found to have a wide variety of effects on the responses of neurons in visual cortex. We describe a model of attention that exhibits each of these different forms of attentional modulation, depending on the stimulus conditions and the spread (or selectivity) of the attention field in the model. The model helps reconcile proposals that have been taken to represent alternative theories of attention. We argue that the variety and complexity of the results reported in the literature emerge from the variety of empirical protocols that were used, such that the results observed in any one experiment depended on the stimulus conditions and the subject's attentional strategy, a notion that we define precisely in terms of the attention field in the model, but that has not typically been completely under experimental control.},
author = {Reynolds, John H and Heeger, David J},
doi = {10.1016/j.neuron.2009.01.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Reynolds, Heeger/Reynolds, Heeger - 2009 - The normalization model of attention. - Neuron(2).pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Attention,Attention: physiology,Computer Simulation,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Models, Neurological,Neurons,Neurons: physiology,Visual Cortex,Visual Cortex: physiology,Visual Fields,Visual Perception,Visual Perception: physiology},
month = jan,
number = {2},
pages = {168--85},
pmid = {19186161},
publisher = {Elsevier Inc.},
title = {{The normalization model of attention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2752446\&tool=pmcentrez\&rendertype=abstract},
volume = {61},
year = {2009}
}
@article{Reynolds2004,
abstract = {Single-unit recording studies in the macaque have carefully documented the modulatory effects of attention on the response properties of visual cortical neurons. Attention produces qualitatively different effects on firing rate, depending on whether a stimulus appears alone or accompanied by distracters. Studies of contrast gain control in anesthetized mammals have found parallel patterns of results when the luminance contrast of a stimulus increases. This finding suggests that attention has co-opted the circuits that mediate contrast gain control and that it operates by increasing the effective contrast of the attended stimulus. Consistent with this idea, microstimulation of the frontal eye fields, one of several areas that control the allocation of spatial attention, induces spatially local increases in sensitivity both at the behavioral level and among neurons in area V4, where endogenously generated attention increases contrast sensitivity. Studies in the slice have begun to explain how modulatory signals might cause such increases in sensitivity.},
author = {Reynolds, John H and Chelazzi, Leonardo},
doi = {10.1146/annurev.neuro.26.041002.131039},
file = {:Users/pkmital/Documents/Mendeley Desktop/Reynolds, Chelazzi/Reynolds, Chelazzi - 2004 - Attentional modulation of visual processing. - Annual review of neuroscience.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Attention,Attention: physiology,Contrast Sensitivity,Contrast Sensitivity: physiology,Eye Movements,Eye Movements: physiology,Humans,Models, Neurological,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology},
month = jan,
pages = {611--47},
pmid = {15217345},
title = {{Attentional modulation of visual processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15217345},
volume = {27},
year = {2004}
}
@article{Wrigley2004,
abstract = {The human auditory system is able to separate acoustic mixtures in order to create a perceptual description of each sound source. It has been proposed that this is achieved by an auditory scene analysis (ASA) in which a mixture of sounds is parsed to give a number of perceptual streams, each of which describes a single sound source. It is widely assumed that ASA is a precursor of attentional mechanisms, which select a stream for attentional focus. However, recent studies suggest that attention plays a key role in the formation of auditory streams. Motivated by these findings, this paper presents a conceptual framework for auditory selective attention in which the formation of groups and streams is heavily influenced by conscious and subconscious attention. This framework is implemented as a computational model comprising a network of neural oscillators, which perform stream segregation on the basis of oscillatory correlation. Within the network, attentional interest is modeled as a Gaussian distribution in frequency. This determines the connection weights between oscillators and the attentional process, which is modeled as an attentional leaky integrator (ALI). Acoustic features are held to be the subject of attention if their oscillatory activity coincides temporally with a peak in the ALI activity. The output of the model is an "attentional stream," which encodes the frequency bands in the attentional focus at each epoch. The model successfully simulates a range of psychophysical phenomena.},
author = {Wrigley, Stuart N and Brown, Guy J},
doi = {10.1109/TNN.2004.832710},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wrigley, Brown/Wrigley, Brown - 2004 - A computational model of auditory selective attention. - IEEE transactions on neural networks a publication of.pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Biological Clocks,Biological Clocks: physiology,Humans,Memory,Memory: physiology,Models, Neurological,Neural Networks (Computer),Neurons,Neurons: physiology,Normal Distribution,Synapses,Synapses: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = sep,
number = {5},
pages = {1151--63},
pmid = {15484891},
title = {{A computational model of auditory selective attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15484891},
volume = {15},
year = {2004}
}
@article{Fox2008,
author = {Fox, Emily B and Sudderth, Erik B and Jordan, Michael I and Willsky, Alan S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fox et al/Fox et al. - 2008 - Nonparametric Bayesian Learning of Switching Linear Dynamical Systems - Electrical Engineering.pdf:pdf},
journal = {Electrical Engineering},
title = {{Nonparametric Bayesian Learning of Switching Linear Dynamical Systems}},
year = {2008}
}
@article{Beheshti2010,
author = {Beheshti, Jamshid and Large, Andrew and Julien, Charles-Antoine and Tam, Marni},
doi = {10.1002/meet.14504701061},
file = {:Users/pkmital/Documents/Mendeley Desktop/Beheshti et al/Beheshti et al. - 2010 - A comparison of a conventional taxonomy with a 3D visualization for use by children - Proceedings of the Americ.pdf:pdf},
issn = {00447870},
journal = {Proceedings of the American Society for Information Science and Technology},
month = nov,
number = {1},
pages = {1--9},
title = {{A comparison of a conventional taxonomy with a 3D visualization for use by children}},
url = {http://doi.wiley.com/10.1002/meet.14504701061},
volume = {47},
year = {2010}
}
@article{Rinne2006,
abstract = {We used behavioral and event-related potential (ERP) measures to study the neural mechanisms of involuntary attention switching to changes in unattended sounds. Our subjects discriminated two equiprobable sounds differing in frequency (fundamental frequency 186 or 196 Hz) while task-irrelevant intensity decrements or increments (-3, -6, -9, +3, +6, or +9 dB, standard intensity 60 dB HL) infrequently occurred in the same sounds. In line with the results of previous studies, discrimination performance deteriorated with increasing magnitude of the task-irrelevant intensity change. However, these distraction effects were dissimilar for intensity increments and decrements: while there were no differences in reaction time (RT) between intensity decrements and increments, hit rates (HR) were lower for large intensity increments than for large decrements. ERPs to task-irrelevant intensity increments and decrements were also distinctly different: the response to intensity increments consisted of an N1 enhancement, mismatch negativity (MMN), and P3a, while the response to intensity decrements consisted only of MMN. These results are consistent with the assumption that two separate mechanisms (indexed by N1 and MMN) underlie auditory change detection. However, the finding that distinct distraction effects were obtained for both intensity decrements and increments but that the P3a is elicited only by the intensity increments seems to suggest that P3a may not be regarded as a general index of attentional shift but rather it is only generated in conditions in which an enhanced N1 is elicited, too.},
author = {Rinne, Teemu and S\"{a}rkk\"{a}, Anna and Degerman, Alexander and Schr\"{o}ger, Erich and Alho, Kimmo},
doi = {10.1016/j.brainres.2006.01.043},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rinne et al/Rinne et al. - 2006 - Two separate mechanisms underlie auditory change detection and involuntary control of attention. - Brain research.pdf:pdf},
issn = {0006-8993},
journal = {Brain research},
keywords = {Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Field Dependence-Independence,Humans,Male,Reference Values},
month = mar,
number = {1},
pages = {135--43},
pmid = {16487946},
title = {{Two separate mechanisms underlie auditory change detection and involuntary control of attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16487946},
volume = {1077},
year = {2006}
}
@article{Wainwright2007,
author = {Wainwright, Martin J. and Jordan, Michael I.},
doi = {10.1561/2200000001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wainwright, Jordan/Wainwright, Jordan - 2007 - Graphical Models, Exponential Families, and Variational Inference - Foundations and Trends® in Machine Lear.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends® in Machine Learning},
number = {1–2},
pages = {1--305},
title = {{Graphical Models, Exponential Families, and Variational Inference}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL\&doi=2200000001},
volume = {1},
year = {2007}
}
@article{Shannon1948,
author = {Shannon, CE},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shannon/Shannon - 1948 - A mathematical theory of communication - The Bell System Technical Journal.pdf:pdf},
journal = {The Bell System Technical Journal},
number = {July},
pages = {379--423; 623--656},
title = {{A mathematical theory of communication}},
url = {http://dl.acm.org/citation.cfm?id=584093},
volume = {27},
year = {1948}
}
@article{Naselaris2009,
abstract = {Recent studies have used fMRI signals from early visual areas to reconstruct simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural encoding model that characterizes responses in early visual areas, a semantic encoding model that characterizes responses in anterior visual areas, and prior information about the structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect on the quality of natural image reconstructions. We also demonstrate that much of the variance in the responses of anterior visual areas to complex natural images is explained by the semantic category of the image alone.},
author = {Naselaris, Thomas and Prenger, Ryan J and Kay, Kendrick N and Oliver, Michael and Gallant, Jack L},
doi = {10.1016/j.neuron.2009.09.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Naselaris et al/Naselaris et al. - 2009 - Bayesian reconstruction of natural images from human brain activity. - Neuron.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Bayes Theorem,Brain Mapping,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models, Neurological,Oxygen,Oxygen: blood,Photic Stimulation,Photic Stimulation: methods,Psychophysics,Semantics,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: blood supply,Visual Cortex: physiology,Visual Perception},
month = oct,
number = {6},
pages = {902--15},
pmid = {19778517},
title = {{Bayesian reconstruction of natural images from human brain activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19778517},
volume = {63},
year = {2009}
}
@article{Raftopoulos2009,
author = {Raftopoulos, Athanassios},
file = {:Users/pkmital/Documents/Mendeley Desktop/Raftopoulos/Raftopoulos - 2009 - Cognition and perception - Unknown.pdf:pdf},
isbn = {9780262013215},
title = {{Cognition and perception}},
url = {http://mitpress.mit.edu/books/chapters/0262013215chap1.pdf},
year = {2009}
}
@article{Kotchoubey2006,
abstract = {The prevailing cognitive-psychological accounts of event-related brain potentials (ERPs) assume that ERP components manifest information processing operations leading from stimulus to response. Since this view encounters numerous difficulties already analyzed in previous studies, an alternative view is presented here that regards cortical control of behavior as a repetitive sensorimotor cycle consisting of two phases: (i) feedforward anticipation and (ii) feedback cortical performance. This view allows us to interpret in an integrative manner numerous data obtained from very different domains of ERP studies: from biophysics of ERP waves to their relationship to the processing of language, in which verbal behavior is viewed as likewise controlled by the same two basic control processes: feedforward (hypothesis building) and feedback (hypothesis checking). The proposed approach is intentionally simplified, explaining numerous effects on the basis of few assumptions and relating several levels of analysis: neurophysiology, macroelectrical processes (i.e. ERPs), cognition and behavior. It can, therefore, be regarded as a first approximation to a general theory of ERPs.},
author = {Kotchoubey, Boris},
doi = {10.1016/j.neubiorev.2005.04.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kotchoubey/Kotchoubey - 2006 - Event-related potentials, cognition, and behavior a biological approach. - Neuroscience and biobehavioral reviews.pdf:pdf},
issn = {0149-7634},
journal = {Neuroscience and biobehavioral reviews},
keywords = {Animals,Attention,Attention: physiology,Behavior,Behavior: physiology,Cognition,Cognition: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Feedback,Humans,Language,Models, Biological},
month = jan,
number = {1},
pages = {42--65},
pmid = {16033699},
title = {{Event-related potentials, cognition, and behavior: a biological approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16033699},
volume = {30},
year = {2006}
}
@inproceedings{Bottcher2009,
abstract = {A simple audio only game was designed in order to test the possibilities of different interactive sound synthesis techniques simulating aerodynamic sword-like sounds. The Wii remote was used as the controller for generating the sound and this device was connected to the Max/MSP sound synthesis engine. In order to gain a user centered perspective on the potential of the diverse synthesis techniques, in terms of sound quality, interactivity and entertainment value, several techniques to synthesize real time interactive sword-like sounds were implemented. In this test a sample based model was compared to physically inspired modal synthesis, purely perceptually modeled subtractive synthesis and granular synthesis.},
author = {B\"{o}ttcher, Niels and Serafin, Stefania},
booktitle = {Proc. of the Audio Engineering Society 35th International Conference, London},
file = {::},
pages = {1--6},
title = {{Design and Evaluation of Physically Inspired Models of Sound Effects in Computer Games}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=15167},
year = {2009}
}
@article{DiCarlo2012,
abstract = {Mounting evidence suggests that 'core object recognition,' the ability to rapidly recognize objects despite substantial appearance variation, is solved in the brain via a cascade of reflexive, largely feedforward computations that culminate in a powerful neuronal representation in the inferior temporal cortex. However, the algorithm that produces this solution remains poorly understood. Here we review evidence ranging from individual neurons and neuronal populations to behavior and computational models. We propose that understanding this algorithm will require using neuronal and psychophysical data to sift through many computational models, each based on building blocks of small, canonical subnetworks with a common functional goal.},
author = {DiCarlo, James J and Zoccolan, Davide and Rust, Nicole C},
doi = {10.1016/j.neuron.2012.01.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/DiCarlo, Zoccolan, Rust/DiCarlo, Zoccolan, Rust - 2012 - How does the brain solve visual object recognition - Neuron.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Attention,Attention: physiology,Brain,Brain: cytology,Brain: physiology,Cognition,Cognition: physiology,Humans,Models, Neurological,Neurons,Neurons: physiology,Pattern Recognition, Visual,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology},
month = feb,
number = {3},
pages = {415--34},
pmid = {22325196},
publisher = {Elsevier Inc.},
title = {{How does the brain solve visual object recognition?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3306444\&tool=pmcentrez\&rendertype=abstract},
volume = {73},
year = {2012}
}
@article{Hansen2007,
abstract = {The existence and location of a human counterpart of macaque visual area V4 are disputed. To resolve this issue, we used functional magnetic resonance imaging to obtain topographic maps from human subjects, using visual stimuli and tasks designed to maximize accuracy of topographic maps of the fovea and parafovea and to measure the effects of attention on topographic maps. We identified multiple topographic transitions, each clearly visible in > or = 75\% of the maps, that we interpret as boundaries of distinct cortical regions. We call two of these regions dorsal V4 and ventral V4 (together comprising human area V4) because they share several defining characteristics with the macaque regions V4d and V4v (which together comprise macaque area V4). Ventral V4 is adjacent to V3v, and dorsal V4 is adjacent to parafoveal V3d. Ventral V4 and dorsal V4 meet in the foveal confluence shared by V1, V2, and V3. Ventral V4 and dorsal V4 represent complementary regions of the visual field, because ventral V4 represents the upper field and a subregion of the lower field, whereas dorsal V4 represents lower-field locations that are not represented by ventral V4. Finally, attentional modulation of spatial tuning is similar across dorsal and ventral V4, but attention has a smaller effect in V3d and V3v and a larger effect in a neighboring lateral occipital region.},
author = {Hansen, Kathleen a and Kay, Kendrick N and Gallant, Jack L},
doi = {10.1523/JNEUROSCI.2991-07.2007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hansen, Kay, Gallant/Hansen, Kay, Gallant - 2007 - Topographic organization in and near human visual area V4. - The Journal of neuroscience the official jou.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Brain Mapping,Functional Laterality,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Oxygen,Oxygen: blood,Photic Stimulation,Photic Stimulation: methods,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: anatomy \& histology},
month = oct,
number = {44},
pages = {11896--911},
pmid = {17978030},
title = {{Topographic organization in and near human visual area V4.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17978030},
volume = {27},
year = {2007}
}
@article{Birchfield2003,
address = {New York, New York, USA},
author = {Birchfield, David},
doi = {10.1145/982484.982504},
file = {::},
isbn = {1581137753},
journal = {Proceedings of the 2003 ACM SIGMM workshop on Experiential telepresence - ETP '03},
keywords = {arts,composition,digital audio,generative,generative model,generative system,genetic algorithm,multimedia,music,music cognition,music theory,perception},
pages = {99},
publisher = {ACM Press},
title = {{Generative model for the creation of musical emotion, meaning, and form}},
url = {http://portal.acm.org/citation.cfm?doid=982484.982504},
year = {2003}
}
@article{Forssen2007,
author = {Forss\'{e}n, Per-Erik},
file = {:Users/pkmital/Documents/Mendeley Desktop/Forss\'{e}n/Forss\'{e}n - 2007 - Maximally stable colour regions for recognition and matching - Computer Vision and Pattern Recognition 2007, (CVPR07).pdf:pdf},
journal = {Computer Vision and Pattern Recognition 2007, (CVPR07).},
title = {{Maximally stable colour regions for recognition and matching}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270145},
year = {2007}
}
@article{Taylor1998,
author = {Taylor, Tracy L and Klein, Raymond M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Taylor, Klein/Taylor, Klein - 1998 - On the causes and effects of inhibition of return - Psychonomic Bulletin \& Review.pdf:pdf},
journal = {Psychonomic Bulletin \& Review},
number = {4},
pages = {625--643},
title = {{On the causes and effects of inhibition of return}},
volume = {5},
year = {1998}
}
@inproceedings{Veneri2008,
address = {Paris},
author = {Veneri, Olivier and Planqueel, Yann},
booktitle = {Game Developers Conference},
file = {::},
title = {{Create a scalable and creative audio environment: middleware project PLAY ALL}},
year = {2008}
}
@article{Kavukcuoglu,
author = {Kavukcuoglu, Koray and Sermanet, Pierre and Boureau, Y-lan and Gregor, Karol and Lecun, Yann},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kavukcuoglu et al/Kavukcuoglu et al. - Unknown - Learning Convolutional Feature Hierarchies for Visual Recognition - New York.pdf:pdf},
journal = {New York},
number = {1},
pages = {1--9},
title = {{Learning Convolutional Feature Hierarchies for Visual Recognition}}
}
@article{Haxby2011,
author = {Haxby, James V. and Guntupalli, J. Swaroop and Connolly, Andrew C. and Halchenko, Yaroslav O. and Conroy, Bryan R. and Gobbini, M. Ida and Hanke, Michael and Ramadge, Peter J.},
doi = {10.1016/j.neuron.2011.08.026},
file = {:Users/pkmital/Documents/Mendeley Desktop/Haxby et al/Haxby et al. - 2011 - A Common, High-Dimensional Model of the Representational Space in Human Ventral Temporal Cortex - Neuron.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = oct,
number = {2},
pages = {404--416},
title = {{A Common, High-Dimensional Model of the Representational Space in Human Ventral Temporal Cortex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627311007811},
volume = {72},
year = {2011}
}
@article{Vikram2011,
author = {Vikram, Tadmeri Narayan and Tscherepanow, Marko and Wrede, Britta},
doi = {10.1109/WACV.2011.5711499},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vikram, Tscherepanow, Wrede/Vikram, Tscherepanow, Wrede - 2011 - A random center surround bottom up visual attention model useful for salient region detection - 201.pdf:pdf},
isbn = {978-1-4244-9496-5},
journal = {2011 IEEE Workshop on Applications of Computer Vision (WACV)},
month = jan,
pages = {166--173},
publisher = {Ieee},
title = {{A random center surround bottom up visual attention model useful for salient region detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5711499},
year = {2011}
}
@article{Hubel1974,
author = {Hubel, D H and Wiesel, T N},
doi = {10.1002/cne.901580304},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hubel, Wiesel/Hubel, Wiesel - 1974 - Sequence regularity and geometry of orientation columns in the monkey striate cortex. - The Journal of comparative neurology.pdf:pdf},
issn = {0021-9967},
journal = {The Journal of comparative neurology},
keywords = {Animals,Brain Mapping,Cats,Dominance, Cerebral,Electric Stimulation,Electrophysiology,Functional Laterality,Macaca,Macaca: anatomy \& histology,Orientation,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Fields,Visual Perception,Visual Perception: physiology},
month = dec,
number = {3},
pages = {267--93},
pmid = {4436456},
title = {{Sequence regularity and geometry of orientation columns in the monkey striate cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/4436456},
volume = {158},
year = {1974}
}
@article{Kliegl2006,
abstract = {Reading requires the orchestration of visual, attentional, language-related, and oculomotor processing constraints. This study replicates previous effects of frequency, predictability, and length of fixated words on fixation durations in natural reading and demonstrates new effects of these variables related to 144 sentences. Such evidence for distributed processing of words across fixation durations challenges psycholinguistic immediacy-of-processing and eye-mind assumptions. Most of the time the mind processes several words in parallel at different perceptual and cognitive levels. Eye movements can help to unravel these processes.},
author = {Kliegl, Reinhold and Nuthmann, Antje and Engbert, Ralf},
doi = {10.1037/0096-3445.135.1.12},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kliegl, Nuthmann, Engbert/Kliegl, Nuthmann, Engbert - 2006 - Tracking the mind during reading the influence of past, present, and future words on fixation durations. - Journal of experimental psychology. General.pdf:pdf},
issn = {0096-3445},
journal = {Journal of experimental psychology. General},
keywords = {Adolescent,Adult,Aged,Aged, 80 and over,Comprehension,Eye Movements,Female,Fixation, Ocular,Humans,Male,Middle Aged,Orientation,Psycholinguistics,Reaction Time,Reading,Regression Analysis,Semantics,Visual Fields},
month = feb,
number = {1},
pages = {12--35},
pmid = {16478314},
title = {{Tracking the mind during reading: the influence of past, present, and future words on fixation durations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16478314},
volume = {135},
year = {2006}
}
@article{Hollingworth2002,
author = {Hollingworth, Andrew and Henderson, John M},
doi = {10.1037//0096-1523.28.1.113},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Henderson/Hollingworth, Henderson - 2002 - Accurate Visual Memory for Previously Attended Objects in Natural Scenes - Perception.pdf:pdf},
journal = {Perception},
number = {1},
pages = {113--136},
title = {{Accurate Visual Memory for Previously Attended Objects in Natural Scenes}},
volume = {28},
year = {2002}
}
@book{RistoMikkulainen2005,
abstract = {For more than 30 years, the visual cortex has been the source of new theories and ideas about how the brain processes information. The visual cortex is easily accessible through a variety of recording and imagining techniques and allows mapping of high level behavior relatively directly to neural mechanisms. Understanding the computations in the visual cortex is therefore an important step toward a general theory of computational brain theory.},
editor = {Mikkulainen, Risto},
isbn = {0387220240},
pages = {538},
publisher = {Springer},
title = {{Computational Maps in the Visual Cortex}},
url = {http://books.google.co.uk/books/about/Computational\_Maps\_in\_the\_Visual\_Cortex.html?id=A25SmJVTZq0C\&pgis=1},
year = {2005}
}
@inproceedings{Hoffman2008,
author = {Hoffman, Matthew and Blei, David and Cook, Perry},
booktitle = {International Symposium on Music Information Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hoffman, Blei, Cook/Hoffman, Blei, Cook - 2008 - Content-based musical similarity computation using the hierarchical dirichlet process - International Symposium on Music Information Retrieval.pdf:pdf},
pages = {1--6},
title = {{Content-based musical similarity computation using the hierarchical dirichlet process}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OHp3sRnZD-oC\&amp;oi=fnd\&amp;pg=PA349\&amp;dq=CONTENT-BASED+MUSICAL+SIMILARITY+COMPUTATION+USING+THE+HIERARCHICAL+DIRICHLET+PROCESS\&amp;ots=oDMNnClva-\&amp;sig=Jw3Wa\_p-4ugXg4GWBD9MuEk\_IYI},
year = {2008}
}
@article{Serre,
author = {Serre, T. and Wolf, L. and Poggio, T.},
doi = {10.1109/CVPR.2005.254},
file = {:Users/pkmital/Documents/Mendeley Desktop/Serre, Wolf, Poggio/Serre, Wolf, Poggio - Unknown - Object Recognition with Features Inspired by Visual Cortex - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05).pdf:pdf},
isbn = {0-7695-2372-2},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
pages = {994--1000},
publisher = {Ieee},
title = {{Object Recognition with Features Inspired by Visual Cortex}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467551},
volume = {2}
}
@article{Robertson1993,
author = {Robertson, GG and Card, SK and Mackinlay, Jock D.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Robertson, Card, Mackinlay/Robertson, Card, Mackinlay - 1993 - Information visualization using 3D interactive animation - Communications of the ACM.pdf:pdf},
journal = {Communications of the ACM},
number = {4},
title = {{Information visualization using 3D interactive animation}},
url = {http://dl.acm.org/citation.cfm?id=153577},
year = {1993}
}
@article{Tervaniemi1997a,
abstract = {Infrequent (10\%) pure tones were randomly presented among nine different missing-fundamental tones having the same pitch (10\% each) to subjects playing a computer game. MMN (an index of pre-attentive change detection) was elicited by timbre-deviant pure tones with 150 and 500 ms stimulus duration. This suggests that the spectral component of timbre is pre-attentively determined from relatively short (150 ms) acoustic samples. Previous research established that resolving the pitch of the same missing-fundamental tones requires longer (> 150 ms) sounds. Consequently, timbre and pitch are probably determined by separate neural processes. The present results also demonstrate pre-attentive categorization of sounds based on timbre as MMN could only be elicited by the pure tones if their timbre was contrasted with the combined group of the nine standard sounds of qualitatively similar rich timbre.},
author = {Tervaniemi, M and Winkler, I and N\"{a}\"{a}t\"{a}nen, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tervaniemi, Winkler, N\"{a}\"{a}t\"{a}nen/Tervaniemi, Winkler, N\"{a}\"{a}t\"{a}nen - 1997 - Pre-attentive categorization of sounds by timbre as revealed by event-related potentials. - Ne.pdf:pdf},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Adult,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Random Allocation,Sound,Time Factors},
month = jul,
number = {11},
pages = {2571--4},
pmid = {9261829},
title = {{Pre-attentive categorization of sounds by timbre as revealed by event-related potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9261829},
volume = {8},
year = {1997}
}
@article{Rabiner1989,
author = {Rabiner, L.R.},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=18626},
volume = {77},
year = {1989}
}
@article{Parikh2008,
author = {Parikh, Devi and Zitnick, C. Lawrence},
doi = {10.1109/CVPR.2008.4587595},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Zitnick/Parikh, Zitnick - 2008 - From appearance to context-based recognition Dense labeling in small images - 2008 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1--8},
publisher = {Ieee},
title = {{From appearance to context-based recognition: Dense labeling in small images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587595},
year = {2008}
}
@article{Schedl2011,
author = {Schedl, Markus and Knees, Peter and B\"{o}ck, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schedl, Knees, B\"{o}ck/Schedl, Knees, B\"{o}ck - 2011 - Investigating the Similarity Space of Music Artists on the Micro-Blogosphere - Proceedings of the Internat.pdf:pdf},
journal = {Proceedings of the International Symposium on Music Information Retrieval (ISMIR2011)},
title = {{Investigating the Similarity Space of Music Artists on the Micro-Blogosphere}},
url = {http://www.mirlab.org/conference\_papers/International\_Conference/ISMIR 2011/papers/OS4-3.pdf},
year = {2011}
}
@article{Chklovskii2004,
abstract = {In mammalian visual cortex, neurons are organized according to their functional properties into multiple maps such as retinotopic, ocular dominance, orientation preference, direction of motion, and others. What determines the organization of cortical maps? We argue that cortical maps reflect neuronal connectivity in intracortical circuits. Because connecting distant neurons requires costly wiring (i.e., axons and dendrites), there is an evolutionary pressure to place connected neurons as close to each other as possible. Then, cortical maps may be viewed as solutions that minimize wiring cost for given intracortical connectivity. These solutions can help us in inferring intracortical connectivity and, ultimately, in understanding the function of the visual system.},
author = {Chklovskii, Dmitri B and Koulakov, Alexei a},
doi = {10.1146/annurev.neuro.27.070203.144226},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chklovskii, Koulakov/Chklovskii, Koulakov - 2004 - Maps in the brain what can we learn from them - Annual review of neuroscience.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Axons,Axons: physiology,Axons: ultrastructure,Brain Mapping,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Humans,Nerve Net,Nerve Net: anatomy \& histology,Nerve Net: growth \& development,Nerve Net: physiology,Neural Pathways,Neural Pathways: anatomy \& histology,Neural Pathways: growth \& development,Neural Pathways: physiology,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: growth \& development,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: anatomy \& histology,Visual Pathways: growth \& development,Visual Pathways: physiology},
month = jan,
number = {Mitchison 1991},
pages = {369--92},
pmid = {15217337},
title = {{Maps in the brain: what can we learn from them?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15217337},
volume = {27},
year = {2004}
}
@article{Woodward2006a,
author = {Woodward, Charles},
file = {::},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
title = {{Implementation of an Augmented Reality System on a PDA}},
year = {2006}
}
@article{Tatler2011,
author = {Tatler, Benjamin W and Hayhoe, Mary M and Land, Michael F and Ballard, Dana H},
doi = {10.1167/11.5.5.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler et al/Tatler et al. - 2011 - Eye guidance in natural vision Reinterpreting salience - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,11,1167,2011,23,5,b,ballard,citation,content,d,doi,eye guidance in natural,eye movements,f,h,hayhoe,http,journal of vision,journalofvision,land,learning,m,natural tasks,org,prediction,reinterpreting,reward,salience,tatler,vision,w,www},
pages = {1--23},
title = {{Eye guidance in natural vision : Reinterpreting salience}},
volume = {11},
year = {2011}
}
@article{Sutton1965a,
author = {Sutton, S and Braren, M and John, ER and Zubin, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sutton et al/Sutton et al. - 1965 - Evoked-potential correlates of stimulus uncertainty - Science(2).pdf:pdf},
journal = {Science},
title = {{Evoked-potential correlates of stimulus uncertainty}},
url = {http://www.sciencemag.org/content/150/3700/1187.short},
year = {1965}
}
@inproceedings{Donoser2006,
author = {Donoser, Michael and Bischof, Horst},
booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donoser, Bischof/Donoser, Bischof - 2006 - 3D segmentation by maximally stable volumes (MSVs) - Pattern Recognition, 2006. ICPR 2006. 18th International Conference on.pdf:pdf},
pages = {63--66},
publisher = {IEEE},
title = {{3D segmentation by maximally stable volumes (MSVs)}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1698834},
volume = {1},
year = {2006}
}
@article{Hutchison1973a,
author = {Hutchison, David and Mitchell, John C and Forsyth, David and Torr, Philip},
journal = {New York},
title = {{Computer Vision – ECCV 2008 10th European Conference on Computer Vision}},
year = {1973}
}
@phdthesis{Glenncross2002a,
author = {Glenncross, Masshuda},
file = {::},
school = {University of Manchester},
title = {{A Framework for Physically Based Modelling in Virtual Reality}},
year = {2002}
}
@article{VandenDoel,
author = {van den Doel, Kees and Pai, Dinesh K.},
file = {::},
journal = {Audio anecdotes},
pages = {1--8},
title = {{Modal Synthesis for Vibrating Objects}}
}
@article{Zwislocki1960,
author = {Zwislocki, J.},
doi = {10.1121/1.1908276},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
language = {en},
month = aug,
number = {8},
pages = {1046},
publisher = {Acoustical Society of America},
title = {{Theory of Temporal Auditory Summation}},
url = {http://link.aip.org/link/?JASMAN/32/1046/1},
volume = {32},
year = {1960}
}
@article{Kimurac,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - Unknown - Multiterminal source coding for cascading and feedback refinement - Unknown.pdf:pdf},
keywords = {cascading,feedback,multiterminal source coding,refinement,scalable coding,side information},
title = {{Multiterminal source coding for cascading and feedback refinement}}
}
@article{Eitz2012,
author = {Eitz, Mathias and Richter, Ronald and Boubekeur, Tamy and Hildebrand, Kristian and Alexa, Marc},
doi = {10.1145/2185520.2185527},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eitz et al/Eitz et al. - 2012 - Sketch-based shape retrieval - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {Shape Retrieval, Visual Search, Bag-of-Features, L,bag-of-features,lo-,shape retrieval,visual search},
month = jul,
number = {4},
pages = {1--10},
title = {{Sketch-based shape retrieval}},
url = {http://dl.acm.org/citation.cfm?doid=2185520.2185527},
volume = {31},
year = {2012}
}
@article{Wang2010,
author = {Scotia, Nova},
doi = {10.3758/APP},
file = {:Users/pkmital/Documents/Mendeley Desktop/Scotia/Scotia - 2010 - Inhibition of return in static but not necessarily in dynamic search - Unknown.pdf:pdf},
number = {1},
pages = {76--85},
title = {{Inhibition of return in static but not necessarily in dynamic search}},
volume = {72},
year = {2010}
}
@article{Kurzhals2013,
abstract = {We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shotbased, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.},
author = {Kurzhals, Kuno and Weiskopf, Daniel},
doi = {10.1109/TVCG.2013.194},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kurzhals, Weiskopf/Kurzhals, Weiskopf - 2013 - Space-time visual analytics of eye-tracking data for dynamic stimuli. - IEEE transactions on visualization a.pdf:pdf},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
month = dec,
number = {12},
pages = {2129--38},
pmid = {24051779},
title = {{Space-time visual analytics of eye-tracking data for dynamic stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24051779},
volume = {19},
year = {2013}
}
@article{Kayser2005b,
abstract = {Our nervous system is confronted with a barrage of sensory stimuli, but neural resources are limited and not all stimuli can be processed to the same extent. Mechanisms exist to bias attention toward the particularly salient events, thereby providing a weighted representation of our environment. Our understanding of these mechanisms is still limited, but theoretical models can replicate such a weighting of sensory inputs and provide a basis for understanding the underlying principles. Here, we describe such a model for the auditory system-an auditory saliency map. We experimentally validate the model on natural acoustical scenarios, demonstrating that it reproduces human judgments of auditory saliency and predicts the detectability of salient sounds embedded in noisy backgrounds. In addition, it also predicts the natural orienting behavior of naive macaque monkeys to the same salient stimuli. The structure of the suggested model is identical to that of successfully used visual saliency maps. Hence, we conclude that saliency is determined either by implementing similar mechanisms in different unisensory pathways or by the same mechanism in multisensory areas. In any case, our results demonstrate that different primate sensory systems rely on common principles for extracting relevant sensory events.},
author = {Kayser, Christoph and Petkov, Christopher I and Lippert, Michael and Logothetis, Nikos K},
doi = {10.1016/j.cub.2005.09.040},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kayser et al/Kayser et al. - 2005 - Mechanisms for allocating auditory attention an auditory saliency map. - Current biology CB(3).pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Acoustic Stimulation,Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Macaca mulatta,Macaca mulatta: physiology,Models, Neurological,Orientation,Orientation: physiology,Species Specificity},
month = nov,
number = {21},
pages = {1943--7},
pmid = {16271872},
title = {{Mechanisms for allocating auditory attention: an auditory saliency map.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271872},
volume = {15},
year = {2005}
}
@article{Henderson1999b,
abstract = {Target objects presented within color images of naturalistic scenes were deleted or rotated during a saccade to or from the target object or to a control region of the scene. Despite instructions to memorize the details of the scenes and to monitor for object changes, viewers frequently failed to notice the changes. However, the failure to detect change was mediated by three other important factors: First, accuracy generally increased as the distance between the changing region and the fixation immediately before or after the change decreased. Second, changes were sometimes initially missed, but subsequently noticed when the changed region was later refixated. Third, when an object disappeared from a scene, detection of that disappearance was greatly improved when the deletion occurred during the saccade toward that object. These results suggest that fixation position and saccade direction play an important role in determining whether changes will be detected. It appears that more information can be retained across views than has been suggested by previous studies.},
author = {Henderson, John M and Hollingworth, Andrew},
doi = {10.1111/1467-9280.00183},
issn = {09567976},
journal = {Psychological Science},
number = {5},
pages = {438--443},
publisher = {SAGE Publications},
title = {{The Role of Fixation Position in Detecting Scene Changes Across Saccades}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.00183},
volume = {10},
year = {1999}
}
@article{Geisler2006,
abstract = {Two of the factors limiting progress in understanding the mechanisms of visual search are the difficulty of controlling and manipulating the retinal stimulus when the eyes are free to move and the lack of an ideal observer theory for fixation selection during search. Recently, we developed a method to precisely control retinal stimulation with gaze-contingent displays (J. S. Perry \& W. S. Geisler, 2002), and we derived a theory of optimal eye movements in visual search (J. Najemnik \& W. S. Geisler, 2005). Here, we report a parametric study of visual search for sine-wave targets added to spatial noise backgrounds that have spectral characteristics similar to natural images (the amplitude spectrum of the noise falls inversely with spatial frequency). Search time, search accuracy, and eye fixations were measured as a function of target spatial frequency, 1/f noise contrast, and the resolution falloff of the display from the point of fixation. The results are systematic and similar for the two observers. We find that many aspects of search performance and eye movement pattern are similar to those of an ideal searcher that has the same falloff in resolution with retinal eccentricity as the human visual system.},
author = {Geisler, Wilson S and Perry, Jeffrey S and Najemnik, Jiri},
doi = {10.1167/6.9.1},
file = {:Users/pkmital/Documents/Mendeley Desktop/Geisler, Perry, Najemnik/Geisler, Perry, Najemnik - 2006 - Visual search the role of peripheral information measured using gaze-contingent displays. - Journal of vision.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Artifacts,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Models, Psychological,Photic Stimulation,Retina,Retina: physiology,Space Perception,Space Perception: physiology,Time Factors,Visual Perception,Visual Perception: physiology},
month = jan,
number = {9},
pages = {858--73},
pmid = {17083280},
title = {{Visual search: the role of peripheral information measured using gaze-contingent displays.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17083280},
volume = {6},
year = {2006}
}
@article{Laubrock2006,
abstract = {Research on eye movements in reading has made significant advances during the past few years, due to both experimental and computational research. Age effects have not been extensively studied, but the overall pattern suggests more quantitative than qualitative differences in fixation durations and fixation probabilities. Here we focus on age-differential effects of word frequency on reading time and on probabilities of skipping a word or regressing to previous ones. We present an overview of SWIFT [Engbert, R., Nuthmann, A., Richter, E.M., Kliegl, R., 2005. SWIFT: a dynamical model of saccade generation during reading. Psychological Review 112, 777-813], a fully implemented computational model of saccade generation and lexical processing during reading, based on spatially distributed processing over several words. Preliminary simulations of age differences recovered most, but not all experimental effects. Age differences in parameter estimates point towards an important role of visual acuity for oculomotor as well as lexical processing.},
author = {Laubrock, Jochen and Kliegl, Reinhold and Engbert, Ralf},
doi = {10.1016/j.neubiorev.2006.06.013},
file = {:Users/pkmital/Documents/Mendeley Desktop/Laubrock, Kliegl, Engbert/Laubrock, Kliegl, Engbert - 2006 - SWIFT explorations of age differences in eye movements during reading. - Neuroscience and biobehavioral reviews.pdf:pdf},
issn = {0149-7634},
journal = {Neuroscience and biobehavioral reviews},
keywords = {Aging,Aging: physiology,Computer Simulation,Eye Movements,Eye Movements: physiology,Humans,Models, Biological,Reading},
month = jan,
number = {6},
pages = {872--84},
pmid = {16904181},
title = {{SWIFT explorations of age differences in eye movements during reading.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16904181},
volume = {30},
year = {2006}
}
@inproceedings{Raghuvanshi2009,
abstract = {We present a method for real-time sound propagation that captures all wave effects, including diffraction and reverberation, for multiple moving sources and a moving listener in a complex, static 3D scene. It performs an offline numerical simulation over the scene and then applies a novel technique to extract and compactly en- code the perceptually salient information in the resulting acoustic responses. Each response is automatically broken into two phases: early reflections (ER) and late reverberation (LR), via a threshold on the temporal density of arriving wavefronts. The LR is simulated and stored in the frequency domain, once per room in the scene. The ER accounts for more detailed spatial variation, by recording a set of peak delays/amplitudes in the time domain and a residual frequency response sampled in octave frequency bands, at each source/receiver point pair in a 5D grid. An efficient run-time uses this precomputed representation to perform binaural sound rendering based on frequency-domain convolution. Our system demonstrates realistic, wave-based acoustic effects in real time, including diffraction low-passing behind obstructions, sound focusing, hollow reverberation in empty rooms, sound diffusion in fully-furnished rooms, and realistic late reverberation.},
address = {Los Angeles},
author = {Raghuvanshi, Nikunj and Snyder, John and Mehra, Ravish and Lin, Ming and Govindaraju, Naga},
booktitle = {SIGGRAPH 2010: The 37th International Conference and Exhibition on Computer Graphics and Interactive Techniques.},
file = {::},
title = {{Precomputed Wave Simulation for Real-Time Sound Propagation of Dynamic Sources in Complex Scenes}},
year = {2009}
}
@article{Judd2009,
author = {Judd, Tilke and Ehinger, Krista and Durand, Fredo and Torralba, Antonio},
doi = {10.1109/ICCV.2009.5459462},
file = {:Users/pkmital/Documents/Mendeley Desktop/Judd et al/Judd et al. - 2009 - Learning to predict where humans look - 2009 IEEE 12th International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4244-4420-5},
journal = {2009 IEEE 12th International Conference on Computer Vision},
month = sep,
pages = {2106--2113},
publisher = {Ieee},
title = {{Learning to predict where humans look}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459462},
year = {2009}
}
@article{Brosch2011,
abstract = {Selective attention is not a unitary construct, but is composed of several processes. Attention selection may be guided by low-level stimulus properties, by the emotional value of the stimulus, or more voluntarily by the goals and plans of the observer. Whether these three systems operate independently during attention selection or not remains a debated question. We report results from two studies investigating the extent to which these different attention mechanisms may interact with one another. Using a standard dot probe paradigm wherein effects of exogenous, emotional, and endogenous attention were orthogonally manipulated, we found attentional facilitation effects for each component, indicated by faster decision times for validly, as opposed to invalidly cued targets. Moreover, results confirmed that these three attentional effects added up in a linear fashion. Complementing ERP results allowed us to disentangle the respective contributions of the two reflexive, bottom-up attention processes (exogenous vs. emotional) by showing non-overlapping temporal loci for attentional effects related either to low-level physical properties or the emotional content of the stimulus. These findings suggest that multiple separate attention mechanisms can operate simultaneously to yield a rapid and efficient visual processing of various classes of potentially relevant stimuli.},
author = {Brosch, Tobias and Pourtois, Gilles and Sander, David and Vuilleumier, Patrik},
doi = {10.1016/j.neuropsychologia.2011.02.056},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brosch et al/Brosch et al. - 2011 - Additive effects of emotional, endogenous, and exogenous attention behavioral and electrophysiological evidence. - Neuropsychologia.pdf:pdf},
issn = {1873-3514},
journal = {Neuropsychologia},
month = jun,
number = {7},
pages = {1779--87},
pmid = {21382388},
publisher = {Elsevier Ltd},
title = {{Additive effects of emotional, endogenous, and exogenous attention: behavioral and electrophysiological evidence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21382388},
volume = {49},
year = {2011}
}
@article{Hard2006,
abstract = {Everyday events, such as making a bed, can be segmented hierarchically, with the coarse level characterized by changes in the actor's goals and the fine level by subgoals (Zacks, Tversky, \& Iyer, 2001). Does hierarchical event perception depend on knowledge of actors' intentions? This question was addressed by asking participants to segment films of abstract, schematic events. Films were novel or familiarized, viewed forward or backward, and simultaneously described or not. The participants interpreted familiar films as more intentional than novel films and forward films as more intentional than backward films. Regardless of experience and film direction, however, the participants identified similar event boundaries and organized them hierarchically. An analysis of the movements in each frame revealed that event segments corresponded to bursts of change in movement features, with greater bursts for coarse than for fine units. Perceiving event structure appears to enable event schemas, rather than resulting from them.},
author = {Hard, Bridgette M and Tversky, Barbara and Lang, David S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hard, Tversky, Lang/Hard, Tversky, Lang - 2006 - Making sense of abstract events building event schemas. - Memory \& cognition.pdf:pdf},
issn = {0090-502X},
journal = {Memory \& cognition},
keywords = {Concept Formation,Cues,Discrimination Learning,Goals,Humans,Intention,Locomotion,Motion Perception,Orientation,Pattern Recognition, Visual,Problem Solving,Psychomotor Performance,Reversal Learning,Social Environment},
month = sep,
number = {6},
pages = {1221--35},
pmid = {17225504},
title = {{Making sense of abstract events: building event schemas.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17225504},
volume = {34},
year = {2006}
}
@article{Benson2009,
abstract = {Saccadic scanning was examined for typically developing (TD) adults and those with autistic spectrum disorder (ASD) during inspection of the 'Repin' picture (Yarbus, A. (1967). Eye movements and vision. New York: Plenum) under two different viewing instructions: (A) material instructions ('Estimate the material circumstances of the family'); and (B) social instructions ('Estimate how long the unexpected visitor has been away'). Proportions of fixations and viewing time on the people and the objects in the scene differed between the two task instructions for TD, but not ASD participants showing that people with ASD did not differentially sample the scene according to top down instruction. One tentative explanation for these findings is that dysfunctional or underdeveloped fronto-parietal feedback systems in ASD, could result in defective saccadic sampling strategies, leading to impairments with cognitive processing in ASD.},
author = {Benson, Valerie and Piper, Jenna and Fletcher-Watson, Sue},
doi = {10.1016/j.neuropsychologia.2008.11.019},
file = {:Users/pkmital/Documents/Mendeley Desktop/Benson, Piper, Fletcher-Watson/Benson, Piper, Fletcher-Watson - 2009 - Atypical saccadic scanning in autistic spectrum disorder. - Neuropsychologia.pdf:pdf},
issn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Adolescent,Analysis of Variance,Attention,Attention: physiology,Autistic Disorder,Autistic Disorder: physiopathology,Autistic Disorder: psychology,Eye Movements,Eye Movements: physiology,Facial Expression,Female,Head Movements,Humans,Male,Motion Pictures as Topic,Neuropsychological Tests,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Social Perception,Time Factors,Young Adult},
month = mar,
number = {4},
pages = {1178--82},
pmid = {19094999},
title = {{Atypical saccadic scanning in autistic spectrum disorder.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19094999},
volume = {47},
year = {2009}
}
@article{Greene2009a,
abstract = {Human observers are able to rapidly and accurately categorize natural scenes, but the representation mediating this feat is still unknown. Here we propose a framework of rapid scene categorization that does not segment a scene into objects and instead uses a vocabulary of global, ecological properties that describe spatial and functional aspects of scene space (such as navigability or mean depth). In Experiment 1, we obtained ground truth rankings on global properties for use in Experiments 2-4. To what extent do human observers use global property information when rapidly categorizing natural scenes? In Experiment 2, we found that global property resemblance was a strong predictor of both false alarm rates and reaction times in a rapid scene categorization experiment. To what extent is global property information alone a sufficient predictor of rapid natural scene categorization? In Experiment 3, we found that the performance of a classifier representing only these properties is indistinguishable from human performance in a rapid scene categorization task in terms of both accuracy and false alarms. To what extent is this high predictability unique to a global property representation? In Experiment 4, we compared two models that represent scene object information to human categorization performance and found that these models had lower fidelity at representing the patterns of performance than the global property model. These results provide support for the hypothesis that rapid categorization of natural scenes may not be mediated primarily though objects and parts, but also through global properties of structure and affordance.},
author = {Greene, Michelle R and Oliva, Aude},
doi = {10.1016/j.cogpsych.2008.06.001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Greene, Oliva/Greene, Oliva - 2009 - Recognition of natural scenes from global properties seeing the forest without representing the trees. - Cognitive psychology.pdf:pdf},
issn = {1095-5623},
journal = {Cognitive psychology},
keywords = {Adolescent,Adult,Female,Humans,Male,Models, Psychological,Pattern Recognition, Visual,Reaction Time},
month = mar,
number = {2},
pages = {137--76},
pmid = {18762289},
publisher = {Elsevier Inc.},
title = {{Recognition of natural scenes from global properties: seeing the forest without representing the trees.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2759758\&tool=pmcentrez\&rendertype=abstract},
volume = {58},
year = {2009}
}
@article{Itti2001,
abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
author = {Itti, L and Koch, C},
doi = {10.1038/35058500},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Koch/Itti, Koch - 2001 - Computational modelling of visual attention. - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Humans,Models, Neurological,Neurons,Neurons: metabolism,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = mar,
number = {3},
pages = {194--203},
pmid = {11256080},
title = {{Computational modelling of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11256080},
volume = {2},
year = {2001}
}
@article{Collins2009,
author = {Collins, Karen},
doi = {10.1080/07494460802663983},
file = {::},
issn = {0749-4467},
journal = {Contemporary Music Review},
month = feb,
number = {1},
pages = {5--15},
title = {{An Introduction to Procedural Music in Video Games}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/07494460802663983\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {28},
year = {2009}
}
@article{Ehinger2009,
abstract = {How predictable are human eye movements during search in real world scenes? We recorded 14 observers' eye movements as they performed a search task (person detection) in 912 outdoor scenes. Observers were highly consistent in the regions fixated during search, even when the target was absent from the scene. These eye movements were used to evaluate computational models of search guidance from three sources: saliency, target features, and scene context. Each of these models independently outperformed a cross-image control in predicting human fixations. Models that combined sources of guidance ultimately predicted 94\% of human agreement, with the scene context component providing the most explanatory power. None of the models, however, could reach the precision and fidelity of an attentional map defined by human fixations. This work puts forth a benchmark for computational models of search in real world scenes. Further improvements in modeling should capture mechanisms underlying the selectivity of observer's fixations during search.},
author = {Ehinger, Krista a and Hidalgo-Sotelo, Barbara and Torralba, Antonio and Oliva, Aude},
doi = {10.1080/13506280902834720},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ehinger et al/Ehinger et al. - 2009 - Modeling Search for People in 900 Scenes A combined source model of eye guidance. - Visual cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual cognition},
month = aug,
number = {6-7},
pages = {945--978},
pmid = {20011676},
title = {{Modeling Search for People in 900 Scenes: A combined source model of eye guidance.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2790194\&tool=pmcentrez\&rendertype=abstract},
volume = {17},
year = {2009}
}
@article{Alain2000,
author = {Alain, Claude and Arnott, Stephen R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alain, Arnott/Alain, Arnott - 2000 - Selectively attending to auditory objects - Frontiers in Bioscience.pdf:pdf},
journal = {Frontiers in Bioscience},
number = {10},
pages = {202--212},
title = {{Selectively attending to auditory objects}},
url = {http://www.bioscience.org/2000/v5/d/alain/fulltext.htm},
year = {2000}
}
@article{Brenner2000,
abstract = {The idea that extra-retinal information about the orientation of the eyes could be used to judge an object's distance has a long history, and has been the issue of considerable debate throughout this century. We here show that the poor performance in comparison with judgements of direction has geometrical rather than physiological reasons, and discuss why previous studies have misled us into believing that information about distance is even poorer than the geometry predicts.},
author = {Brenner, E and Smeets, J B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brenner, Smeets/Brenner, Smeets - 2000 - Comparing extra-retinal information about distance and direction. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Convergence, Ocular,Convergence, Ocular: physiology,Distance Perception,Distance Perception: physiology,Humans,Mathematics,Saccades,Saccades: physiology,Size Perception,Size Perception: physiology,Space Perception,Space Perception: physiology,Vision, Binocular,Vision, Binocular: physiology},
month = jan,
number = {13},
pages = {1649--51},
pmid = {10814753},
title = {{Comparing extra-retinal information about distance and direction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10814753},
volume = {40},
year = {2000}
}
@article{Pazo-Alvarez2003,
author = {Pazo-Alvarez, P. and Cadaveira, F. and Amenedo, E.},
doi = {10.1016/S0301-0511(03)00049-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pazo-Alvarez, Cadaveira, Amenedo/Pazo-Alvarez, Cadaveira, Amenedo - 2003 - MMN in the visual modality a review - Biological Psychology.pdf:pdf},
issn = {03010511},
journal = {Biological Psychology},
keywords = {e v ent-related potential,erp,mismatch negati v ity,mmn,preattentional processing,vision},
month = jul,
number = {3},
pages = {199--236},
title = {{MMN in the visual modality: a review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0301051103000498},
volume = {63},
year = {2003}
}
@article{Hutchinson2009,
abstract = {Functional neuroimaging studies of humans engaged in retrieval from episodic memory have revealed a surprisingly consistent pattern of retrieval-related activity in lateral posterior parietal cortex (PPC). Given the well-established role of lateral PPC in subserving goal-directed and reflexive attention, it has been hypothesized that PPC activation during retrieval reflects the recruitment of parietal attention mechanisms during remembering. Here, we evaluate this hypothesis by considering the anatomical overlap of retrieval and attention effects in lateral PPC. We begin by briefly reviewing the literature implicating dorsal PPC in goal-directed attention and ventral PPC in reflexive attention. We then discuss the pattern of dorsal and ventral PPC activation during episodic retrieval, and conclude with consideration of the degree of anatomical convergence across the two domains. This assessment revealed that predominantly divergent subregions of lateral PPC are engaged during acts of episodic retrieval and during goal-directed and reflexive attention, suggesting that PPC retrieval effects reflect functionally distinct mechanisms from these forms of attention. Although attention must play a role in aspects of retrieval, the data reviewed here suggest that further investigation into the relationship between processes of attention and memory, as well as alternative accounts of PPC contributions to retrieval, is warranted.},
author = {Hutchinson, J Benjamin and Uncapher, Melina R and Wagner, Anthony D},
doi = {10.1101/lm.919109},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hutchinson, Uncapher, Wagner/Hutchinson, Uncapher, Wagner - 2009 - Posterior parietal cortex and episodic retrieval convergent and divergent effects of attention and memory. - Learning \& memory (Cold Spring Harbor, N.Y.).pdf:pdf},
issn = {1549-5485},
journal = {Learning \& memory (Cold Spring Harbor, N.Y.)},
keywords = {Animals,Attention,Attention: physiology,Brain Mapping,Discrimination Learning,Humans,Memory,Memory: physiology,Parietal Lobe,Parietal Lobe: anatomy \& histology,Parietal Lobe: physiology},
month = jun,
number = {6},
pages = {343--56},
pmid = {19470649},
title = {{Posterior parietal cortex and episodic retrieval: convergent and divergent effects of attention and memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2704099\&tool=pmcentrez\&rendertype=abstract},
volume = {16},
year = {2009}
}
@article{Colin2002,
abstract = {The ventriloquism effect is the tendency to underestimate the spatial separation between synchronous auditory and visual signals moderately separated in space. If, as it is thought, this effect is pre-attentive, it could modulate the mismatch negativity (MMN) that indexes the automatic, pre-attentive detection of deviant auditory stimuli rarely occurring in a sequence of standard stimuli. We assessed the existence of an MMN evoked by auditory and visual signals made up of standard sounds coming from the same location as the visual signal and deviant sounds coming from lateral deviations (20 or 60 degrees). As first observed in a behavioral study, a ventriloquism effect occurred for 20 degrees spatial separation but not for 60 degrees.},
author = {Colin, C and Radeau, M and Soquet, a and Dachy, B and Deltenre, P},
file = {:Users/pkmital/Documents/Mendeley Desktop/Colin et al/Colin et al. - 2002 - Electrophysiology of spatial scene analysis the mismatch negativity (MMN) is sensitive to the ventriloquism illusion. - Clinical neurophysiology official journal of the International Federation of Clinical Neurophysiology.pdf:pdf},
isbn = {1322650454},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Acoustic Stimulation: statistics \& numerical data,Adolescent,Adult,Analysis of Variance,Electrophysiology,Evoked Potentials,Evoked Potentials: physiology,Female,Humans,Illusions,Illusions: physiology,Male,Middle Aged,Photic Stimulation,Photic Stimulation: methods,Spatial Behavior,Spatial Behavior: physiology},
month = apr,
number = {4},
pages = {507--18},
pmid = {11955995},
title = {{Electrophysiology of spatial scene analysis: the mismatch negativity (MMN) is sensitive to the ventriloquism illusion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11955995},
volume = {113},
year = {2002}
}
@article{Kanoh2001,
author = {Kanoh, S and Arai, Toshinori and Futami, R. and Hoshimiya, N.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kanoh et al/Kanoh et al. - 2001 - Properties of auditory temporal integration revealed by mismatch negativity - Engineering in Medicine and Biology.pdf:pdf},
journal = {Engineering in Medicine and Biology Society, 2001. Proceedings of the 23rd Annual International Conference of the IEEE},
keywords = {at-,audition,mismatch negativity,mmn,ory,sensory mem-,temporal integration,temporal sequence},
title = {{Properties of auditory temporal integration revealed by mismatch negativity}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1019123},
volume = {1},
year = {2001}
}
@article{Bevilacqua,
author = {Bevilacqua, Frederic and Schnell, Norbert and Rasamimanana, Nicolas and Zamborlin, Bruno and Guedy, Fabrice},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bevilacqua et al/Bevilacqua et al. - Unknown - Online Gesture Analysis and Control of Audio Processing - interactions.pdf:pdf},
journal = {interactions},
keywords = {gesture control,gesture following,gesture recognition,interactive systems,music,sound synthesis},
title = {{Online Gesture Analysis and Control of Audio Processing}}
}
@article{Bar2004,
author = {Bar, Moshe},
doi = {10.1038/nrn1476},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bar/Bar - 2004 - Visual objects in context. - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Nerve Net,Nerve Net: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Visual Perception,Visual Perception: physiology},
month = aug,
number = {8},
pages = {617--29},
pmid = {15263892},
title = {{Visual objects in context.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15263892},
volume = {5},
year = {2004}
}
@inproceedings{Matas2002,
author = {Matas, J and Chum, O and Urban, M and Pajdla, T},
booktitle = {British Machine Vision Conference},
doi = {10.1016/j.imavis.2004.02.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Matas et al/Matas et al. - 2002 - Robust wide-baseline stereo from maximally stable extremal regions - British Machine Vision Conference.pdf:pdf},
issn = {02628856},
month = sep,
number = {10},
pages = {384--393},
title = {{Robust wide-baseline stereo from maximally stable extremal regions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885604000435},
volume = {22},
year = {2002}
}
@inproceedings{Smaragdis2010,
author = {Smaragdis, P. and Raj, B.},
booktitle = {Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Raj/Smaragdis, Raj - 2010 - The Markov selection model for concurrent speech recognition - Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop on.pdf:pdf},
issn = {1551-2541},
pages = {214--219},
publisher = {IEEE},
title = {{The Markov selection model for concurrent speech recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5588124},
year = {2010}
}
@article{Smith2013,
author = {Smith, Tim J and Mital, Parag K},
doi = {10.1167/XX.XX.XX.doi},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Mital/Smith, Mital - 2013 - Attentional synchrony and the influence of viewing task on gaze behavior in static and dynamic scenes - Journal of.pdf:pdf},
journal = {Journal of Vision},
number = {June},
pages = {1--25},
title = {{Attentional synchrony and the influence of viewing task on gaze behavior in static and dynamic scenes}},
volume = {13},
year = {2013}
}
@article{Henderson1987,
abstract = {The results of three different experiments suggested that the relation between an object in the fovea on fixation n and an object subsequently brought into the fovea on fixation n + 1 affects the time to identify the second object. In Experiment 1 we extended previous work by demonstrating that a previously seen related priming object speeded the time to name a target object even when a saccade intervened between the two objects. In Experiment 2 we replicated this result and further showed that the benefit on naming time was due to facilitation from the related object rather than inhibition from the unrelated object. In addition, naming of the target object was much slower in both experiments when there was not a peripheral preview of the target object on fixation n. However, because the effect of the foveal priming object was greater when the target was not present than when it was present, priming did not appear to make extraction of the extrafoveal information more efficient. In Experiment 3, fixation times were recorded while subjects looked at four objects in order to identify them. Fixation time on an object was shorter when a related object was fixated immediately before it, even though the four objects did not form a scene. The size of the facilitation was roughly comparable to that in several analogous experiments where scenes were used. The results suggest that the effects of a predictive scene context on object identification may be explainable in terms of an object-to-object or "intralevel" priming mechanism.},
author = {Henderson, J M and Pollatsek, a and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Pollatsek, Rayner/Henderson, Pollatsek, Rayner - 1987 - Effects of foveal priming and extrafoveal preview on object identification. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Cues,Eye Movements,Fixation, Ocular,Fovea Centralis,Fovea Centralis: physiology,Humans,Inhibition (Psychology),Macula Lutea,Macula Lutea: physiology,Reaction Time,Semantics,Visual Perception,Visual Perception: physiology},
month = aug,
number = {3},
pages = {449--63},
pmid = {2958593},
title = {{Effects of foveal priming and extrafoveal preview on object identification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2958593},
volume = {13},
year = {1987}
}
@article{Santella2004,
address = {New York, New York, USA},
author = {Santella, Anthony and DeCarlo, Doug},
doi = {10.1145/968363.968368},
file = {:Users/pkmital/Documents/Mendeley Desktop/Santella, DeCarlo/Santella, DeCarlo - 2004 - Robust clustering of eye movement recordings for quantification of visual interest - Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004.pdf:pdf},
isbn = {1581138253},
journal = {Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004},
keywords = {clustering,eye movement analysis,mean shift,measures of visual interest},
pages = {27--34},
publisher = {ACM Press},
title = {{Robust clustering of eye movement recordings for quantification of visual interest}},
url = {http://portal.acm.org/citation.cfm?doid=968363.968368},
year = {2004}
}
@article{Hinterstoisser2010a,
author = {Hinterstoisser, Stefan and Lepetit, Vincent and Ilic, Slobodan and Fua, Pascal and Navab, Nassir},
doi = {10.1109/CVPR.2010.5539908},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hinterstoisser et al/Hinterstoisser et al. - 2010 - Dominant orientation templates for real-time detection of texture-less objects - 2010 IEEE Computer Socie.pdf:pdf},
isbn = {978-1-4244-6984-0},
journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {2257--2264},
publisher = {Ieee},
title = {{Dominant orientation templates for real-time detection of texture-less objects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539908},
year = {2010}
}
@article{Naatanen1978,
author = {N\"{a}\"{a}t\"{a}nen, R and Gaillard, AWK and M\"{a}ntysalo, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen, Gaillard, M\"{a}ntysalo/N\"{a}\"{a}t\"{a}nen, Gaillard, M\"{a}ntysalo - 1978 - Early selective-attention effect on evoked potential reinterpreted - Acta psychologica.pdf:pdf},
journal = {Acta psychologica},
pages = {313--329},
title = {{Early selective-attention effect on evoked potential reinterpreted}},
url = {http://www.sciencedirect.com/science/article/pii/0001691878900069},
volume = {42},
year = {1978}
}
@article{Henderson1995,
author = {Henderson, John M. and Dixon, Peter and Petersen, Alan and Twilley, Leslie C.},
doi = {10.1037//0096-1523.21.1.82},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson et al/Henderson et al. - 1995 - Evidence for the use of phonological representations during transsaccadic word recognition. - Journal of Experimental Psychology Human Perception and Performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {1},
pages = {82--97},
title = {{Evidence for the use of phonological representations during transsaccadic word recognition.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.21.1.82},
volume = {21},
year = {1995}
}
@article{Mihalas2011,
abstract = {Visual attention is often understood as a modulatory field acting at early stages of processing, but the mechanisms that direct and fit the field to the attended object are not known. We show that a purely spatial attention field propagating downward in the neuronal network responsible for perceptual organization will be reshaped, repositioned, and sharpened to match the object's shape and scale. Key features of the model are grouping neurons integrating local features into coherent tentative objects, excitatory feedback to the same local feature neurons that caused grouping neuron activation, and inhibition between incompatible interpretations both at the local feature level and at the object representation level.},
author = {Mihalas, Stefan and Dong, Yi and von der Heydt, R\"{u}diger and Niebur, Ernst},
doi = {10.1073/pnas.1014655108},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mihalas et al/Mihalas et al. - 2011 - Mechanisms of perceptual organization provide auto-zoom and auto-localization for attention to objects. - Proceedings of the National Academy of Sciences of the United States of America.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = may,
number = {18},
pages = {7583--8},
pmid = {21502489},
title = {{Mechanisms of perceptual organization provide auto-zoom and auto-localization for attention to objects.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3088583\&tool=pmcentrez\&rendertype=abstract},
volume = {108},
year = {2011}
}
@article{Fox2007,
author = {Fox, Emily B and Sudderth, Erik B and Jordan, Michael I and Willsky, Alan S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fox et al/Fox et al. - 2007 - Developing a tempered HDP-HMM for Systems with State Persistence - Technology.pdf:pdf},
journal = {Technology},
number = {November},
pages = {1--44},
title = {{Developing a tempered HDP-HMM for Systems with State Persistence}},
year = {2007}
}
@misc{Aufderheide2008,
author = {Aufderheide, Pat and Jaszi, Peter},
title = {{Center for Social Media: Recut, Reframe, Recycle}},
url = {http://www.centerforsocialmedia.org/fair-use/best-practices/online-video/recut-reframe-recycle},
year = {2008}
}
@inproceedings{Menzies2009,
abstract = {Phya is an open source C++ library that facilitates physically motivated audio in virtual environments. A review is presented and recent developments in the context of game audio, including the launch of VFoley, a project using Phya as the basis for a fully fledged virtual sound design environment. This will enable sound designers to rapidly produce rich Foley content from within a virtual environment, and author enhanced objects for use by Phya enabled applications.},
address = {London, UK.},
author = {Menzies, Dylan},
booktitle = {AES 35th International Conference},
file = {::},
pages = {1--8},
title = {{Phya and VFoley , Physically Motivated Audio for Virtual Environments}},
year = {2009}
}
@article{Eitz2011,
author = {Eitz, Mathias and Richter, Ronald and Hildebrand, Kristian and Boubekeur, Tamy and Alexa, Marc},
doi = {10.1109/MCG.2011.67},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eitz et al/Eitz et al. - 2011 - Photosketcher Interactive Sketch-Based Image Synthesis - IEEE Computer Graphics and Applications.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
month = nov,
number = {6},
pages = {56--66},
title = {{Photosketcher: Interactive Sketch-Based Image Synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5959134},
volume = {31},
year = {2011}
}
@article{Moradi2003,
author = {Moradi, F. and Liu, L.C. and Cheng, K. and Waggoner, R.a. and Tanaka, K. and a.a. Ioannides},
doi = {10.1016/S1053-8119(02)00053-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Moradi et al/Moradi et al. - 2003 - Consistent and precise localization of brain activity in human primary visual cortex by MEG and fMRI - NeuroImage.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {field,fmri,functional magnetic resonance imaging,human,magnetic field tomography,magnetoencephalography,meg,mft,primary visual cortex,striate cortex or v1,visual evoked},
month = mar,
number = {3},
pages = {595--609},
title = {{Consistent and precise localization of brain activity in human primary visual cortex by MEG and fMRI}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811902000538},
volume = {18},
year = {2003}
}
@article{Murphy-Chutorian2009,
abstract = {The capacity to estimate the head pose of another person is a common human ability that presents a unique challenge for computer vision systems. Compared to face detection and recognition, which have been the primary foci of face-related vision research, identity-invariant head pose estimation has fewer rigorously evaluated systems or generic solutions. In this paper, we discuss the inherent difficulties in head pose estimation and present an organized survey describing the evolution of the field. Our discussion focuses on the advantages and disadvantages of each approach and spans 90 of the most innovative and characteristic papers that have been published on this topic. We compare these systems by focusing on their ability to estimate coarse and fine head pose, highlighting approaches that are well suited for unconstrained environments.},
author = {Murphy-Chutorian, Erik and Trivedi, Mohan Manubhai},
doi = {10.1109/TPAMI.2008.106},
file = {:Users/pkmital/Documents/Mendeley Desktop/Murphy-Chutorian, Trivedi/Murphy-Chutorian, Trivedi - 2009 - Head pose estimation in computer vision a survey. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Artificial Intelligence,Head,Humans,Nonlinear Dynamics,Video Recording,Visual Perception},
month = apr,
number = {4},
pages = {607--26},
pmid = {19229078},
title = {{Head pose estimation in computer vision: a survey.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19229078},
volume = {31},
year = {2009}
}
@article{Bendixen2009,
abstract = {The auditory system has been shown to detect predictability in a tone sequence, but does it use the extracted regularities for actually predicting the continuation of the sequence? The present study sought to find evidence for the generation of such predictions. Predictability was manipulated in an isochronous series of tones in which every other tone was a repetition of its predecessor. The existence of predictions was probed by occasionally omitting either the first (unpredictable) or the second (predictable) tone of a same-frequency tone pair. Event-related electrical brain activity elicited by the omission of an unpredictable tone differed from the response to the actual tone right from the tone onset. In contrast, early electrical brain activity elicited by the omission of a predictable tone was quite similar to the response to the actual tone. This suggests that the auditory system preactivates the neural circuits for expected input, using sequential predictions to specifically prepare for future acoustic events.},
author = {Bendixen, Alexandra and Schr\"{o}ger, Erich and Winkler, Istv\'{a}n},
doi = {10.1523/JNEUROSCI.1493-09.2009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bendixen, Schr\"{o}ger, Winkler/Bendixen, Schr\"{o}ger, Winkler - 2009 - I heard that coming event-related potential evidence for stimulus-driven prediction in the auditor.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Hearing,Humans,Male,Predictive Value of Tests,Psychoacoustics,Young Adult},
month = jul,
number = {26},
pages = {8447--51},
pmid = {19571135},
title = {{I heard that coming: event-related potential evidence for stimulus-driven prediction in the auditory system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19571135},
volume = {29},
year = {2009}
}
@article{Klin2003,
abstract = {Normative-IQ individuals with autism are capable of solving explicit social cognitive problems at a level that is not matched by their ability to meet the demands of everyday social situations. The magnitude of this discrepancy is now being documented through newer techniques such as eye tracking, which allows us to see and measure how individuals with autism search for meaning when presented with naturalistic social scenes. This paper offers an approach to social cognitive development intended to address the above discrepancy, which is considered a key element for any understanding of the pathophysiology of autism. This approach, called the enactive mind (EM), originates from the emerging work on 'embodied cognitive science', a neuroscience framework that views cognition as bodily experiences accrued as a result of an organism's adaptive actions upon salient aspects of the surrounding environment. The EM approach offers a developmental hypothesis of autism in which the process of acquisition of embodied social cognition is derailed early on, as a result of reduced salience of social stimuli and concomitant enactment of socially irrelevant aspects of the environment.},
author = {Klin, Ami and Jones, Warren and Schultz, Robert and Volkmar, Fred},
doi = {10.1098/rstb.2002.1202},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klin et al/Klin et al. - 2003 - The enactive mind, or from actions to cognition lessons from autism. - Philosophical transactions of the Royal Society of London. Series B, Biological sciences.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Autistic Disorder,Autistic Disorder: psychology,Cognition,Humans,Psychological Theory,Psychophysiology,Visual Perception},
month = mar,
number = {1430},
pages = {345--60},
pmid = {12639332},
title = {{The enactive mind, or from actions to cognition: lessons from autism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12639332},
volume = {358},
year = {2003}
}
@article{Apter1969a,
author = {Apter, MJ},
file = {:Users/pkmital/Documents/Mendeley Desktop/Apter/Apter - 1969 - Cybernetics and art - Leonardo(2).pdf:pdf},
journal = {Leonardo},
number = {3},
pages = {257--265},
title = {{Cybernetics and art}},
url = {http://www.jstor.org/stable/10.2307/1572155},
volume = {2},
year = {1969}
}
@inproceedings{Mital2012b,
author = {Mital, Parag Kumar and Grierson, Mick},
booktitle = {International Symposium on Music Information Retrieval 2012 (In Review)},
title = {{Audio Content-based Information Display: Mining Unknown Electronic Music Databases through Interactive Visualization of Latent Component Relationships}},
year = {2012}
}
@phdthesis{Perry1991,
author = {Perry, Ramond Cook},
file = {::},
pages = {171},
school = {Stanford University},
title = {{Identification of Control Parameters in an Articulatory Vocal Tract Model, with Applications to the Synthesis of Singing}},
type = {Doctor of Philosophy},
year = {1991}
}
@phdthesis{Bimber2005a,
author = {Bimber, O. and Raskar, R.},
file = {::},
publisher = {Peters},
title = {{Spatial augmented reality}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Spatial+Augmented+Reality\#0},
year = {2005}
}
@article{Kumar2002,
author = {Kumar, Arun N and Han, Yanning and Ramat, Stefano and Leigh, R John},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kumar et al/Kumar et al. - 2002 - Anticipatory saccadic-vergence responses in humans. - Annals of the New York Academy of Sciences.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
keywords = {Convergence, Ocular,Convergence, Ocular: physiology,Fixation, Ocular,Humans,Neurons,Neurons: physiology,Photic Stimulation,Reaction Time,Saccades,Saccades: physiology},
month = apr,
pages = {495--8},
pmid = {11960850},
title = {{Anticipatory saccadic-vergence responses in humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11960850},
volume = {956},
year = {2002}
}
@article{Tsotsos2005,
author = {Tsotsos, John K. and Liu, Yueju and Martinez-Trujillo, Julio C. and Pomplun, Marc and Simine, Evgueni and Zhou, Kunhao},
doi = {10.1016/j.cviu.2004.10.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tsotsos et al/Tsotsos et al. - 2005 - Attending to visual motion - Computer Vision and Image Understanding.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {affine motion,attention,feature binding,selective tuning,visual motion analysis},
month = oct,
number = {1-2},
pages = {3--40},
title = {{Attending to visual motion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314205000779},
volume = {100},
year = {2005}
}
@article{Sziklai1956,
author = {Sziklai, George},
journal = {IEEE Transactions on Information Theory},
number = {3},
pages = {125--128},
title = {{Some studies in the speed of visual perception}},
volume = {2},
year = {1956}
}
@article{Kimura2006a,
author = {Kimura, Akisato and Uyematsu, Tomohiko and Systems, Integrated},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu, Systems/Kimura, Uyematsu, Systems - 2006 - Multiterminal source coding for cascading and feedback refinemet systems - Science.pdf:pdf},
journal = {Science},
pages = {1--28},
title = {{Multiterminal source coding for cascading and feedback refinemet systems}},
year = {2006}
}
@misc{Compuserve1987,
author = {Compuserve},
booktitle = {http://www.w3.org/},
file = {:Users/pkmital/Documents/Mendeley Desktop/Compuserve/Compuserve - 1987 - GIF (tm) Graphics Interchange Format (tm) A standard defining a mechanism for the storage and transmission of raste.html:html},
title = {{GIF (tm) Graphics Interchange Format (tm) A standard defining a mechanism for the storage and transmission of raster-based graphics information}},
url = {http://www.w3.org/Graphics/GIF/spec-gif87.txt},
urldate = {20/09/13},
year = {1987}
}
@article{Bressloff2002,
abstract = {Many observers see geometric visual hallucinations after taking hallucinogens such as LSD, cannabis, mescaline or psilocybin; on viewing bright flickering lights; on waking up or falling asleep; in "near-death" experiences; and in many other syndromes. Kl\"{u}ver organized the images into four groups called form constants: (I) tunnels and funnels, (II) spirals, (III) lattices, including honeycombs and triangles, and (IV) cobwebs. In most cases, the images are seen in both eyes and move with them. We interpret this to mean that they are generated in the brain. Here, we summarize a theory of their origin in visual cortex (area V1), based on the assumption that the form of the retino-cortical map and the architecture of V1 determine their geometry. (A much longer and more detailed mathematical version has been published in Philosophical Transactions of the Royal Society B, 356 [2001].) We model V1 as the continuum limit of a lattice of interconnected hypercolumns, each comprising a number of interconnected iso-orientation columns. Based on anatomical evidence, we assume that the lateral connectivity between hypercolumns exhibits symmetries, rendering it invariant under the action of the Euclidean group E(2), composed of reflections and translations in the plane, and a (novel) shift-twist action. Using this symmetry, we show that the various patterns of activity that spontaneously emerge when V1's spatially uniform resting state becomes unstable correspond to the form constants when transformed to the visual field using the retino-cortical map. The results are sensitive to the detailed specification of the lateral connectivity and suggest that the cortical mechanisms that generate geometric visual hallucinations are closely related to those used to process edges, contours, surfaces, and textures.},
author = {Bressloff, Paul C and Cowan, Jack D and Golubitsky, Martin and Thomas, Peter J and Wiener, Matthew C},
doi = {10.1162/089976602317250861},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bressloff et al/Bressloff et al. - 2002 - What geometric visual hallucinations tell us about the visual cortex. - Neural computation.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Hallucinations,Hallucinations: physiopathology,Humans,Mathematics,Models, Neurological,Visual Cortex,Visual Cortex: physiopathology},
month = mar,
number = {3},
pages = {473--91},
pmid = {11860679},
title = {{What geometric visual hallucinations tell us about the visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11860679},
volume = {14},
year = {2002}
}
@article{Maji2009,
author = {Maji, S. and Malik, J.},
doi = {10.1109/CVPR.2009.5206693},
file = {:Users/pkmital/Documents/Mendeley Desktop/Maji, Malik/Maji, Malik - 2009 - Object detection using a max-margin Hough transform - 2009 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1038--1045},
publisher = {Ieee},
title = {{Object detection using a max-margin Hough transform}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206693},
year = {2009}
}
@article{Mooser2007,
author = {Mooser, Jonathan and You, Suya and Neumann, Ulrich},
doi = {10.1109/ISMAR.2007.4538839},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mooser, You, Neumann/Mooser, You, Neumann - 2007 - Real-Time Object Tracking for Augmented Reality Combining Graph Cuts and Optical Flow - 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--8},
publisher = {Ieee},
title = {{Real-Time Object Tracking for Augmented Reality Combining Graph Cuts and Optical Flow}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538839},
year = {2007}
}
@article{CaseyICMC2007,
author = {Casey, Michael and Grierson, Mick},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey, Grierson/Casey, Grierson - 2007 - SoundspotterRemix-TV fast approximate matching for audio and video performance - Proceedings of the Internation.pdf:pdf},
journal = {Proceedings of the International Computer Music Conference},
title = {{Soundspotter/Remix-TV: fast approximate matching for audio and video performance}},
url = {http://doc.gold.ac.uk/~mus02mg/wp-content/uploads/soundspotter.pdf},
year = {2007}
}
@article{Ramanan2012,
author = {Ramanan, D.},
doi = {10.1109/CVPR.2012.6248014},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ramanan/Ramanan - 2012 - Face detection, pose estimation, and landmark localization in the wild - 2012 IEEE Conference on Computer Vision and Pa.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {2879--2886},
publisher = {Ieee},
title = {{Face detection, pose estimation, and landmark localization in the wild}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6248014},
year = {2012}
}
@article{Zhang2012a,
abstract = {The bottom-up contribution to the allocation of exogenous attention is a saliency map, whose neural substrate is hard to identify because of possible contamination by top-down signals. We obviated this possibility using stimuli that observers could not perceive, but that nevertheless, through orientation contrast between foreground and background regions, attracted attention to improve a localized visual discrimination. When orientation contrast increased, so did the degree of attraction, and two physiological measures: the amplitude of the earliest (C1) component of the ERP, which is associated with primary visual cortex, and fMRI BOLD signals in areas V1-V4 (but not the intraparietal sulcus). Significantly, across observers, the degree of attraction correlated with the C1 amplitude and just the V1 BOLD signal. These findings strongly support the proposal that a bottom-up saliency map is created in V1, challenging the dominant view that the saliency map is generated in the parietal cortex.},
author = {Zhang, Xilin and Zhaoping, Li and Zhou, Tiangang and Fang, Fang},
doi = {10.1016/j.neuron.2011.10.035},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang et al/Zhang et al. - 2012 - Neural activities in v1 create a bottom-up saliency map. - Neuron.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Contrast Sensitivity,Contrast Sensitivity: physiology,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Image Processing, Computer-Assisted,Male,Models, Biological,Orientation,Oxygen,Oxygen: blood,Photic Stimulation,Photic Stimulation: methods,Psychophysics,Reaction Time,Visual Cortex,Visual Cortex: blood supply,Visual Cortex: physiology,Young Adult},
month = jan,
number = {1},
pages = {183--92},
pmid = {22243756},
publisher = {Elsevier Inc.},
title = {{Neural activities in v1 create a bottom-up saliency map.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22243756},
volume = {73},
year = {2012}
}
@article{King2002,
abstract = {New evidence has challenged a widely accepted interpretation of Hering's law of equal innervation, which states that disjunctive saccades are produced by the linear addition of conjugate and vergence innervation commands produced by independent oculomotor subsystems. We hypothesize, instead, that saccades are produced by a monocular premotor control network. A model, based on this hypothesis and consistent with known brain-stem anatomy, simulates realistic disjunctive saccades including initial and late slow vergence movements.},
author = {King, W M and Zhou, Wu},
file = {:Users/pkmital/Documents/Mendeley Desktop/King, Zhou/King, Zhou - 2002 - Neural basis of disjunctive eye movements. - Annals of the New York Academy of Sciences.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
keywords = {Animals,Eye Movements,Eye Movements: physiology,Haplorhini,Models, Neurological,Saccades,Saccades: physiology,Vision, Binocular,Vision, Binocular: physiology},
month = apr,
pages = {273--83},
pmid = {11960811},
title = {{Neural basis of disjunctive eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11960811},
volume = {956},
year = {2002}
}
@article{Theios1989,
abstract = {This article reviews the research literature on the differences between word reading and picture naming. A theory for the visual and cognitive processing of pictures and words is then introduced. The theory accounts for slower naming of pictures than reading of words. Reading aloud involves a fast, grapheme-to-phoneme transformation process, whereas picture naming involves two additional processes: (a) determining the meaning of the pictorial stimulus and (b) finding a name for the pictorial stimulus. We conducted a reading-naming experiment, and the time to achieve (a) and (b) was determined to be approximately 160 ms. On the basis of data from a second experiment, we demonstrated that there is no significant difference in time to visually compare two pictures or two words when size of the stimuli is equated. There is no difference in time to make the two types of cross-modality conceptual comparisons (picture first, then word, or word first, then picture). The symmetry of the visual and conceptual comparison results supports the hypothesis that the coding of the mind is neither intrinsically linguistic nor imagistic, but rather it is abstract. There is a potent stimulus size effect, equal for both pictorial and lexical stimuli. Small stimuli take longer to be visually processed than do larger stimuli. For optimal processing, stimuli should not only be equated for size, but should subtend a visual angle of at least 3 degrees. The article ends with the presentation of a mathematical theory that jointly accounts for the data from word-reading, picture-naming visual comparison, and conceptual-comparison experiments.},
author = {Theios, J and Amrhein, P C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theios, Amrhein/Theios, Amrhein - 1989 - Theoretical analysis of the cognitive processing of lexical and pictorial stimuli reading, naming, and visual and conceptual comparisons. - Psychological review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Adult,Cognition,Concept Formation,Female,Form Perception,Humans,Male,Pattern Recognition, Visual,Psychological Theory,Reaction Time,Reading,Semantics},
month = jan,
number = {1},
pages = {5--24},
pmid = {2928419},
title = {{Theoretical analysis of the cognitive processing of lexical and pictorial stimuli: reading, naming, and visual and conceptual comparisons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2928419},
volume = {96},
year = {1989}
}
@article{Theeuwes2003,
abstract = {Previous research has shown that in visual search static singletons have the ability to capture attention (Theeuwes, 1991a, 1992). The present study investigated whether these singletons also have the ability to capture the eyes. Participants had to make an eye movement and respond manually to a shape singleton while a color singleton was present. When participants searched for a unique shape while a unique color singleton was present there was strong attentional and oculomotor capture (Experiment 1). However, when participants searched for a specific-shape singleton (a green circle) when a specific-color singleton (a red element) had to be ignored, there was attentional capture but no oculomotor capture (Experiment 2). The results suggest that an attentional set for a specific feature value defining both the target and the distractor (as in Experiment 2) allows such a fast disengagement of attention from the location of the distractor that a saccade execution to that location is prevented.},
author = {Theeuwes, Jan and {De Vries}, Giel-Jan and Godijn, Richard},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theeuwes, De Vries, Godijn/Theeuwes, De Vries, Godijn - 2003 - Attentional and oculomotor capture with static singletons. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Color Perception,Fixation, Ocular,Form Perception,Humans,Reaction Time,Saccades,Saccades: physiology,Visual Perception},
month = jul,
number = {5},
pages = {735--46},
pmid = {12956581},
title = {{Attentional and oculomotor capture with static singletons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12956581},
volume = {65},
year = {2003}
}
@article{Blei2003,
author = {Blei, D.M. and Ng, A.Y. and Jordan, M.I.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Blei, Ng, Jordan/Blei, Ng, Jordan - 2003 - Latent dirichlet allocation - The Journal of Machine Learning Research.pdf:pdf},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
pages = {993--1022},
publisher = {JMLR. org},
title = {{Latent dirichlet allocation}},
url = {http://portal.acm.org/citation.cfm?id=944937},
volume = {3},
year = {2003}
}
@article{Jaeger2006,
author = {Jaeger, Timothy},
file = {:Users/pkmital/Documents/Mendeley Desktop/Jaeger/Jaeger - 2006 - VJ Live Cinema Unraveled - Unknown.pdf:pdf},
title = {{VJ: Live Cinema Unraveled}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:live+cinema+unraveled\#1},
year = {2006}
}
@book{D'Esposito2003,
author = {D'Esposito, M.},
booktitle = {Annals of Physics},
file = {:Users/pkmital/Documents/Mendeley Desktop/D'Esposito/D'Esposito - 2003 - Neurological foundations of cognitive neuroscience - Annals of Physics.pdf:pdf},
isbn = {0262042096},
pages = {258},
publisher = {The MIT Press},
title = {{Neurological foundations of cognitive neuroscience}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=\_yGXmYtUpY4C\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=Neurological+foundations+of+cognitive+neuroscience\&amp;ots=6CMNsFgup-\&amp;sig=4w7K7In1qiXk4sIvJC\_wlKfFTiQ},
volume = {54},
year = {2003}
}
@article{Dominik2009,
author = {Dominik, L and Jarke, Matthias},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dominik, Jarke/Dominik, Jarke - 2009 - Adaptive multimodal exploration of music collections - Proceedings of the 10th International Society for Music I.pdf:pdf},
journal = {Proceedings of the 10th International Society for Music Information Retrieval Conference},
number = {Ismir},
pages = {195--200},
title = {{Adaptive multimodal exploration of music collections}},
year = {2009}
}
@inproceedings{Rath2003,
abstract = {As part of the SOb European project several cartoon models of contact sounds of solid bodies, “hitting”, “bouncing”, “dropping”, “breaking”, “rolling”, have been developed and implemented as modules (and sub-patches) for free real-time sound software pd 1. The models are accessed through perceptually meaningful parameters and run with low computational load on standard PC hardware. The underlying idea of cartoonification, its motivation and background in psychoacoustic research are sketched first. The main common sound-core of most models, a physics-based algorithm of impact-interaction with interacting resonators in modal description, is shortly presented. The impact module is embedded in patches of higher-level control to model more complex contact scenarios. The structure, use and potential of the resulting sound objects is described. While the results are a possible basis for reactive sonic interfaces in Human-Computer-Interaction, they can as well be exploited for musical purposes.},
address = {Firenze, Italy},
author = {Rath, M. and Avanzini, F. and Bernardini, N. and Borin, G. and Fontana, F. and Ottaviani, L. and Rocchesso, D.},
booktitle = {Proceedings of the XIV Colloquium on Musical Informatics (XIV CIM 2003)},
file = {::},
pages = {6},
title = {{An Introductory Catalog of Computer-Synthesized Contact Sounds, in Real-Time}},
year = {2003}
}
@article{Soltani2010a,
abstract = {The primate visual system continuously selects spatial proscribed regions, features or objects for further processing. These selection mechanisms--collectively termed selective visual attention--are guided by intrinsic, bottom-up and by task-dependent, top-down signals. While much psychophysical research has shown that overt and covert attention is partially allocated based on saliency-driven exogenous signals, it is unclear how this is accomplished at the neuronal level. Recent electrophysiological experiments in monkeys point to the gradual emergence of saliency signals when ascending the dorsal visual stream and to the influence of top-down attention on these signals. To elucidate the neural mechanisms underlying these observations, we construct a biologically plausible network of spiking neurons to simulate the formation of saliency signals in different cortical areas. We find that saliency signals are rapidly generated through lateral excitation and inhibition in successive layers of neural populations selective to a single feature. These signals can be improved by feedback from a higher cortical area that represents a saliency map. In addition, we show how top-down attention can affect the saliency signals by disrupting this feedback through its action on the saliency map. While we find that saliency computations require dominant slow NMDA currents, the signal rapidly emerges from successive regions of the network. In conclusion, using a detailed spiking network model we find biophysical mechanisms and limitations of saliency computations which can be tested experimentally.},
author = {Soltani, Alireza and Koch, Christof},
doi = {10.1523/JNEUROSCI.1517-10.2010},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Attention,Attention: physiology,Computer Simulation,Feedback, Physiological,Feedback, Physiological: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Photic Stimulation,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = sep,
number = {38},
pages = {12831--43},
pmid = {20861387},
title = {{Visual saliency computations: mechanisms, constraints, and the effect of feedback.}},
url = {http://www.jneurosci.org/content/30/38/12831.long},
volume = {30},
year = {2010}
}
@inproceedings{Menzies2010,
abstract = {While it may be many years before high resolution active acoustic boundaries will be widely available, accurate soundfield control presents an interesting theoretical problem. We investigate and compare several different methods, including existing methods and two new ones, that aim to find the driving functions for sources on a general boundary, such that any given soundfield is reproduced as accurately as possible everywhere within. The methods considered include High Order Ambisonics, Wavefields, boundary element modeling, a modal boundary decomposition approach, and pressure control points. Finally a method is presented, referred to here as Distributed Modal Constraints, in which multiple regions are constrained by modal expansions simultaneously.},
author = {Menzies, Dylan},
booktitle = {Proceedings of the 2nd International Symposium on Ambisonics and Spherical Acoustics},
file = {::},
title = {{Soundfield Synthesis for General Enclosures}},
year = {2010}
}
@article{Kundu2010,
address = {New York, New York, USA},
author = {Kundu, Abhijit and Krishna, K. Madhava and Jawahar, C. V.},
doi = {10.1145/1924559.1924593},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kundu, Krishna, Jawahar/Kundu, Krishna, Jawahar - 2010 - Realtime motion segmentation based multibody visual SLAM - Proceedings of the Seventh Indian Conference on Computer Vision, Graphics and Image Processing - ICVGIP '10.pdf:pdf},
isbn = {9781450300605},
journal = {Proceedings of the Seventh Indian Conference on Computer Vision, Graphics and Image Processing - ICVGIP '10},
pages = {251--258},
publisher = {ACM Press},
title = {{Realtime motion segmentation based multibody visual SLAM}},
url = {http://portal.acm.org/citation.cfm?doid=1924559.1924593},
year = {2010}
}
@article{Kliegl2007,
abstract = {Using the gaze-contingent boundary paradigm with the boundary placed after word n, the experiment manipulated preview of word n + 2 for fixations on word n. There was no preview benefit for 1st-pass reading on word n + 2, replicating the results of K. Rayner, B. J. Juhasz, and S. J. Brown (2007), but there was a preview benefit on the 3-letter word n + 1, that is, after the boundary but before word n + 2. Additionally, both word n + 1 and word n + 2 exhibited parafoveal-on-foveal effects on word n. Thus, during a fixation on word n and given a short word n + 1, some information is extracted from word n + 2, supporting the hypothesis of distributed processing in the perceptual span.},
author = {Kliegl, Reinhold and Risse, Sarah and Laubrock, Jochen},
doi = {10.1037/0096-1523.33.5.1250},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kliegl, Risse, Laubrock/Kliegl, Risse, Laubrock - 2007 - Preview benefit and parafoveal-on-foveal effects from word n 2. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Fovea Centralis,Fovea Centralis: physiology,Humans,Visual Perception,Vocabulary},
month = oct,
number = {5},
pages = {1250--5},
pmid = {17924820},
title = {{Preview benefit and parafoveal-on-foveal effects from word n + 2.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17924820},
volume = {33},
year = {2007}
}
@article{Kaplan2000a,
address = {New York, New York, USA},
author = {Kaplan, Craig S. and Salesin, David H.},
doi = {10.1145/344779.345022},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kaplan, Salesin/Kaplan, Salesin - 2000 - Escherization - Proceedings of the 27th annual conference on Computer graphics and interactive techniques - SIG.pdf:pdf},
isbn = {1581132085},
journal = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques - SIGGRAPH '00},
keywords = {escher,morphing,optimization,simulated annealing,tesselations,tilings},
pages = {499--510},
publisher = {ACM Press},
title = {{Escherization}},
url = {http://portal.acm.org/citation.cfm?doid=344779.345022},
year = {2000}
}
@article{Adelson1985,
abstract = {A motion sequence may be represented as a single pattern in x-y-t space; a velocity of motion corresponds to a three-dimensional orientation in this space. Motion sinformation can be extracted by a system that responds to the oriented spatiotemporal energy. We discuss a class of models for human motion mechanisms in which the first stage consists of linear filters that are oriented in space-time and tuned in spatial frequency. The outputs of quadrature pairs of such filters are squared and summed to give a measure of motion energy. These responses are then fed into an opponent stage. Energy models can be built from elements that are consistent with known physiology and psychophysics, and they permit a qualitative understanding of a variety of motion phenomena.},
author = {Adelson, E H and Bergen, J R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Adelson, Bergen/Adelson, Bergen - 1985 - Spatiotemporal energy models for the perception of motion. - Journal of the Optical Society of America. A, Optics and image science.pdf:pdf},
issn = {0740-3232},
journal = {Journal of the Optical Society of America. A, Optics and image science},
keywords = {Humans,Models, Psychological,Motion Perception,Motion Perception: physiology,Orientation,Space Perception,Space Perception: physiology,Time Perception,Time Perception: physiology},
month = feb,
number = {2},
pages = {284--99},
pmid = {3973762},
title = {{Spatiotemporal energy models for the perception of motion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3973762},
volume = {2},
year = {1985}
}
@book{Bregman1994,
abstract = {"Bregman has written a major book, a unique and important contribution to the rapidly expanding field of complex auditory perception. This is a big, rich, and fulfilling piece of work that deserves the wide audience it is sure to attract." -- Stewart H. Hulse, "Science" Auditory Scene Analysis addresses the problem of hearing complex auditory environments, using a series of creative analogies to describe the process required of the human auditory system as it analyzes mixtures of sounds to recover descriptions of individual sounds. In a unified and comprehensive way, Bregman establishes a theoretical framework that integrates his findings with an unusually wide range of previous research in psychoacoustics, speech perception, music theory and composition, and computer modeling.},
author = {Bregman, Albert S.},
isbn = {0262521954},
pages = {773},
publisher = {MIT Press},
title = {{Auditory Scene Analysis: The Perceptual Organization of Sound}},
url = {http://books.google.co.uk/books/about/Auditory\_Scene\_Analysis.html?id=jI8muSpAC5AC\&pgis=1},
year = {1994}
}
@article{Binder1999,
abstract = {The present experiment used 2 different eye-contingent display change techniques to determine whether information is extracted from English text even when it is to the left of the currently fixated word. Preview display changes were during the 1st saccade entering the target word region, whereas postview display changes were during the 1st saccade leaving that region. Previews and postviews were either identical, related, or unrelated to the target word. "Wrong" information in the target-word region affected reading even when that information was seen only after readers were fixating to the right of that region: When readers skipped the target word, such information caused readers to regress to the target word more; when readers initially fixated the target word, such information increased "2nd-pass" processing time on the target region. The data suggest that readers often still attend to a word after it is skipped and that when readers fixate a word, they occasionally attend to the word after they have begun to fixate the next word.},
author = {Binder, K S and Pollatsek, a and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Binder, Pollatsek, Rayner/Binder, Pollatsek, Rayner - 1999 - Extraction of information to the left of the fixated word in reading. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Fixation, Ocular,Fixation, Ocular: physiology,Humans,Reading,Visual Fields,Visual Fields: physiology,Vocabulary},
month = aug,
number = {4},
pages = {1162--72},
pmid = {10464948},
title = {{Extraction of information to the left of the fixated word in reading.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10464948},
volume = {25},
year = {1999}
}
@article{Fukuchi,
author = {Fukuchi, Ken and Miyazato, Kouji and Kimura, Akisato and Takagi, Shigeru and Yamato, Junji},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fukuchi et al/Fukuchi et al. - Unknown - Saliency - based video segmentation with graph cuts and sequentially - updated priors - Technology.pdf:pdf},
journal = {Technology},
number = {2},
pages = {2009--2009},
title = {{Saliency - based video segmentation with graph cuts and sequentially - updated priors}}
}
@article{Turatto2001,
abstract = {The aim of the present study was to investigate mechanisms underlying attentional capture by color. Previous work has shown that a color singleton is able to summon attention only in the presence of a relevant attentional set, whereas when a color singleton is not useful for a task, evidence for purely stimulus-driven attentional capture is controversial. Three visual search experiments (T-L task) were conducted using a method different from that based on set sizes, consisting of monitoring target-singleton distance in a unique display size. In Experiment 1, we demonstrated that attention can be summoned in a real stimulus-driven manner by an irrelevant color singleton. Experiment 2A extended this observation, showing that the color singleton attracted attention even when capture was detrimental. However, Experiment 2B showed that such capture can be strategically prevented. Finally, in Experiment 3, we examined whether such a capture was due to a spatial shift or to a filtering cost, providing evidence supporting the shift hypothesis. Stimulus-driven capture was observed when color was neither the defining nor the reported target attribute (Yantis, 1993) and when subjects naive of visual search tasks were used. The present results give experimental support to many contemporary models of visual attention.},
author = {Turatto, M and Galfano, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Turatto, Galfano/Turatto, Galfano - 2001 - Attentional capture by color without any relevant attentional set. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adult,Attention,Color Perception,Female,Humans,Male,Orientation,Pattern Recognition, Visual,Psychophysics,Reaction Time},
month = feb,
number = {2},
pages = {286--97},
pmid = {11281103},
title = {{Attentional capture by color without any relevant attentional set.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11281103},
volume = {63},
year = {2001}
}
@article{Kyprianidis2012,
author = {Kyprianidis, J and Collomosse, John and Wang, Tinghuai and Isenberg, Tobias},
doi = {10.1109/TVCG.2012.160.research.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kyprianidis et al/Kyprianidis et al. - 2012 - State of the 'Art' A Taxonomy of Artistic Stylization Techniques for Images and Video - IEEE transactions on.pdf:pdf},
journal = {IEEE transactions on Visualization and Computer Graphics},
title = {{State of the 'Art': A Taxonomy of Artistic Stylization Techniques for Images and Video}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6243138},
year = {2012}
}
@article{Hohwy2012,
abstract = {Conscious perception and attention are difficult to study, partly because their relation to each other is not fully understood. Rather than conceiving and studying them in isolation from each other it may be useful to locate them in an independently motivated, general framework, from which a principled account of how they relate can then emerge. Accordingly, these mental phenomena are here reviewed through the prism of the increasingly influential predictive coding framework. On this framework, conscious perception can be seen as the upshot of prediction error minimization and attention as the optimization of precision expectations during such perceptual inference. This approach maps on well to a range of standard characteristics of conscious perception and attention, and can be used to interpret a range of empirical findings on their relation to each other.},
author = {Hohwy, Jakob},
doi = {10.3389/fpsyg.2012.00096},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hohwy/Hohwy - 2012 - Attention and conscious perception in the hypothesis testing brain. - Frontiers in psychology.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {blindness,change,free energy,inattentional blindness,precision expectation,prediction error minimization,prediction error minimization, precision expectati,unconscious processing},
month = jan,
number = {April},
pages = {96},
pmid = {22485102},
title = {{Attention and conscious perception in the hypothesis testing brain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3317264\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2012}
}
@article{Rolfs2005,
abstract = {Fixational eye movements occur involuntarily during visual fixation of stationary scenes. The fastest components of these miniature eye movements are microsaccades, which can be observed about once per second. Recent studies demonstrated that microsaccades are linked to covert shifts of visual attention. Here, we generalized this finding in two ways. First, we used peripheral cues, rather than the centrally presented cues of earlier studies. Second, we spatially cued attention in vision and audition to visual and auditory targets. An analysis of microsaccade responses revealed an equivalent impact of visual and auditory cues on microsaccade-rate signature (i.e. an initial inhibition followed by an overshoot and a final return to the pre-cue baseline rate). With visual cues or visual targets, microsaccades were briefly aligned with cue direction and then opposite to cue direction during the overshoot epoch, probably as a result of an inhibition of an automatic saccade to the peripheral cue. With left auditory cues and auditory targets microsaccades oriented in cue direction. We argue that microsaccades can be used to study crossmodal integration of sensory information and to map the time course of saccade preparation during covert shifts of visual and auditory attention.},
author = {Rolfs, Martin and Engbert, Ralf and Kliegl, Reinhold},
doi = {10.1007/s00221-005-2382-y},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rolfs, Engbert, Kliegl/Rolfs, Engbert, Kliegl - 2005 - Crossmodal coupling of oculomotor control and spatial attention in vision and audition. - Experimenta.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Acoustic Stimulation,Adolescent,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Cues,Data Interpretation, Statistical,Female,Fixation, Ocular,Fixation, Ocular: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Male,Mental Processes,Mental Processes: physiology,Oculomotor Muscles,Oculomotor Muscles: innervation,Oculomotor Muscles: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Saccades,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {3-4},
pages = {427--39},
pmid = {16032403},
title = {{Crossmodal coupling of oculomotor control and spatial attention in vision and audition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16032403},
volume = {166},
year = {2005}
}
@article{Guo2003a,
author = {Guo, G and Li, S Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo, Li/Guo, Li - 2003 - Content-Based Audio Classification and Retrieval by Support Vector Machines - IEEE Trans. Neural Networks.pdf:pdf},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {209--215},
title = {{Content-Based Audio Classification and Retrieval by Support Vector Machines}},
volume = {14},
year = {2003}
}
@inproceedings{Farnell2010,
abstract = {This work presents an overview of real-time client-side synthetic sound for use in games and interactive applications. Creating and managing native sound synthesis code for immediate client-side execution is large scale programming and design task. We need a good understanding of sound design practice to optimally solve the problem, but this is not sound design, nor is it music. We wish to sketch out a systematic way of attacking the general programming problems of procedural sound, for the general case of sound effects. There are two commonly used sources of sound, digital samples made by recording, and synthesised sounds created from first principles. While the former is the currently preferred method for most games, our focus is the second kind of sound generation. This approach has many benefits and tradeoffs. We can demonstrate that as complexity increases it eventually becomes more effective and efficient to synthesise many sounds on the client machine. We will remain aware of the most complicated and difficult application, multi-player network games, where a proper solution must allow for object replication across multiple clients and deal with issues like consistency, latency and client CPU usage.},
author = {Farnell, Andy James},
booktitle = {Sounding Out 3},
file = {::},
pages = {1--9},
title = {{Sound synthesis for games}},
year = {2010}
}
@article{Reynolds2009,
abstract = {Attention has been found to have a wide variety of effects on the responses of neurons in visual cortex. We describe a model of attention that exhibits each of these different forms of attentional modulation, depending on the stimulus conditions and the spread (or selectivity) of the attention field in the model. The model helps reconcile proposals that have been taken to represent alternative theories of attention. We argue that the variety and complexity of the results reported in the literature emerge from the variety of empirical protocols that were used, such that the results observed in any one experiment depended on the stimulus conditions and the subject's attentional strategy, a notion that we define precisely in terms of the attention field in the model, but that has not typically been completely under experimental control.},
author = {Reynolds, John H and Heeger, David J},
doi = {10.1016/j.neuron.2009.01.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Reynolds, Heeger/Reynolds, Heeger - 2009 - The normalization model of attention. - Neuron.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Attention,Attention: physiology,Computer Simulation,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Models, Neurological,Neurons,Neurons: physiology,Visual Cortex,Visual Cortex: physiology,Visual Fields,Visual Perception,Visual Perception: physiology},
month = jan,
number = {2},
pages = {168--85},
pmid = {19186161},
title = {{The normalization model of attention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2752446\&tool=pmcentrez\&rendertype=abstract},
volume = {61},
year = {2009}
}
@article{Seo2010,
author = {Seo, SangHyun and Yoon, KyungHyun},
doi = {10.1007/s00371-010-0505-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Seo, Yoon/Seo, Yoon - 2010 - Color juxtaposition for pointillism based on an artistic color model and a statistical analysis - The Visual Computer.pdf:pdf},
isbn = {0037101005},
issn = {0178-2789},
journal = {The Visual Computer: International Journal of Computer Graphics},
keywords = {juxtaposition of color,non-photorealistic rendering,painterly,pointillism,rendering},
month = apr,
number = {6-8},
pages = {421--431},
title = {{Color juxtaposition for pointillism based on an artistic color model and a statistical analysis}},
url = {http://www.springerlink.com/index/10.1007/s00371-010-0505-3},
volume = {26},
year = {2010}
}
@article{Heise2012,
author = {Heise, S and Hlatky, M and Loviscach, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Heise, Hlatky, Loviscach/Heise, Hlatky, Loviscach - 2012 - Soundtorch Quick browsing in large audio collections - Audio Engineering Society Convention 125.pdf:pdf},
journal = {Audio Engineering Society Convention 125},
title = {{Soundtorch: Quick browsing in large audio collections}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=14696},
year = {2012}
}
@article{Johnson2012,
author = {Johnson, Colin G.},
doi = {10.1007/s12559-012-9141-8},
file = {:Users/pkmital/Documents/Mendeley Desktop/Johnson/Johnson - 2012 - Connotation in Computational Creativity - Cognitive Computation.pdf:pdf},
isbn = {1255901291418},
issn = {1866-9956},
journal = {Cognitive Computation},
month = apr,
number = {3},
pages = {280--291},
title = {{Connotation in Computational Creativity}},
url = {http://link.springer.com/10.1007/s12559-012-9141-8},
volume = {4},
year = {2012}
}
@article{Parikh,
author = {Parikh, Devi and Zitnick, C Lawrence and Chen, Tsuhan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Zitnick, Chen/Parikh, Zitnick, Chen - Unknown - Determining Patch Saliency Using Low-Level Context - Context.pdf:pdf},
journal = {Context},
title = {{Determining Patch Saliency Using Low-Level Context}}
}
@article{Curcio1990,
author = {Curcio, CA and Allen, KA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Curcio, Allen/Curcio, Allen - 1990 - Topography of ganglion cells in human retina - Journal of Comparative Neurology.pdf:pdf},
journal = {Journal of Comparative Neurology},
pages = {5--25},
title = {{Topography of ganglion cells in human retina}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cne.903000103/full},
volume = {300},
year = {1990}
}
@article{Zieger2008,
author = {Zieger, Christian},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zieger/Zieger - 2008 - An HMM based system for acoustic event detection - Multimodal Technologies for Perception of Humans.pdf:pdf},
journal = {Multimodal Technologies for Perception of Humans},
title = {{An HMM based system for acoustic event detection}},
url = {http://www.springerlink.com/index/H2180QXV05133147.pdf},
year = {2008}
}
@article{Alvarez2008,
abstract = {The representation of visual information inside the focus of attention is more precise than the representation of information outside the focus of attention. We found that the visual system can compensate for the cost of withdrawing attention by pooling noisy local features and computing summary statistics. The location of an individual object is a local feature, whereas the center of mass of several objects (centroid) is a summary feature representing the mean object location. Three experiments showed that withdrawing attention degraded the representation of individual positions more than the representation of the centroid. It appears that information outside the focus of attention can be represented at an abstract level that lacks local detail, but nevertheless carries a precise statistical summary of the scene. The term ensemble features refers to a broad class of statistical summary features that we propose collectively make up the representation of information outside the focus of attention.},
author = {Alvarez, George a and Oliva, Aude},
doi = {10.1111/j.1467-9280.2008.02098.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Alvarez, Oliva/Alvarez, Oliva - 2008 - The representation of simple ensemble visual features outside the focus of attention. - Psychological science.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science},
keywords = {Adolescent,Adult,Attention,Humans,Visual Perception},
month = apr,
number = {4},
pages = {392--8},
pmid = {18399893},
title = {{The representation of simple ensemble visual features outside the focus of attention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2587223\&tool=pmcentrez\&rendertype=abstract},
volume = {19},
year = {2008}
}
@article{Orabona2007,
author = {Orabona, Francesco and Metta, Giorgio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Orabona, Metta/Orabona, Metta - 2007 - A Proto-object based visual attention model - Attention in cognitive systems. Theories.pdf:pdf},
journal = {Attention in cognitive systems. Theories},
title = {{A Proto-object based visual attention model}},
url = {http://www.springerlink.com/index/71U3T3262424M763.pdf},
year = {2007}
}
@article{Aslin2012,
abstract = {Eye-trackers suitable for use with infants are now marketed by several commercial vendors. As eye-trackers become more prevalent in infancy research, there is the potential for users to be unaware of dangers lurking "under the hood" if they assume the eye-tracker introduces no errors in measuring infants' gaze. Moreover, the influx of voluminous datasets from eye-trackers requires users to think hard about what they are measuring and what these measures mean for making inferences about underlying cognitive processes. The present commentary highlights these concerns, both technical and interpretive, and reviews the five articles that comprise this Special Issue.},
author = {Aslin, Richard N},
doi = {10.1111/j.1532-7078.2011.00097.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Aslin/Aslin - 2012 - Infant eyes A window on cognitive development. - Infancy the official journal of the International Society on Infant Stu.pdf:pdf},
issn = {1532-7078},
journal = {Infancy : the official journal of the International Society on Infant Studies},
month = jan,
number = {1},
pages = {126--140},
pmid = {22267956},
title = {{Infant eyes: A window on cognitive development.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22267956},
volume = {17},
year = {2012}
}
@article{Hutchinson2009a,
abstract = {We present a new method for modeling fMRI time series data called Hidden Process Models (HPMs). Like several earlier models for fMRI analysis, Hidden Process Models assume that the observed data is generated by a sequence of underlying mental processes that may be triggered by stimuli. HPMs go beyond these earlier models by allowing for processes whose timing may be unknown, and that might not be directly tied to specific stimuli. HPMs provide a principled, probabilistic framework for simultaneously learning the contribution of each process to the observed data, as well as the timing and identities of each instantiated process. They also provide a framework for evaluating and selecting among competing models that assume different numbers and types of underlying mental processes. We describe the HPM framework and its learning and inference algorithms, and present experimental results demonstrating its use on simulated and real fMRI data. Our experiments compare several models of the data using cross-validated data log-likelihood in an fMRI study involving overlapping mental processes whose timings are not fully known.},
author = {Hutchinson, Rebecca a and Niculescu, Radu Stefan and Keller, Timothy a and Rustandi, Indrayana and Mitchell, Tom M},
doi = {10.1016/j.neuroimage.2009.01.025},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hutchinson et al/Hutchinson et al. - 2009 - Modeling fMRI data generated by overlapping cognitive processes with unknown onsets using Hidden Process Mode.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Algorithms,Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Magnetic Resonance Imaging,Models, Neurological,Models, Theoretical},
month = may,
number = {1},
pages = {87--104},
pmid = {19457397},
publisher = {Elsevier Inc.},
title = {{Modeling fMRI data generated by overlapping cognitive processes with unknown onsets using Hidden Process Models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19457397},
volume = {46},
year = {2009}
}
@article{Khan2001,
abstract = {Ocular dominance is the tendency to prefer visual input from one eye to the other [e.g. Porac, C. \& Coren, S. (1976). The dominant eye. Psychological Bulletin 83(5), 880-897]. In standard sighting tests, most people consistently fall into either the left- or right eye-dominant category [Miles, W. R. (1930). Ocular dominance in human adults. Journal of General Psychology 3, 412-420]. Here we show this static concept to be flawed, being based on the limited results of sighting with gaze pointed straight ahead. In a reach-grasp task for targets within the binocular visual field, subjects switched between left and right eye dominance depending on horizontal gaze angle. On average, ocular dominance switched at gaze angles of only 15.5 degrees off center.},
author = {Khan, a Z and Crawford, J D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Khan, Crawford/Khan, Crawford - 2001 - Ocular dominance reverses as a function of horizontal gaze angle. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Diplopia,Diplopia: etiology,Diplopia: physiopathology,Dominance, Cerebral,Dominance, Cerebral: physiology,Eye Movements,Eye Movements: physiology,Humans,Psychomotor Performance,Psychomotor Performance: physiology,Vision, Binocular,Vision, Binocular: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {14},
pages = {1743--8},
pmid = {11369037},
title = {{Ocular dominance reverses as a function of horizontal gaze angle.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11369037},
volume = {41},
year = {2001}
}
@article{Klin2002,
abstract = {Manifestations of core social deficits in autism are more pronounced in everyday settings than in explicit experimental tasks. To bring experimental measures in line with clinical observation, we report a novel method of quantifying atypical strategies of social monitoring in a setting that simulates the demands of daily experience. Enhanced ecological validity was intended to maximize between-group effect sizes and assess the predictive utility of experimental variables relative to outcome measures of social competence.},
author = {Klin, Ami and Jones, Warren and Schultz, Robert and Volkmar, Fred and Cohen, Donald},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klin et al/Klin et al. - 2002 - Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism. - Archives of general psychiatry.pdf:pdf},
issn = {0003-990X},
journal = {Archives of general psychiatry},
keywords = {Adolescent,Adult,Attention,Autistic Disorder,Autistic Disorder: diagnosis,Autistic Disorder: epidemiology,Autistic Disorder: psychology,Face,Fixation, Ocular,Humans,Male,Probability,Risk Factors,Social Adjustment,Social Behavior,Visual Perception},
month = sep,
number = {9},
pages = {809--16},
pmid = {12215080},
title = {{Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12215080},
volume = {59},
year = {2002}
}
@article{Inhoff1989,
author = {Inhoff, Albrecht Werner},
doi = {10.1080/14640748908402353},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff/Inhoff - 1989 - The Quarterly Journal of During Reading - Experimental Psychology.pdf:pdf},
journal = {Experimental Psychology},
number = {769850735},
title = {{The Quarterly Journal of During Reading}},
year = {1989}
}
@article{Humphreysa,
author = {Humphreys, Greg and Houston, Mike and Klosowski, James T and Ahern, Sean and Kirchner, Peter D},
file = {::},
journal = {Work},
keywords = {cluster rendering,dering,parallel ren-,remote graphics,scalable rendering,stream,tiled displays,virtual graphics},
title = {{Chromium: A Stream-Processing Framework for Interactive Rendering on Clusters}}
}
@article{Kravets2012,
author = {Kravets, David},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kravets/Kravets - 2012 - YouTube Alters Copyright Algorithms, Will ‘Manually’ Review Some Claims - Wired.com.html:html},
journal = {Wired.com},
month = oct,
title = {{YouTube Alters Copyright Algorithms, Will ‘Manually’ Review Some Claims}},
url = {http://www.wired.com/threatlevel/2012/10/youtube-copyright-algorithm/},
year = {2012}
}
@article{Tikka2010,
author = {Tikka, Pia},
doi = {10.1080/14626268.2011.550028},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tikka/Tikka - 2010 - Enactive media – generalising from enactive cinema - Digital Creativity.pdf:pdf},
issn = {1462-6268},
journal = {Digital Creativity},
month = dec,
number = {4},
pages = {205--214},
title = {{Enactive media – generalising from enactive cinema}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14626268.2011.550028},
volume = {21},
year = {2010}
}
@article{Ramenahalli2013,
author = {Ramenahalli, Sudarshan and Mendat, Daniel R. and Dura-Bernal, Salvador and Culurciello, Eugenio and Niebur, Ernst and Andreou, Andreas},
doi = {10.1109/CISS.2013.6552285},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ramenahalli et al/Ramenahalli et al. - 2013 - Audio-visual saliency map Overview, basic models and hardware implementation - 2013 47th Annual Conference o.pdf:pdf},
isbn = {978-1-4673-5239-0},
journal = {2013 47th Annual Conference on Information Sciences and Systems (CISS)},
month = mar,
pages = {1--6},
publisher = {Ieee},
title = {{Audio-visual saliency map: Overview, basic models and hardware implementation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6552285},
year = {2013}
}
@article{Meeting2005,
author = {Meeting, Eleventh and Conference, International and Display, Auditory},
file = {:Users/pkmital/Documents/Mendeley Desktop/Meeting, Conference, Display/Meeting, Conference, Display - 2005 - A Study of Spatial Cognition in an Immersive Virtual Audio Environment Comparing Blind and Blindfolded Individuals BP 133 F-91403 Orsay France - Most.pdf:pdf},
journal = {Most},
pages = {1--8},
title = {{A Study of Spatial Cognition in an Immersive Virtual Audio Environment : Comparing Blind and Blindfolded Individuals BP 133 F-91403 Orsay France}},
year = {2005}
}
@incollection{Casey2009,
address = {New York},
author = {Casey, Michael},
booktitle = {The Oxford Handbook of Computer Music and Digital Sound Culture},
editor = {Dean, R.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey/Casey - 2009 - Soundspotting a new kind of process - The Oxford Handbook of Computer Music and Digital Sound Culture.pdf:pdf},
pages = {421--453},
publisher = {Oxford University Press},
title = {{Soundspotting: a new kind of process?}},
year = {2009}
}
@article{Schyns1994,
author = {Schyns, Philippe G and Oliva, Aude},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schyns, Oliva/Schyns, Oliva - 1994 - From Blobs to Boundary Edges Evidence for Time- and Spatial-Scale-Dependent Scene Recognition - Psychological Science.pdf:pdf},
journal = {Psychological Science},
number = {4},
pages = {195--200},
title = {{From Blobs to Boundary Edges: Evidence for Time- and Spatial-Scale-Dependent Scene Recognition}},
volume = {5},
year = {1994}
}
@inproceedings{Menzies2002a,
author = {Menzies, Dylan},
booktitle = {Proceedings of the 2002 International Conference on Auditory Display},
file = {::},
pages = {1--7},
publisher = {Citeseer},
title = {{Scene management for modelled audio objects in interactive worlds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.9249\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Kimura2001a,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2001 - Weak Coding with Linked Encoders for Mixed Sources - Unknown.pdf:pdf},
pages = {1--3},
title = {{Weak Coding with Linked Encoders for Mixed Sources}},
volume = {1},
year = {2001}
}
@article{Fischer2006a,
author = {Fischer, Martin H},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fischer/Fischer - 2006 - EYE MOVEMENTS AS A METHOD FOR INVESTIGATING ATTENTION Edited by - Text.pdf:pdf},
journal = {Text},
title = {{EYE MOVEMENTS AS A METHOD FOR INVESTIGATING ATTENTION Edited by}},
year = {2006}
}
@article{Borji2013,
author = {Borji, Ali and Sihite, DN and Itti, Laurent},
doi = {10.1167/13.10.Einh},
file = {:Users/pkmital/Documents/Mendeley Desktop/Borji, Sihite, Itti/Borji, Sihite, Itti - 2013 - Objects do not predict fixations better than early saliency A re-analysis of Einh\"{a}user et al.'s data - Jou.pdf:pdf},
journal = {Journal of Vision},
pages = {1--4},
title = {{Objects do not predict fixations better than early saliency: A re-analysis of Einh\"{a}user et al.'s data}},
url = {http://ww.w.journalofvision.org/content/13/10/18.short},
volume = {13},
year = {2013}
}
@article{Stewart2008,
author = {Stewart, R and Levy, M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stewart, Levy/Stewart, Levy - 2008 - 3D interactive environment for music collection navigation - Proc. DAFx-08.pdf:pdf},
journal = {Proc. DAFx-08},
pages = {1--5},
title = {{3D interactive environment for music collection navigation}},
url = {http://www.acoustics.hut.fi/dafx08/papers/dafx08\_03.pdf},
year = {2008}
}
@article{Libertus2007,
author = {Onat, S and Libertus, Klaus and K\"{o}nig, Peter},
doi = {10.1167/7.10.11.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Onat, Libertus, K\"{o}nig/Onat, Libertus, K\"{o}nig - 2007 - Integrating audiovisual information for the control of overt attention - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,11,1167,16,2007,7,attention,citation,crossmodal integration,doi,eye movements,http,integrating audiovisual information for,journal of vision,journalofvision,k,k\"{o}nig,libertus,linearity,natural stimuli,onat,org,overt attention,p,s,saliency map,the control of overt},
pages = {1--16},
title = {{Integrating audiovisual information for the control of overt attention}},
url = {http://www.journalofvision.org/content/7/10/11.short},
volume = {7},
year = {2007}
}
@article{Botvinick1998,
author = {Botvinick, M and Cohen, J},
doi = {10.1038/35784},
file = {:Users/pkmital/Documents/Mendeley Desktop/Botvinick, Cohen/Botvinick, Cohen - 1998 - Rubber hands 'feel' touch that eyes see. - Nature.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Ego,Humans,Illusions,Proprioception,Proprioception: physiology,Questionnaires,Touch,Touch: physiology,Visual Perception,Visual Perception: physiology},
month = feb,
number = {6669},
pages = {756},
pmid = {9486643},
title = {{Rubber hands 'feel' touch that eyes see.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9486643},
volume = {391},
year = {1998}
}
@article{Vig2010,
author = {Vig, Eleonora and Dorr, Michael and Martinetz, Thomas and Barth, Erhardt},
doi = {10.1007/s12559-010-9061-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vig et al/Vig et al. - 2010 - Eye Movements Show Optimal Average Anticipation with Natural Dynamic Scenes - Cognitive Computation.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {behaviour \'{a} natural dynamic,eye movements \'{a} anticipatory,gaze,scenes \'{a} saliency maps},
month = aug,
number = {1},
pages = {79--88},
title = {{Eye Movements Show Optimal Average Anticipation with Natural Dynamic Scenes}},
url = {http://link.springer.com/10.1007/s12559-010-9061-4},
volume = {3},
year = {2010}
}
@article{Prinza,
author = {Prinz, Jesse J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prinz/Prinz - Unknown - Sensation and Perception - Unknown.pdf:pdf},
title = {{Sensation and Perception}}
}
@article{Sivic2003,
author = {Sivic, Josef and Zisserman, Andrew},
doi = {10.1109/ICCV.2003.1238663},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sivic, Zisserman/Sivic, Zisserman - 2003 - Video Google a text retrieval approach to object matching in videos - Proceedings Ninth IEEE International Conference on Computer Vision.pdf:pdf},
isbn = {0-7695-1950-4},
journal = {Proceedings Ninth IEEE International Conference on Computer Vision},
number = {Iccv},
pages = {1470--1477 vol.2},
publisher = {Ieee},
title = {{Video Google: a text retrieval approach to object matching in videos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1238663},
year = {2003}
}
@article{Fishman2010,
author = {Fishman, YI and Steinschneider, M},
doi = {10.1523/JNEUROSCI.1780-10.2010.Neural},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fishman, Steinschneider/Fishman, Steinschneider - 2010 - Neural correlates of auditory scene analysis based on inharmonicity in monkey primary auditory cortex -.pdf:pdf},
journal = {The Journal of Neuroscience},
number = {37},
pages = {12480--12494},
title = {{Neural correlates of auditory scene analysis based on inharmonicity in monkey primary auditory cortex}},
url = {http://www.jneurosci.org/content/30/37/12480.short},
volume = {30},
year = {2010}
}
@article{Zitnick2012,
author = {Zitnick, C. L. and Parikh, D.},
doi = {10.1109/CVPR.2012.6247729},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zitnick, Parikh/Zitnick, Parikh - 2012 - The role of image understanding in contour detection - 2012 IEEE Conference on Computer Vision and Pattern Reco.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {622--629},
publisher = {Ieee},
title = {{The role of image understanding in contour detection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247729},
year = {2012}
}
@article{Pang,
author = {Pang, Derek},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pang/Pang - Unknown - Dynamic Markov random fields for stochastic modeling g of visual attention Where would you focus - Unknown.pdf:pdf},
number = {1},
title = {{Dynamic Markov random fields for stochastic modeling g of visual attention Where would you focus ?}}
}
@article{Bar2003,
abstract = {The majority of the research related to visual recognition has so far focused on bottom-up analysis, where the input is processed in a cascade of cortical regions that analyze increasingly complex information. Gradually more studies emphasize the role of top-down facilitation in cortical analysis, but it remains something of a mystery how such processing would be initiated. After all, top-down facilitation implies that high-level information is activated earlier than some relevant lower-level information. Building on previous studies, I propose a specific mechanism for the activation of top-down facilitation during visual object recognition. The gist of this hypothesis is that a partially analyzed version of the input image (i.e., a blurred image) is projected rapidly from early visual areas directly to the prefrontal cortex (PFC). This coarse representation activates in the PFC expectations about the most likely interpretations of the input image, which are then back-projected as an "initial guess" to the temporal cortex to be integrated with the bottom-up analysis. The top-down process facilitates recognition by substantially limiting the number of object representations that need to be considered. Furthermore, such a rapid mechanism may provide critical information when a quick response is necessary.},
author = {Bar, Moshe},
doi = {10.1162/089892903321662976},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bar/Bar - 2003 - A cortical mechanism for triggering top-down facilitation in visual object recognition. - Journal of cognitive neuroscience.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Humans,Photic Stimulation,Photic Stimulation: methods,Prefrontal Cortex,Prefrontal Cortex: physiology,Recognition (Psychology),Recognition (Psychology): physiology},
month = may,
number = {4},
pages = {600--9},
pmid = {12803970},
title = {{A cortical mechanism for triggering top-down facilitation in visual object recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12803970},
volume = {15},
year = {2003}
}
@article{Baccino2005,
author = {Baccino, Thierry and Manunta, Yves},
doi = {10.1027/0269-8803.19.3.204},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baccino, Manunta/Baccino, Manunta - 2005 - Eye-Fixation-Related Potentials Insight into Parafoveal Processing - Journal of Psychophysiology.pdf:pdf},
issn = {0269-8803},
journal = {Journal of Psychophysiology},
keywords = {adjacent words are processed,efrp,erp,eye movement,one of the main,parafoveal processing,questions in reading is,reading,simultaneously or consec-,the elements of the,underlying this question are,utively,whether two},
month = jan,
number = {3},
pages = {204--215},
title = {{Eye-Fixation-Related Potentials: Insight into
Parafoveal Processing}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/0269-8803.19.3.204},
volume = {19},
year = {2005}
}
@inproceedings{Grigoriou2010,
abstract = {In this work a novel audio binaural mixing platform is presented which employs advanced gestural-based interaction techniques for controlling the mixing parameters. State-of-the-art binaural technology algorithms are used for producing the final two- channel binaural signal. These algorithms are optimized for real- time operation, able to manipulate high-quality audio (typically 24bit / 96kHz) for an arbitrary number of fixed-position or moving sound sources in closed acoustic enclosures. Simple gestural rules are employed, which aim to provide the complete functionality required for the mixing process, using low cost equipment. It is shown that the proposed platform can be efficiently used for general audio mixing / mastering purposes, providing an attractive alternative to legacy hardware control designs and software-based mixing user interfaces.},
author = {Grigoriou, Nikolas and Floros, Andreas and Drossos, K.},
booktitle = {Proceedings of the 5th Audio Mostly Conference: A Conference on Interaction with Sound},
file = {::},
pages = {1--6},
publisher = {ACM},
title = {{Binaural mixing using gestural control interaction}},
url = {http://portal.acm.org/citation.cfm?id=1859803},
year = {2010}
}
@incollection{Rensink2001,
author = {Rensink, RA},
booktitle = {Vision \& Attention},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rensink/Rensink - 2001 - Change blindness Implications for the nature of visual attention - Vision \& Attention.pdf:pdf},
pages = {169--188},
title = {{Change blindness: Implications for the nature of visual attention}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=BhDZX3z8WA8C\&amp;oi=fnd\&amp;pg=PA169\&amp;dq=Change+Blindness+:+Implications+for+the+Nature+of+Visual+Attention\&amp;ots=L2n3EUWBSO\&amp;sig=FYiCdeEnS6NWjavotWrQqDnOaFE},
year = {2001}
}
@misc{htf2013,
booktitle = {en.wikipedia.org},
title = {{Happy Tree Friends}},
year = {2013}
}
@article{Galanter2003,
author = {Galanter, Philip},
file = {:Users/pkmital/Documents/Mendeley Desktop/Galanter/Galanter - 2003 - What is Generative Art Complexity theory as a context for art theory - In GA2003–6th Generative Art Conference.pdf:pdf},
journal = {In GA2003–6th Generative Art Conference},
title = {{What is Generative Art? Complexity theory as a context for art theory}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.2634},
year = {2003}
}
@article{Geller2008b,
author = {Geller, T.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {11--17},
publisher = {IEEE Computer Society Press},
title = {{Overcoming the uncanny valley}},
url = {http://www.computer.org/portal/cms\_docs\_cga/cga/content/mcg2008040011.pdf},
volume = {28},
year = {2008}
}
@article{Biederman1974,
abstract = {Presented jumbled and coherent scenes for 20-300 msec. Ss selected from a pair of labels the one they considered a better description. In Exp II, a cue designated one object. Jumbling reduced both the accuracy of identification of cued objects and of descriptor choice. (PsycINFO Database Record (c) 2007 APA},
author = {Biederman, I and Rabinowitz, J C and Glass, A L and Stacy, E W},
doi = {10.1037/h0037158},
issn = {00221015},
journal = {Journal of Experimental Psychology},
number = {3},
pages = {597--600},
publisher = {Elsevier},
title = {{On the information extracted from a glance at a scene}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022101507675296},
volume = {103},
year = {1974}
}
@article{Brockmole2005,
abstract = {The authors examined the prioritization of abruptly appearing objects in real-world scenes by measuring the eyes' propensity to be directed to the new object. New objects were fixated more often than chance whether they appeared during fixations (transient onsets) or saccades (nontransient onsets). However, onsets that appeared during fixations were fixated sooner and more often than those coincident with saccades. Prioritization of onsets during saccades, but not fixations, were affected by manipulations of memory: Reducing scene viewing time prior to the onset eliminated prioritization, whereas prior study of the scenes increased prioritization. Transient objects draw attention quickly and do not depend on memory, but without a transient signal, new objects are prioritized over several saccades as memory is used to explicitly identify the change. These effects were not modulated by observers' expectations concerning the appearance of new objects, suggesting the prioritization of a transient is automatic and that memory-guided prioritization is implicit.},
author = {Brockmole, James R and Henderson, John M},
doi = {10.1037/0096-1523.31.5.857},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmole, Henderson/Brockmole, Henderson - 2005 - Prioritization of new objects in real-world scenes evidence from eye movements. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Attention,Discrimination Learning,Eye Movements,Humans,Memory, Short-Term,Orientation,Pattern Recognition, Visual,Probability,Reaction Time,Saccades,Social Environment},
month = oct,
number = {5},
pages = {857--68},
pmid = {16262483},
title = {{Prioritization of new objects in real-world scenes: evidence from eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16262483},
volume = {31},
year = {2005}
}
@article{Simons2005,
abstract = {Change blindness is the striking failure to see large changes that normally would be noticed easily. Over the past decade this phenomenon has greatly contributed to our understanding of attention, perception, and even consciousness. The surprising extent of change blindness explains its broad appeal, but its counterintuitive nature has also engendered confusions about the kinds of inferences that legitimately follow from it. Here we discuss the legitimate and the erroneous inferences that have been drawn, and offer a set of requirements to help separate them. In doing so, we clarify the genuine contributions of change blindness research to our understanding of visual perception and awareness, and provide a glimpse of some ways in which change blindness might shape future research.},
author = {Simons, Daniel J and Rensink, Ronald a},
doi = {10.1016/j.tics.2004.11.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Simons, Rensink/Simons, Rensink - 2005 - Change blindness past, present, and future. - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Attention,Attention: physiology,Awareness,Awareness: physiology,Humans,Perceptual Disorders,Perceptual Disorders: physiopathology,Photic Stimulation,Recognition (Psychology),Signal Detection, Psychological,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {16--20},
pmid = {15639436},
title = {{Change blindness: past, present, and future.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15639436},
volume = {9},
year = {2005}
}
@article{Vatikiotis-Bateson1998,
abstract = {Perceiver eye movements were recorded during audiovisual presentations of extended monologues. Monologues were presented at different image sizes and with different levels of acoustic masking noise. Two clear targets of gaze fixation were identified, the eyes and the mouth. Regardless of image size, perceivers of both Japanese and English gazed more at the mouth as masking noise levels increased. However, even at the highest noise levels and largest image sizes, subjects gazed at the mouth only about half the time. For the eye target, perceivers typically gazed at one eye more than the other, and the tendency became stronger at higher noise levels. English perceivers displayed more variety of gaze-sequence patterns (e.g., left eye to mouth to left eye to right eye) and persisted in using them at higher noise levels than did Japanese perceivers. No segment-level correlations were found between perceiver eye motions and phoneme identity of the stimuli.},
author = {Vatikiotis-Bateson, E and Eigsti, I M and Yano, S and Munhall, K G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vatikiotis-Bateson et al/Vatikiotis-Bateson et al. - 1998 - Eye movement of perceivers during audiovisual speech perception. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Japan,Perceptual Masking,Speech Perception,Speech Perception: physiology,Visual Perception,Visual Perception: physiology},
month = aug,
number = {6},
pages = {926--40},
pmid = {9718953},
title = {{Eye movement of perceivers during audiovisual speech perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15462626},
volume = {60},
year = {1998}
}
@article{Fadeev2009,
author = {Fadeev, Aleksey and Missaoui, Oualid and Frigui, Hichem},
doi = {10.1109/ICMLA.2009.120},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fadeev, Missaoui, Frigui/Fadeev, Missaoui, Frigui - 2009 - Dominant Audio Descriptors for Audio Classification and Retrieval - 2009 International Conference on M.pdf:pdf},
isbn = {978-0-7695-3926-3},
journal = {2009 International Conference on Machine Learning and Applications},
month = dec,
pages = {75--78},
publisher = {Ieee},
title = {{Dominant Audio Descriptors for Audio Classification and Retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5381799},
year = {2009}
}
@article{Kimura2009,
author = {Kimura, A. and Kashino, K. and Fukuchi, K. and Akamine, K. and Miyazato, K. and Takagi, S.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura et al/Kimura et al. - 2009 - Cognitive developmental approach towards the realization of human-like visual scene understanding Framework and core technologies - brl.ntt.co.jp.pdf:pdf},
journal = {brl.ntt.co.jp},
pages = {8--8},
title = {{Cognitive developmental approach towards the realization of human-like visual scene understanding: Framework and core technologies}},
url = {http://www.brl.ntt.co.jp/people/akisato/pdf/090927posterCVHR2009.pdf},
year = {2009}
}
@inproceedings{Eladhari2006,
author = {Eladhari, Mirjam and Nieuwdorp, Rik and Fridenfalk, Mikael},
booktitle = {Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology},
file = {::},
isbn = {1595933808},
keywords = {adaptive audio,believable agents,game,music,role playing},
pages = {54--es},
publisher = {ACM},
title = {{The Soundtrack of Your Mind: Mind Music - Adaptive Audio for Game Characters}},
url = {http://portal.acm.org/citation.cfm?id=1178887},
year = {2006}
}
@article{Kumar2005a,
abstract = {We compared the dynamic properties of memory-guided and visually-guided saccade-vergence movements. For memory-guided responses, convergence components were slowed proportionally more than corresponding saccadic components, compared with visually-guided responses. This result is consistent with independent saccadic and vergence systems, and supports a Hering-type model for saccade-vergence interactions.},
author = {Kumar, Arun N and Han, Yanning H and Liao, Ke and Leigh, R John},
doi = {10.1196/annals.1325.046},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kumar et al/Kumar et al. - 2005 - Tests of Hering- and Helmholtz-type models for saccade-vergence interactions by comparing visually guided and memory-guided movements. - Annals of the New York Academy of Sciences.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
keywords = {Convergence, Ocular,Convergence, Ocular: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Memory,Memory: physiology,Models, Biological,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = apr,
pages = {466--9},
pmid = {15827001},
title = {{Tests of Hering- and Helmholtz-type models for saccade-vergence interactions by comparing visually guided and memory-guided movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15827001},
volume = {1039},
year = {2005}
}
@article{Liang2001,
author = {Liang, Lin and Liu, Ce and Xu, Ying-Qing and Guo, Baining and Shum, Heung-Yeung},
doi = {10.1145/501786.501787},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liang et al/Liang et al. - 2001 - Real-time texture synthesis by patch-based sampling - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = jul,
number = {3},
pages = {127--150},
title = {{Real-time texture synthesis by patch-based sampling}},
url = {http://portal.acm.org/citation.cfm?doid=501786.501787},
volume = {20},
year = {2001}
}
@article{Tong2012,
abstract = {Considerable information about mental states can be decoded from noninvasive measures of human brain activity. Analyses of brain activity patterns can reveal what a person is seeing, perceiving, attending to, or remembering. Moreover, multidimensional models can be used to investigate how the brain encodes complex visual scenes or abstract semantic information. Such feats of "brain reading" or "mind reading," though impressive, raise important conceptual, methodological, and ethical issues. What does successful decoding reveal about the cognitive functions performed by a brain region? How should brain signals be spatially selected and mathematically combined to ensure that decoding reflects inherent computations of the brain rather than those performed by the decoder? We highlight recent advances and describe how multivoxel pattern analysis can provide a window into mind-brain relationships with unprecedented specificity, when carefully applied. However, as brain-reading technology advances, issues of neuroethics and mental privacy will be important to consider.},
author = {Tong, Frank and Pratte, Michael S},
doi = {10.1146/annurev-psych-120710-100412},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tong, Pratte/Tong, Pratte - 2012 - Decoding patterns of human brain activity. - Annual review of psychology.pdf:pdf},
issn = {1545-2085},
journal = {Annual review of psychology},
keywords = {Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Functional Neuroimaging,Functional Neuroimaging: methods,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Memory,Memory: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
pages = {483--509},
pmid = {21943172},
title = {{Decoding patterns of human brain activity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21943172},
volume = {63},
year = {2012}
}
@article{Hussain2008,
author = {Hussain, Zakria and Shawe-taylor, John},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hussain, Shawe-taylor/Hussain, Shawe-taylor - 2008 - Matching pursuit algorithms in machine learning - Inverse Problems.pdf:pdf},
journal = {Inverse Problems},
title = {{Matching pursuit algorithms in machine learning}},
year = {2008}
}
@article{Escera2000,
abstract = {This article reviews recent event-related brain potential (ERP) studies of involuntary attention and distractibility in response to novelty and change in the acoustic environment. These studies show that the mismatch negativity, N(1) and P(3a) ERP components elicited by deviant or novel sounds in an unattended sequence of repetitive stimuli index different processes along the course to involuntary attention switch to distracting stimuli. These studies used new auditory-auditory and auditory-visual distraction paradigms, which enable one to assess objectively abnormal distractibility in several clinical patient groups, such as those suffering from closed-head injuries or chronic alcoholism.},
author = {Escera, C and Alho, K and Schr\"{o}ger, E and Winkler, I},
doi = {13877},
file = {:Users/pkmital/Documents/Mendeley Desktop/Escera et al/Escera et al. - 2000 - Involuntary attention and distractibility as evaluated with event-related brain potentials. - Audiology \& neuro-o.pdf:pdf},
issn = {1420-3030},
journal = {Audiology \& neuro-otology},
keywords = {Attention,Attention: physiology,Auditory Pathways,Auditory Pathways: physiopathology,Auditory Perception,Auditory Perception: physiology,Auditory Perceptual Disorders,Auditory Perceptual Disorders: diagnosis,Auditory Perceptual Disorders: physiopathology,Brain Mapping,Contingent Negative Variation,Contingent Negative Variation: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans},
number = {3-4},
pages = {151--66},
pmid = {10859410},
title = {{Involuntary attention and distractibility as evaluated with event-related brain potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10859410},
volume = {5},
year = {2000}
}
@article{Lartillot2007,
author = {Lartillot, Olivier},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lartillot/Lartillot - 2007 - MIR in Matlab (II) A toolbox for musical feature extraction from audio - International Conference on Music Information.pdf:pdf},
journal = {International Conference on Music Information},
number = {Ii},
title = {{MIR in Matlab (II): A toolbox for musical feature extraction from audio}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.5053\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Hasson2008,
author = {Hasson, Uri and Landesman, Ohad and Knappmeyer, Barbara and Vallines, Ignacio and Rubin, Nava and Heeger, David J.},
doi = {10.3167/proj.2008.020102},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hasson et al/Hasson et al. - 2008 - Neurocinematics The Neuroscience of Film - Projections.pdf:pdf},
issn = {19349688},
journal = {Projections},
keywords = {cognitive control,cognitive film theory,fmri,inter-subject correlation,science,social neuro-},
month = aug,
number = {1},
pages = {1--26},
title = {{Neurocinematics: The Neuroscience of Film}},
url = {http://openurl.ingenta.com/content/xref?genre=article\&issn=1934-9688\&volume=2\&issue=1\&spage=1},
volume = {2},
year = {2008}
}
@article{Klein2000,
abstract = {If and when search involves the serial inspection of items by covert or overt attention, its efficiency would be enhanced by a mechanism that would discourage re-inspections of items or regions of the display that had already been examined. Klein (1988, 2000; Klein \& Dukewich, 2006) proposed that inhibition of return (IOR) might be such a mechanism. The present experiments explored this proposal by combining a dynamic search task (Horowitz \& Wolfe, 1998, 2003) with a probe-detection task. IOR was observed when search was most efficient (static and slower dynamic search). IOR was not observed when search performance was less efficient (fast dynamic search).These findings are consistent with the "foraging facilitator" proposal of IOR and are unpredicted by theories of search that assume parallel accumulation of information across the array (plus noise) as a general explanation for the effect of set size upon search performance.},
author = {Klein, RM},
doi = {10.3758/APP.72.1.76},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein/Klein - 2000 - Inhibition of return - Trends in cognitive sciences.pdf:pdf},
issn = {1943-393X},
journal = {Trends in cognitive sciences},
keywords = {Attention,Cues,Female,Fixation,Humans,Inhibition (Psychology),Male,Ocular,Reaction Time,Visual Perception},
month = jan,
number = {1},
pages = {76--85},
pmid = {20045881},
title = {{Inhibition of return}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21365310 http://www.sciencedirect.com/science/article/pii/S1364661300014522},
volume = {72},
year = {2000}
}
@inproceedings{Werlberger2009,
author = {Werlberger, Manuel and Trobin, W. and Pock, T. and Wedel, A. and Cremers, D. and Bischof, H.},
booktitle = {Proceedings of the British machine vision conference},
file = {:Users/pkmital/Documents/Mendeley Desktop/Werlberger et al/Werlberger et al. - 2009 - Anisotropic Huber-L1 optical flow - Proceedings of the British machine vision conference.pdf:pdf},
pages = {1--11},
publisher = {Citeseer},
title = {{Anisotropic Huber-L1 optical flow}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.1214\&amp;rep=rep1\&amp;type=pdf},
year = {2009}
}
@incollection{Collins2007,
address = {New York, New York, USA},
author = {Collins, Karen},
booktitle = {Essays on Sound and Vision},
doi = {10.1145/281388.281880},
editor = {Hawkins, Stan and Richardson, John},
file = {::},
isbn = {1581130457},
pages = {263--298},
publisher = {ACM Press},
title = {{An Introduction to the Participatory and Non-Linear Aspects of Video Games Audio}},
url = {http://portal.acm.org/citation.cfm?doid=281388.281880},
year = {2007}
}
@book{Honour2009,
author = {Honour, Hugh and Fleming, John},
isbn = {1856695840},
pages = {996},
publisher = {Laurence King},
title = {{A World History of Art}},
url = {http://www.amazon.co.uk/World-History-Art-Hugh-Honour/dp/1856695840},
year = {2009}
}
@article{Teki2011a,
abstract = {Auditory figure-ground segregation, listeners' ability to selectively hear out a sound of interest from a background of competing sounds, is a fundamental aspect of scene analysis. In contrast to the disordered acoustic environment we experience during everyday listening, most studies of auditory segregation have used relatively simple, temporally regular signals. We developed a new figure-ground stimulus that incorporates stochastic variation of the figure and background that captures the rich spectrotemporal complexity of natural acoustic scenes. Figure and background signals overlap in spectrotemporal space, but vary in the statistics of fluctuation, such that the only way to extract the figure is by integrating the patterns over time and frequency. Our behavioral results demonstrate that human listeners are remarkably sensitive to the appearance of such figures. In a functional magnetic resonance imaging experiment, aimed at investigating preattentive, stimulus-driven, auditory segregation mechanisms, naive subjects listened to these stimuli while performing an irrelevant task. Results demonstrate significant activations in the intraparietal sulcus (IPS) and the superior temporal sulcus related to bottom-up, stimulus-driven figure-ground decomposition. We did not observe any significant activation in the primary auditory cortex. Our results support a role for automatic, bottom-up mechanisms in the IPS in mediating stimulus-driven, auditory figure-ground segregation, which is consistent with accumulating evidence implicating the IPS in structuring sensory input and perceptual organization.},
author = {Teki, Sundeep and Chait, Maria and Kumar, Sukhbinder and von Kriegstein, Katharina and Griffiths, Timothy D},
doi = {10.1523/JNEUROSCI.3788-10.2011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Teki et al/Teki et al. - 2011 - Brain bases for auditory stimulus-driven figure-ground segregation. - The Journal of neuroscience the official journal of the Society for Neuroscience.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Pathways,Auditory Pathways: blood supply,Auditory Perception,Auditory Perception: physiology,Brain,Brain Mapping,Brain: blood supply,Brain: physiology,Female,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Oxygen,Oxygen: blood,Psychoacoustics,Signal Detection, Psychological,Signal Detection, Psychological: physiology},
month = jan,
number = {1},
pages = {164--71},
pmid = {21209201},
title = {{Brain bases for auditory stimulus-driven figure-ground segregation.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3059575\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Parikh2009a,
author = {Parikh, D. and Zitnick, C.L.},
doi = {10.1109/CVPR.2009.5206549},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Zitnick/Parikh, Zitnick - 2009 - Unsupervised learning of hierarchical spatial structures in images - 2009 IEEE Conference on Computer Vision and Pattern Recognition(2).pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {2743--2750},
publisher = {Ieee},
title = {{Unsupervised learning of hierarchical spatial structures in images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206549},
year = {2009}
}
@article{Grandvalet,
author = {Grandvalet, Yves and Eck, Douglas and Paiement, Jean-Francois and Bengio, Samy},
file = {::},
pages = {1--8},
title = {{A Generative Model for Rhythms}}
}
@article{Menzies2006,
abstract = {Ambisonic encodings can be rendered binaurally, as well as for speaker arrays. We first consider how binaural signals can be calculated from high-order Ambisonic encodings of general soundfields containing near and far sources. For sufficently near sources we identify an error resulting fromthe limited field of validity of the freefield harmonic expansion. A modified expansion is derived that can render such sources without error.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--17},
title = {{Nearfield Binaural Synthesis and Ambisonics}},
year = {2006}
}
@article{Henderson2006,
abstract = {The mismatch negativity is an event-related potential that represents a preattentive change detection process. The aim of this study was to determine whether the mismatch negativity was present during 'change blindness', a striking phenomenon in which surprisingly large changes in a complex scene are not seen when they occur during a blink or an eye movement. In this study, large orientation changes elicited a candidate mismatch negativity between 180 and 320 ms that appeared to be independent of participants' performance (uncued 76\% correct, miscued 59\% correct with chance performance at 50\%). This negativity, however, disappeared in the miscued 'change blind' condition. In conclusion, the mismatch negativity does not appear to be present during change blindness suggesting that in complex scenes even large changes may not trigger preattentive change detection processes.},
author = {Henderson, Ross M and Orbach, Harry S},
doi = {10.1097/01.wnr.0000223390.36457.b4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Orbach/Henderson, Orbach - 2006 - Is there a mismatch negativity during change blindness - Neuroreport.pdf:pdf},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adolescent,Adult,Blindness,Blindness: physiopathology,Contingent Negative Variation,Contingent Negative Variation: physiology,Cues,Electroencephalography,Electroencephalography: methods,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Orientation,Orientation: physiology,Reaction Time,Reaction Time: physiology,Time Factors},
month = jul,
number = {10},
pages = {1011--5},
pmid = {16791094},
title = {{Is there a mismatch negativity during change blindness?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16791094},
volume = {17},
year = {2006}
}
@article{MCGURK1976,
author = {McGurk, Harry and Macdonald, John},
doi = {10.1038/264746a0},
issn = {0028-0836},
journal = {Nature},
month = dec,
number = {5588},
pages = {746--748},
shorttitle = {Nature},
title = {{Hearing lips and seeing voices}},
url = {http://dx.doi.org/10.1038/264746a0},
volume = {264},
year = {1976}
}
@article{Oliva2001,
author = {Oliva, Aude and Torralba, Antonio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Oliva, Torralba/Oliva, Torralba - 2001 - Modeling the Shape of the Scene A Holistic Representation of the Spatial Envelope ∗ - International Journal.pdf:pdf},
journal = {International Journal},
keywords = {energy spectrum,natural images,principal components,scene recognition,spatial layout},
number = {3},
pages = {145--175},
title = {{Modeling the Shape of the Scene : A Holistic Representation of the Spatial Envelope ∗}},
volume = {42},
year = {2001}
}
@article{Jiang2004a,
author = {Jiang, B. and Neumann, U. and You, S.},
file = {::},
journal = {IEEE Virtual Reality, 2004. Proceedings},
pages = {3--275},
title = {{A robust hybrid tracking system for outdoor augmented reality}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1310049},
year = {2004}
}
@article{Mercado2010,
author = {Mercado, Pedro and Lukashevich, Hanna},
doi = {10.1109/ICMLA.2010.100},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mercado, Lukashevich/Mercado, Lukashevich - 2010 - Feature Selection in Clustering with Constraints Application to Active Exploration of Music Collections - 2010 Ninth International Conference on Machine Learning and Applications.pdf:pdf},
isbn = {978-1-4244-9211-4},
journal = {2010 Ninth International Conference on Machine Learning and Applications},
keywords = {-feature selection,clustering with constraints,music information retrieval,spec-,tral clustering},
month = dec,
number = {1},
pages = {649--654},
publisher = {Ieee},
title = {{Feature Selection in Clustering with Constraints: Application to Active Exploration of Music Collections}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5708899},
year = {2010}
}
@article{Hollingworth2001a,
abstract = {Eye movements were monitored while participants performed a change detection task with images of natural scenes. An initial and a modified scene image were displayed in alternation, separated by a blank interval (flicker paradigm). In the modified image, a single target object was changed either by deleting that object from the scene or by rotating that object 90 degrees in depth. In Experiment 1, fixation position at detection was more likely to be in the target object region than in any other region of the scene. In Experiment 2, participants detected scene changes more accurately, with fewer false alarms, and more quickly when allowed to move their eyes in the scene than when required to maintain central fixation. These data suggest a major role for fixation position in the detection of changes to natural scenes across discrete views.},
author = {Hollingworth, a and Schrock, G and Henderson, J M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Schrock, Henderson/Hollingworth, Schrock, Henderson - 2001 - Change detection in the flicker paradigm the role of fixation position within the scene. - Memory \& cognition.pdf:pdf},
issn = {0090-502X},
journal = {Memory \& cognition},
keywords = {Fixation, Ocular,Humans,Reaction Time,Saccades,Signal Detection, Psychological},
month = mar,
number = {2},
pages = {296--304},
pmid = {11352212},
title = {{Change detection in the flicker paradigm: the role of fixation position within the scene.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11352212},
volume = {29},
year = {2001}
}
@article{Peters2005,
abstract = {Recent research Parkhurst, D., Law, K., \& Niebur, E., 2002. Modeling the role of salience in the allocation of overt visual attention. Vision Research 42 (1) (2002) 107-123 showed that a model of bottom-up visual attention can account in part for the spatial locations fixated by humans while free-viewing complex natural and artificial scenes. That study used a definition of salience based on local detectors with coarse global surround inhibition. Here, we use a similar framework to investigate the roles of several types of non-linear interactions known to exist in visual cortex, and of eccentricity-dependent processing. For each of these, we added a component to the salience model, including richer interactions among orientation-tuned units, both at spatial short range (for clutter reduction) and long range (for contour facilitation), and a detailed model of eccentricity-dependent changes in visual processing. Subjects free-viewed naturalistic and artificial images while their eye movements were recorded, and the resulting fixation locations were compared with the models' predicted salience maps. We found that the proposed interactions indeed play a significant role in the spatiotemporal deployment of attention in natural scenes; about half of the observed inter-subject variance can be explained by these different models. This suggests that attentional guidance does not depend solely on local visual features, but must also include the effects of interactions among features. As models of these interactions become more accurate in predicting behaviorally-relevant salient locations, they become useful to a range of applications in computer vision and human-machine interface design.},
author = {Peters, Robert J and Iyer, Asha and Itti, Laurent and Koch, Christof},
institution = {Computation and Neural Systems, California Institute of Technology, Mail code 139-74, Caltech, Pasadena, CA 91125, USA. rjpeters@usc.edu},
journal = {Vision Research},
keywords = {adolescent,adult,attention,attention physiology,eye movements,eye movements physiology,fixation,form perception,humans,mathematics,models,ocular,ocular physiology,orientation,orientation physiology,pattern recognition,photic stimulation,photic stimulation methods,psychological,psychophysics,saccades,visual,visual perception,visual perception physiology,visual physiology},
number = {18},
pages = {2397--2416},
pmid = {15935435},
publisher = {Elsevier},
title = {{Components of bottom-up gaze allocation in natural images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15935435},
volume = {45},
year = {2005}
}
@article{Henderson2008,
abstract = {How sensitive are viewers to changes in global image properties across saccades during active real-world scene perception? This question was investigated by globally increasing and/or decreasing luminance or contrast in photographs of real-world scenes across saccadic eye movements or during matched brief interruptions in a flicker paradigm. The results from two experiments demonstrated very poor sensitivity to global image changes in both the saccade-contingent and flicker paradigms, suggesting that the specific values of basic sensory properties do not contribute to the perception of stability across saccades during complex scene perception. In addition, overall sensitivity was significantly worse in the saccade-contingent change paradigm than the flicker paradigm, suggesting that the flicker paradigm is an imperfect simulation of transsaccadic vision.},
author = {Henderson, John M and Brockmole, James R and Gajewski, Daniel a},
doi = {10.1016/j.visres.2007.10.008},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Brockmole, Gajewski/Henderson, Brockmole, Gajewski - 2008 - Differential detection of global luminance and contrast changes across saccades and flickers during active scene perception. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Contrast Sensitivity,Contrast Sensitivity: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Lighting,Memory,Memory: physiology,Photic Stimulation,Photic Stimulation: methods,Photography,Psychomotor Performance,Psychophysics,Saccades,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {16--29},
pmid = {18078976},
title = {{Differential detection of global luminance and contrast changes across saccades and flickers during active scene perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18078976},
volume = {48},
year = {2008}
}
@inproceedings{Kim2010,
author = {Kim, Kiyoung and Lepetit, Vincent and Woo, Woontack},
booktitle = {Proceedings of the 2010 International Symposium on Mixed and Augmented Reality},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kim, Lepetit, Woo/Kim, Lepetit, Woo - 2010 - Keyframe-based Modeling and Tracking of Multiple 3D Objects ∗ - Proceedings of the 2010 International Symposium on Mixed and Augmented Reality.pdf:pdf},
title = {{Keyframe-based Modeling and Tracking of Multiple 3D Objects ∗}},
year = {2010}
}
@book{Dewey2005,
author = {Dewey, J.},
booktitle = {New York},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dewey/Dewey - 2005 - Art as experience - New York.pdf:pdf},
isbn = {0399531971},
publisher = {Perigee},
title = {{Art as experience}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:ART+AS+EXPERIENCE\#0},
year = {2005}
}
@article{Res1987,
author = {Res, Exp Brain},
file = {:Users/pkmital/Documents/Mendeley Desktop/Res/Res - 1987 - E ,x \_mental Bran Research 9 - Experimental Brain Research.pdf:pdf},
journal = {Experimental Brain Research},
keywords = {a p - overlap,anticipation -,express saccades,h u m a,n eye saccades -,visual guiding - g},
pages = {115--121},
title = {{E ,x \_mental Bran Research 9}},
year = {1987}
}
@article{Schwarz2007,
author = {Schwarz, Diemo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2007 - Corpus-based concatenative synthesis - Signal Processing Magazine, IEEE.pdf:pdf},
journal = {Signal Processing Magazine, IEEE},
pages = {0--3},
title = {{Corpus-based concatenative synthesis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4117932},
year = {2007}
}
@article{Hollingworth2004,
abstract = {In a change detection paradigm, the global orientation of a natural scene was incrementally changed in 1 degree intervals. In Experiments 1 and 2, participants demonstrated sustained change blindness to incremental rotation, often coming to consider a significantly different scene viewpoint as an unchanged continuation of the original view. Experiment 3 showed that participants who failed to detect the incremental rotation nevertheless reliably detected a single-step rotation back to the initial view. Together, these results demonstrate an important dissociation between explicit change detection and visual memory. Following a change, visual memory is updated to reflect the changed state of the environment, even if the change was not detected.},
author = {Hollingworth, Andrew and Henderson, John M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth, Henderson/Hollingworth, Henderson - 2004 - Sustained change blindness to incremental scene rotation a dissociation between explicit change detection and visual memory. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Humans,Memory,Rotation,Signal Detection, Psychological,Visual Perception},
month = jul,
number = {5},
pages = {800--7},
pmid = {15495905},
title = {{Sustained change blindness to incremental scene rotation: a dissociation between explicit change detection and visual memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15495905},
volume = {66},
year = {2004}
}
@article{Gibson2008,
author = {Gibson, Bradley and Folk, Charles and Theeuwes, Jan and Kingstone, Alan},
doi = {10.1080/13506280701843708},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gibson et al/Gibson et al. - 2008 - Introduction - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = jan,
number = {2},
pages = {145--154},
title = {{Introduction}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280701843708\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {16},
year = {2008}
}
@article{Logothetis1995,
abstract = {BACKGROUND: The inferior temporal cortex (IT) of the monkey has long been known to play an essential role in visual object recognition. Damage to this area results in severe deficits in perceptual learning and object recognition, without significantly affecting basic visual capacities. Consistent with these ablation studies is the discovery of IT neurons that respond to complex two-dimensional visual patterns, or objects such as faces or body parts. What is the role of these neurons in object recognition? Is such a complex configurational selectivity specific to biologically meaningful objects, or does it develop as a result of extensive exposure to any objects whose identification relies on subtle shape differences? If so, would IT neurons respond selectively to recently learned views of features of novel objects? The present study addresses this question by using combined psychophysical and electrophysiological experiments, in which monkeys learned to classify and recognize computer-generated three-dimensional objects.

RESULTS: A population of IT neurons was found that responded selectively to views of previously unfamiliar objects. The cells discharged maximally to one view of an object, and their response declined gradually as the object was rotated away from this preferred view. No selective responses were ever encountered for views that the animal systematically failed to recognize. Most neurons also exhibited orientation-dependent responses during view-plane rotations. Some neurons were found to be tuned around two views of the same object, and a very small number of cells responded in a view-invariant manner. For the five different objects that were used extensively during the training of the animals, and for which behavioral performance became view-independent, multiple cells were found that were tuned around different views of the same object. A number of view-selective units showed response invariance for changes in the size of the object or the position of its image within the parafovea.

CONCLUSION: Our results suggest that IT neurons can develop a complex receptive field organization as a consequence of extensive training in the discrimination and recognition of objects. None of these objects had any prior meaning for the animal, nor did they resemble anything familiar in the monkey's environment. Simple geometric features did not appear to account for the neurons' selective responses. These findings support the idea that a population of neurons--each tuned to a different object aspect, and each showing a certain degree of invariance to image transformations--may, as an ensemble, encode at least some types of complex three-dimensional objects. In such a system, several neurons may be active for any given vantage point, with a single unit acting like a blurred template for a limited neighborhood of a single view.},
author = {Logothetis, N K and Pauls, J and Poggio, T},
file = {:Users/pkmital/Documents/Mendeley Desktop/Logothetis, Pauls, Poggio/Logothetis, Pauls, Poggio - 1995 - Shape representation in the inferior temporal cortex of monkeys. - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Animals,Form Perception,Form Perception: physiology,Image Processing, Computer-Assisted,Macaca mulatta,Neurons,Neurons: physiology,Temporal Lobe,Temporal Lobe: physiology},
month = may,
number = {5},
pages = {552--63},
pmid = {7583105},
title = {{Shape representation in the inferior temporal cortex of monkeys.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7583105},
volume = {5},
year = {1995}
}
@article{Deng,
author = {Deng, Y. and Chakrabartty, S. and Cauwenberghs, G.},
doi = {10.1109/IJCNN.2004.1380859},
file = {:Users/pkmital/Documents/Mendeley Desktop/Deng, Chakrabartty, Cauwenberghs/Deng, Chakrabartty, Cauwenberghs - Unknown - Analog auditory perception model for robust speech recognition - 2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541).pdf:pdf},
isbn = {0-7803-8359-1},
journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
number = {1},
pages = {1705--1709},
publisher = {Ieee},
title = {{Analog auditory perception model for robust speech recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1380859},
volume = {3}
}
@article{Wolfe1989,
abstract = {Subjects searched sets of items for targets defined by conjunctions of color and form, color and orientation, or color and size. Set size was varied and reaction times (RT) were measured. For many unpracticed subjects, the slopes of the resulting RT X Set Size functions are too shallow to be consistent with Treisman's feature integration model, which proposes serial, self-terminating search for conjunctions. Searches for triple conjunctions (Color X Size X Form) are easier than searches for standard conjunctions and can be independent of set size. A guided search model similar to Hoffman's (1979) two-stage model can account for these data. In the model, parallel processes use information about simple features to guide attention in the search for conjunctions. Triple conjunctions are found more efficiently than standard conjunctions because three parallel processes can guide attention more effectively than two.},
author = {Wolfe, J M and Cave, K R and Franzel, S L},
institution = {Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge 02139.},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {3},
pages = {419--433},
pmid = {2527952},
publisher = {American Psychological Association},
title = {{Guided search: an alternative to the feature integration model for visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2527952},
volume = {15},
year = {1989}
}
@article{Tanaka2007,
abstract = {We often generate movements without any external event that immediately triggers them. How the brain decides the timing of self-initiated movements remains unclear. Previous studies suggest that the basal ganglia-thalamocortical pathways play this role, but the subcortical signals that determine movement timing have not been identified. The present study reports that a subset of thalamic neurons predicts the timing of self-initiated saccadic eye movements. When monkeys made a saccade in response to the fixation point (FP) offset in the traditional memory saccade task, neurons in the ventrolateral and the ventroanterior nuclei of the thalamus exhibited a gradual buildup of activity that peaked around the most probable time of the FP offset; however, neither the timing nor the magnitude of neuronal activity correlated with saccade latencies, suggesting that the brain is unlikely to have used this information to decide the times of saccades in the traditional memory saccade task. In contrast, when monkeys were required to make a self-timed saccade within a fixed time interval after an external cue, the same neurons again exhibited a strong buildup of activity that preceded saccades by several hundred milliseconds, showing a close correlation between the times of neuronal activity and the times of self-initiated saccades. The results suggest that neurons in the motor thalamus carry subjective time information, which is used by cortical networks to determine the timing of self-initiated saccades.},
author = {Tanaka, Masaki},
doi = {10.1523/JNEUROSCI.1873-07.2007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tanaka/Tanaka - 2007 - Cognitive signals in the primate motor thalamus predict saccade timing. - The Journal of neuroscience the official journal of the Society for Neuroscience.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Animals,Behavior, Animal,Brain Mapping,Female,Fixation, Ocular,Fixation, Ocular: physiology,Macaca fascicularis,Male,Memory,Memory: physiology,Neurons,Neurons: physiology,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Thalamus,Thalamus: cytology,Thalamus: physiology,Time Factors},
month = oct,
number = {44},
pages = {12109--18},
pmid = {17978052},
title = {{Cognitive signals in the primate motor thalamus predict saccade timing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17978052},
volume = {27},
year = {2007}
}
@inproceedings{Schwarz2003,
abstract = {Concatenative data-driven synthesis methods are gaining more interest
for musical sound synthesis and effects. They are based on
a large database of sounds and a unit selection algorithm which
finds the units that match best a given sequence of target units.
We describe related work and our CATERPILLAR synthesis system,
focusing on recent new developments: the advantages of the
addition of a relational SQL database, work on segmentation by
alignment, the reformulation and extension of the unit selection
algorithm using a constraint resolution approach, and new applications
for musical and speech synthesis.},
address = {London, U.K.},
author = {Schwarz, D},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
keywords = {CSS},
title = {{The \{C\}aterpillar \{S\}ystem for Data-Driven Concatenative Sound Synthesis}},
year = {2003}
}
@article{Batista1999,
author = {Batista, a. P.},
doi = {10.1126/science.285.5425.257},
file = {:Users/pkmital/Documents/Mendeley Desktop/Batista/Batista - 1999 - Reach Plans in Eye-Centered Coordinates - Science.pdf:pdf},
issn = {00368075},
journal = {Science},
month = jul,
number = {5425},
pages = {257--260},
title = {{Reach Plans in Eye-Centered Coordinates}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.285.5425.257},
volume = {285},
year = {1999}
}
@article{Wass2012,
abstract = {Researchers studying infants' spontaneous allocation of attention have traditionally relied on hand-coding infants' direction of gaze from videos; these techniques have low temporal and spatial resolution and are labor intensive. Eye-tracking technology potentially allows for much more precise measurement of how attention is allocated at the subsecond scale, but a number of technical and methodological issues have given rise to caution about the quality and reliability of high temporal resolution data obtained from infants. We present analyses suggesting that when standard dispersal-based fixation detection algorithms are used to parse eye-tracking data obtained from infants, the results appear to be heavily influenced by interindividual variations in data quality. We discuss the causes of these artifacts, including fragmentary fixations arising from flickery or unreliable contact with the eyetracker and variable degrees of imprecision in reported position of gaze. We also present new algorithms designed to cope with these problems by including a number of new post hoc verification checks to identify and eliminate fixations that may be artifactual. We assess the results of our algorithms by testing their reliability using a variety of methods and on several data sets. We contend that, with appropriate data analysis methods, fixation duration can be a reliable and stable measure in infants. We conclude by discussing ways in which studying fixation durations during unconstrained orienting may offer insights into the relationship between attention and learning in naturalistic settings.},
author = {Wass, S V and Smith, T J and Johnson, M H},
doi = {10.3758/s13428-012-0245-6},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wass, Smith, Johnson/Wass, Smith, Johnson - 2012 - Parsing eye-tracking data of variable quality to provide accurate fixation duration estimates in infants a.pdf:pdf},
isbn = {1342801202},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {attention,birkbeck college,centre for brain and,cognitive development,eyetracker,fixation duration,free viewing,h,infant,j,johnson,m,methodology,naturalistic,s,smith,t,v,wass},
month = oct,
pmid = {22956360},
title = {{Parsing eye-tracking data of variable quality to provide accurate fixation duration estimates in infants and adults.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22956360},
year = {2012}
}
@phdthesis{Martino2000,
abstract = {A compelling area of exploration in the domain of physical modeling and vocal synthesis is the production of non-human, expressive, animal-like vocalizations. Animal sounds can convey a wide variety of emotional states, and synthesizing life-like vocalizations would allow for interesting applications in the world of video games, film, music, and artificial intelligence systems. This paper describes Synthasaurus, a synthesis engine prototype developed in Opcode MAX/MSP, which enables one to create emotive animal-like calls, and provides enough flexibility to synthesize a variety of organisms that can resemble different mammals, birds, reptiles and amphibians. Alien, robotic, and other imaginary creatures can also be conceived. Synthasaurus builds on research and technology developed for human speech synthesis, with special kinds of control added for creating more animal-like sounds.},
author = {Martino, Robert},
booktitle = {Synthesis},
file = {::},
title = {{Synthasaurus : An ANimal Vocalization Synthesizer}},
year = {2000}
}
@article{Horn1981,
author = {Horn, BKP and Schunck, BG},
file = {:Users/pkmital/Documents/Mendeley Desktop/Horn, Schunck/Horn, Schunck - 1981 - Determining optical flow - Artificial intelligence.pdf:pdf},
journal = {Artificial intelligence},
keywords = {Apparent Motion.,Brightness Change Constraint Equation,Flow Smoothness,Motion Field,Optical Flow,Variational Methods},
pages = {185--203},
title = {{Determining optical flow}},
url = {http://www.sciencedirect.com/science/article/pii/0004370281900242},
volume = {17},
year = {1981}
}
@article{Eitz2009,
address = {New York, New York, USA},
author = {Eitz, Mathias and Hildebrand, Kristian and Boubekeur, Tamy and Alexa, Marc},
doi = {10.1145/1572741.1572747},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eitz et al/Eitz et al. - 2009 - A descriptor for large scale image retrieval based on sketched feature lines - Proceedings of the 6th Eurographics.pdf:pdf},
isbn = {9781605586021},
journal = {Proceedings of the 6th Eurographics Symposium on Sketch-Based Interfaces and Modeling - SBIM '09},
pages = {29},
publisher = {ACM Press},
title = {{A descriptor for large scale image retrieval based on sketched feature lines}},
url = {http://portal.acm.org/citation.cfm?doid=1572741.1572747},
year = {2009}
}
@article{Zhang2012,
abstract = {We introduce the EXtract-and-COmplete Layering method (EXCOL)--a novel cartoon animation processing technique to convert a traditional animated cartoon video into multiple semantically meaningful layers. Our technique is inspired by vision-based layering techniques but focuses on shape cues in both the extraction and completion steps to reflect the unique characteristics of cartoon animation. For layer extraction, we define a novel similarity measure incorporating both shape and color of automatically segmented regions within individual frames and propagate a small set of user-specified layer labels among similar regions across frames. By clustering regions with the same labels, each frame is appropriately partitioned into different layers, with each layer containing semantically meaningful content. Then, a warping-based approach is used to fill missing parts caused by occlusion within the extracted layers to achieve a complete representation. EXCOL provides a flexible way to effectively reuse traditional cartoon animations with only a small amount of user interaction. It is demonstrated that our EXCOL method is effective and robust, and the layered representation benefits a variety of applications in cartoon animation processing.},
author = {Zhang, Lei and Huang, Hua and Fu, Hongbo},
doi = {10.1109/TVCG.2011.111},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang, Huang, Fu/Zhang, Huang, Fu - 2012 - EXCOL an EXtract-and-COmplete layering approach to cartoon animation reusing. - IEEE transactions on visualiza.pdf:pdf},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
month = jul,
number = {7},
pages = {1156--69},
pmid = {21690640},
title = {{EXCOL: an EXtract-and-COmplete layering approach to cartoon animation reusing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21690640},
volume = {18},
year = {2012}
}
@article{Quigley2005,
author = {Quigley, Cliodhna and Onat, S and Harding, Sue and Cooke, Martin},
file = {:Users/pkmital/Documents/Mendeley Desktop/Quigley et al/Quigley et al. - 2005 - Audio-visual integration during overt visual attention - Journal of Eye Movement.pdf:pdf},
journal = {Journal of Eye Movement},
number = {2},
pages = {1--17},
title = {{Audio-visual integration during overt visual attention}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.2208\&amp;rep=rep1\&amp;type=pdf},
volume = {1},
year = {2005}
}
@article{Luo2001,
author = {Luo, M. R. and Cui, G. and Rigg, B.},
doi = {10.1002/col.1049},
file = {:Users/pkmital/Documents/Mendeley Desktop/Luo, Cui, Rigg/Luo, Cui, Rigg - 2001 - The development of the CIE 2000 colour-difference formula CIEDE2000 - Color Research \& Application.pdf:pdf},
issn = {0361-2317},
journal = {Color Research \& Application},
keywords = {bfp,cie,cie94,ciede2000,cielab,cmc,color difference metrics,lcd},
month = oct,
number = {5},
pages = {340--350},
title = {{The development of the CIE 2000 colour-difference formula: CIEDE2000}},
url = {http://doi.wiley.com/10.1002/col.1049},
volume = {26},
year = {2001}
}
@article{Parra2005,
abstract = {In this paper, we describe a simple set of "recipes" for the analysis of high spatial density EEG. We focus on a linear integration of multiple channels for extracting individual components without making any spatial or anatomical modeling assumptions, instead requiring particular statistical properties such as maximum difference, maximum power, or statistical independence. We demonstrate how corresponding algorithms, for example, linear discriminant analysis, principal component analysis and independent component analysis, can be used to remove eye-motion artifacts, extract strong evoked responses, and decompose temporally overlapping components. The general approach is shown to be consistent with the underlying physics of EEG, which specifies a linear mixing model of the underlying neural and non-neural current sources.},
author = {Parra, Lucas C and Spence, Clay D and Gerson, Adam D and Sajda, Paul},
doi = {10.1016/j.neuroimage.2005.05.032},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parra et al/Parra et al. - 2005 - Recipes for the linear analysis of EEG. - NeuroImage.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Algorithms,Analysis of Variance,Artifacts,Data Interpretation, Statistical,Electroencephalography,Electroencephalography: statistics \& numerical dat,Evoked Potentials,Evoked Potentials: physiology,Eye Movements,Humans,Linear Models,Logistic Models,Reproducibility of Results},
month = nov,
number = {2},
pages = {326--41},
pmid = {16084117},
title = {{Recipes for the linear analysis of EEG.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16084117},
volume = {28},
year = {2005}
}
@article{Hollingworth1999,
author = {Hollingworth, a},
doi = {10.1016/S0001-6918(98)00053-5},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth/Hollingworth - 1999 - Object identification is isolated from scene semantic constraint evidence from object type and token discrimination - Acta Psychologica.pdf:pdf},
issn = {00016918},
journal = {Acta Psychologica},
month = sep,
number = {2-3},
pages = {319--343},
title = {{Object identification is isolated from scene semantic constraint: evidence from object type and token discrimination}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0001691898000535},
volume = {102},
year = {1999}
}
@article{Wolfe2004,
abstract = {As you drive into the centre of town, cars and trucks approach from several directions, and pedestrians swarm into the intersection. The wind blows a newspaper into the gutter and a pigeon does something unexpected on your windshield. This would be a demanding and stressful situation, but you would probably make it to the other side of town without mishap. Why is this situation taxing, and how do you cope?},
author = {Wolfe, Jeremy M and Horowitz, Todd S},
institution = {Visual Attention Laboratory, Brigham and Women's Hospital and Harvard Medical School, 64 Sidney Street, Cambridge, Massachusetts 02139, USA. wolfe@search.bwh.harvard.edu},
journal = {Nature Reviews Neuroscience},
keywords = {animals,attention,attention physiology,brain,brain physiology,cues,humans,pattern recognition,psychomotor performance,psychomotor performance physiology,visual,visual perception,visual perception physiology,visual physiology},
number = {6},
pages = {495--501},
pmid = {15152199},
publisher = {Nature Publishing Group},
title = {{What attributes guide the deployment of visual attention and how do they do it?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15152199},
volume = {5},
year = {2004}
}
@misc{Guo2010,
abstract = {Salient areas in natural scenes are generally regarded as areas which the human eye will typically focus on, and finding these areas is the key step in object detection. In computer vision, many models have been proposed to simulate the behavior of eyes such as SaliencyToolBox (STB), Neuromorphic Vision Toolkit (NVT), and others, but they demand high computational cost and computing useful results mostly relies on their choice of parameters. Although some region-based approaches were proposed to reduce the computational complexity of feature maps, these approaches still were not able to work in real time. Recently, a simple and fast approach called spectral residual (SR) was proposed, which uses the SR of the amplitude spectrum to calculate the image's saliency map. However, in our previous work, we pointed out that it is the phase spectrum, not the amplitude spectrum, of an image's Fourier transform that is key to calculating the location of salient areas, and proposed the phase spectrum of Fourier transform (PFT) model. In this paper, we present a quaternion representation of an image which is composed of intensity, color, and motion features. Based on the principle of PFT, a novel multiresolution spatiotemporal saliency detection model called phase spectrum of quaternion Fourier transform (PQFT) is proposed in this paper to calculate the spatiotemporal saliency map of an image by its quaternion representation. Distinct from other models, the added motion dimension allows the phase spectrum to represent spatiotemporal saliency in order to perform attention selection not only for images but also for videos. In addition, the PQFT model can compute the saliency map of an image under various resolutions from coarse to fine. Therefore, the hierarchical selectivity (HS) framework based on the PQFT model is introduced here to construct the tree structure representation of an image. With the help of HS, a model called multiresolution wavelet domain foveation (MWDF) is proposed in this paper to improve coding efficiency in image and video compression. Extensive tests of videos, natural images, and psychological patterns show that the proposed PQFT model is more effective in saliency detection and can predict eye fixations better than other state-of-the-art models in previous literature. Moreover, our model requires low computational cost and, therefore, can work in real time. Additional experiments on image and video compression show that the HS-MWDF model can achieve higher compression rate than the traditional model.},
author = {Guo, Chenlei and Zhang, Liming},
booktitle = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
doi = {10.1109/TIP.2009.2030969},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo, Zhang/Guo, Zhang - 2010 - A novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression..pdf:pdf},
issn = {1941-0042},
month = jan,
number = {1},
pages = {185--98},
pmid = {19709976},
title = {{A novel multiresolution spatiotemporal saliency detection model and its applications in image and video compression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19709976},
volume = {19},
year = {2010}
}
@book{Ashby1956,
address = {London, U.K.},
author = {Ashby, WR},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ashby/Ashby - 1956 - An introduction to cybernetics - Unknown.pdf:pdf},
publisher = {Chapman \& Hall Ltd.},
title = {{An introduction to cybernetics}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:An+Introduction+to+Cybernetics\#0},
year = {1956}
}
@article{Farnell2007,
abstract = {This document looks generally at the application of synthetic audio to video games and presents some experimental results and analysis from research in generating efficient synthetic sound for vir- tual worlds. Dynamic sound effects for real-time use in game worlds require far more careful thought to de- sign than brute force methods employed where sound is computed prior to delivery, not just in terms of static computational cost, but in how they are structured and behave when parametrised by world events. To make synthetic audio a possibility for the next generation of game audio compromises must be found that satisfy several conflicting variables. Examples are presented that demonstrate cost effective approximations based on key physical parameters and psychoacoustic cues, what can be called ”Practical synthetic sound design”.},
author = {Farnell, Andy},
file = {::},
title = {{Synthetic game audio with Puredata}},
year = {2007}
}
@article{Tatler2005a,
author = {Tatler, Benjamin W and Gilchrist, Iain D and Land, Michael F},
doi = {10.1080/02724980443000430},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Gilchrist, Land/Tatler, Gilchrist, Land - 2005 - Visual memory for objects in natural scenes From fixations to object files - Quarterly Journal of Experimental Psychology.pdf:pdf},
journal = {Quarterly Journal of Experimental Psychology},
number = {789284484},
title = {{Visual memory for objects in natural scenes : From fixations to object files}},
year = {2005}
}
@article{Whitney2003,
abstract = {Although the visual cortex is organized retinotopically, it is not clear whether the cortical representation of position necessarily reflects perceived position. Using functional magnetic resonance imaging (fMRI), we show that the retinotopic representation of a stationary object in the cortex was systematically shifted when visual motion was present in the scene. Whereas the object could appear shifted in the direction of the visual motion, the representation of the object in the visual cortex was always shifted in the opposite direction. The results show that the representation of position in the primary visual cortex, as revealed by fMRI, can be dissociated from perceived location.},
author = {Whitney, David and Goltz, Herbert C and Thomas, Christopher G and Gati, Joseph S and Menon, Ravi S and Goodale, Melvyn a},
doi = {10.1126/science.1087839},
file = {:Users/pkmital/Documents/Mendeley Desktop/Whitney et al/Whitney et al. - 2003 - Flexible retinotopy motion-dependent position coding in the visual cortex. - Science (New York, N.Y.).pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Attention,Brain Mapping,Humans,Illusions,Illusions: physiology,Magnetic Resonance Imaging,Motion Perception,Motion Perception: physiology,Photic Stimulation,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {5646},
pages = {878--81},
pmid = {14500849},
title = {{Flexible retinotopy: motion-dependent position coding in the visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14500849},
volume = {302},
year = {2003}
}
@article{Teki2013,
abstract = {In contrast to the complex acoustic environments we encounter everyday, most studies of auditory segregation have used relatively simple signals. Here, we synthesized a new stimulus to examine the detection of coherent patterns ('figures') from overlapping 'background' signals. In a series of experiments, we demonstrate that human listeners are remarkably sensitive to the emergence of such figures and can tolerate a variety of spectral and temporal perturbations. This robust behavior is consistent with the existence of automatic auditory segregation mechanisms that are highly sensitive to correlations across frequency and time. The observed behavior cannot be explained purely on the basis of adaptation-based models used to explain the segregation of deterministic narrowband signals. We show that the present results are consistent with the predictions of a model of auditory perceptual organization based on temporal coherence. Our data thus support a role for temporal coherence as an organizational principle underlying auditory segregation. DOI:http://dx.doi.org/10.7554/eLife.00699.001.},
author = {Teki, Sundeep and Chait, Maria and Kumar, Sukhbinder and Shamma, Shihab and Griffiths, Timothy D},
doi = {10.7554/eLife.00699},
file = {:Users/pkmital/Documents/Mendeley Desktop/Teki et al/Teki et al. - 2013 - Segregation of complex acoustic scenes based on temporal coherence. - eLife.pdf:pdf},
issn = {2050-084X},
journal = {eLife},
month = jan,
pages = {e00699},
pmid = {23898398},
title = {{Segregation of complex acoustic scenes based on temporal coherence.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3721234\&tool=pmcentrez\&rendertype=abstract},
volume = {2},
year = {2013}
}
@article{Kaneva2010,
author = {Kaneva, Biliana and Sivic, Josef and Torralba, Antonio and Avidan, Shai and Freeman, William T},
doi = {10.1109/JPROC.2009.2031133},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kaneva et al/Kaneva et al. - 2010 - Infinite Images Creating and Exploring a Large Photorealistic Virtual Space - Proceedings of the IEEE.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {image mosaicing,internet images,large datasets,scene recognition,transformed image retrieval,virtual scene},
month = aug,
number = {8},
pages = {1391--1407},
title = {{Infinite Images: Creating and Exploring a Large Photorealistic Virtual Space}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5473074},
volume = {98},
year = {2010}
}
@article{Rakthanmanon2012,
address = {New York, New York, USA},
author = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon and Zhu, Qiang and Zakaria, Jesin and Keogh, Eamonn},
doi = {10.1145/2339530.2339576},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rakthanmanon et al/Rakthanmanon et al. - 2012 - Searching and mining trillions of time series subsequences under dynamic time warping - Proceedings of the.pdf:pdf},
isbn = {9781450314626},
journal = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '12},
keywords = {lower bounds,similarity search,time series},
pages = {262},
publisher = {ACM Press},
title = {{Searching and mining trillions of time series subsequences under dynamic time warping}},
url = {http://dl.acm.org/citation.cfm?doid=2339530.2339576},
year = {2012}
}
@article{Raghuvanshi,
abstract = {Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design. Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the Wave Equation in rectangular domains, and utilizes an efficient implementation of the Discrete Cosine Transform on Graphics Processors (GPU) to achieve at least a 100-fold performance gain compared to a standard Finite-Difference Time-Domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.},
author = {Raghuvanshi, Nikunj and Narain, Rahul and Lin, Ming C},
doi = {10.1109/TVCG.2009.27},
file = {::},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
number = {5},
pages = {789--801},
pmid = {19590105},
title = {{Efficient and accurate sound propagation using adaptive rectangular decomposition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19590105},
volume = {15}
}
@article{Slaney1988,
author = {Slaney, Malcolm},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slaney/Slaney - 1988 - Lyon 's Cochlear Model - Control.pdf:pdf},
journal = {Control},
pages = {1--79},
title = {{Lyon 's Cochlear Model}},
year = {1988}
}
@article{Hooge1999,
abstract = {The present study concerns the dynamics of multiple fixation search. We tried to gain insight into: (1) how the peripheral and foveal stimulus affect fixation duration; and (2) how fixation duration affects the peripheral target selection for saccades. We replicated the non-corroborating results of Luria and Strauss (1975) ('Eye movements during search for coded and uncoded targets', Perception and Psychophysics 17, 303-308) (saccades were selective), and Zelinsky (1996) (Using eye movements to assess the selectivity of search movements. Vision research 36(14), 2177-2187) (saccades were not selective), by manipulating the critical features for peripheral selection and discrimination separately. We found search to be more selective and efficient when the selection task was easy or when fixations were long-lasting. Remarkably, subjects did not increase their fixation durations when the peripheral selection task was more difficult. Only the discrimination task affected the fixation duration. This implies that the time available for peripheral target selection is determined mainly by the discrimination task. The results of the present experiment suggest that, besides the difficulty of the peripheral selection task, fixation duration is an important factor determining the selection of potential targets for eye movements.},
author = {Hooge, I T and Erkelens, C J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hooge, Erkelens/Hooge, Erkelens - 1999 - Peripheral vision and oculomotor control during visual search. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Fixation, Ocular,Fovea Centralis,Humans,Male,Middle Aged,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Saccades,Saccades: physiology,Time Factors,Visual Fields},
month = apr,
number = {8},
pages = {1567--75},
pmid = {10343822},
title = {{Peripheral vision and oculomotor control during visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10343822},
volume = {39},
year = {1999}
}
@article{Eklundh,
author = {Eklundh, Jan-olof},
file = {:Users/pkmital/Documents/Mendeley Desktop/Eklundh/Eklundh - Unknown - Computer Vision and Active Perception Lab Royal Institute of Technology, Stockholm, Sweden - System.pdf:pdf},
journal = {System},
number = {January 2005},
title = {{Computer Vision and Active Perception Lab Royal Institute of Technology, Stockholm, Sweden}}
}
@article{Carruthers2009,
abstract = {Four different accounts of the relationship between third-person mindreading and first-person metacognition are compared and evaluated. While three of them endorse the existence of introspection for propositional attitudes, the fourth (defended here) claims that our knowledge of our own attitudes results from turning our mindreading capacities upon ourselves. Section 1 of this target article introduces the four accounts. Section 2 develops the "mindreading is prior" model in more detail, showing how it predicts introspection for perceptual and quasi-perceptual (e.g., imagistic) mental events while claiming that metacognitive access to our own attitudes always results from swift unconscious self-interpretation. This section also considers the model's relationship to the expression of attitudes in speech. Section 3 argues that the commonsense belief in the existence of introspection should be given no weight. Section 4 argues briefly that data from childhood development are of no help in resolving this debate. Section 5 considers the evolutionary claims to which the different accounts are committed, and argues that the three introspective views make predictions that are not borne out by the data. Section 6 examines the extensive evidence that people often confabulate when self-attributing attitudes. Section 7 considers "two systems" accounts of human thinking and reasoning, arguing that although there are introspectable events within System 2, there are no introspectable attitudes. Section 8 examines alleged evidence of "unsymbolized thinking". Section 9 considers the claim that schizophrenia exhibits a dissociation between mindreading and metacognition. Finally, section 10 evaluates the claim that autism presents a dissociation in the opposite direction, of metacognition without mindreading.},
author = {Carruthers, Peter},
doi = {10.1017/S0140525X09000545},
file = {:Users/pkmital/Documents/Mendeley Desktop/Carruthers/Carruthers - 2009 - How we know our own minds the relationship between mindreading and metacognition. - The Behavioral and brain science.pdf:pdf},
issn = {1469-1825},
journal = {The Behavioral and brain sciences},
keywords = {Adult,Attitude,Autistic Disorder,Autistic Disorder: psychology,Biological Evolution,Child Behavior,Child, Preschool,Cognition,Consciousness,Humans,Intuition,Models, Psychological,Schizophrenic Psychology,Self-Assessment,Thinking},
month = apr,
number = {2},
pages = {121--38; discussion 138--82},
pmid = {19386144},
title = {{How we know our own minds: the relationship between mindreading and metacognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19386144},
volume = {32},
year = {2009}
}
@article{Kajii2000,
abstract = {In the present study, the optimal viewing position (OVP) phenomenon in Japanese Hiragana was investigated, with special reference to a comparison between the vertical and the horizontal meridians in the visual field. In the first experiment, word recognition scores were determined while the eyes were fixating predetermined locations in vertically and horizontally displayed words. Similar to what has been reported for Roman scripts, OVP curves, which were asymmetric with respect to the beginning of words, were observed in both conditions. However, this asymmetry was less pronounced for vertically than for horizontally displayed words. In the second experiment, the visibility of individual characters within strings was examined for the vertical and horizontal meridians. As for Roman characters, letter identification scores were better in the right than in the left visual field. However, identification scores did not differ between the upper and the lower sides of fixation along the vertical meridian. The results showed that the model proposed by Nazir, O'Regan, and Jacobs (1991) cannot entirely account for the OVP phenomenon. A model in which visual and lexical factors are combined is proposed instead.},
author = {Kajii, N and Osaka, N},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kajii, Osaka/Kajii, Osaka - 2000 - Optimal viewing position in vertically and horizontally presented Japanese words. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adult,Attention,Discrimination Learning,Fixation, Ocular,Humans,Japan,Language,Orientation,Pattern Recognition, Visual,Psychophysics,Reading},
month = nov,
number = {8},
pages = {1634--44},
pmid = {11140184},
title = {{Optimal viewing position in vertically and horizontally presented Japanese words.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11140184},
volume = {62},
year = {2000}
}
@article{Mitrovic2007,
author = {Mitrovic, Dalibor and Zeppelzauer, Matthias and Eidenberger, Horst},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mitrovic, Zeppelzauer, Eidenberger/Mitrovic, Zeppelzauer, Eidenberger - 2007 - Analysis of the data quality of audio descriptions of environmental sounds - Journal of Digital Information Management.pdf:pdf},
issn = {0972-7272},
journal = {Journal of Digital Information Management},
number = {2},
pages = {48},
publisher = {Citeseer},
title = {{Analysis of the data quality of audio descriptions of environmental sounds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1611\&amp;rep=rep1\&amp;type=pdf},
volume = {5},
year = {2007}
}
@article{Healey2004,
author = {Healey, Christopher G. and Tateosian, Laura and Enns, James T. and Remple, Mark},
doi = {10.1145/966131.966135},
file = {:Users/pkmital/Documents/Mendeley Desktop/Healey et al/Healey et al. - 2004 - Perceptually based brush strokes for nonphotorealistic visualization - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = jan,
number = {1},
pages = {64--96},
title = {{Perceptually based brush strokes for nonphotorealistic visualization}},
url = {http://portal.acm.org/citation.cfm?doid=966131.966135},
volume = {23},
year = {2004}
}
@article{Hayhoe2003,
author = {Hayhoe, Mary M and Mruczek, Ryan and Pelz, Jeff B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hayhoe, Mruczek, Pelz/Hayhoe, Mruczek, Pelz - 2003 - Visual memory and motor planning in a natural task Anurag Shrivastava - Distribution.pdf:pdf},
journal = {Distribution},
keywords = {eye-hand coordination,natural tasks,saccades},
pages = {49--63},
title = {{Visual memory and motor planning in a natural task Anurag Shrivastava}},
year = {2003}
}
@article{Mustafa2012,
author = {Mustafa, Maryam and Guthe, Stefan and Magnor, Marcus},
doi = {10.1145/2325722.2325725},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mustafa, Guthe, Magnor/Mustafa, Guthe, Magnor - 2012 - Single-trial EEG classification of artifacts in videos - ACM Transactions on Applied Perception.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
month = jul,
number = {3},
pages = {1--15},
title = {{Single-trial EEG classification of artifacts in videos}},
url = {http://dl.acm.org/citation.cfm?doid=2325722.2325725},
volume = {9},
year = {2012}
}
@article{Parikh2007a,
author = {Parikh, Devi and Chen, Tsuhan},
doi = {10.1109/CVPR.2007.383370},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Chen/Parikh, Chen - 2007 - Unsupervised Learning of Hierarchical Semantics of Objects (hSOs) - 2007 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {1-4244-1179-3},
journal = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1--8},
publisher = {Ieee},
title = {{Unsupervised Learning of Hierarchical Semantics of Objects (hSOs)}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270368},
year = {2007}
}
@article{Cristino2009,
author = {Cristino, Filipe and Baddeley, Roland},
doi = {10.1080/13506280902834696},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cristino, Baddeley/Cristino, Baddeley - 2009 - The nature of the visual representations involved in eye movements when walking down the street - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {880--903},
title = {{The nature of the visual representations involved in eye movements when walking down the street}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902834696\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Cusack2003,
author = {Cusack, Rhodri and Carlyon, Robert P.},
doi = {10.1037/0096-1523.29.3.713},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cusack, Carlyon/Cusack, Carlyon - 2003 - Perceptual asymetries in audition. - Journal of Experimental Psychology Human Perception and Performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
number = {3},
pages = {713--725},
title = {{Perceptual asymetries in audition.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.29.3.713},
volume = {29},
year = {2003}
}
@inproceedings{Schwarz2003a,
address = {London, U.K.},
author = {Schwarz, D},
booktitle = {Proceedings of the 6th International Conference on Digital Audio Effects (DAFx-03)},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2003 - The caterpillar system for data-driven concatenative sound synthesis - Proceedings of the 6th International Conference.pdf:pdf},
title = {{The caterpillar system for data-driven concatenative sound synthesis}},
url = {http://recherche.ircam.fr/equipes/analyse-synthese/concat/doc/catdafx.pdf},
year = {2003}
}
@article{Perona1990,
author = {Perona, P. and Malik, J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Perona, Malik/Perona, Malik - 1990 - Scale-space and edge detection using anisotropic diffusion - Pattern Analysis and Machine Intelligence, IEEE Transactions on.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {7},
pages = {629--639},
publisher = {IEEE},
title = {{Scale-space and edge detection using anisotropic diffusion}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=56205},
volume = {12},
year = {1990}
}
@article{Navalpakkam2005,
abstract = {We propose a computational model for the task-specific guidance of visual attention in real-world scenes. Our model emphasizes four aspects that are important in biological vision: determining task-relevance of an entity, biasing attention for the low-level visual features of desired targets, recognizing these targets using the same low-level features, and incrementally building a visual map of task-relevance at every scene location. Given a task definition in the form of keywords, the model first determines and stores the task-relevant entities in working memory, using prior knowledge stored in long-term memory. It attempts to detect the most relevant entity by biasing its visual attention system with the entity's learned low-level features. It attends to the most salient location in the scene, and attempts to recognize the attended object through hierarchical matching against object representations stored in long-term memory. It updates its working memory with the task-relevance of the recognized entity and updates a topographic task-relevance map with the location and relevance of the recognized entity. The model is tested on three types of tasks: single-target detection in 343 natural and synthetic images, where biasing for the target accelerates target detection over twofold on average; sequential multiple-target detection in 28 natural images, where biasing, recognition, working memory and long term memory contribute to rapidly finding all targets; and learning a map of likely locations of cars from a video clip filmed while driving on a highway. The model's performance on search for single features and feature conjunctions is consistent with existing psychophysical data. These results of our biologically-motivated architecture suggest that the model may provide a reasonable approximation to many brain processes involved in complex task-driven visual behaviors.},
author = {Navalpakkam, Vidhya and Itti, Laurent},
doi = {10.1016/j.visres.2004.07.042},
file = {:Users/pkmital/Documents/Mendeley Desktop/Navalpakkam, Itti/Navalpakkam, Itti - 2005 - Modeling the influence of task on attention. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Attention: physiology,Cues,Humans,Memory,Memory: physiology,Models, Psychological,Pattern Recognition, Visual,Psychophysics,Recognition (Psychology),Recognition (Psychology): physiology,Visual Perception,Visual Perception: physiology},
month = jan,
number = {2},
pages = {205--31},
pmid = {15581921},
title = {{Modeling the influence of task on attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15581921},
volume = {45},
year = {2005}
}
@article{Couturier2002a,
author = {Couturier, D and Kessous, J M and Verfaille, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Couturier, Kessous, Verfaille/Couturier, Kessous, Verfaille - 2002 - Parameters using Perceptual Spaces - Organised Sound.pdf:pdf},
journal = {Organised Sound},
number = {2},
pages = {135--152},
title = {{Parameters using Perceptual Spaces}},
volume = {7},
year = {2002}
}
@article{Zhang2004,
author = {Zhang, Dengsheng and Lu, Guojun},
doi = {10.1016/j.patcog.2003.07.008},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang, Lu/Zhang, Lu - 2004 - Review of shape representation and description techniques - Pattern recognition.pdf:pdf},
issn = {0031-3203},
journal = {Pattern recognition},
keywords = {cbir,image retrieval,review,shape,shape descriptor},
number = {1},
pages = {1--19},
publisher = {Elsevier},
title = {{Review of shape representation and description techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303002759},
volume = {37},
year = {2004}
}
@misc{Smitelli2009,
author = {Smitelli, Scott},
booktitle = {Personal website},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smitelli/Smitelli - 2009 - Fun with YouTube's Audio Content ID System - Personal website.html:html},
title = {{Fun with YouTube's Audio Content ID System}},
url = {http://www.scottsmitelli.com/articles/youtube-audio-content-id},
urldate = {27/08/13},
year = {2009}
}
@article{Moore2003,
author = {Moore, Tirin and Armstrong, KM},
doi = {10.1038/nature01285.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Moore, Armstrong/Moore, Armstrong - 2003 - Selective gating of visual signals by microstimulation of frontal cortex - Nature.pdf:pdf},
journal = {Nature},
number = {January},
pages = {370--373},
title = {{Selective gating of visual signals by microstimulation of frontal cortex}},
url = {http://www.nature.com/nature/journal/v421/n6921/abs/nature01341.html},
volume = {421},
year = {2003}
}
@article{Morrone2000,
abstract = {The continuously changing optic flow on the retina provides information about direction of heading and about the three-dimensional structure of the environment. Here we use functional magnetic resonance imaging (fMRI) to demonstrate that an area in human cortex responds selectively to components of optic flow, such as circular and radial motion. This area is within the region commonly referrred to as V5/MT complex, but is distinct from the part of this region that responds to translation. The functional properties of these two areas of the V5/MT complex are also different; the response to optic flow was obtained only with changing flow stimuli, whereas response to translation occurred during exposure to continuous motion.},
author = {Morrone, M C and Tosetti, M and Montanaro, D and Fiorentini, a and Cioni, G and Burr, D C},
doi = {10.1038/81860},
file = {:Users/pkmital/Documents/Mendeley Desktop/Morrone et al/Morrone et al. - 2000 - A cortical area that responds specifically to optic flow, revealed by fMRI. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adult,Brain Mapping,Female,Humans,Magnetic Resonance Imaging,Male,Motion Perception,Motion Perception: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Rotation,Rotation: adverse effects,Temporal Lobe,Temporal Lobe: anatomy \& histology,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology},
month = dec,
number = {12},
pages = {1322--8},
pmid = {11100154},
title = {{A cortical area that responds specifically to optic flow, revealed by fMRI.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11100154},
volume = {3},
year = {2000}
}
@article{Hubel1972,
author = {Hubel, D H and Wiesel, T N},
doi = {10.1002/cne.901460402},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hubel, Wiesel/Hubel, Wiesel - 1972 - Laminar and columnar distribution of geniculo-cortical fibers in the macaque monkey. - The Journal of comparative.pdf:pdf},
issn = {0021-9967},
journal = {The Journal of comparative neurology},
keywords = {Animals,Axons,Dominance, Cerebral,Geniculate Bodies,Geniculate Bodies: anatomy \& histology,Geniculate Bodies: physiology,Haplorhini,Haplorhini: anatomy \& histology,Macaca,Macaca: anatomy \& histology,Nerve Degeneration,Neural Pathways,Neural Pathways: anatomy \& histology,Staining and Labeling,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology},
month = dec,
number = {4},
pages = {421--50},
pmid = {4117368},
title = {{Laminar and columnar distribution of geniculo-cortical fibers in the macaque monkey.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/4117368},
volume = {146},
year = {1972}
}
@article{Horng1998,
abstract = {Vergence eye movements have traditionally been considered the product of a single neural control center and are usually studied by combining the movements of each eye into a single 'vergence' response. In the present experiment, disparity-driven eye movements were produced by symmetrical step stimuli, and the dynamic properties of each eye movement were analyzed separately. Although the final positions of the two eyes were symmetrical, large dynamic asymmetries often occurred. The timing between the two eyes showed fair synchrony as they attained maximum velocity at approximately the same time. Since the final static positions were symmetrical, asymmetries occurring during the initial dynamic component must necessarily be compensated by offsetting asymmetries in the latter portion of the response.},
author = {Horng, J L and Semmlow, J L and Hung, G K and Ciuffreda, K J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Horng et al/Horng et al. - 1998 - Dynamic asymmetries in disparity convergence eye movements. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Convergence, Ocular,Humans,Middle Aged,Psychological Tests,Saccades,Vision Disparity},
month = sep,
number = {18},
pages = {2761--8},
pmid = {9775324},
title = {{Dynamic asymmetries in disparity convergence eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9775324},
volume = {38},
year = {1998}
}
@inproceedings{Smaragdis2007a,
author = {Smaragdis, Paris and Raj, Bhiksha and Shashanka, Madhusudana},
booktitle = {Proceedings of the 7th international conference on Independent component analysis and signal separation},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smaragdis, Raj, Shashanka/Smaragdis, Raj, Shashanka - 2007 - Supervised and semi-supervised separation of sounds from single-channel mixtures - Proceedings of the 7th international conference on Independent component analysis and signal separation.pdf:pdf},
title = {{Supervised and semi-supervised separation of sounds from single-channel mixtures}},
url = {http://www.springerlink.com/index/j31352756qr63220.pdf},
year = {2007}
}
@article{Henderson2009c,
author = {Henderson, John M. and Smith, Tim J.},
doi = {10.1080/13506280802685552},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Smith/Henderson, Smith - 2009 - How are eye fixation durations controlled during scene viewing Further evidence from a scene onset delay parad.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6-7},
pages = {1055--1082},
title = {{How are eye fixation durations controlled during scene viewing? Further evidence from a scene onset delay paradigm}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13506280802685552},
volume = {17},
year = {2009}
}
@inproceedings{Ravelli2008a,
address = {Philadelphia, PA},
author = {Ravelli, E and Richard, G and Daudet, L},
booktitle = {Int. Conf. Music Info. Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ravelli, Richard, Daudet/Ravelli, Richard, Daudet - 2008 - Fast MIR in a Sparse Transform Domain - Int. Conf. Music Info. Retrieval.pdf:pdf},
title = {{Fast MIR in a Sparse Transform Domain}},
year = {2008}
}
@article{Sams1983,
abstract = {Two auditory stimuli differing in pitch were presented in random order and equal probability with the constant inter-stimulus interval of 1 sec. The subject's task was to count one of these stimuli. The event-related brain potentials (ERPs) to each stimulus were averaged according to the immediately preceding stimulus sequence. It was found that when a few consecutive repetitions of one stimulus occurred, the ERP to the other stimulus immediately after those repetitions included features resembling those of the ERP to the infrequent stimulus usually observed in the so called 'oddball paradigm'. These features included, among other things, the mismatch negativity usually regarded as a scalp reflection of the neuronal mismatch process with an existing neuronal model. The mismatch negativity was accompanied by an 'N2b', a sharper and later negativity. Interestingly, N2b only occurred when the not-to-be-counted stimulus succeeded (one or several) counted stimuli but not when the order was reversed. This suggests that N2b reflects template mismatch, the occurrence of a stimulus mismatching with the mental image of the target stimulus voluntarily held by the subject.},
author = {Sams, M and Alho, K and N\"{a}\"{a}t\"{a}nen, R},
issn = {0301-0511},
journal = {Biological psychology},
keywords = {Adult,Cerebral Cortex,Cerebral Cortex: physiology,Electroencephalography,Electrooculography,Evoked Potentials, Auditory,Female,Humans,Male,Models, Neurological,Pitch Discrimination,Pitch Discrimination: physiology,Reading},
month = aug,
number = {1},
pages = {41--58},
pmid = {6626636},
title = {{Sequential effects on the ERP in discriminating two stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6626636},
volume = {17},
year = {1983}
}
@article{Oliva2000,
author = {Oliva, Aude and Schyns, Philippe G},
doi = {10.1006/cogp.1999.0728},
file = {:Users/pkmital/Documents/Mendeley Desktop/Oliva, Schyns/Oliva, Schyns - 2000 - Diagnostic Colors Mediate Scene Recognition - Cognitive Psychology.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {1975,a,a screen on which,appeared in rapid succession,b,categorization,classical scene-recognition experiment,color,diagnostic information,in potter,l,recognition,s,scene,slides of real-world scenes,spa-,spatial layout,subjects faced,tial scale},
pages = {176--210},
title = {{Diagnostic Colors Mediate Scene Recognition}},
volume = {41},
year = {2000}
}
@article{Kameyama,
author = {Kameyama, K. and Taga, K.},
doi = {10.1109/IJCNN.2004.1381146},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kameyama, Taga/Kameyama, Taga - Unknown - Texture classification by support vector machines with kernels for higher-order Gabor filtering - 2004 IEEE I.pdf:pdf},
isbn = {0-7803-8359-1},
journal = {2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)},
number = {1},
pages = {3009--3014},
publisher = {Ieee},
title = {{Texture classification by support vector machines with kernels for higher-order Gabor filtering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1381146},
volume = {4}
}
@article{Droll2009,
author = {Droll, Jason and Eckstein, Miguel},
doi = {10.1080/13506280902797125},
file = {:Users/pkmital/Documents/Mendeley Desktop/Droll, Eckstein/Droll, Eckstein - 2009 - Gaze control and memory for objects while walking in a real world environment - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1159--1184},
title = {{Gaze control and memory for objects while walking in a real world environment}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902797125\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Hubel1962,
author = {Hubel, DH and Wiesel, T. N.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hubel, Wiesel/Hubel, Wiesel - 1962 - Receptive fields, binocular interaction and functional architecture in the cat's visual cortex - The Journal of physiology.pdf:pdf},
journal = {The Journal of physiology},
pages = {106--154},
title = {{Receptive fields, binocular interaction and functional architecture in the cat's visual cortex}},
url = {http://jp.physoc.org/content/160/1/106.full.pdf},
volume = {160},
year = {1962}
}
@article{Manovich2009,
author = {Manovich, Lev},
file = {:Users/pkmital/Documents/Mendeley Desktop/Manovich/Manovich - 2009 - The Practice of Everyday (Media) Life From Mass Consumption to Mass Cultural Production - Critical Inquiry.pdf:pdf},
journal = {Critical Inquiry},
number = {2},
pages = {319--331},
title = {{The Practice of Everyday (Media) Life: From Mass Consumption to Mass Cultural Production?}},
volume = {35},
year = {2009}
}
@article{Kahneman1992,
abstract = {A series of experiments explored a form of object-specific priming. In all experiments a preview field containing two or more letters is followed by a target letter that is to be named. The displays are designed to produce a perceptual interpretation of the target as a new state of an object that previously contained one of the primes. The link is produced in different experiments by a shared location, by a shared relative position in a moving pattern, or by successive appearance in the same moving frame. An object-specific advantage is consistently observed: naming is facilitated by a preview of the target, if (and in some cases only if) the two appearances are linked to the same object. The amount and the object specificity of the preview benefit are not affected by extending the preview duration to 1 s, or by extending the temporal gap between fields to 590 ms. The results are interpreted in terms of a reviewing process, which is triggered by the appearance of the target and retrieves just one of the previewed items. In the absence of an object link, the reviewing item is selected at random. We develop the concept of an object file as a temporary episodic representation, within which successive states of an object are linked and integrated.},
author = {Kahneman, D and Treisman, A and Gibbs, B J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kahneman, Treisman, Gibbs/Kahneman, Treisman, Gibbs - 1992 - The reviewing of object files object-specific integration of information - Cognitive Psychology.pdf:pdf},
issn = {0010-0285},
journal = {Cognitive Psychology},
keywords = {Adult,Attention,Concept Formation,Discrimination Learning,Female,Humans,Male,Mental Recall,Motion Perception,Orientation,Pattern Recognition,Visual},
month = apr,
number = {2},
pages = {175--219},
pmid = {1582172},
title = {{The reviewing of object files: object-specific integration of information}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1582172},
volume = {24},
year = {1992}
}
@article{McDermott2009,
author = {McDermott, Josh H},
doi = {10.1016/j.cub.2009.09.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/McDermott/McDermott - 2009 - The cocktail party problem. - Current biology CB.pdf:pdf},
issn = {1879-0445},
journal = {Current biology : CB},
keywords = {Animal Communication,Animals,Humans,Noise,Sound},
month = dec,
number = {22},
pages = {R1024--7},
pmid = {19948136},
title = {{The cocktail party problem.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19948136},
volume = {19},
year = {2009}
}
@article{Tervaniemi2000,
abstract = {Previous positron emission tomography (PET) and functional magnetic resonance imaging (fMRI) studies show that during attentive listening, processing of phonetic information is associated with higher activity in the left auditory cortex than in the right auditory cortex while the opposite is true for musical information. The present PET study determined whether automatically activated neural mechanisms for phonetic and musical information are lateralized. To this end, subjects engaged in a visual word classification task were presented with phonetic sound sequences consisting of frequent (P = 0.8) and infrequent (P = 0.2) phonemes and with musical sound sequences consisting of frequent (P = 0.8) and infrequent (P = 0.2) chords. The phonemes and chords were matched in spectral complexity as well as in the magnitude of frequency difference between the frequent and infrequent sounds (/e/ vs. /o/; A major vs. A minor). In addition, control sequences, consisting of either frequent (/e/; A major) or infrequent sounds (/o/; A minor) were employed in separate blocks. When sound sequences consisted of intermixed frequent and infrequent sounds, automatic phonetic processing was lateralized to the left hemisphere and musical to the right hemisphere. This lateralization, however, did not occur in control blocks with one type of sound (frequent or infrequent). The data thus indicate that automatic activation of lateralized neuronal circuits requires sound comparison based on short-term sound representations.},
author = {Tervaniemi, M and Medvedev, S V and Alho, K and Pakhomov, S V and Roudas, M S and {Van Zuijen}, T L and N\"{a}\"{a}t\"{a}nen, R},
issn = {1065-9471},
journal = {Human brain mapping},
keywords = {Adult,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Brain: radionuclide imaging,Dominance, Cerebral,Dominance, Cerebral: physiology,Humans,Male,Music,Phonetics,Tomography, Emission-Computed},
month = jun,
number = {2},
pages = {74--9},
pmid = {10864231},
title = {{Lateralized automatic auditory processing of phonetic versus musical information: a PET study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10864231},
volume = {10},
year = {2000}
}
@article{Chun2007,
abstract = {Attention and memory cannot operate without each other. In this review, we discuss two lines of recent evidence that support this interdependence. First, memory has a limited capacity, and thus attention determines what will be encoded. Division of attention during encoding prevents the formation of conscious memories, although the role of attention in formation of unconscious memories is more complex. Such memories can be encoded even when there is another concurrent task, but the stimuli that are to be encoded must be selected from among other competing stimuli. Second, memory from past experience guides what should be attended. Brain areas that are important for memory, such as the hippocampus and medial temporal lobe structures, are recruited in attention tasks, and memory directly affects frontal-parietal networks involved in spatial orienting. Thus, exploring the interactions between attention and memory can provide new insights into these fundamental topics of cognitive neuroscience.},
author = {Chun, Marvin M and Turk-Browne, Nicholas B},
doi = {10.1016/j.conb.2007.03.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chun, Turk-Browne/Chun, Turk-Browne - 2007 - Interactions between attention and memory. - Current opinion in neurobiology.pdf:pdf},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animals,Attention,Brain Mapping,Choice Behavior,Choice Behavior: physiology,Diagnostic Imaging,Diagnostic Imaging: methods,Humans,Memory},
month = apr,
number = {2},
pages = {177--84},
pmid = {17379501},
title = {{Interactions between attention and memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17379501},
volume = {17},
year = {2007}
}
@inproceedings{Jarvelainen2000,
abstract = {This paper surveys some of the methods of algorithmic composition. Western classical music has been formalized in many ways throughout centuries, but the development of computers and the exponential growth of computing power have made it possible to generate music automatically. Common composing algorithms include state machines, rule-based grammars, stochastic processes, genetic algorithms, and so on. But who or what is the composer: the user or the maker of the algorithm?},
author = {Jarvelainen, H.},
booktitle = {Seminar on content creation, Telecommunications software and multimedia laboratory, Helsinki University of Technology},
file = {::},
pages = {11},
title = {{Algorithmic musical composition}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Algorithmic+Musical+Composition\#0},
year = {2000}
}
@incollection{Ist2010,
author = {Winkler, Istv\'{a}n},
booktitle = {Unconscious Memory Representations in Perception: Processes and mechanisms in the brain (Advances in Consciousness Research)},
isbn = {9027252149},
pages = {71--106},
publisher = {John Benjamins Publishing Company},
title = {{In search for auditory object representations}},
url = {http://www.amazon.com/Unconscious-Memory-Representations-Perception-Consciousness/dp/9027252149},
year = {2010}
}
@article{Hung1997,
abstract = {The dynamic characteristics of horizontal convergence and divergence eye movement responses to symmetric stimuli were examined. Binocular eye movements were recorded in five, visually normal adult subjects using the infrared reflection technique for symmetric convergent and divergent blur-free, disparity-only, step stimuli of 2, 4, 8, 12, and 16 deg. The main sequence as well as other temporal parameters including latency, time-to-peak velocity, time constant, and total duration were analyzed. A number of fundamental differences in the response characteristics were found between convergence and divergence. First, the slope of the peak velocity vs amplitude curve was approximately twice as high for convergence than divergence. The results are consistent with neurophysiological findings in monkeys and most findings in humans. Second, the initial fast component for convergence exhibited a larger amplitude than for divergence. This may reflect differences in central neural gain for convergence and divergence. And, third, all temporally related components were shorter for convergence than divergence. These findings provide an overall framework for vergence control and suggest fundamental differences in neural processing delays and neural controller pathways for convergence and divergence.},
author = {Hung, G K and Zhu, H and Ciuffreda, K J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hung, Zhu, Ciuffreda/Hung, Zhu, Ciuffreda - 1997 - Convergence and divergence exhibit different response characteristics to symmetric stimuli. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Convergence, Ocular,Convergence, Ocular: physiology,Humans,Middle Aged,Time Factors,Vision Disparity,Vision Disparity: physiology,Vision, Binocular},
month = may,
number = {9},
pages = {1197--205},
pmid = {9196737},
title = {{Convergence and divergence exhibit different response characteristics to symmetric stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9196737},
volume = {37},
year = {1997}
}
@article{Blei2006,
author = {Blei, David M.},
doi = {10.1214/06-BA104},
file = {:Users/pkmital/Documents/Mendeley Desktop/Blei/Blei - 2006 - Variational inference for Dirichlet process mixtures - Unknown.pdf:pdf},
issn = {1936-0975},
keywords = {bayesian computation,dirichlet processes,hierarchical models,image,processing,variational inference},
month = mar,
number = {1},
pages = {121--143},
title = {{Variational inference for Dirichlet process mixtures}},
volume = {1},
year = {2006}
}
@article{Kilthau2002,
author = {Kilthau, S.L. and Drew, M.S. and Moller, T.},
doi = {10.1109/ICIP.2002.1038113},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kilthau, Drew, Moller/Kilthau, Drew, Moller - 2002 - Full search content independent block matching based on the fast Fourier transform - Proceedings. International Conference on Image Processing.pdf:pdf},
isbn = {0-7803-7622-6},
journal = {Proceedings. International Conference on Image Processing},
pages = {I--669--I--672},
publisher = {Ieee},
title = {{Full search content independent block matching based on the fast Fourier transform}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1038113},
volume = {1},
year = {2002}
}
@article{McDermott2011,
author = {McDermott, Josh H. and Simoncelli, Eero P.},
doi = {10.1016/j.neuron.2011.06.032},
file = {:Users/pkmital/Documents/Mendeley Desktop/McDermott, Simoncelli/McDermott, Simoncelli - 2011 - Sound Texture Perception via Statistics of the Auditory Periphery Evidence from Sound Synthesis - Neuron.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = sep,
number = {5},
pages = {926--940},
title = {{Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627311005629},
volume = {71},
year = {2011}
}
@article{Kimurag,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - Unknown - Particle-based simulation of the Gel’fand-Pinsker channel capacity and the Wyner-Ziv rate-distortion function - East.pdf:pdf},
journal = {East},
title = {{Particle-based simulation of the Gel’fand-Pinsker channel capacity and the Wyner-Ziv rate-distortion function}}
}
@article{Cusack2011,
abstract = {A key challenge of object recognition is achieving a balance between selectivity for relevant features and invariance to irrelevant ones. Computational and cognitive models predict that optimal selectivity for features will differ by object, and here we investigate whether this is reflected in visual representations in the human ventral stream. We describe a new real-time neuroimaging method, dynamically adaptive imaging (DAI), that enabled measurement of neural selectivity along multiple feature dimensions in the neighborhood of single referent objects. The neural response evoked by a referent was compared to that evoked by 91 naturalistic objects using multi-voxel pattern analysis. Iteratively, the objects evoking the most similar responses were selected and presented again, to converge upon a subset that characterizes the referent's "neural neighborhood." This was used to derive the feature selectivity of the response. For three different referents, we found strikingly different selectivity, both in individual features and in the balance of tuning to sensory versus semantic features. Additional analyses placed a lower bound on the number of distinct activation patterns present. The results suggest that either the degree of specificity available for object representation in the ventral stream varies by class, or that different objects evoke different processing strategies. Hum Brain Mapp, 2011. © 2011 Wiley-Liss, Inc.},
author = {Cusack, Rhodri and Veldsman, Michele and Naci, Lorina and Mitchell, Daniel J and Linke, Annika C},
doi = {10.1002/hbm.21219},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cusack et al/Cusack et al. - 2011 - Seeing different objects in different ways Measuring ventral visual tuning to sensory and semantic features with dynamically adaptive imaging. - Human brain mapping.pdf:pdf},
issn = {1097-0193},
journal = {Human brain mapping},
keywords = {fmri,object recognition,real-time imaging,ventral stream},
month = mar,
pages = {1--12},
pmid = {21391273},
title = {{Seeing different objects in different ways: Measuring ventral visual tuning to sensory and semantic features with dynamically adaptive imaging.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21391273},
volume = {00000},
year = {2011}
}
@article{Zirnsak2011,
abstract = {Can we attend to multiple distinct spatial locations at the same time? According to a recent psychophysical study [J. Dubois et al. (2009)Journal of Vision, 9, 3.1-11] such a split of spatial attention might be limited to short periods of time. Following N. P. Bichot et al. [(1999)Perception \& Psychophysics, 61, 403-423] subjects had to report the identity of multiple letters that were briefly presented at different locations, while two of these locations (targets) were relevant for a concurrent shape comparison task. In addition to the design used by Bichot et al. stimulus onset asynchrony between shape onset and letters was systematically varied. In general, the performance of subjects was superior at target locations. Furthermore, for short stimulus onset asynchronies, performance was simultaneously increasing at both target locations. For longer stimulus onset asynchronies, however, performance deteriorated at one of the target locations while increasing at the other target location. It was hypothesized that this dynamic deployment of attention might be caused by competitive processes in saccade-related structures such as the frontal eye field. Here we simulated the task of Dubois et al. using a systems-level model of attention. Our results are consistent with recent findings in the frontal eye field obtained during covert visual search, and they support the view of a transient deployment of spatial attention to multiple stimuli in the early epoch of target selection.},
author = {Zirnsak, Marc and Beuth, Frederik and Hamker, Fred H},
doi = {10.1111/j.1460-9568.2011.07718.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zirnsak, Beuth, Hamker/Zirnsak, Beuth, Hamker - 2011 - Split of spatial attention as predicted by a systems-level model of visual attention. - The European jou.pdf:pdf},
issn = {1460-9568},
journal = {The European journal of neuroscience},
keywords = {Attention,Attention: physiology,Computer Simulation,Eye Movements,Eye Movements: physiology,Models, Neurological,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {11},
pages = {2035--45},
pmid = {21645099},
title = {{Split of spatial attention as predicted by a systems-level model of visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21645099},
volume = {33},
year = {2011}
}
@article{Theeuwes1992,
abstract = {Three visual-search experiments tested whether the preattentive parallel stage can selectively guide the attentive stage to a particular known-to-be-relevant target feature. Subjects searched multielement displays for a salient green circle that had a unique form when surrounded by green nontarget squares or had a unique color when surrounded by red nontarget circles. In the distractor conditions, a salient item in the other dimension was present as well. As an extension of earlier findings (Theeuwes, 1991), the results showed that complete top-down selectivity toward a particular feature was not possible, not even after extended and consistent practice. The results reveal that selectivity depends on the relative discriminability of the stimulus dimensions: the presence of an irrelevant item with a unique color interferes with parallel search for a unique form, and vice versa.},
author = {Theeuwes, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Theeuwes/Theeuwes - 1992 - Perceptual selectivity for color and form. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Color Perception,Color Perception: physiology,Equipment Design,Female,Form Perception,Form Perception: physiology,Humans,Male,Mental Processes,Perceptual Masking},
month = jun,
number = {6},
pages = {599--606},
pmid = {1620571},
title = {{Perceptual selectivity for color and form.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1620571},
volume = {51},
year = {1992}
}
@article{Frauenberger2003,
author = {Frauenberger, Christopher and Noisternig, Markus},
file = {:Users/pkmital/Documents/Mendeley Desktop/Frauenberger, Noisternig/Frauenberger, Noisternig - 2003 - 3D audio interfaces for the blind - Proceedings of the 2003 International Conference on Auditory Displays.pdf:pdf},
journal = {Proceedings of the 2003 International Conference on Auditory Displays},
pages = {1--4},
title = {{3D audio interfaces for the blind}},
url = {http://iem.at/~noisternig/publications/Frauenberger\_2003.pdf},
year = {2003}
}
@article{Thompson2006,
author = {Kosslyn, S. M. and Ganis, G. and Thompson, WL},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kosslyn, Ganis, Thompson/Kosslyn, Ganis, Thompson - 2006 - Mental imagery and the human brain - Progress in Psychological Science Around the World.pdf:pdf},
journal = {Progress in Psychological Science Around the World},
pages = {195--209},
title = {{Mental imagery and the human brain}},
url = {http://books.google.com/books?hl=en\&lr=\&id=Zmkys\_IGa2YC\&oi=fnd\&pg=PA195\&dq=Mental+imagery+and+the+human+brain\&ots=rDaZOQDs1l\&sig=O6Zx\_s31XCZfkJRG-zJ5qu3MX9w},
volume = {1},
year = {2006}
}
@article{Schreiner2000,
abstract = {Two fundamental aspects of frequency analysis shape the functional organization of primary auditory cortex. For one, the decomposition of complex sounds into different frequency components is reflected in the tonotopic organization of auditory cortical fields. Second, recent findings suggest that this decomposition is carried out in parallel for a wide range of frequency resolutions by neurons with frequency receptive fields of different sizes (bandwidths). A systematic representation of the range of frequency resolution and, equivalently, spectral integration shapes the functional organization of the iso-frequency domain. Distinct subregions, or "modules," along the iso-frequency domain can be demonstrated with various measures of spectral integration, including pure-tone tuning curves, noise masking, and electrical cochlear stimulation. This modularity in the representation of spectral integration is expressed by intrinsic cortical connections. This organization has implications for our understanding of psychophysical spectral integration measures such as the critical band and general cortical coding strategies.},
author = {Schreiner, C E and Read, H L and Sutter, M L},
doi = {10.1146/annurev.neuro.23.1.501},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schreiner, Read, Sutter/Schreiner, Read, Sutter - 2000 - Modular organization of frequency integration in primary auditory cortex. - Annual review of neuroscien.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Auditory Cortex,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping},
month = jan,
pages = {501--29},
pmid = {10845073},
title = {{Modular organization of frequency integration in primary auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10845073},
volume = {23},
year = {2000}
}
@article{Kutas2009,
author = {Kutas, Marta and Mccarthy, Gregory and Donchin, Emanuel and Klein, M G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kutas et al/Kutas et al. - 2009 - Augmenting Mental Chronometry The P300 as a Measure of Stimulus Evaluation Time Published by American Association for the Advancement of Science Stable URL httpwww.jstor.orgstable1744874 Augmenting Mental Chronometry The P30.pdf:pdf},
journal = {Advancement Of Science},
number = {4305},
pages = {792--795},
title = {{Augmenting Mental Chronometry : The P300 as a Measure of Stimulus Evaluation Time Published by : American Association for the Advancement of Science Stable URL : http://www.jstor.org/stable/1744874 Augmenting Mental Chronometry : The P300 as a Measure of }},
volume = {197},
year = {2009}
}
@article{Lilly1977,
author = {Lilly, JC},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lilly/Lilly - 1977 - The deep self - New York, Simon \& Schuster. Lodeon, J.(1986), \ldots.pdf:pdf},
journal = {New York, Simon \& Schuster. Lodeon, J.(1986), \ldots},
title = {{The deep self}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Deep+Self\#1},
year = {1977}
}
@article{Parkhurst2002,
abstract = {A biologically motivated computational model of bottom-up visual selective attention was used to examine the degree to which stimulus salience guides the allocation of attention. Human eye movements were recorded while participants viewed a series of digitized images of complex natural and artificial scenes. Stimulus dependence of attention, as measured by the correlation between computed stimulus salience and fixation locations, was found to be significantly greater than that expected by chance alone and furthermore was greatest for eye movements that immediately follow stimulus onset. The ability to guide attention of three modeled stimulus features (color, intensity and orientation) was examined and found to vary with image type. Additionally, the effect of the drop in visual sensitivity as a function of eccentricity on stimulus salience was examined, modeled, and shown to be an important determiner of attentional allocation. Overall, the results indicate that stimulus-driven, bottom-up mechanisms contribute significantly to attentional guidance under natural viewing conditions.},
author = {Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
chapter = {107},
institution = {The Department of Psychology, The Johns Hopkins University, 3400 N. Charles Street, Baltimore, MD 21218, USA.},
journal = {Vision Research},
keywords = {analysis variance,attention,attention physiology,biological,computer simulation,eye movements,eye movements physiology,female,humans,male,models,normal distribution,visual perception,visual perception physiology},
number = {1},
pages = {107--123},
pmid = {11804636},
publisher = {Elsevier},
title = {{Modeling the role of salience in the allocation of overt visual attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11804636},
volume = {42},
year = {2002}
}
@article{Tatler2007a,
abstract = {The antisaccade task requires participants to inhibit the reflexive tendency to look at a sudden onset target and instead direct their gaze to the opposite hemifield. As such it provides a convenient tool with which to investigate the cognitive and neural systems that support goal-directed behaviour. Recent models of cognitive control suggest that antisaccade performance on a single trial should vary as a function of the outcome (correct antisaccade or erroneous prosaccade) of the previous trial. In addition, repetition priming effects suggest that the spatial location of the target on the previous trial may also influence current trial performance. Thus an analysis of contingency effects in antisaccade performance may provide new insights into the factors that influence the monitoring and modulation of the antisaccade task and other ongoing behaviours. Using a multilevel modelling analysis we explored previous trial effects on current trial performance in a large antisaccade dataset. We found (1) repetition priming effects following correct antisaccades; (2) contrary to models of cognitive control antisaccade error rates were increased on trials following an error, suggesting that failures to adequately maintain the task goal can persist across more than one trial; and (3) current trial latencies varied according to the previous trial outcome (correct antisaccade, slowly corrected error or rapidly corrected error). These results are discussed in terms of current models of antisaccade performance and cognitive control and further demonstrate the utility of multilevel modelling for analysing antisaccade data.},
author = {Tatler, Benjamin W and Hutton, Samuel B},
doi = {10.1007/s00221-006-0799-6},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Hutton/Tatler, Hutton - 2007 - Trial by trial effects in the antisaccade task. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adult,Attention,Attention: physiology,Cognition,Cognition: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Learning,Learning: physiology,Memory, Short-Term,Memory, Short-Term: physiology,Models, Neurological,Neural Inhibition,Neural Inhibition: physiology,Neuropsychological Tests,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Saccades,Saccades: physiology},
month = may,
number = {3},
pages = {387--96},
pmid = {17136522},
title = {{Trial by trial effects in the antisaccade task.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17136522},
volume = {179},
year = {2007}
}
@article{Hauk2007,
abstract = {Using an object decision task, event-related potentials (ERPs), and minimum norm current source estimates, we investigated early spatiotemporal aspects of cortical activation elicited by line drawings that were manipulated on two dimensions: authenticity and typicality. Authentic objects were those that match real-world experience, whereas nonauthentic objects were "doctored" by deletion or addition of features (e.g., a camel with its hump removed, a hammer with two handles). The main manipulation of interest for both authentic and nonauthentic objects was the degree of typicality in the object's structure: typical items are composed of parts that have tended to co-occur across many different objects in the perceiver's experience. The ERP pattern revealed a significant typicality effect at 116 msec after stimulus onset. Both atypical authentic objects (e.g., a camel with its hump) and atypical nonauthentic objects (e.g., a jackal with a hump) elicited stronger brain activation than did objects with typical structure. A significant effect of authenticity was observed at 480 msec, with stronger activation for the nonauthentic objects. The factors of typicality and authenticity interacted at 160 and 330 msec. The most prominent source of the typicality effect was the bilateral occipitotemporal cortex, whereas the interaction and the authenticity effects were mainly observed in the more anterior bilateral temporal cortex. These findings support the hypothesis that within the first few hundred milliseconds after stimulus presentation onset, visual-form-related perceptual and conceptual processes represent distinct but interacting stages in object recognition.},
author = {Hauk, O and Patterson, K and Woollams, a and Cooper-Pye, E and Pulverm\"{u}ller, F and Rogers, T T},
doi = {10.1162/jocn.2007.19.8.1338},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hauk et al/Hauk et al. - 2007 - How the camel lost its hump the impact of object typicality on event-related potential signals in object decision. - Journal of cognitive neuroscience.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Adult,Decision Making,Decision Making: physiology,Evoked Potentials,Female,Form Perception,Form Perception: physiology,Humans,Male,Occipital Lobe,Occipital Lobe: physiology,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Recognition (Psychology),Recognition (Psychology): physiology,Temporal Lobe,Temporal Lobe: physiology},
month = aug,
number = {8},
pages = {1338--53},
pmid = {17651007},
title = {{How the camel lost its hump: the impact of object typicality on event-related potential signals in object decision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17651007},
volume = {19},
year = {2007}
}
@article{Bergeaud,
author = {Bergeaud, F},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bergeaud/Bergeaud - Unknown - Matching pursuit of images - Image Processing,1995. Proceedings.,.pdf:pdf},
journal = {Image Processing,1995. Proceedings.,},
title = {{Matching pursuit of images}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=529037}
}
@article{Morup2007,
author = {M$\backslash$orup, M and Schmidt, M N and Hansen, L K},
journal = {J. Machine Learning},
title = {{Shift Invariant Sparse Coding of Image and Music Data}},
year = {2007}
}
@article{Scholl2001,
abstract = {What are the units of attention? In addition to standard models holding that attention can select spatial regions and visual features, recent work suggests that in some cases attention can directly select discrete objects. This paper reviews the state of the art with regard to such 'object-based' attention, and explores how objects of attention relate to locations, reference frames, perceptual groups, surfaces, parts, and features. Also discussed are the dynamic aspects of objecthood, including the question of how attended objects are individuated in time, and the possibility of attending to simple dynamic motions and events. The final sections of this review generalize these issues beyond vision science, to other modalities and fields such as auditory objects of attention and the infant's 'object concept'.},
author = {Scholl, B J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Scholl/Scholl - 2001 - Objects and attention the state of the art. - Cognition.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Attention,Auditory Perception,Child Development,Humans,Infant,Models, Psychological,Motion Perception,Space Perception,Visual Perception},
month = jun,
number = {1-2},
pages = {1--46},
pmid = {11245838},
title = {{Objects and attention: the state of the art.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11245838},
volume = {80},
year = {2001}
}
@article{Ballard2009,
abstract = {Gaze changes and the resultant fixations that orchestrate the sequential acquisition of information from the visual environment are the central feature of primate vision. How are we to understand their function? For the most part, theories of fixation targets have been image based: The hypothesis being that the eye is drawn to places in the scene that contain discontinuities in image features such as motion, colour, and texture. But are these features the cause of the fixations, or merely the result of fixations that have been planned to serve some visual function? This paper examines the issue and reviews evidence from various image-based and task-based sources. Our conclusion is that the evidence is overwhelmingly in favour of fixation control being essentially task based.},
author = {Ballard, Dana H and Hayhoe, Mary M},
doi = {10.1080/13506280902978477},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ballard, Hayhoe/Ballard, Hayhoe - 2009 - Modelling the role of task in the control of gaze. - Visual cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual cognition},
month = aug,
number = {6-7},
pages = {1185--1204},
pmid = {20411027},
title = {{Modelling the role of task in the control of gaze.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2856937\&tool=pmcentrez\&rendertype=abstract},
volume = {17},
year = {2009}
}
@article{Pamphlet2004,
author = {Pamphlet, A Great Bear},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pamphlet/Pamphlet - 2004 - The Art of Noise - Unknown.pdf:pdf},
title = {{The Art of Noise}},
year = {2004}
}
@article{Chang2005,
author = {Chang, Youngha and Saito, Suguru and Uchikawa, Keiji and Nakajima, Masayuki},
doi = {10.1145/1077399.1077408},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chang et al/Chang et al. - 2005 - Example-Based Color Stylization of Images - ACM Transactions on Applied Perception.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
month = jul,
number = {3},
pages = {322--345},
title = {{Example-Based Color Stylization of Images}},
url = {http://portal.acm.org/citation.cfm?doid=1077399.1077408},
volume = {2},
year = {2005}
}
@phdthesis{Rubin1915,
address = {K\o benhavn og Kristiania, Gyldendal},
author = {Rubin, Edgar 1886-1951},
edition = {1. del},
publisher = {Nordisk forlag},
title = {{Synsoplevede figurer: studier i psykologisk analyse}},
url = {https://catalyst.library.jhu.edu/catalog/bib\_756042},
year = {1915}
}
@article{Krieger2000,
abstract = {Based on an information theoretical approach, we investigate feature selection processes in saccadic object and scene analysis. Saccadic eye movements of human observers are recorded for a variety of natural and artificial test images. These experimental data are used for a statistical evaluation of the fixated image regions. Analysis of second-order statistics indicates that regions with higher spatial variance have a higher probability to be fixated, but no significant differences beyond these variance effects could be found at the level of power spectra. By contrast, an investigation with higher-order statistics, as reflected in the bispectral density, yielded clear structural differences between the image regions selected by saccadic eye movements as opposed to regions selected by a random process. These results indicate that nonredundant, intrinsically two-dimensional image features like curved lines and edges, occlusions, isolated spots, etc. play an important role in the saccadic selection process which must be integrated with top-down knowledge to fully predict object and scene analysis by human observers.},
author = {Krieger, G and Rentschler, I and Hauske, G and Schill, K and Zetzsche, C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Krieger et al/Krieger et al. - 2000 - Object and scene analysis by saccadic eye-movements an investigation with higher-order statistics. - Spatial vision.pdf:pdf},
issn = {0169-1015},
journal = {Spatial vision},
keywords = {Adult,Computer Simulation,Data Interpretation, Statistical,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Image Processing, Computer-Assisted,Motion Perception,Motion Perception: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reference Values,Saccades,Saccades: physiology,Video Recording},
month = jan,
number = {2-3},
pages = {201--14},
pmid = {11198232},
title = {{Object and scene analysis by saccadic eye-movements: an investigation with higher-order statistics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11198232},
volume = {13},
year = {2000}
}
@article{Slaney2001a,
author = {Slaney, Malcolm},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slaney/Slaney - 2001 - Slaney and Covell (2001) Algorithm - Compute.pdf:pdf},
journal = {Compute},
title = {{Slaney and Covell (2001) Algorithm}},
year = {2001}
}
@article{Howard2011,
abstract = {Low-level stimulus salience and task relevance together determine the human fixation priority assigned to scene locations (Fecteau and Munoz in Trends Cogn Sci 10(8):382-390, 2006). However, surprisingly little is known about the contribution of task relevance to eye movements during real-world visual search where stimuli are in constant motion and where the 'target' for the visual search is abstract and semantic in nature. Here, we investigate this issue when participants continuously search an array of four closed-circuit television (CCTV) screens for suspicious events. We recorded eye movements whilst participants watched real CCTV footage and moved a joystick to continuously indicate perceived suspiciousness. We find that when multiple areas of a display compete for attention, gaze is allocated according to relative levels of reported suspiciousness. Furthermore, this measure of task relevance accounted for twice the amount of variance in gaze likelihood as the amount of low-level visual changes over time in the video stimuli.},
author = {Howard, Christina J and Gilchrist, Iain D and Troscianko, Tom and Behera, Ardhendu and Hogg, David C},
doi = {10.1007/s00221-011-2812-y},
file = {:Users/pkmital/Documents/Mendeley Desktop/Howard et al/Howard et al. - 2011 - Task relevance predicts gaze in videos of real moving scenes. - Experimental brain research. Experimentelle Hi.pdf:pdf},
isbn = {0022101128},
issn = {1432-1106},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Male,Photic Stimulation,Photic Stimulation: methods,Predictive Value of Tests,Videotape Recording,Visual Perception,Visual Perception: physiology,Young Adult},
month = sep,
number = {1},
pages = {131--7},
pmid = {21822674},
title = {{Task relevance predicts gaze in videos of real moving scenes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21822674},
volume = {214},
year = {2011}
}
@inproceedings{Taubin1989,
author = {Taubin, G. and Bolle, R.M. and Cooper, D.B.},
booktitle = {Computer Vision and Pattern Recognition, 1989. Proceedings CVPR'89., IEEE Computer Society Conference on},
file = {:Users/pkmital/Documents/Mendeley Desktop/Taubin, Bolle, Cooper/Taubin, Bolle, Cooper - 1989 - Representing and comparing shapes using shape polynomials - Computer Vision and Pattern Recognition, 1989. Proceedings CVPR'89., IEEE Computer Society Conference on.pdf:pdf},
pages = {510--516},
publisher = {IEEE},
title = {{Representing and comparing shapes using shape polynomials}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=37894},
year = {1989}
}
@article{Rosenblum2008a,
author = {Rosenblum, Editors Lawrence and Julier, Simon and Bruns, Erich},
file = {::},
journal = {IEEE Computer Graphics and Applications},
pages = {98--102},
publisher = {IEEE Computer Society},
title = {{Projects in VR}},
url = {http://doi.ieeecomputersociety.org/10.1109/MCG.2008.77},
year = {2008}
}
@article{Caldara2011,
abstract = {Eye movement data analyses are commonly based on the probability of occurrence of saccades and fixations (and their characteristics) in given regions of interest (ROIs). In this article, we introduce an alternative method for computing statistical fixation maps of eye movements-iMap-based on an approach inspired by methods used in functional magnetic resonance imaging. Importantly, iMap does not require the a priori segmentation of the experimental images into ROIs. With iMap, fixation data are first smoothed by convolving Gaussian kernels to generate three-dimensional fixation maps. This procedure embodies eyetracker accuracy, but the Gaussian kernel can also be flexibly set to represent acuity or attentional constraints. In addition, the smoothed fixation data generated by iMap conform to the assumptions of the robust statistical random field theory (RFT) approach, which is applied thereafter to assess significant fixation spots and differences across the three-dimensional fixation maps. The RFT corrects for the multiple statistical comparisons generated by the numerous pixels constituting the digital images. To illustrate the processing steps of iMap, we provide sample analyses of real eye movement data from face, visual scene, and memory processing. The iMap MATLAB toolbox is editable and freely available for download online ( www.unifr.ch/psycho/ibmlab/ ).},
author = {Caldara, Roberto and Miellet, S\'{e}bastien},
doi = {10.3758/s13428-011-0092-x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Caldara, Miellet/Caldara, Miellet - 2011 - iMap a novel method for statistical fixation mapping of eye movement data. - Behavior research methods.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {data-driven analyses,eye movements,matlab toolbox,random field theory,statistical fixation maps},
month = apr,
pmid = {21512875},
title = {{iMap: a novel method for statistical fixation mapping of eye movement data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21512875},
year = {2011}
}
@phdthesis{Dissertation2006,
author = {Winnemoller, H and Adviser-Gooch, B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winnemoller, Adviser-Gooch/Winnemoller, Adviser-Gooch - 2006 - Perceptually-motivated non-photorealistic graphics - Unknown.pdf:pdf},
number = {December},
title = {{Perceptually-motivated non-photorealistic graphics}},
url = {http://dl.acm.org/citation.cfm?id=1237353},
year = {2006}
}
@article{Buneo2006,
abstract = {We present a view of the posterior parietal cortex (PPC) as a sensorimotor interface for visually guided movements. Special attention is given to the role of the PPC in arm movement planning, where representations of target position and current hand position in an eye-centered frame of reference appear to be mapped directly to a representation of motor error in a hand-centered frame of reference. This mapping is direct in the sense that it does not require target position to be transformed into intermediate reference frames in order to derive a motor error signal in hand-centered coordinates. Despite being direct, this transformation appears to manifest in the PPC as a gradual change in the functional properties of cells along the ventro-dorsal axis of the superior parietal lobule (SPL), i.e. from deep in the sulcus to the cortical surface. Possible roles for the PPC in context dependent coordinate transformations, formation of intrinsic movement representations, and in online control of visually guided arm movements are also discussed. Overall these studies point to the emerging view that, for arm movements, the PPC plays a role not only in the inverse transformations required to convert sensory information into motor commands but also in 'forward' transformations as well, i.e. in integrating sensory input with previous and ongoing motor commands to maintain a continuous estimate of arm state that can be used to update present and future movement plans. Critically, this state estimate appears to be encoded in an eye-centered frame of reference.},
author = {Buneo, Christopher a and Andersen, Richard a},
doi = {10.1016/j.neuropsychologia.2005.10.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Buneo, Andersen/Buneo, Andersen - 2006 - The posterior parietal cortex sensorimotor interface for the planning and online control of visually guided movements. - Neuropsychologia.pdf:pdf},
issn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Animals,Arm,Arm: physiology,Brain Mapping,Eye Movements,Humans,Movement,Movement: physiology,Parietal Lobe,Parietal Lobe: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Space Perception,Space Perception: physiology},
month = jan,
number = {13},
pages = {2594--606},
pmid = {16300804},
title = {{The posterior parietal cortex: sensorimotor interface for the planning and online control of visually guided movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16300804},
volume = {44},
year = {2006}
}
@article{Norman2006,
abstract = {A key challenge for cognitive neuroscience is determining how mental representations map onto patterns of neural activity. Recently, researchers have started to address this question by applying sophisticated pattern-classification algorithms to distributed (multi-voxel) patterns of functional MRI data, with the goal of decoding the information that is represented in the subject's brain at a particular point in time. This multi-voxel pattern analysis (MVPA) approach has led to several impressive feats of mind reading. More importantly, MVPA methods constitute a useful new tool for advancing our understanding of neural information processing. We review how researchers are using MVPA methods to characterize neural coding and information processing in domains ranging from visual perception to memory search.},
author = {Norman, Kenneth a and Polyn, Sean M and Detre, Greg J and Haxby, James V},
doi = {10.1016/j.tics.2006.07.005},
file = {:Users/pkmital/Documents/Mendeley Desktop/Norman et al/Norman et al. - 2006 - Beyond mind-reading multi-voxel pattern analysis of fMRI data. - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Algorithms,Artificial Intelligence,Brain,Brain: physiology,Cognition,Cognition: physiology,Discrimination Learning,Discrimination Learning: physiology,Electroencephalography,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Memory,Memory: physiology,Mental Processes,Mental Processes: physiology,Multivariate Analysis,Orientation,Orientation: physiology,Pattern Recognition, Automated,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Signal Processing, Computer-Assisted,Visual Perception,Visual Perception: physiology},
month = sep,
number = {9},
pages = {424--30},
pmid = {16899397},
title = {{Beyond mind-reading: multi-voxel pattern analysis of fMRI data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16899397},
volume = {10},
year = {2006}
}
@article{Smolic,
author = {Smolic, a. and Wiegand, T.},
doi = {10.1109/ICIP.2001.958259},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smolic, Wiegand/Smolic, Wiegand - Unknown - High-resolution video mosaicing - Proceedings 2001 International Conference on Image Processing (Cat. No.01C.pdf:pdf},
isbn = {0-7803-6725-1},
journal = {Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)},
pages = {872--875},
publisher = {Ieee},
title = {{High-resolution video mosaicing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=958259},
volume = {2}
}
@article{Brown2008,
abstract = {We propose a linear ballistic accumulator (LBA) model of decision making and reaction time. The LBA is simpler than other models of choice response time, with independent accumulators that race towards a common response threshold. Activity in the accumulators increases in a linear and deterministic manner. The simplicity of the model allows complete analytic solutions for choices between any number of alternatives. These solutions (and freely-available computer code) make the model easy to apply to both binary and multiple choice situations. Using data from five previously published experiments, we demonstrate that the LBA model successfully accommodates empirical phenomena from binary and multiple choice tasks that have proven difficult for other theoretical accounts. Our results are encouraging in a field beset by the tradeoff between complexity and completeness.},
author = {Brown, Scott D and Heathcote, Andrew},
doi = {10.1016/j.cogpsych.2007.12.002},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brown, Heathcote/Brown, Heathcote - 2008 - The simplest complete model of choice response time linear ballistic accumulation. - Cognitive psychology.pdf:pdf},
issn = {1095-5623},
journal = {Cognitive psychology},
keywords = {Choice Behavior,Decision Making,Empirical Research,Humans,Linear Models,Models, Psychological,Reaction Time},
month = nov,
number = {3},
pages = {153--78},
pmid = {18243170},
title = {{The simplest complete model of choice response time: linear ballistic accumulation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18243170},
volume = {57},
year = {2008}
}
@article{Brand1998,
author = {Brand, Matthew},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brand/Brand - 1998 - Pattern discovery via entropy minimization Publication History – - Artificial Intelligence.pdf:pdf},
journal = {Artificial Intelligence},
title = {{Pattern discovery via entropy minimization Publication History :–}},
year = {1998}
}
@book{Bishop2006,
author = {Bishop, CM},
booktitle = {Pattern Recognition},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bishop/Bishop - 2006 - Pattern recognition and machine learning - Pattern Recognition.pdf:pdf},
title = {{Pattern recognition and machine learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
year = {2006}
}
@article{Garrido2009,
abstract = {The mismatch negativity (MMN) is a brain response to violations of a rule, established by a sequence of sensory stimuli (typically in the auditory domain) [N\"{a}\"{a}t\"{a}nen R. Attention and brain function. Hillsdale, NJ: Lawrence Erlbaum; 1992]. The MMN reflects the brain's ability to perform automatic comparisons between consecutive stimuli and provides an electrophysiological index of sensory learning and perceptual accuracy. Although the MMN has been studied extensively, the neurophysiological mechanisms underlying the MMN are not well understood. Several hypotheses have been put forward to explain the generation of the MMN; amongst these accounts, the "adaptation hypothesis" and the "model adjustment hypothesis" have received the most attention. This paper presents a review of studies that focus on neuronal mechanisms underlying the MMN generation, discusses the two major explanatory hypotheses, and proposes predictive coding as a general framework that attempts to unify both.},
author = {Garrido, Marta I and Kilner, James M and Stephan, Klaas E and Friston, Karl J},
doi = {10.1016/j.clinph.2008.11.029},
file = {:Users/pkmital/Documents/Mendeley Desktop/Garrido et al/Garrido et al. - 2009 - The mismatch negativity a review of underlying mechanisms. - Clinical neurophysiology official journal of the I.pdf:pdf},
issn = {1872-8952},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Adaptation, Physiological,Adaptation, Physiological: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Humans,Learning,Learning: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Perception,Perception: physiology,Sensation,Sensation: physiology},
month = mar,
number = {3},
pages = {453--63},
pmid = {19181570},
publisher = {International Federation of Clinical Neurophysiology},
title = {{The mismatch negativity: a review of underlying mechanisms.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2671031\&tool=pmcentrez\&rendertype=abstract},
volume = {120},
year = {2009}
}
@article{Sun2003,
author = {Sun, Yaoru and Fisher, Robert},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sun, Fisher/Sun, Fisher - 2003 - Object-based visual attention for computer vision - Artificial Intelligence.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {grouping salience,hierarchical selectivity,integrated competition,object-based visual attention,visual attention},
number = {1},
pages = {77--123},
title = {{Object-based visual attention for computer vision}},
url = {http://www.sciencedirect.com/science/article/pii/S0004370202003995},
volume = {146},
year = {2003}
}
@article{Ghahramani2005,
author = {Ghahramani, Zoubin},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ghahramani/Ghahramani - 2005 - Bayesian Methods for Machine Learning - Unknown.pdf:pdf},
number = {May},
title = {{Bayesian Methods for Machine Learning}},
year = {2005}
}
@article{Fougnie2013,
abstract = {Influential theories of visual working memory have proposed that the basic units of memory are integrated object representations. Key support for this proposal is provided by the same object benefit: It is easier to remember multiple features of a single object than the same set of features distributed across multiple objects. Here, we replicate the object benefit but demonstrate that features are not stored as single, integrated representations. Specifically, participants could remember 10 features better when arranged in 5 objects compared to 10 objects, yet memory for one object feature was largely independent of memory for the other object feature. These results rule out the possibility that integrated representations drive the object benefit and require a revision of the concept of object-based memory representations. We propose that working memory is object-based in regard to the factors that enhance performance but feature based in regard to the level of representational failure. (PsycINFO Database Record (c) 2013 APA, all rights reserved).},
author = {Fougnie, Daryl and Cormiea, Sarah M and Alvarez, George a},
doi = {10.1037/a0030300},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fougnie, Cormiea, Alvarez/Fougnie, Cormiea, Alvarez - 2013 - Object-based benefits without object-based representations. - Journal of experimental psychology. Gen.pdf:pdf},
issn = {1939-2222},
journal = {Journal of experimental psychology. General},
keywords = {attention,features,objects,short-term memory,working memory},
month = aug,
number = {3},
pages = {621--6},
pmid = {23067063},
title = {{Object-based benefits without object-based representations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23067063},
volume = {142},
year = {2013}
}
@article{Krauzlis1999a,
author = {Krauzlis, R},
doi = {10.1016/S0166-2236(99)01464-2},
file = {:Users/pkmital/Documents/Mendeley Desktop/Krauzlis/Krauzlis - 1999 - Tracking with the mind's eye - Trends in Neurosciences.pdf:pdf},
issn = {01662236},
journal = {Trends in Neurosciences},
month = dec,
number = {12},
pages = {544--550},
title = {{Tracking with the mind's eye}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223699014642},
volume = {22},
year = {1999}
}
@article{Long2007,
address = {New York, New York, USA},
author = {Long, Jeremy and Mould, David},
doi = {10.1145/1268517.1268559},
file = {:Users/pkmital/Documents/Mendeley Desktop/Long, Mould/Long, Mould - 2007 - Improved image quilting - Proceedings of Graphics Interface 2007 on - GI '07.pdf:pdf},
isbn = {9781568813370},
issn = {07135424},
journal = {Proceedings of Graphics Interface 2007 on - GI '07},
keywords = {ample,minimum error boundary cut,non-parametric synthesis from ex-,patch-based texture synthesis,texture synthesis},
pages = {257},
publisher = {ACM Press},
title = {{Improved image quilting}},
url = {http://portal.acm.org/citation.cfm?doid=1268517.1268559},
year = {2007}
}
@article{Tse2002,
abstract = {Recent work shows that abrupt onsets reflexively capture attention and trigger saccades that compete with voluntary saccades. To test whether oculomotor capture occurs when no saccade is being planned, we measured fixational eye movements in the absence or presence of an abrupt onset at peripheral locations. We found no effect of abrupt onset location on the average pattern of eye movements during fixation. We conclude that the capture of eye movements by an abrupt onset only happens when the oculomotor system has been preset to make a saccade. This implies that the oculomotor system is not obligatorily driven by events in the visual array.},
author = {Tse, P U and Sheinberg, D L and Logothetis, N K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tse, Sheinberg, Logothetis/Tse, Sheinberg, Logothetis - 2002 - Fixational eye movements are not affected by abrupt onsets that capture attention. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adult,Attention,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Psychophysics,Saccades,Saccades: physiology},
month = jun,
number = {13},
pages = {1663--9},
pmid = {12079794},
title = {{Fixational eye movements are not affected by abrupt onsets that capture attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12079794},
volume = {42},
year = {2002}
}
@article{Degerman2007,
abstract = {Coherent perception of objects in our environment often requires perceptual integration of auditory and visual information. Recent behavioral data suggest that audiovisual integration depends on attention. The current study investigated the neural basis of audiovisual integration using 3-Tesla functional magnetic resonance imaging (fMRI) in 12 healthy volunteers during attention to auditory or visual features, or audiovisual feature combinations of abstract stimuli (simultaneous harmonic sounds and colored circles). Audiovisual attention was found to modulate activity in the same frontal, temporal, parietal and occipital cortical regions as auditory and visual attention. In addition, attention to audiovisual feature combinations produced stronger activity in the superior temporal cortices than attention to only auditory or visual features. These modality-specific areas might be involved in attention-dependent perceptual binding of synchronous auditory and visual events into coherent audiovisual objects. Furthermore, the modality-specific temporal auditory and occipital visual cortical areas showed attention-related modulations during both auditory and visual attention tasks. This result supports the proposal that attention to stimuli in one modality can spread to encompass synchronously presented stimuli in another modality.},
author = {Degerman, Alexander and Rinne, Teemu and Pekkola, Johanna and Autti, Taina and J\"{a}\"{a}skel\"{a}inen, Iiro P and Sams, Mikko and Alho, Kimmo},
doi = {10.1016/j.neuroimage.2006.11.019},
file = {:Users/pkmital/Documents/Mendeley Desktop/Degerman et al/Degerman et al. - 2007 - Human brain activity associated with audiovisual perception and attention. - NeuroImage.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adolescent,Adult,Attention,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Color,Female,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Reference Values,Sound,Visual Perception,Visual Perception: physiology},
month = feb,
number = {4},
pages = {1683--91},
pmid = {17204433},
title = {{Human brain activity associated with audiovisual perception and attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17204433},
volume = {34},
year = {2007}
}
@article{Bordier2013,
abstract = {The investigation of brain activity using naturalistic, ecologically-valid stimuli is becoming an important challenge for neuroscience research. Several approaches have been proposed, primarily relying on data-driven methods (e.g. independent component analysis, ICA). However, data-driven methods often require some post-hoc interpretation of the imaging results to draw inferences about the underlying sensory, motor or cognitive functions. Here, we propose using a biologically-plausible computational model to extract (multi-)sensory stimulus statistics that can be used for standard hypothesis-driven analyses (general linear model, GLM). We ran two separate fMRI experiments, which both involved subjects watching an episode of a TV-series. In Exp 1, we manipulated the presentation by switching on-and-off color, motion and/or sound at variable intervals, whereas in Exp 2, the video was played in the original version, with all the consequent continuous changes of the different sensory features intact. Both for vision and audition, we extracted stimulus statistics corresponding to spatial and temporal discontinuities of low-level features, as well as a combined measure related to the overall stimulus saliency. Results showed that activity in occipital visual cortex and the superior temporal auditory cortex co-varied with changes of low-level features. Visual saliency was found to further boost activity in extra-striate visual cortex plus posterior parietal cortex, while auditory saliency was found to enhance activity in the superior temporal cortex. Data-driven ICA analyses of the same datasets also identified "sensory" networks comprising visual and auditory areas, but without providing specific information about the possible underlying processes, e.g., these processes could relate to modality, stimulus features and/or saliency. We conclude that the combination of computational modeling and GLM enables the tracking of the impact of bottom-up signals on brain activity during viewing of complex and dynamic multisensory stimuli, beyond the capability of purely data-driven approaches.},
author = {Bordier, Cecile and Puja, Francesco and Macaluso, Emiliano},
doi = {10.1016/j.neuroimage.2012.11.031},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bordier, Puja, Macaluso/Bordier, Puja, Macaluso - 2013 - Sensory processing during viewing of cinematographic material computational modeling and functional neu.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Biologically-inspired vision and audition,Cinematographic material,Data-driven,Multi-sensory,Saliency},
month = feb,
pages = {213--26},
pmid = {23202431},
publisher = {Elsevier Inc.},
title = {{Sensory processing during viewing of cinematographic material: computational modeling and functional neuroimaging.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23202431},
volume = {67},
year = {2013}
}
@book{Durham2009,
author = {Durham, MG and Kellner, DM},
booktitle = {About this Catalog},
file = {:Users/pkmital/Documents/Mendeley Desktop/Durham, Kellner/Durham, Kellner - 2009 - Media and cultural studies Keyworks - About this Catalog.pdf:pdf},
isbn = {9781405132589},
publisher = {Blackwell Publishing},
title = {{Media and cultural studies: Keyworks}},
url = {http://catalog.ucr.edu/archive/catalog08-09.pdf\#page=321 http://books.google.com/books?hl=en\&lr=\&id=I8dPhB88Sx4C\&oi=fnd\&pg=PR8\&dq=Media+and+Cultural+Studies:+KeyWorks\&ots=CC2GoF5EgT\&sig=VLWkaaEjnhLsg\_bbVTxZAWOjvqY},
year = {2009}
}
@article{Trujillo2005,
abstract = {OBJECTIVE: (1) To investigate the neural synchrony hypothesis by examining if there was more synchrony for upright than inverted Mooney faces, replicating a previous study; (2) to investigate whether inverted stimuli evoke neural synchrony by comparing them to a new scrambled control condition, less likely to produce face perception. METHODS: Multichannel EEG was recorded via nose reference while participants viewed upright, inverted, and scrambled Mooney face stimuli. Gamma-range spectral power and inter-electrode phase synchrony were calculated via a wavelet-based method for upright stimuli perceived as faces and inverted/scrambled stimuli perceived as non-faces. RESULTS: When the frequency of interest was selected from the upright condition exhibiting maximal spectral power responses (as in the previous study) greater phase synchrony was found in the upright than inverted/scrambled conditions. However, substantial synchrony was present in all conditions, suggesting that choosing the frequency of interest from the upright condition only may have been biased. In addition, artifacts related to nose reference contamination by micro-saccades were found to be differentially present across experimental conditions in the raw EEG. When frequency of interest was selected instead from each experimental condition and the data were transformed to a laplacian 'reference free' derivation, the between-condition phase synchrony differences disappeared. Spectral power differences were robust to the change in reference, but not the combined changes in reference and frequency selection criteria. CONCLUSIONS: Synchrony differences between face/non-face perceptions depend upon frequency selection and recording reference. Optimal selection of these parameters abolishes differential synchrony between conditions. SIGNIFICANCE: Neural synchrony is present not just for face percepts for upright stimuli, but also for non-face percepts achieved for inverted/scrambled Mooney stimuli.},
author = {Trujillo, Logan T and Peterson, Mary a and Kaszniak, Alfred W and Allen, John J B},
doi = {10.1016/j.clinph.2004.07.025},
file = {:Users/pkmital/Documents/Mendeley Desktop/Trujillo et al/Trujillo et al. - 2005 - EEG phase synchrony differences across visual perception conditions may depend on recording and analysis method.pdf:pdf},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Adult,Analysis of Variance,Attention,Attention: physiology,Automatic Data Processing,Automatic Data Processing: methods,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Discrimination Learning,Electroencephalography,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Facial Expression,Female,Generalization, Stimulus,Generalization, Stimulus: physiology,Humans,Male,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Spectrum Analysis,Spectrum Analysis: methods,Time Factors},
month = jan,
number = {1},
pages = {172--89},
pmid = {15589196},
title = {{EEG phase synchrony differences across visual perception conditions may depend on recording and analysis methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15589196},
volume = {116},
year = {2005}
}
@article{Sayeed2006,
author = {Sayeed, Rezwan and Howard, Toby},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sayeed, Howard/Sayeed, Howard - 2006 - State of the art non-photorealistic rendering (NPR) techniques - Eurographics UK Theory And Practice Of \ldots.pdf:pdf},
journal = {Eurographics UK: Theory And Practice Of \ldots},
pages = {1--10},
title = {{State of the art non-photorealistic rendering (NPR) techniques}},
url = {http://www.cs.man.ac.uk/~toby/papers/Sayeed-npr-1.pdf},
year = {2006}
}
@article{Lotte2007,
abstract = {In this paper we review classification algorithms used to design brain-computer interface (BCI) systems based on electroencephalography (EEG). We briefly present the commonly employed algorithms and describe their critical properties. Based on the literature, we compare them in terms of performance and provide guidelines to choose the suitable classification algorithm(s) for a specific BCI.},
author = {Lotte, F and Congedo, M and L\'{e}cuyer, a and Lamarche, F and Arnaldi, B},
doi = {10.1088/1741-2560/4/2/R01},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lotte et al/Lotte et al. - 2007 - A review of classification algorithms for EEG-based brain-computer interfaces. - Journal of neural engineering.pdf:pdf},
issn = {1741-2560},
journal = {Journal of neural engineering},
keywords = {Algorithms,Artificial Intelligence,Brain,Brain: physiology,Communication Aids for Disabled,Electroencephalography,Electroencephalography: methods,Evoked Potentials,Evoked Potentials: physiology,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,User-Computer Interface},
month = jun,
number = {2},
pages = {R1--R13},
pmid = {17409472},
title = {{A review of classification algorithms for EEG-based brain-computer interfaces.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17409472},
volume = {4},
year = {2007}
}
@article{Gottlieb1998,
abstract = {When natural scenes are viewed, a multitude of objects that are stable in their environments are brought in and out of view by eye movements. The posterior parietal cortex is crucial for the analysis of space, visual attention and movement. Neurons in one of its subdivisions, the lateral intraparietal area (LIP), have visual responses to stimuli appearing abruptly at particular retinal locations (their receptive fields). We have tested the responses of LIP neurons to stimuli that entered their receptive field by saccades. Neurons had little or no response to stimuli brought into their receptive field by saccades, unless the stimuli were behaviourally significant. We established behavioural significance in two ways: either by making a stable stimulus task-relevant, or by taking advantage of the attentional attraction of an abruptly appearing stimulus. Our results show that under ordinary circumstances the entire visual world is only weakly represented in LIP. The visual representation in LIP is sparse, with only the most salient or behaviourally relevant objects being strongly represented.},
author = {Gottlieb, J P and Kusunoki, M and Goldberg, M E},
doi = {10.1038/35135},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gottlieb, Kusunoki, Goldberg/Gottlieb, Kusunoki, Goldberg - 1998 - The representation of visual salience in monkey parietal cortex. - Nature.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Animals,Cues,Macaca mulatta,Male,Neurons,Neurons: physiology,Parietal Lobe,Parietal Lobe: physiology,Psychomotor Performance,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
number = {6666},
pages = {481--4},
pmid = {9461214},
title = {{The representation of visual salience in monkey parietal cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9461214},
volume = {391},
year = {1998}
}
@article{Cutting1986,
author = {Cutting, James E},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cutting/Cutting - 1986 - On the efficacy of cinema or what the visual system did not evolve to do - New York.pdf:pdf},
journal = {New York},
title = {{On the efficacy of cinema or what the visual system did not evolve to do}},
volume = {1859},
year = {1986}
}
@article{Hollingworth2006,
author = {Hollingworth, Andrew},
doi = {10.1080/13506280500193818},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hollingworth/Hollingworth - 2006 - Visual memory for natural scenes Evidence from change detection and visual search - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {4-8},
pages = {781--807},
title = {{Visual memory for natural scenes: Evidence from change detection and visual search}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280500193818\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {14},
year = {2006}
}
@article{Kennedy2002,
author = {Kennedy, Alan},
doi = {10.1080/0272498024400007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kennedy/Kennedy - 2002 - Parafoveal-on-foveal interactions in word recognition - Unknown.pdf:pdf},
number = {4},
pages = {1307--1337},
title = {{Parafoveal-on-foveal interactions in word recognition}},
year = {2002}
}
@article{Cusack2010,
abstract = {An important component of perception, attention, and memory is the structuring of information into subsets ("objects"), which allows some parts to be considered together but kept separate from others. Portions of the posterior parietal lobe respond proportionally to the number of objects in the scope of attention and short-term memory, up to a capacity limit of around four, suggesting they have a role in this important process. This study investigates the relationship of discrete object representation to other parietal functions. Two experiments and two supplementary analyses were conducted to evaluate responsivity in parietal regions to the number of objects, the number of spatial locations, attention switching, and general task difficulty. Using transparent motion, it was found that a posterior and inferior parietal response to multiple objects persists even in the absence of a change in visual extent or the number of spatial locations. In a monitoring task, it was found that attention switching (or task difficulty) and object representation have distinct neural signatures, with the former showing greater recruitment of an anterior and lateral intraparietal sulcus (IPS) region, but the latter in a posterior and lateral region. A dissociation was also seen between selectivity for object load across tasks in the inferior IPS and feature or object-related memory load in the superior IPS.},
author = {Cusack, Rhodri and Mitchell, Daniel J and Duncan, John},
doi = {10.1162/jocn.2009.21194},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cusack, Mitchell, Duncan/Cusack, Mitchell, Duncan - 2010 - Discrete object representation, attention switching, and task difficulty in the parietal lobe. - Journal of cognitive neuroscience.pdf:pdf},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
keywords = {Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Frontal Lobe,Frontal Lobe: anatomy \& histology,Frontal Lobe: physiology,Humans,Magnetic Resonance Imaging,Memory, Short-Term,Memory, Short-Term: physiology,Occipital Lobe,Occipital Lobe: anatomy \& histology,Occipital Lobe: physiology,Parietal Lobe,Parietal Lobe: anatomy \& histology,Parietal Lobe: physiology,Signal Detection, Psychological,Visual Perception,Visual Perception: physiology},
month = jan,
number = {1},
pages = {32--47},
pmid = {19199425},
title = {{Discrete object representation, attention switching, and task difficulty in the parietal lobe.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19199425},
volume = {22},
year = {2010}
}
@article{Dowson2008,
abstract = {Mutual Information (MI) is popular for registration via function optimisation. This work proposes an inverse compositional formulation of MI for Levenberg-Marquardt optimisation. This yields a constant Hessian, which may be pre-computed. Speed improvements of 15\% were obtained, with convergence accuracies similar to those of the standard formulation.},
author = {Dowson, Nicholas and Bowden, Richard},
doi = {10.1109/TPAMI.2007.70757},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dowson, Bowden/Dowson, Bowden - 2008 - Mutual information for Lucas-Kanade Tracking (MILK) an inverse compositional formulation. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Motion,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Subtraction Technique},
month = jan,
number = {1},
pages = {180--5},
pmid = {18000334},
title = {{Mutual information for Lucas-Kanade Tracking (MILK): an inverse compositional formulation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18000334},
volume = {30},
year = {2008}
}
@inproceedings{Lamere2007,
author = {Lamere, Paul and Eck, Douglas},
booktitle = {Proceedings of the 8th International Conference on Music Information Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lamere, Eck/Lamere, Eck - 2007 - Using 3d visualizations to explore and discover music - Proceedings of the 8th International Conference on Music In.pdf:pdf},
title = {{Using 3d visualizations to explore and discover music}},
url = {http://ismir2007.ismir.net/proceedings/ISMIR2007\_p173\_lamere.pdf},
year = {2007}
}
@article{Hahnloser2010,
abstract = {Songbirds are well suited to studies of vocal processing not only because of their impressive motor abilities, but also because of their exquisite sensory system that allows them to detect subtle song variability, memorize complex songs, and monitor auditory feedback during singing. Recent experiments point to areas outside the traditional song system for being relevant to sensory functions implicated in song learning. By manipulating or suppressing activity in these areas, adult birds lose their ability to recognize the songs of their tutors and juveniles are unable to form accurate copies of tutor song. Taken together, these experiments show that the sensory mechanisms for vocal learning encompass a larger network than previously thought.},
author = {Hahnloser, Richard H R and Kotowicz, Andreas},
doi = {10.1016/j.conb.2010.02.011},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hahnloser, Kotowicz/Hahnloser, Kotowicz - 2010 - Auditory representations and memory in birdsong learning. - Current opinion in neurobiology.pdf:pdf},
issn = {1873-6882},
journal = {Current opinion in neurobiology},
keywords = {Animals,Auditory Perception,Auditory Perception: physiology,Behavior, Animal,Behavior, Animal: physiology,Female,Humans,Learning,Learning: physiology,Male,Memory,Memory: physiology,Songbirds,Songbirds: physiology,Vocalization, Animal,Vocalization, Animal: physiology},
month = jun,
number = {3},
pages = {332--9},
pmid = {20307967},
publisher = {Elsevier Ltd},
title = {{Auditory representations and memory in birdsong learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20307967},
volume = {20},
year = {2010}
}
@article{Pape1999a,
author = {Pape, Dave},
file = {::},
journal = {Proceedings of SPIE},
keywords = {application framework,stereo perspective},
number = {Figure 1},
pages = {346--353},
publisher = {Spie},
title = {{Transparently supporting a wide range of VR and stereoscopic display devices}},
url = {http://link.aip.org/link/?PSI/3639/346/1\&Agg=doi},
year = {1999}
}
@article{Todorov2011,
author = {Todorov, Alexander and Dotsch, Ron and Wigboldus, Daniel H. J. and Said, Chris P.},
doi = {10.1111/j.1751-9004.2011.00389.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Todorov et al/Todorov et al. - 2011 - Data-driven Methods for Modeling Social Perception - Social and Personality Psychology Compass.pdf:pdf},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = oct,
number = {10},
pages = {775--791},
title = {{Data-driven Methods for Modeling Social Perception}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2011.00389.x},
volume = {5},
year = {2011}
}
@article{Hodgson2002,
abstract = {Previous studies have shown that the retinal eccentricity of target stimuli has surprisingly little effect on the latency of visually driven saccades. But up until now researchers have addressed this issue by presenting saccadic targets in an unstructured visual field. This contrasts with everyday vision in which eye movements are initiated to stimuli within a cluttered environment. The present experiment compared latencies for target onsets in an empty visual field with a condition in which continuously illuminated location markers "tagged" the possible target locations. Previous reports of no effect of eccentricity on latencies in an unstructured field were replicated. However, a significant effect of eccentricity was found when location markers were used. Interestingly this did not reflect a lengthening of latencies as would be predicted by a reduction in target discriminability. Instead, latencies were relatively facilitated to near-visual onsets in the location marker condition. It is concluded that under more natural viewing conditions the latency of saccades is likely to be modulated by the eccentricity of target stimuli. This effect can be explained by competitive attentional interactions in saccade target selection processes.},
author = {Hodgson, Timothy L},
doi = {10.1007/s00221-002-1162-1},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hodgson/Hodgson - 2002 - The location marker effect. Saccadic latency increases with target eccentricity. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adult,Attention,Attention: physiology,Brain,Brain: physiology,Cues,Female,Humans,Male,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Visual Fields,Visual Fields: physiology,Visual Perception,Visual Perception: physiology},
month = aug,
number = {4},
pages = {539--42},
pmid = {12172666},
title = {{The location marker effect. Saccadic latency increases with target eccentricity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12172666},
volume = {145},
year = {2002}
}
@article{Davis1939,
author = {Davis, P. A.},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
month = nov,
publisher = {American Physiological Society},
title = {{Effects of Acoustic Stimuli on the Waking Human Brain}},
url = {http://www.deepdyve.com/lp/the-american-physiological-society/effects-of-acoustic-stimuli-on-the-waking-human-brain-41X0c7nB8M/fulltext},
volume = {2},
year = {1939}
}
@article{Yeh2009,
address = {New York, New York, USA},
author = {Yeh, Mei-Chen and Cheng, Kwang-Ting},
doi = {10.1145/1631272.1631375},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yeh, Cheng/Yeh, Cheng - 2009 - A compact, effective descriptor for video copy detection - Proceedings of the seventeen ACM international conference on Multimedia - MM '09.pdf:pdf},
isbn = {9781605586083},
journal = {Proceedings of the seventeen ACM international conference on Multimedia - MM '09},
keywords = {frame descriptor,graph representation,video copy detection},
pages = {633},
publisher = {ACM Press},
title = {{A compact, effective descriptor for video copy detection}},
url = {http://portal.acm.org/citation.cfm?doid=1631272.1631375},
year = {2009}
}
@article{Weiss2011,
author = {Weiss, Ron J. and Bello, Juan Pablo},
doi = {10.1109/JSTSP.2011.2145356},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weiss, Bello/Weiss, Bello - 2011 - Unsupervised Discovery of Temporal Structure in Music - IEEE Journal of Selected Topics in Signal Processing.pdf:pdf},
issn = {1932-4553},
journal = {IEEE Journal of Selected Topics in Signal Processing},
month = oct,
number = {6},
pages = {1240--1251},
title = {{Unsupervised Discovery of Temporal Structure in Music}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5753914},
volume = {5},
year = {2011}
}
@article{Teh2009,
author = {Teh, Y.W. and Jordan, M.I.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Teh, Jordan/Teh, Jordan - 2009 - Hierarchical Bayesian nonparametric models with applications - Bayesian Nonparametrics.pdf:pdf},
isbn = {0521513464},
journal = {Bayesian Nonparametrics},
pages = {158},
publisher = {Cambridge Univ Pr},
title = {{Hierarchical Bayesian nonparametric models with applications}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=0GUzMF59AsgC\&amp;oi=fnd\&amp;pg=PA158\&amp;dq=Hierarchical+Bayesian+Nonparametric+Models+with+Applications\&amp;ots=SUnONOJHRP\&amp;sig=-eXHx5V42RpP9UPAQv0ViMNCQtI},
year = {2009}
}
@article{Efros2001,
author = {Efros, AA and Freeman, WT},
file = {:Users/pkmital/Documents/Mendeley Desktop/Efros, Freeman/Efros, Freeman - 2001 - Image quilting for texture synthesis and transfer - SIGGRAPH 2001 Proceedings of the 28th annual conference on C.pdf:pdf},
journal = {SIGGRAPH 2001: Proceedings of the 28th annual conference on Computer graphics and interactive techniques.},
title = {{Image quilting for texture synthesis and transfer}},
url = {http://dl.acm.org/citation.cfm?id=383296},
year = {2001}
}
@article{Bosch2006,
author = {Bosch, Anna and Zisserman, Andrew and Mu\~{n}oz, Xavier},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bosch, Zisserman, Mu\~{n}oz/Bosch, Zisserman, Mu\~{n}oz - 2006 - Scene Classification via pLSA - Lecture Notes in Computer Science.pdf:pdf},
journal = {Lecture Notes in Computer Science},
pages = {517--530},
title = {{Scene Classification via pLSA}},
volume = {3954},
year = {2006}
}
@article{Frintrop2008,
author = {Frintrop, S. and Jensfelt, P.},
doi = {10.1109/TRO.2008.2004977},
file = {:Users/pkmital/Documents/Mendeley Desktop/Frintrop, Jensfelt/Frintrop, Jensfelt - 2008 - Attentional Landmarks and Active Gaze Control for Visual SLAM - IEEE Transactions on Robotics.pdf:pdf},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
month = oct,
number = {5},
pages = {1054--1065},
title = {{Attentional Landmarks and Active Gaze Control for Visual SLAM}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4636757},
volume = {24},
year = {2008}
}
@article{Tatler2009,
author = {Tatler, Benjamin and Vincent, Benjamin},
doi = {10.1080/13506280902764539},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Vincent/Tatler, Vincent - 2009 - The prominence of behavioural biases in eye guidance - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1029--1054},
title = {{The prominence of behavioural biases in eye guidance}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902764539\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Johansson1975,
author = {Johansson, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Johansson/Johansson - 1975 - Visual motion perception. - Scientific American.pdf:pdf},
journal = {Scientific American},
keywords = {aperture problem,complementary computing,decision-making,feature tracking,formotion,lip,motion capture,motion integration,motion segmentation,mst,mt,neural network,v1,v2},
title = {{Visual motion perception.}},
url = {http://psycnet.apa.org/psycinfo/1975-28753-001},
year = {1975}
}
@inproceedings{Paul2010,
author = {Paul, Leonard J},
booktitle = {Game Sound Conference 2010},
file = {::},
title = {{Procedural Sound Design}},
year = {2010}
}
@article{Lazebnik,
author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
doi = {10.1109/CVPR.2006.68},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lazebnik, Schmid, Ponce/Lazebnik, Schmid, Ponce - Unknown - Beyond Bags of Features Spatial Pyramid Matching for Recognizing Natural Scene Categories - 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06).pdf:pdf},
isbn = {0-7695-2597-0},
journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06)},
pages = {2169--2178},
publisher = {Ieee},
title = {{Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1641019}
}
@article{Inhoff1998,
abstract = {Eye-movement-contingent display changes were used to control the visibility of characters during the reading of Chinese text. Characters outside a window of legible text were masked by dissimilar characters, and effects of viewing constraints were ascertained in several oculomotor measures. The results revealed an asymmetric perceptual span that extended 1 character to the left of the fixated character and 3 characters to its right. The size of right-directed saccades extended across 2 to 2 1/2 character spaces, indicating that the perceptual spans of successive fixations overlapped slightly and that some linguistic information was integrated across fixations. The relatively small spatial overlap of successive spans appears to reflect a text-specific process. However, the results also revealed substantial similarities in the coding of morphographic Chinese and alphabetic English texts, indicating that text-specific coding routines are subordinated to general coding principles.},
author = {Inhoff, a W and Liu, W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff, Liu/Inhoff, Liu - 1998 - The perceptual span and oculomotor activity during the reading of Chinese sentences. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {China,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Language,Reading,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = feb,
number = {1},
pages = {20--34},
pmid = {9483822},
title = {{The perceptual span and oculomotor activity during the reading of Chinese sentences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9483822},
volume = {24},
year = {1998}
}
@article{Fawcett2006,
author = {Fawcett, T},
doi = {10.1016/j.patrec.2005.10.010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fawcett/Fawcett - 2006 - An introduction to ROC analysis - Pattern Recognition Letters.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {classifier evaluation,evaluation metrics,roc analysis},
month = jun,
number = {8},
pages = {861--874},
title = {{An introduction to ROC analysis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016786550500303X},
volume = {27},
year = {2006}
}
@article{Thorpe,
author = {Thorpe, Simon},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thorpe/Thorpe - Unknown - Ultra-rapid scene categorization with a wave of spikes - Unknown.pdf:pdf},
title = {{Ultra-rapid scene categorization with a wave of spikes}}
}
@article{Rhodes2010,
author = {Rhodes, Christophe and Crawford, Tim and Casey, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rhodes, Crawford, Casey/Rhodes, Crawford, Casey - 2010 - Investigating music collections at different scales with AudioDB - Journal of New Music.pdf:pdf},
journal = {Journal of New Music},
pages = {1--19},
title = {{Investigating music collections at different scales with AudioDB}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09298215.2010.516832},
year = {2010}
}
@book{DouglasKahn1994,
author = {Kahn, Douglas},
isbn = {026261104X},
pages = {466},
publisher = {The MIT Press},
title = {{Wireless Imagination: Sound, Radio, and the Avant-Garde}},
url = {http://www.amazon.com/Wireless-Imagination-Sound-Radio-Avant-Garde/dp/026261104X},
year = {1994}
}
@book{Murdock2003,
author = {Murdock, James},
file = {:Users/pkmital/Documents/Mendeley Desktop/Murdock/Murdock - 2003 - Normal forms and unfoldings for local dynamical systems - Unknown.pdf:pdf},
isbn = {0387954643},
publisher = {Springer Verlag},
title = {{Normal forms and unfoldings for local dynamical systems}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=bDnXl81BsLsC\&amp;oi=fnd\&amp;pg=PR5\&amp;dq=Normal+Forms+and+Unfoldings+for+Local+Dynamical+Systems\&amp;ots=sAxegRwyPR\&amp;sig=UiPymwh5\_Y\_tNt7ujQlFDsmCN30},
year = {2003}
}
@article{Osada2002,
author = {Osada, Robert and Funkhouser, Thomas and Chazelle, Bernard and Dobkin, David},
doi = {10.1145/571647.571648},
file = {:Users/pkmital/Documents/Mendeley Desktop/Osada et al/Osada et al. - 2002 - Shape distributions - ACM Transactions on Graphics.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = oct,
number = {4},
pages = {807--832},
title = {{Shape distributions}},
url = {http://portal.acm.org/citation.cfm?doid=571647.571648},
volume = {21},
year = {2002}
}
@article{Mather2013a,
author = {Mather, M. and Cacioppo, J. T. and Kanwisher, N.},
doi = {10.1177/1745691612469036},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mather, Cacioppo, Kanwisher/Mather, Cacioppo, Kanwisher - 2013 - Introduction to the Special Section 20 Years of fMRI--What Has It Done for Understanding Cognition.pdf:pdf},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
month = jan,
number = {1},
pages = {41--43},
title = {{Introduction to the Special Section: 20 Years of fMRI--What Has It Done for Understanding Cognition?}},
url = {http://pps.sagepub.com/lookup/doi/10.1177/1745691612469036},
volume = {8},
year = {2013}
}
@article{Singhai2010,
author = {Singhai, Nidhi and Shandilya, Shishir K.},
doi = {10.5120/802-1139},
file = {:Users/pkmital/Documents/Mendeley Desktop/Singhai, Shandilya/Singhai, Shandilya - 2010 - A Survey On “Content Based Image Retrieval Systems” - International Journal of Computer Applications.pdf:pdf},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {color histogram,content based image retrieval,edge density,neuro fuzzy,texture},
month = jul,
number = {2},
pages = {22--26},
title = {{A Survey On: “Content Based Image Retrieval Systems”}},
url = {http://www.ijcaonline.org/volume4/number2/pxc3871139.pdf},
volume = {4},
year = {2010}
}
@article{VanderBurg2011,
abstract = {In dynamic cluttered environments, audition and vision may benefit from each other in determining what deserves further attention and what does not. We investigated the underlying neural mechanisms responsible for attentional guidance by audiovisual stimuli in such an environment. Event-related potentials (ERPs) were measured during visual search through dynamic displays consisting of line elements that randomly changed orientation. Search accuracy improved when a target orientation change was synchronized with an auditory signal as compared to when the auditory signal was absent or synchronized with a distractor orientation change. The ERP data show that behavioral benefits were related to an early multisensory interaction over left parieto-occipital cortex (50-60 ms post-stimulus onset), which was followed by an early positive modulation (80-100 ms) over occipital and temporal areas contralateral to the audiovisual event, an enhanced N2pc (210-250 ms), and a contralateral negative slow wave (CNSW). The early multisensory interaction was correlated with behavioral search benefits, indicating that participants with a strong multisensory interaction benefited the most from the synchronized auditory signal. We suggest that an auditory signal enhances the neural response to a synchronized visual event, which increases the chances of selection in a multiple object environment.},
author = {{Van der Burg}, Erik and Talsma, Durk and Olivers, Christian N L and Hickey, Clayton and Theeuwes, Jan},
doi = {10.1016/j.neuroimage.2010.12.068},
file = {:Users/pkmital/Documents/Mendeley Desktop/Van der Burg et al/Van der Burg et al. - 2011 - Early multisensory interactions affect the competition among multiple visual objects. - NeuroImage.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Acoustic Stimulation,Adolescent,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Cognition,Cognition: physiology,Electroencephalography,Evoked Potentials,Evoked Potentials: physiology,Eye Movements,Eye Movements: physiology,Female,Fixation, Ocular,Functional Laterality,Functional Laterality: physiology,Humans,Male,Memory, Short-Term,Memory, Short-Term: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Visual Fields,Visual Fields: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = apr,
number = {3},
pages = {1208--18},
pmid = {21195781},
title = {{Early multisensory interactions affect the competition among multiple visual objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21195781},
volume = {55},
year = {2011}
}
@article{Besle2007,
author = {Besle, Julien and Caclin, Anne and Mayet, Romaine and Delpuech, Claude and Lecaignard, Fran\c{c}oise and Giard, Marie-H\'{e}l\`{e}ne and Morlet, Dominique},
doi = {10.1027/0269-8803.21.34.231},
file = {:Users/pkmital/Documents/Mendeley Desktop/Besle et al/Besle et al. - 2007 - Audiovisual Events in Sensory Memory - Journal of Psychophysiology.pdf:pdf},
issn = {0269-8803},
journal = {Journal of Psychophysiology},
keywords = {audiovisual,eeg,erp,feature conjuction,meg,mmn,sensory memory},
month = jan,
number = {3},
pages = {231--238},
title = {{Audiovisual Events in Sensory Memory}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/0269-8803.21.34.231},
volume = {21},
year = {2007}
}
@phdthesis{Systeme2004a,
author = {Systeme, Interaktive and Universit, Technischen and Schmalstieg, Dieter and Reitmayr, Gerhard},
file = {::},
title = {{XML Databases for Augmented Reality}},
year = {2004}
}
@article{Pasman2006a,
author = {Pasman, W. and Woodward, C.},
file = {::},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {276--277},
publisher = {IEEE Comput. Soc},
title = {{Implementation of an augmented reality system on a PDA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240718},
year = {2006}
}
@article{Naatanen1987,
author = {N\"{a}\"{a}t\"{a}nen, R and Picton, T},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen, Picton/N\"{a}\"{a}t\"{a}nen, Picton - 1987 - The N1 Wave of the Human Electric and Magnetic Response to Sound A Review and an Analysis of the Component.pdf:pdf},
journal = {Psychophysiology},
number = {4},
pages = {375--425},
title = {{The N1 Wave of the Human Electric and Magnetic Response to Sound: A Review and an Analysis of the Component Structure}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1469-8986.1987.tb00311.x/full},
volume = {24},
year = {1987}
}
@article{Kimura2005,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 2005 - Universal source coding for complementary delivery - Science.pdf:pdf},
journal = {Science},
pages = {1--25},
title = {{Universal source coding for complementary delivery}},
year = {2005}
}
@article{Naatanen1987a,
author = {N\"{a}\"{a}t\"{a}nen, Risto and Picton, Terence},
doi = {10.1111/j.1469-8986.1987.tb00311.x},
issn = {0048-5772},
journal = {Psychophysiology},
month = jul,
number = {4},
pages = {375--425},
title = {{The N1 Wave of the Human Electric and Magnetic Response to Sound: A Review and an Analysis of the Component Structure}},
url = {http://doi.wiley.com/10.1111/j.1469-8986.1987.tb00311.x},
volume = {24},
year = {1987}
}
@article{Davis1980,
author = {Davis, S and Mermelstein, Paul},
file = {:Users/pkmital/Documents/Mendeley Desktop/Davis, Mermelstein/Davis, Mermelstein - 1980 - Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences - IEEE Transactions on Acoustics, Speech and Signal Processing.pdf:pdf},
journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
number = {4},
pages = {357--366},
title = {{Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163420},
volume = {ASSP-28},
year = {1980}
}
@article{Kimura2006e,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - 2006 - Information-theoretical analysis of index searching - Science.pdf:pdf},
journal = {Science},
pages = {1--20},
title = {{Information-theoretical analysis of index searching}},
year = {2006}
}
@article{Kay2008a,
abstract = {A challenging goal in neuroscience is to be able to read out, or decode, mental content from brain activity. Recent functional magnetic resonance imaging (fMRI) studies have decoded orientation, position and object category from activity in visual cortex. However, these studies typically used relatively simple stimuli (for example, gratings) or images drawn from fixed categories (for example, faces, houses), and decoding was based on previous measurements of brain activity evoked by those same stimuli or categories. To overcome these limitations, here we develop a decoding method based on quantitative receptive-field models that characterize the relationship between visual stimuli and fMRI activity in early visual areas. These models describe the tuning of individual voxels for space, orientation and spatial frequency, and are estimated directly from responses evoked by natural images. We show that these receptive-field models make it possible to identify, from a large set of completely novel natural images, which specific image was seen by an observer. Identification is not a mere consequence of the retinotopic organization of visual areas; simpler receptive-field models that describe only spatial tuning yield much poorer identification performance. Our results suggest that it may soon be possible to reconstruct a picture of a person's visual experience from measurements of brain activity alone.},
author = {Kay, Kendrick N and Naselaris, Thomas and Prenger, Ryan J and Gallant, Jack L},
doi = {10.1038/nature06713},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kay et al/Kay et al. - 2008 - Identifying natural images from human brain activity. - Nature(2).pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Brain,Brain Mapping,Brain Mapping: methods,Brain: physiology,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Nature,Photic Stimulation,Photography,Research Design,Visual Perception,Visual Perception: physiology},
month = mar,
number = {7185},
pages = {352--5},
pmid = {18322462},
title = {{Identifying natural images from human brain activity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3556484\&tool=pmcentrez\&rendertype=abstract},
volume = {452},
year = {2008}
}
@article{Zion-Golumbic2007,
abstract = {Most natural sounds are composed of a mixture of frequencies, which activate separate neurons in the tonotopic auditory cortex. Nevertheless, we perceive this mixture as an integrated sound with unique acoustic properties. We used the Mismatch Negativity (MMN), a marker of auditory change detection, to determine whether individual harmonics are represented in sensory memory. The MMN elicited by duration and pitch deviations were compared for harmonic and pure tones. Controlled for acoustic differences between standards and deviants and their relative probabilities, the MMN was larger for harmonic than pure tones for duration but not for pitch deviance. Because the magnitude of the MMN reflects the number of concurrent changes in the acoustic input relative to a preexistent acoustic representation, these results suggest that duration is represented and compared separately for individual frequencies, whereas pitch comparison occurs after integration.},
author = {Zion-Golumbic, Elana and Deouell, Leon Y and Whalen, Douglas H and Bentin, Shlomo},
doi = {10.1111/j.1469-8986.2007.00554.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zion-Golumbic et al/Zion-Golumbic et al. - 2007 - Representation of harmonic frequencies in auditory memory a mismatch negativity study. - Psychophysiology.pdf:pdf},
issn = {0048-5772},
journal = {Psychophysiology},
keywords = {Acoustic Stimulation,Adult,Auditory Perception,Auditory Perception: physiology,Data Interpretation, Statistical,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Memory,Memory: physiology,Models, Neurological,Pitch Perception,Pitch Perception: physiology},
month = sep,
number = {5},
pages = {671--9},
pmid = {17608799},
title = {{Representation of harmonic frequencies in auditory memory: a mismatch negativity study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17608799},
volume = {44},
year = {2007}
}
@article{Yuille2011,
author = {a.L. Yuille},
doi = {10.1109/ICCVW.2011.6130421},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yuille/Yuille - 2011 - Towards a theory of compositional learning and encoding of objects - 2011 IEEE International Conference on Computer Visi.pdf:pdf},
isbn = {978-1-4673-0063-6},
journal = {2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)},
month = nov,
pages = {1448--1455},
publisher = {Ieee},
title = {{Towards a theory of compositional learning and encoding of objects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6130421},
year = {2011}
}
@article{Shah2009,
author = {Shah, M.},
doi = {10.1109/CVPR.2009.5206845},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shah/Shah - 2009 - Learning semantic visual vocabularies using diffusion distance - 2009 IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {978-1-4244-3992-8},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {461--468},
publisher = {Ieee},
title = {{Learning semantic visual vocabularies using diffusion distance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206845},
year = {2009}
}
@article{Thompson2011,
author = {Thompson, William L. and Hsiao, Yaling and Kosslyn, Stephen M.},
doi = {10.1080/20445911.2011.477810},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thompson, Hsiao, Kosslyn/Thompson, Hsiao, Kosslyn - 2011 - Dissociation between visual attention and visual mental imagery - Journal of Cognitive Psychology.pdf:pdf},
issn = {2044-5911},
journal = {Journal of Cognitive Psychology},
month = mar,
number = {2},
pages = {256--263},
title = {{Dissociation between visual attention and visual mental imagery}},
url = {http://www.tandfonline.com/doi/abs/10.1080/20445911.2011.477810},
volume = {23},
year = {2011}
}
@article{Litwinowicz1997,
address = {New York, New York, USA},
author = {Litwinowicz, Peter},
doi = {10.1145/258734.258893},
file = {:Users/pkmital/Documents/Mendeley Desktop/Litwinowicz/Litwinowicz - 1997 - Processing images and video for an impressionist effect - SIGGRAPH '97 Proceedings of the 24th annual conference on.pdf:pdf},
isbn = {0897918967},
journal = {SIGGRAPH '97 Proceedings of the 24th annual conference on Computer graphics and interactive techniques},
pages = {407--414},
publisher = {ACM Press},
title = {{Processing images and video for an impressionist effect}},
url = {http://portal.acm.org/citation.cfm?doid=258734.258893 http://dl.acm.org/citation.cfm?id=258893},
year = {1997}
}
@article{Kunar2006,
abstract = {In visual search tasks, attention can be guided to a target item--appearing amidst distractors--on the basis of simple features (e.g., finding the red letter among green). Chun and Jiang's (1998) contextual cuing effect shows that reaction times (RTs) are also speeded if the spatial configuration of items in a scene is repeated over time. In the present studies, we ask whether global properties of the scene can speed search (e.g., if the display is mostly red, then the target is at location X). In Experiment 1A, the overall background color of the display predicted the target location, and the predictive color could appear 0, 400, or 800 msec in advance of the search array. Mean RTs were faster in predictive than in nonpredictive conditions. However, there was little improvement in search slopes. The global color cue did not improve search efficiency. Experiments 1B-1F replicated this effect using different predictive properties (e.g., background orientation-texture and stimulus color). The results showed a strong RT effect of predictive background, but (at best) only a weak improvement in search efficiency. A strong improvement in efficiency was found, however, when the informative background was presented 1,500 msec prior to the onset of the search stimuli and when observers were given explicit instructions to use the cue (Experiment 2).},
author = {Kunar, Melina a and Flusberg, Stephen J and Wolfe, Jeremy M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kunar, Flusberg, Wolfe/Kunar, Flusberg, Wolfe - 2006 - Contextual cuing by global features. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Color Perception,Cues,Female,Field Dependence-Independence,Humans,Judgment,Male,Middle Aged,Orientation,Reaction Time},
month = oct,
number = {7},
pages = {1204--16},
pmid = {17355043},
title = {{Contextual cuing by global features.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2678916\&tool=pmcentrez\&rendertype=abstract},
volume = {68},
year = {2006}
}
@article{Mital2011,
author = {Mital, Parag K. and Smith, Tim J. and Hill, Robin L. and Henderson, John M.},
doi = {10.1007/s12559-010-9074-z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mital et al/Mital et al. - 2011 - Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion - Cognitive Computation.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {eye movements \'{a} dynamic,scenes \'{a} features \'{a},visual attention \'{a} clustering},
month = oct,
title = {{Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion}},
url = {http://www.springerlink.com/index/10.1007/s12559-010-9074-z},
year = {2011}
}
@article{Menzies2006a,
abstract = {Ambisonic encodings can be rendered binaurally, as well as for speaker arrays. We first consider how binaural signals can be calculated from high-order Ambisonic encodings of general soundfields containing near and far sources. For sufficently near sources we identify an error resulting fromthe limited field of validity of the freefield harmonic expansion. A modified expansion is derived that can render such sources without error.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--17},
title = {{Nearfield Binaural Synthesis and Ambisonics}},
year = {2006}
}
@article{Corbetta2002,
abstract = {We review evidence for partially segregated networks of brain areas that carry out different attentional functions. One system, which includes parts of the intraparietal cortex and superior frontal cortex, is involved in preparing and applying goal-directed (top-down) selection for stimuli and responses. This system is also modulated by the detection of stimuli. The other system, which includes the temporoparietal cortex and inferior frontal cortex, and is largely lateralized to the right hemisphere, is not involved in top-down selection. Instead, this system is specialized for the detection of behaviourally relevant stimuli, particularly when they are salient or unexpected. This ventral frontoparietal network works as a 'circuit breaker' for the dorsal system, directing attention to salient events. Both attentional systems interact during normal vision, and both are disrupted in unilateral spatial neglect.},
author = {Corbetta, Maurizio and Shulman, Gordon L},
doi = {10.1038/nrn755},
file = {:Users/pkmital/Documents/Mendeley Desktop/Corbetta, Shulman/Corbetta, Shulman - 2002 - Control of goal-directed and stimulus-driven attention in the brain. - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Cerebral Cortex,Cerebral Cortex: anatomy \& histology,Cerebral Cortex: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Orientation,Orientation: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Perceptual Disorders,Perceptual Disorders: pathology,Perceptual Disorders: physiopathology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Visual Pathways,Visual Pathways: physiology,Volition,Volition: physiology},
month = mar,
number = {3},
pages = {201--15},
pmid = {11994752},
title = {{Control of goal-directed and stimulus-driven attention in the brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11994752},
volume = {3},
year = {2002}
}
@article{Rasmussen2007a,
author = {Rasmussen, Carl Edward},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasmussen/Rasmussen - 2007 - Bayesian Inference and Gaussian Processes - Unknown.pdf:pdf},
title = {{Bayesian Inference and Gaussian Processes}},
year = {2007}
}
@article{Koch1985,
abstract = {Psychophysical and physiological evidence indicates that the visual system of primates and humans has evolved a specialized processing focus moving across the visual scene. This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention. Specifically, we propose the following: (1) A number of elementary features, such as color, orientation, direction of movement, disparity etc. are represented in parallel in different topographical maps, called the early representation. (2) There exists a selective mapping from the early topographic representation into a more central non-topographic representation, such that at any instant the central representation contains the properties of only a single location in the visual scene, the selected location. We suggest that this mapping is the principal expression of early selective visual attention. One function of selective attention is to fuse information from different maps into one coherent whole. (3) Certain selection rules determine which locations will be mapped into the central representation. The major rule, using the conspicuity of locations in the early representation, is implemented using a so-called Winner-Take-All network. Inhibiting the selected location in this network causes an automatic shift towards the next most conspicious location. Additional rules are proximity and similarity preferences. We discuss how these rules can be implemented in neuron-like networks and suggest a possible role for the extensive back-projection from the visual cortex to the LGN.},
author = {Koch, C and Ullman, S},
doi = {10.1016/j.imavis.2008.02.004},
issn = {07219075},
journal = {Human Neurobiology},
number = {4},
pages = {219--227},
pmid = {3836989},
publisher = {Springer},
title = {{Shifts in selective visual attention: towards the underlying neural circuitry.}},
url = {http://papers.klab.caltech.edu/104/1/200.pdf},
volume = {4},
year = {1985}
}
@misc{Privitera2000,
abstract = {Many machine vision applications, such as compression, pictorial database querying, and image understanding, often need to analyze in detail only a representative subset of the image, which may be arranged into sequences of loci called regions-of-interest (ROIs). We have investigated and developed a methodology that serves to automatically identify such a subset of aROIs (algorithmically detected ROIs) using different image processing algorithms (IPAs), and appropriate clustering procedures. In human perception, an internal representation directs top-down, context-dependent sequences of eye movements to fixate on similar sequences of hROIs (human identified ROIs). In the paper, we introduce our methodology and we compare aROIs with hROIs as a criterion for evaluating and selecting bottom-up, context-free algorithms. An application is finally discussed},
author = {Privitera, C M and Stark, L W},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/34.877520},
issn = {01628828},
number = {9},
pages = {970--982},
publisher = {IEEE Computer Society},
title = {{Algorithms for defining visual regions-of-interest: comparison with eye fixations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=877520},
volume = {22},
year = {2000}
}
@article{Pang2008a,
author = {Pang, Derek and Kimura, Akisato and Takeuchi, Tatsuto},
doi = {10.1109/ICME.2008.4607624},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pang, Kimura, Takeuchi/Pang, Kimura, Takeuchi - 2008 - A stochastic model of selective visual attention with a dynamic Bayesian network - 2008 IEEE International Conference on Multimedia and Expo.pdf:pdf},
isbn = {978-1-4244-2570-9},
journal = {2008 IEEE International Conference on Multimedia and Expo},
keywords = {dynamic bayesian network,hidden markov model,saliency,state space model,visual attention},
month = jun,
pages = {1073--1076},
publisher = {Ieee},
title = {{A stochastic model of selective visual attention with a dynamic Bayesian network}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4607624},
year = {2008}
}
@article{Rinne1999,
author = {Rinne, T and Gratton, G and Fabiani, M and Cowan, N and Maclin, E and Stinard, a and Sinkkonen, J and Alho, K and N\"{a}\"{a}t\"{a}nen, R},
doi = {10.1006/nimg.1999.0495},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rinne et al/Rinne et al. - 1999 - Scalp-recorded optical signals make sound processing in the auditory cortex visible - NeuroImage.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adult,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Brain Mapping: instrumentation,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: instrumentati,Male,Reference Values,Spectroscopy, Near-Infrared,Spectroscopy, Near-Infrared: instrumentation},
month = nov,
number = {5},
pages = {620--4},
pmid = {10547339},
title = {{Scalp-recorded optical signals make sound processing in the auditory cortex visible?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10547339},
volume = {10},
year = {1999}
}
@article{Lewicki2002,
author = {Lewicki, M S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lewicki/Lewicki - 2002 - Efficient Coding of Natural Sounds - Nature Neuroscience.pdf:pdf},
journal = {Nature Neuroscience},
number = {4},
pages = {356--363},
title = {{Efficient Coding of Natural Sounds}},
volume = {5},
year = {2002}
}
@article{McKinney2003,
author = {McKinney, MF},
file = {:Users/pkmital/Documents/Mendeley Desktop/McKinney/McKinney - 2003 - Features for audio and music classification - Proc. ISMIR.pdf:pdf},
journal = {Proc. ISMIR},
title = {{Features for audio and music classification}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Features+for+Audio+and+Music+Classification\#0},
volume = {4},
year = {2003}
}
@phdthesis{Gwee2002,
abstract = {Successful algorithmic music composition requires the efficient creation of works that reflect human preferences. In examining this key issue, we make two main contributions in this dissertation: analysis of the computational complexity of algorithmic music composition, and methods to produce music that approximates a commendable human effort. We use species counterpoint as our compositional model, wherein a set of stylistic and grammatical rules governs the search for suitable countermelodies to match a given melody. Our analysis of the complexity of rule-based music composition considers four different types of computational problems: decision, enumeration, number, and optimization. For restricted versions of the decision problem, we devise a polynomial algorithm by constructing a non-deterministic finite state transducer. This transducer can also solve corresponding restricted versions of the enumeration and number problems. The general forms of the four types of problems, however, are respectively NP- complete, \#P-complete, NP-complete in the strong sense, and NP-equivalent. We prove this by first reducing from the well known Three-Dimensional Matching problem to the music composition decision problem, and then by reducing among the music problems themselves. In order to compose music both correct and human-like, we formulate new “artistry” rules to supplement traditional rules of musical style and grammar. We also propose the fuzzy application of these artistry rules, to complement the crisp application of the traditional rules. We then suggest two methods to model human preferences: (1) distinguish an expert’s compositions from alternative compositions by determining rule weights; (2) train an artificial neural network to reflect an expert’s musical preferences through the latter’s evaluations of a set of compositions. We were able to approximate that elusive factor of human preference with better than 75\% accuracy. To solve the optimization problem, we adapt two different search algorithms: best-first search with branch-and-bound pruning (for m ≥ 1 optimal solutions), and a genetic algorithm (for m ≥ 1 near- optimal solutions). Through these algorithms, we test the techniques of rule weightings and of trained neural networks as evaluation functions. Our adaptation of the genetic algorithm produced optimal countermelodies in execution time favorably comparable to that taken by the best-first algorithm.},
author = {Gwee, N.},
booktitle = {Memory},
file = {::},
number = {December},
publisher = {Citeseer},
school = {Louisiana State University},
title = {{Complexity and Heuristics in Rule-based Algorithmic Music Composition}},
type = {Doctor of Philosophy},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.828\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Godøy2010,
author = {God\o y, Rolf Inge},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = apr,
number = {01},
pages = {54--62},
title = {{Images of Sonic Objects}},
url = {http://journals.cambridge.org/abstract\_S1355771809990264},
volume = {15},
year = {2010}
}
@article{Matsukura2009,
author = {Matsukura, Michi and Brockmole, James and Henderson, John},
doi = {10.1080/13506280902868660},
file = {:Users/pkmital/Documents/Mendeley Desktop/Matsukura, Brockmole, Henderson/Matsukura, Brockmole, Henderson - 2009 - Overt attentional prioritization of new objects and feature changes during real-world scene viewing - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {835--855},
title = {{Overt attentional prioritization of new objects and feature changes during real-world scene viewing}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902868660\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Vikram2012,
author = {Vikram, Tadmeri Narayan and Tscherepanow, Marko and Wrede, Britta},
doi = {10.1016/j.patcog.2012.02.009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vikram, Tscherepanow, Wrede/Vikram, Tscherepanow, Wrede - 2012 - A saliency map based on sampling an image into random rectangular regions of interest - Pattern Rec.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = sep,
number = {9},
pages = {3114--3124},
title = {{A saliency map based on sampling an image into random rectangular regions of interest}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320312000714},
volume = {45},
year = {2012}
}
@article{Smith,
abstract = {The embodiment hypothesis is the idea that intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity. We offer six lessons for developing embodied intelligent agents suggested by research in developmental psychology. We argue that starting as a baby grounded in a physical, social, and linguistic world is crucial to the development of the flexible and inventive intelligence that characterizes humankind.},
author = {Smith, Linda and Gasser, Michael},
doi = {10.1162/1064546053278973},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Gasser/Smith, Gasser - Unknown - The development of embodied cognition six lessons from babies. - Artificial life.pdf:pdf},
issn = {1064-5462},
journal = {Artificial life},
keywords = {Artificial Intelligence,Cognition,Cognition: physiology,Humans,Infant,Infant Behavior,Infant Behavior: physiology},
number = {1-2},
pages = {13--29},
pmid = {15811218},
title = {{The development of embodied cognition: six lessons from babies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15811218},
volume = {11}
}
@article{Watkins2006,
abstract = {When a single brief visual flash is accompanied by two auditory bleeps, it is frequently perceived incorrectly as two flashes. Here, we used high field functional MRI in humans to examine the neural basis of this multisensory perceptual illusion. We show that activity in retinotopic visual cortex is increased by the presence of concurrent auditory stimulation, irrespective of any illusory perception. However, when concurrent auditory stimulation gave rise to illusory visual perception, activity in V1 was enhanced, despite auditory and visual stimulation being unchanged. These findings confirm that responses in human V1 can be altered by sound and show that they reflect subjective perception rather than the physically present visual stimulus. Moreover, as the right superior temporal sulcus and superior colliculus were also activated by illusory visual perception, together with V1, they provide a potential neural substrate for the generation of this multisensory illusion.},
author = {Watkins, S and Shams, L and Tanaka, S and Haynes, J-D and Rees, G},
doi = {10.1016/j.neuroimage.2006.01.016},
file = {:Users/pkmital/Documents/Mendeley Desktop/Watkins et al/Watkins et al. - 2006 - Sound alters activity in human V1 in association with illusory visual perception. - NeuroImage.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Acoustic Stimulation,Adolescent,Adult,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Brain Mapping,Dominance, Cerebral,Dominance, Cerebral: physiology,Female,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Nerve Net,Nerve Net: physiology,Optical Illusions,Optical Illusions: physiology,Photic Stimulation,Psychophysics,Retina,Retina: physiology,Superior Colliculi,Superior Colliculi: physiology,Temporal Lobe,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology},
month = jul,
number = {3},
pages = {1247--56},
pmid = {16556505},
title = {{Sound alters activity in human V1 in association with illusory visual perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16556505},
volume = {31},
year = {2006}
}
@book{Steenhuisen2005,
author = {Steenhuisen, Paul},
isbn = {0888644744},
pages = {344},
publisher = {University of Alberta Press},
title = {{Sonic Mosaics: Conversations with Composers}},
url = {http://www.amazon.com/Sonic-Mosaics-Conversations-Paul-Steenhuisen/dp/0888644744},
year = {2005}
}
@article{Schwarz2008,
author = {Schwarz, Diemo and Cahen, Roland and Britton, Sam},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz, Cahen, Britton/Schwarz, Cahen, Britton - 2008 - Principles and applications of interactive corpus-based concatenative synthesis - Journ\'{e}es d'Informatique Musicale (JIM), GMEA, Albi, France.pdf:pdf},
journal = {Journ\'{e}es d'Informatique Musicale (JIM), GMEA, Albi, France},
publisher = {Citeseer},
title = {{Principles and applications of interactive corpus-based concatenative synthesis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.756\&amp;rep=rep1\&amp;type=pdf},
year = {2008}
}
@article{Hertzmann2001,
address = {New York, New York, USA},
author = {Hertzmann, Aaron and Jacobs, Charles E. and Oliver, Nuria and Curless, Brian and Salesin, David H.},
doi = {10.1145/383259.383295},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hertzmann et al/Hertzmann et al. - 2001 - Image analogies - Proceedings of the 28th annual conference on Computer graphics and interactive techniques -.pdf:pdf},
isbn = {158113374X},
journal = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques - SIGGRAPH '01},
pages = {327--340},
publisher = {ACM Press},
title = {{Image analogies}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383295},
year = {2001}
}
@article{Busch2010a,
abstract = {An important effect of sustained attention is the facilitation of perception. Although the term "sustained" suggests that this beneficial effect endures continuously as long as something is attended, we present electrophysiological evidence that perception at attended locations is actually modulated periodically. Subjects detected brief light flashes that were presented peripherally at locations that were either attended or unattended. We analyzed the correlation between detection performance for attended and unattended stimuli and the phase of ongoing EEG oscillations, which relate to subsecond fluctuations of neuronal excitability. Although on average, detection performance was improved by attention--indicated by reduced detection thresholds at attended locations--we found that detection performance for attended stimuli actually fluctuated over time along with the phase of spontaneous oscillations in the (≈7 Hz) frequency band just before stimulus onset. This fluctuation was absent for unattended stimuli. This pattern of results suggests that "sustained" attention in fact exerts its facilitative effect on perception in a periodic fashion.},
author = {Busch, Niko a and VanRullen, Rufin},
doi = {10.1073/pnas.1004801107},
file = {:Users/pkmital/Documents/Mendeley Desktop/Busch, VanRullen/Busch, VanRullen - 2010 - Spontaneous EEG oscillations reveal periodic sampling of visual attention. - Proceedings of the National Academy of Sciences of the United States of America.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Attention,Electroencephalography,Female,Humans,Male,Visual Perception},
month = sep,
number = {37},
pages = {16048--53},
pmid = {20805482},
title = {{Spontaneous EEG oscillations reveal periodic sampling of visual attention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2941320\&tool=pmcentrez\&rendertype=abstract},
volume = {107},
year = {2010}
}
@phdthesis{Moerel2013,
author = {Moerel, M M L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Moerel/Moerel - 2013 - Encoding of natural sounds in the human brain - Unknown.pdf:pdf},
isbn = {9789462032941},
title = {{Encoding of natural sounds in the human brain}},
year = {2013}
}
@article{Heeger,
author = {Heeger, D.J. and Bergen, J.R.},
doi = {10.1109/ICIP.1995.537718},
file = {:Users/pkmital/Documents/Mendeley Desktop/Heeger, Bergen/Heeger, Bergen - Unknown - Pyramid-based texture analysissynthesis - Proceedings., International Conference on Image Processing.pdf:pdf},
isbn = {0-7803-3122-2},
journal = {Proceedings., International Conference on Image Processing},
pages = {648--651},
publisher = {IEEE Comput. Soc. Press},
title = {{Pyramid-based texture analysis/synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=537718},
volume = {3}
}
@article{Potter1976,
abstract = {Three converving procedures were used to determine whether pictures presented in a rapid sequence at rates comparable to eye fixations are understood and then quickly forgotten. In two experiments, sequences of 16 color photographs were presented at rates of 113, 167, or 333 msec per picture. In one group, subjects were given an immediate test of recognition memory for the pictures and in other groups they searched for a target picture. Even when the target had only been specified by a title (e.g., a boat) detection of a target was strikingly superior to recognition memory. Detection was slightly but significantly better for pictured than named targets. In a third experiment pictures were presented for 50, 70, 90 or 120 msec preceded and followed by a visual mask; at 120 msec recognition memory was as accurate as detection had been. The results, taken together with those in 1969 of Potter and Levy for slower rates of sequential presentation, suggest that on the average a scene is understood and so becomes immune to ordinary visual masking within about 100 msec but requires about 300 msec of further processing before the memory representation is resistant to conceptual masking from a following picture. Possible functions of a short-term conceptual memory, such as the control of eye fixations, are discussed.},
author = {Potter, M C},
journal = {Journal of experimental psychology Human learning and memory},
number = {5},
pages = {509--522},
pmid = {1003124},
publisher = {American Psychological Association},
title = {{Short-term conceptual memory for pictures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1003124},
volume = {2},
year = {1976}
}
@techreport{Veneri,
abstract = {Constantly increasing power of gaming platforms now makes it possible for game developers to consider using procedural techniques in making games. These techniques are actually used to create part of graphical assets such as object’s textures [9] or to generate character motion [26]. However, sound is still a challenging domain for procedural content creation. This article presents a new software framework designed to support the use of procedural audio for games. This framework is named GAF (Game Audio Framework) and is currently developped by CNAM/CEDRIC laboratory in Paris as part of the PLAY ALL platform. In a first part, we will give a quick overview of current framework architectures. In a second part, we will discuss Procedural Audio. In a third and forth part, we will introduce the new framework proposition we make. We end this article with a demonstration of procedural musical capabilities that this framework enables},
author = {Veneri, Olivier and Cedric, Cnam and Natkin, Stephane},
file = {::},
number = {figure 1},
title = {{Procedural Audio for Game using GAF}}
}
@article{Moghaddam1997,
author = {Moghaddam, B. and Pentland, a.},
doi = {10.1109/34.598227},
file = {:Users/pkmital/Documents/Mendeley Desktop/Moghaddam, Pentland/Moghaddam, Pentland - 1997 - Probabilistic visual learning for object representation - IEEE Transactions on Pattern Analysis and Machine.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = jul,
number = {7},
pages = {696--710},
title = {{Probabilistic visual learning for object representation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=598227},
volume = {19},
year = {1997}
}
@article{Vitevitch2000,
author = {Vitevitch, M.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vitevitch/Vitevitch - 2001 - Change deafness The inability to detect changes in a talker's voice - Journal of the Acoustical Society of America.pdf:pdf},
journal = {Journal of the Acoustical Society of America},
number = {5},
pages = {2312},
publisher = {[New York: Acoustical Society of America]},
title = {{Change deafness: The inability to detect changes in a talker's voice}},
url = {http://www.iu.edu/~srlweb/pr/24/Vitevitch-369.pdf},
volume = {109},
year = {2001}
}
@inproceedings{Diakopoulos2004,
author = {Diakopoulos, Nicholas and Essa, Irfan and Jain, Ramesh},
booktitle = {Conference on Image and Video Retrieval (CIVR) 2004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Diakopoulos, Essa, Jain/Diakopoulos, Essa, Jain - 2004 - Content based image synthesis - Conference on Image and Video Retrieval (CIVR) 2004.pdf:pdf},
pages = {299--307},
title = {{Content based image synthesis}},
url = {http://www.springerlink.com/index/9e9bwxef8t52wuph.pdf},
volume = {3115},
year = {2004}
}
@book{Kohler1947,
author = {K\"{o}hler, Wolfgang},
pages = {367},
publisher = {Liveright},
title = {{Gestalt Psychology: An Introduction to New Concepts in Modern Psychology}},
url = {http://books.google.co.uk/books/about/Gestalt\_Psychology.html?id=BAkFAAAAMAAJ\&pgis=1},
year = {1947}
}
@article{Noe2002,
author = {No\"{e}, Alva},
file = {:Users/pkmital/Documents/Mendeley Desktop/No\"{e}/No\"{e} - 2002 - Is the Visual World - Unknown.PDF:PDF},
number = {5},
pages = {1--12},
title = {{Is the Visual World}},
year = {2002}
}
@techreport{Pfeiffer2001,
address = {Australia},
author = {Pfeiffer, S and Vincent, T},
institution = {CSIRO Mathematical and Information Sciences},
keywords = {MIR},
title = {{Formalisation of MPEG-1 compressed domain audio features}},
year = {2001}
}
@article{Brysbaert,
author = {Brysbaert, Marc and Vitu, Francoise},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brysbaert, Vitu/Brysbaert, Vitu - Unknown - Word Skipping Implications for Theories of Eye Movement Control in Reading - Word Journal Of The International Linguistic Association.pdf:pdf},
journal = {Word Journal Of The International Linguistic Association},
pages = {125--147},
title = {{Word Skipping : Implications for Theories of Eye Movement Control in Reading}}
}
@article{Sand2010,
author = {Sand, Andreas},
doi = {10.1109/PDMC-HiBi.2010.24},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sand/Sand - 2010 - HMMlib A C Library for General Hidden Markov Models Exploiting Modern CPUs - Unknown.pdf:pdf},
isbn = {978-1-4244-8753-0},
keywords = {-hmmlib,an hmm as consisting,h idden m arkov,hidden markov models,ii,m odels,of,openmp,rj86,sse,we can formally define},
month = sep,
pages = {126--134},
title = {{HMMlib: A C   Library for General Hidden Markov Models Exploiting Modern CPUs}},
year = {2010}
}
@inproceedings{Donoser2006,
author = {Donoser, M. and Bischof, H.},
booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2006.107},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donoser, Bischof/Donoser, Bischof - 2006 - Efficient maximally stable extremal region (MSER) tracking - 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {0-7695-2597-0},
pages = {553--560},
publisher = {Ieee},
title = {{Efficient maximally stable extremal region (MSER) tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640804 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1640804},
volume = {1},
year = {2006}
}
@inproceedings{Chaudhary1999,
author = {Chaudhary, Amar and Freed, Adrian},
booktitle = {Audio Engineering Society Convention 107},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chaudhary, Freed/Chaudhary, Freed - 1999 - Visualization, Editing and Spatialization of Sound Representations using the OSE Framework - Audio Engineering.pdf:pdf},
title = {{Visualization, Editing and Spatialization of Sound Representations using the OSE Framework}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=8153},
year = {1999}
}
@article{Underwood2009,
author = {Underwood, Geoffrey and Foulsham, Tom and Humphrey, Katherine},
doi = {10.1080/13506280902771278},
file = {:Users/pkmital/Documents/Mendeley Desktop/Underwood, Foulsham, Humphrey/Underwood, Foulsham, Humphrey - 2009 - Saliency and scan patterns in the inspection of real-world scenes Eye movements during encoding and recognition - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {812--834},
title = {{Saliency and scan patterns in the inspection of real-world scenes: Eye movements during encoding and recognition}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902771278\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Board,
author = {Board, Editorial and Ferrari, Domenico and Gerla, Mario},
file = {:Users/pkmital/Documents/Mendeley Desktop/Board, Ferrari, Gerla/Board, Ferrari, Gerla - Unknown - Lecture Notes of the Institute for Computer Sciences , Social-Informatics and Telecommunications Engineering - Middle East.pdf:pdf},
journal = {Middle East},
title = {{Lecture Notes of the Institute for Computer Sciences , Social-Informatics and Telecommunications Engineering}}
}
@article{Inhoff1993,
abstract = {Eye movements were recorded while subjects read passages of text repeatedly (Experiment 1) and while normal text and strings of homogeneous letters were fixated (Experiment 2). Text repetition decreased fixation durations and increased saccade size, presumably because it decreased attention demands. Irrespective of repetition, however, no distinct distribution of brief (express) fixations emerged. In Experiment 2, fixation durations were shorter and saccades were larger when strings of homogeneous letters were "read," indicating that this condition decreased attention demands. Again, however, no distinct distribution of express fixations emerged. These findings pose problems for the view that attentional processes determine the occurrence of brief (express) fixation durations in reading. Supplementary analyses of Experiments 1 and 2 suggested that visuospatial processing affected fixation durations, irrespective of linguistic processing demands.},
author = {Inhoff, a W and Topolski, R and Vitu, F and O'Regan, J K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff et al/Inhoff et al. - 1993 - Attention demands during reading and the occurrence of brief (express) fixations. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Adolescent,Adult,Attention,Female,Fixation, Ocular,Humans,Linguistics,Male,Reading,Saccades,Visual Perception},
month = dec,
number = {6},
pages = {814--23},
pmid = {8134251},
title = {{Attention demands during reading and the occurrence of brief (express) fixations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8134251},
volume = {54},
year = {1993}
}
@article{Markosian1997,
address = {New York, New York, USA},
author = {Markosian, Lee and Kowalski, Michael a. and Goldstein, Daniel and Trychin, Samuel J. and Hughes, John F. and Bourdev, Lubomir D.},
doi = {10.1145/258734.258894},
file = {:Users/pkmital/Documents/Mendeley Desktop/Markosian et al/Markosian et al. - 1997 - Real-time nonphotorealistic rendering - Proceedings of the 24th annual conference on Computer graphics and int.pdf:pdf},
isbn = {0897918967},
journal = {Proceedings of the 24th annual conference on Computer graphics and interactive techniques - SIGGRAPH '97},
number = {i},
pages = {415--420},
publisher = {ACM Press},
title = {{Real-time nonphotorealistic rendering}},
url = {http://portal.acm.org/citation.cfm?doid=258734.258894},
year = {1997}
}
@article{Kanan2009,
author = {Kanan, Christopher and Tong, Mathew and Zhang, Lingyun and Cottrell, Garrison},
doi = {10.1080/13506280902771138},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kanan et al/Kanan et al. - 2009 - SUN Top-down saliency using natural statistics - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {979--1003},
title = {{SUN: Top-down saliency using natural statistics}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902771138\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Hochstein2002,
author = {Hochstein, Shaul},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hochstein/Hochstein - 2002 - View from the Top Hierarchies and Reverse Hierarchies in the Visual System - Neuron.pdf:pdf},
journal = {Neuron},
number = {3},
pages = {791--804},
title = {{View from the Top:: Hierarchies and Reverse Hierarchies in the Visual System}},
url = {http://www.sciencedirect.com/science/article/pii/s0896627302010917},
volume = {36},
year = {2002}
}
@article{Walter2010,
author = {Walter, Sven},
file = {:Users/pkmital/Documents/Mendeley Desktop/Walter/Walter - 2010 - Audiovisual Integration of Natural Stimuli - Cognitive Science.pdf:pdf},
journal = {Cognitive Science},
title = {{Audiovisual Integration of Natural Stimuli}},
volume = {9},
year = {2010}
}
@article{Filimowicz2010b,
author = {Filimowicz, Michael and Stockholm, Jack},
issn = {1469-8153},
journal = {Organised Sound},
language = {English},
month = apr,
number = {01},
pages = {5--12},
title = {{Towards a Phenomenology of the Acoustic Image}},
url = {http://journals.cambridge.org/abstract\_S1355771809990215},
volume = {15},
year = {2010}
}
@article{Cohen2011,
abstract = {Is visual attention required for visual consciousness? In the past decade, many researchers have claimed that awareness can arise in the absence of attention. This claim is largely based on the notion that natural scene (or "gist") perception occurs without attention. This article presents evidence against this idea. We show that when observers perform a variety of demanding, sustained-attention tasks, inattentional blindness occurs for natural scenes. In addition, scene perception is impaired under dual-task conditions, but only when the primary task is sufficiently demanding. This finding suggests that previous studies that have been interpreted as demonstrating scene perception without attention failed to fully engage attention and that natural-scene perception does indeed require attention. Thus, natural-scene perception is not a preattentive process and cannot be used to support the idea of awareness without attention.},
author = {Cohen, Michael a and Alvarez, George a and Nakayama, Ken},
doi = {10.1177/0956797611419168},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cohen, Alvarez, Nakayama/Cohen, Alvarez, Nakayama - 2011 - Natural-scene perception requires attention. - Psychological science.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {Adolescent,Adult,Attention,Awareness,Consciousness,Humans,Photic Stimulation,Visual Perception,Young Adult},
month = sep,
number = {9},
pages = {1165--72},
pmid = {21841149},
title = {{Natural-scene perception requires attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21841149},
volume = {22},
year = {2011}
}
@phdthesis{Donoso2010,
author = {Donoso, Alexander},
file = {:Users/pkmital/Documents/Mendeley Desktop/Donoso/Donoso - 2010 - Processing indexical information demands resources Evidence from the change deafness paradigm. - Unknown.pdf:pdf},
publisher = {University of Kansas},
title = {{Processing indexical information demands resources: Evidence from the change deafness paradigm.}},
url = {http://kuscholarworks.ku.edu/dspace/bitstream/1808/6430/1/Donoso\_ku\_0099M\_10857\_DATA\_1.pdf},
year = {2010}
}
@article{Moulines1990,
author = {Moulines, E. and Charpentier, F.},
issn = {0167-6393},
journal = {Speech communication},
keywords = {Algorithm,Algorithme,Algoritmo,Altura sonida,Calidad sonora,Frequency domain method,M\'{e}thode domaine fr\'{e}quence,M\'{e}thode domaine temps,M\'{e}todo dominio frecuencia,M\'{e}todo dominio tiempo,Pitch(acoustics),Qualit\'{e} sonore,Sound quality,Speech synthesis,Synth\`{e}se parole,S\'{\i}ntesis palabra,Time domain method,Tonie},
language = {eng},
number = {5-6},
pages = {453--467},
publisher = {Elsevier},
title = {{Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones}},
url = {http://cat.inist.fr/?aModele=afficheN\&cpsidt=5356993},
volume = {9},
year = {1990}
}
@article{Naatanen2011,
abstract = {In this review, we will present a model of brain events leading to conscious perception in audition. This represents an updated version of N\"{a}\"{a}t\"{a}nen's previous model of automatic and attentive central auditory processing. This revised model is mainly based on the mismatch negativity (MMN) and N1 indices of automatic processing, the processing negativity (PN) index of selective attention, and their magnetoencephalographic (MEG) and functional magnetic resonance imaging (fMRI) equivalents. Special attention is paid to determining the neural processes that might underlie conscious perception and the borderline between automatic and attention-dependent processes in audition.},
author = {N\"{a}\"{a}t\"{a}nen, Risto and Kujala, Teija and Winkler, Istv\'{a}n},
doi = {10.1111/j.1469-8986.2010.01114.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/N\"{a}\"{a}t\"{a}nen, Kujala, Winkler/N\"{a}\"{a}t\"{a}nen, Kujala, Winkler - 2011 - Auditory processing that leads to conscious perception a unique window to central auditory process.pdf:pdf},
issn = {1540-5958},
journal = {Psychophysiology},
keywords = {Acoustic Stimulation,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Hearing,Hearing: physiology,Humans,Magnetic Resonance Imaging,Magnetoencephalography,Models, Neurological},
month = jan,
number = {1},
pages = {4--22},
pmid = {20880261},
title = {{Auditory processing that leads to conscious perception: a unique window to central auditory processing opened by the mismatch negativity and related responses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20880261},
volume = {48},
year = {2011}
}
@article{Escera2003a,
author = {Escera, Carles and Yago, Elena and Corral, Maria-Jose and Corbera, Silvia and Nunez, M. Isabel},
doi = {10.1046/j.1460-9568.2003.02937.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Escera et al/Escera et al. - 2003 - Attention capture by auditory significant stimuli semantic analysis follows attention switching - European Journa.pdf:pdf},
journal = {European Journal of Neuroscience},
keywords = {evoked potentials,exogenous attention,humans,involuntary,novelty,stimulus-driven},
pages = {2408--2412},
title = {{Attention capture by auditory significant stimuli: semantic analysis follows attention switching}},
url = {http://onlinelibrary.wiley.com/doi/10.1046/j.1460-9568.2003.02937.x/full},
volume = {18},
year = {2003}
}
@article{Snyder1976,
author = {Snyder, Elaine and Hillyard, Steven A.},
doi = {10.1016/S0091-6773(76)91447-4},
issn = {00916773},
journal = {Behavioral Biology},
month = mar,
number = {3},
pages = {319--331},
title = {{Long-latency evoked potentials to irrelevant, deviant stimuli}},
url = {http://dx.doi.org/10.1016/S0091-6773(76)91447-4},
volume = {16},
year = {1976}
}
@article{Hou2011,
abstract = {We introduce a simple image descriptor referred to as the image signature. We show, within the theoretical framework of sparse signal mixing, that this quantity spatially approximates the foreground of an image. We experimentally investigate whether this approximate foreground overlaps with visually conspicuous image locations by developing a saliency algorithm based on the image signature. This saliency algorithm predicts human fixation points best among competitors on the Bruce and Tsotsos [1] benchmark dataset and does so in much shorter running time. In a related experiment, we demonstrate with a change blindness dataset that the distance between images induced by the image signature is closer to human perceptual distance than can be achieved using other saliency algorithms, pixel-wise or GIST [2] descriptor methods.},
author = {Hou, Xiaodi and Harel, Jonathan and Koch, Christof},
doi = {10.1109/TPAMI.2011.146},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hou, Harel, Koch/Hou, Harel, Koch - 2011 - Image Signature Highlighting Sparse Salient Regions. - IEEE transactions on pattern analysis and machine intel.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = jul,
number = {1},
pages = {194--201},
pmid = {21788665},
title = {{Image Signature: Highlighting Sparse Salient Regions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21788665},
volume = {34},
year = {2011}
}
@inproceedings{Smyth2002,
abstract = {This research presents a model of the avian vocal tract, imple- mented using classical waveguide synthesis and numerical meth- ods. The vocal organ of the songbird, the syrinx, has a unique topography of acoustic tubes (a trachea with a bifurcation at its base) making it a rather unique subject for waveguide synthesis. In the upper region of the two bifid bronchi lies a nonlinear vi- brating membrane – the primary resonator in sound production. Unlike most reed musical instruments, the more significant dis- placement of the membrane is perpendicular to the directions of airflow, due to the Bernoulli effect. The model of the membrane displacement, and the resulting pressure through the constriction created by the membrane motion, is therefore derived beginning with the Bernoulli equation.},
author = {Smyth, T. and Smith, J.O.},
booktitle = {DAFX 2002 Proceedings},
file = {::},
pages = {26--29},
publisher = {Citeseer},
title = {{The Sounds of the Avian Syrinx - Are They Really Flute Like?}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.6948\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Benoit2011,
author = {Beno\^{\i}t, Louise and Mairal, Julien},
file = {:Users/pkmital/Documents/Mendeley Desktop/Beno\^{\i}t, Mairal/Beno\^{\i}t, Mairal - 2011 - Sparse image representation with epitomes - Computer Vision and \ldots.pdf:pdf},
journal = {Computer Vision and \ldots},
title = {{Sparse image representation with epitomes}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5995636},
year = {2011}
}
@article{Wever1927,
author = {Wever, EG},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wever/Wever - 1927 - Figure and ground in the visual perception of form - The American Journal of Psychology.pdf:pdf},
journal = {The American Journal of Psychology},
number = {2},
pages = {194--226},
title = {{Figure and ground in the visual perception of form}},
url = {http://www.jstor.org/stable/10.2307/1415201},
volume = {38},
year = {1927}
}
@inproceedings{Lallemand,
author = {Lallemand, Ianis and Schwarz, Diemo and Artieres, Thierry},
booktitle = {Proc. of SMC9, Copenhagen, Denmark},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lallemand, Schwarz, Artieres/Lallemand, Schwarz, Artieres - Unknown - Content-based Retrieval of Environmental Sounds by Multiresolution Analysis - Proc. of SMC9, Copenhagen, Denmark.pdf:pdf},
title = {{Content-based Retrieval of Environmental Sounds by Multiresolution Analysis}}
}
@article{Szeliski2006,
author = {Szeliski, Richard},
doi = {10.1561/0600000009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Szeliski/Szeliski - 2006 - Image Alignment and Stitching A Tutorial - Foundations and Trends® in Computer Graphics and Vision.pdf:pdf},
issn = {1572-2740},
journal = {Foundations and Trends® in Computer Graphics and Vision},
number = {1},
pages = {1--104},
title = {{Image Alignment and Stitching: A Tutorial}},
url = {http://www.nowpublishers.com/product.aspx?product=CGV\&doi=0600000009},
volume = {2},
year = {2006}
}
@article{Dimension2003,
author = {Dimension, Dynamic-segmentation-based Feature and For, Reduction and Audio, Quick and Searching, Video and Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi and Communication, N T T and Laboratories, Science and Corporation, N T T},
file = {:Users/pkmital/Documents/Mendeley Desktop/Dimension et al/Dimension et al. - 2003 - No Title - Dimension Contemporary German Arts And Letters.pdf:pdf},
journal = {Dimension Contemporary German Arts And Letters},
pages = {389--392},
title = {{No Title}},
year = {2003}
}
@article{Kwapisz2011,
author = {Kwapisz, J.R. and Weiss, G.M. and Moore, S.A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kwapisz, Weiss, Moore/Kwapisz, Weiss, Moore - 2011 - Activity recognition using cell phone accelerometers - ACM SIGKDD Explorations Newsletter.pdf:pdf},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
number = {2},
pages = {74--82},
publisher = {ACM},
title = {{Activity recognition using cell phone accelerometers}},
url = {http://portal.acm.org/citation.cfm?id=1964918},
volume = {12},
year = {2011}
}
@article{Najemnik2005,
abstract = {To perform visual search, humans, like many mammals, encode a large field of view with retinas having variable spatial resolution, and then use high-speed eye movements to direct the highest-resolution region, the fovea, towards potential target locations. Good search performance is essential for survival, and hence mammals may have evolved efficient strategies for selecting fixation locations. Here we address two questions: what are the optimal eye movement strategies for a foveated visual system faced with the problem of finding a target in a cluttered environment, and do humans employ optimal eye movement strategies during a search? We derive the ideal bayesian observer for search tasks in which a target is embedded at an unknown location within a random background that has the spectral characteristics of natural scenes. Our ideal searcher uses precise knowledge about the statistics of the scenes in which the target is embedded, and about its own visual system, to make eye movements that gain the most information about target location. We find that humans achieve nearly optimal search performance, even though humans integrate information poorly across fixations. Analysis of the ideal searcher reveals that there is little benefit from perfect integration across fixations-much more important is efficient processing of information on each fixation. Apparently, evolution has exploited this fact to achieve efficient eye movement strategies with minimal neural resources devoted to memory.},
author = {Najemnik, Jiri and Geisler, Wilson S},
institution = {Center for Perceptual Systems and Department of Psychology, University of Texas at Austin, Austin, Texas 78712, USA.},
journal = {Nature},
keywords = {brain,brain physiology,computer simulation,eye movements,eye movements physiology,fixation,humans,ocular,ocular physiology,photic stimulation,psychomotor performance,psychomotor performance physiology,vision},
number = {7031},
pages = {387--391},
pmid = {15772663},
publisher = {Nature Publishing Group},
title = {{Optimal eye movement strategies in visual search.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15772663},
volume = {434},
year = {2005}
}
@article{Kayser2005c,
abstract = {Our nervous system is confronted with a barrage of sensory stimuli, but neural resources are limited and not all stimuli can be processed to the same extent. Mechanisms exist to bias attention toward the particularly salient events, thereby providing a weighted representation of our environment. Our understanding of these mechanisms is still limited, but theoretical models can replicate such a weighting of sensory inputs and provide a basis for understanding the underlying principles. Here, we describe such a model for the auditory system-an auditory saliency map. We experimentally validate the model on natural acoustical scenarios, demonstrating that it reproduces human judgments of auditory saliency and predicts the detectability of salient sounds embedded in noisy backgrounds. In addition, it also predicts the natural orienting behavior of naive macaque monkeys to the same salient stimuli. The structure of the suggested model is identical to that of successfully used visual saliency maps. Hence, we conclude that saliency is determined either by implementing similar mechanisms in different unisensory pathways or by the same mechanism in multisensory areas. In any case, our results demonstrate that different primate sensory systems rely on common principles for extracting relevant sensory events.},
author = {Kayser, Christoph and Petkov, Christopher I and Lippert, Michael and Logothetis, Nikos K},
doi = {10.1016/j.cub.2005.09.040},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kayser et al/Kayser et al. - 2005 - Mechanisms for allocating auditory attention an auditory saliency map. - Current biology CB(4).pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Acoustic Stimulation,Animals,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Macaca mulatta,Macaca mulatta: physiology,Models, Neurological,Orientation,Orientation: physiology,Species Specificity},
month = nov,
number = {21},
pages = {1943--7},
pmid = {16271872},
title = {{Mechanisms for allocating auditory attention: an auditory saliency map.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271872},
volume = {15},
year = {2005}
}
@phdthesis{Lazier2003a,
author = {Lazier, Ari},
booktitle = {Thesis},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lazier/Lazier - 2003 - MoSievius Interactive Audio Mosaicing - Thesis.pdf:pdf},
number = {May},
title = {{MoSievius: Interactive Audio Mosaicing}},
year = {2003}
}
@article{Kimuraa,
author = {Kimura, Akisato},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura/Kimura - Unknown - Coding theorems for correlated sources with cooperative encoding - Main.pdf:pdf},
journal = {Main},
title = {{Coding theorems for correlated sources with cooperative encoding}}
}
@article{Langer2010,
author = {Langer, Tim},
file = {:Users/pkmital/Documents/Mendeley Desktop/Langer/Langer - 2010 - Music Information Retrieval \& Visualization - Trends in Information Visualization.pdf:pdf},
journal = {Trends in Information Visualization},
title = {{Music Information Retrieval \& Visualization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.164.2901\&rep=rep1\&type=pdf},
year = {2010}
}
@article{Battier2007,
author = {Battier, Marc},
doi = {10.1017/S1355771807001902},
file = {:Users/pkmital/Documents/Mendeley Desktop/Battier/Battier - 2007 - What the GRM brought to music from musique concr\`{e}te to acousmatic music - Organised Sound.pdf:pdf},
issn = {1355-7718},
journal = {Organised Sound},
month = nov,
number = {03},
pages = {189--202},
title = {{What the GRM brought to music: from musique concr\`{e}te to acousmatic music}},
url = {http://www.journals.cambridge.org/abstract\_S1355771807001902},
volume = {12},
year = {2007}
}
@article{Baddeley2006,
abstract = {A Bayesian system identification technique was used to determine which image characteristics predict where people fixate when viewing natural images. More specifically an estimate was derived for the mapping between image characteristics at a given location and the probability that this location was fixated. Using a large database of eye fixations to natural images, we determined the most probable (a posteriori) model of this mapping. From a set of candidate feature maps consisting of edge, contrast and luminance maps (at two different spatial scales), fixation probability was dominated by high spatial frequency edge information. The best model applied compressive non-linearity to the high frequency edge detecting filters (approximately a square root). Both low spatial frequency edges and contrast had weaker, but inhibitory, effects. The contributions of the other maps were so small as to be behaviourally irrelevant. This Bayesian method identifies not only the relevant weighting of the different maps, but how this weighting varies as a function of distance from the point of fixation. It was found that rather than centre surround inhibition, the weightings simply averaged over an area of about 2 degrees.},
author = {Baddeley, Roland J and Tatler, Benjamin W},
doi = {10.1016/j.visres.2006.02.024},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baddeley, Tatler/Baddeley, Tatler - 2006 - High frequency edges (but not contrast) predict where we fixate A Bayesian system identification analysis. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Bayes Theorem,Contrast Sensitivity,Contrast Sensitivity: physiology,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Form Perception,Form Perception: physiology,Humans,Models, Biological,Models, Psychological},
month = sep,
number = {18},
pages = {2824--33},
pmid = {16647742},
title = {{High frequency edges (but not contrast) predict where we fixate: A Bayesian system identification analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16647742},
volume = {46},
year = {2006}
}
@article{Kimura1999,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kimura, Uyematsu/Kimura, Uyematsu - 1999 - algorithm for Random Number Generation - Source.pdf:pdf},
journal = {Source},
pages = {2--12},
title = {{algorithm for Random Number Generation}},
year = {1999}
}
@article{Hyvarinen1999,
author = {Hyvarinen, A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hyvarinen/Hyvarinen - 1999 - Fast and robust fixed-point algorithms for independent component analysis - Neural Networks, IEEE Transactions on.pdf:pdf},
issn = {1045-9227},
journal = {Neural Networks, IEEE Transactions on},
number = {3},
pages = {626--634},
publisher = {IEEE},
title = {{Fast and robust fixed-point algorithms for independent component analysis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=761722},
volume = {10},
year = {1999}
}
@article{Lepetit2005,
author = {Lepetit, Vincent and Fua, Pascal},
doi = {10.1561/0600000001},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lepetit, Fua/Lepetit, Fua - 2005 - Monocular Model-Based 3D Tracking of Rigid Objects - Foundations and Trends® in Computer Graphics and Vision.pdf:pdf},
issn = {1572-2740},
journal = {Foundations and Trends® in Computer Graphics and Vision},
number = {1},
pages = {1--89},
title = {{Monocular Model-Based 3D Tracking of Rigid Objects}},
url = {http://www.nowpublishers.com/product.aspx?product=CGV\&doi=0600000001},
volume = {1},
year = {2005}
}
@article{Belardinelli2009,
author = {Belardinelli, Anna and Pirri, Fiora and Carbone, Andrea},
file = {:Users/pkmital/Documents/Mendeley Desktop/Belardinelli, Pirri, Carbone/Belardinelli, Pirri, Carbone - 2009 - Motion saliency maps from spatiotemporal filtering - Attention in Cognitive Systems.pdf:pdf},
journal = {Attention in Cognitive Systems},
pages = {112--123},
title = {{Motion saliency maps from spatiotemporal filtering}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-00582-4\_9},
year = {2009}
}
@article{Bousseau2007,
address = {New York, New York, USA},
author = {Bousseau, Adrien and Neyret, Fabrice and Thollot, Jo\"{e}lle and Salesin, David},
doi = {10.1145/1275808.1276507},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bousseau et al/Bousseau et al. - 2007 - Video watercolorization using bidirectional texture advection - ACM SIGGRAPH 2007 papers on - SIGGRAPH '07.pdf:pdf},
isbn = {9781595936486},
journal = {ACM SIGGRAPH 2007 papers on - SIGGRAPH '07},
keywords = {abstract stylization,ani-,have found ways to,in recent years,mated textures,non-photorealistic rendering,reproduce,researchers in computer graphics,suggest detail through abstract,temporal coherence,washes of color},
pages = {104},
publisher = {ACM Press},
title = {{Video watercolorization using bidirectional texture advection}},
url = {http://portal.acm.org/citation.cfm?doid=1275808.1276507},
year = {2007}
}
@article{Harel2007,
abstract = {A new bottom-up visual saliency model, Graph-Based Visual Saliency (GBVS), is proposed. It consists of two steps: rst forming activation maps on certain feature channels, and then normalizing them in a way which highlights conspicuity and admits combination with other maps. The model is simple, and biologically plausible insofar as it is naturally parallelized. This model powerfully predicts human xations on 749 variations of 108 natural images, achieving 98 \% of the ROC area of a human-based control, whereas the classical algorithms of Itti \&amp; Koch (2, 3, 4) achieve only 84\%. 1},
author = {Harel, Jonathan and Koch, Christof and Perona, Pietro},
doi = {10.1.1.70.2254},
editor = {Sch\"{o}lkopf, B and Platt, J and Hoffman, T},
institution = {CiteSeerX - Scientific Literature Digital Library and Search Engine [http://citeseerx.ist.psu.edu/oai2] (United States)},
issn = {10495258},
journal = {America},
number = {2},
pages = {545},
pmid = {20467426},
publisher = {Citeseer},
title = {{Graph-Based Visual Saliency}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.2254\&amp;rep=rep1\&amp;type=pdf},
volume = {19},
year = {2007}
}
@article{Aucouturier2007a,
abstract = {The "bag-of-frames" approach (BOF) to audio pattern recognition represents signals as the long-term statistical distribution of their local spectral features. This approach has proved nearly optimal for simulating the auditory perception of natural and human environments (or soundscapes), and is also the most predominent paradigm to extract high-level descriptions from music signals. However, recent studies show that, contrary to its application to soundscape signals, BOF only provides limited performance when applied to polyphonic music signals. This paper proposes to explicitly examine the difference between urban soundscapes and polyphonic music with respect to their modeling with the BOF approach. First, the application of the same measure of acoustic similarity on both soundscape and music data sets confirms that the BOF approach can model soundscapes to near-perfect precision, and exhibits none of the limitations observed in the music data set. Second, the modification of this measure by two custom homogeneity transforms reveals critical differences in the temporal and statistical structure of the typical frame distribution of each type of signal. Such differences may explain the uneven performance of BOF algorithms on soundscapes and music signals, and suggest that their human perception rely on cognitive processes of a different nature.},
author = {Aucouturier, Jean-Julien and Defreville, Boris and Pachet, Fran\c{c}ois},
doi = {10.1121/1.2750160},
issn = {15208524},
journal = {Journal of the Acoustical Society of America},
number = {2},
pages = {881--91},
pmid = {17672638},
title = {{The bag-of-frames approach to audio pattern recognition: a sufficient model for urban soundscapes but not for polyphonic music.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17672638},
volume = {122},
year = {2007}
}
@article{Furht1995,
author = {Furht, Borko},
file = {:Users/pkmital/Documents/Mendeley Desktop/Furht/Furht - 1995 - A Survery of Multimedia Compression Techniques and Standards - Real-Time Imaging.pdf:pdf},
journal = {Real-Time Imaging},
pages = {49--67},
title = {{A Survery of Multimedia Compression Techniques and Standards}},
volume = {1},
year = {1995}
}
@article{Benetos2011,
author = {Benetos, Emmanouil and Dixon, Simon},
file = {:Users/pkmital/Documents/Mendeley Desktop/Benetos, Dixon/Benetos, Dixon - 2011 - Multiple-instrument polyphonic music transcription using a convolutive probabilistic model - 8th Sound and Music Computing Conference.pdf:pdf},
journal = {8th Sound and Music Computing Conference},
title = {{Multiple-instrument polyphonic music transcription using a convolutive probabilistic model}},
url = {http://www.eecs.qmul.ac.uk/~simond/pub/2011/Benetos-Dixon-SMC2011.pdf},
year = {2011}
}
@article{Lamberti2003a,
address = {New York, New York, USA},
author = {Lamberti, Fabrizio and Zunino, Claudio and Sanna, Andrea and Fiume, Antonino and Maniezzo, Marco},
file = {::},
journal = {Proceeding of the eighth international conference on 3D web technology - Web3D '03},
pages = {55},
publisher = {ACM Press},
title = {{An accelerated remote graphics architecture for PDAS}},
url = {http://portal.acm.org/citation.cfm?doid=636593.636602},
year = {2003}
}
@article{Ramsey2010,
abstract = {Neuroimaging (e.g. fMRI) data are increasingly used to attempt to identify not only brain regions of interest (ROIs) that are especially active during perception, cognition, and action, but also the qualitative causal relations among activity in these regions (known as effective connectivity; Friston, 1994). Previous investigations and anatomical and physiological knowledge may somewhat constrain the possible hypotheses, but there often remains a vast space of possible causal structures. To find actual effective connectivity relations, search methods must accommodate indirect measurements of nonlinear time series dependencies, feedback, multiple subjects possibly varying in identified regions of interest, and unknown possible location-dependent variations in BOLD response delays. We describe combinations of procedures that under these conditions find feed-forward sub-structure characteristic of a group of subjects. The method is illustrated with an empirical data set and confirmed with simulations of time series of non-linear, randomly generated, effective connectivities, with feedback, subject to random differences of BOLD delays, with regions of interest missing at random for some subjects, measured with noise approximating the signal to noise ratio of the empirical data.},
author = {Ramsey, J D and Hanson, S J and Hanson, C and Halchenko, Y O and Poldrack, R a and Glymour, C},
doi = {10.1016/j.neuroimage.2009.08.065},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ramsey et al/Ramsey et al. - 2010 - Six problems for causal inference from fMRI. - NeuroImage.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Brain,Brain: physiology,Computer Simulation,Databases as Topic,Feedback, Physiological,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models, Neurological,Nonlinear Dynamics,Oxygen,Oxygen: blood,Time Factors},
month = jan,
number = {2},
pages = {1545--58},
pmid = {19747552},
publisher = {Elsevier Inc.},
title = {{Six problems for causal inference from fMRI.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19747552},
volume = {49},
year = {2010}
}
@article{Land2001,
abstract = {Two recent studies have investigated the relations of eye and hand movements in extended food preparation tasks, and here the results are compared. The tasks could be divided into a series of actions performed on objects. The eyes usually reached the next object in the sequence before any sign of manipulative action, indicating that eye movements are planned into the motor pattern and lead each action. The eyes usually fixated the same object throughout the action upon it, although they often moved on to the next object in the sequence before completion of the preceding action. The specific roles of individual fixations could be identified as locating (establishing the locations of objects for future use), directing (establishing target direction prior to contact), guiding (supervising the relative movements of two or three objects) and checking (establishing whether some particular condition is met, prior to the termination of an action). It is argued that, at the beginning of each action, the oculomotor system is supplied with the identity of the required object, information about its location, and instructions about the nature of the monitoring required during the action. The eye movements during this kind of task are nearly all to task-relevant objects, and thus their control is seen as primarily 'top-down', and influenced very little by the 'intrinsic salience' of objects.},
author = {Land, Michael F and Hayhoe, Mary},
editor = {Tistarelli, Massimo and Nixon, Mark},
institution = {School of Biological Sciences, University of Sussex, BN1 9QG, Brighton, UK. m.f.land@sussex.ac.uk},
journal = {Vision Research},
keywords = {eye movements,eye movements physiology,fixation,food handling,food handling methods,humans,ocular,ocular physiology,psychomotor performance,psychomotor performance physiology},
number = {25-26},
pages = {3559--3565},
publisher = {Elsevier},
series = {Lecture Notes in Computer Science},
title = {{In what ways do eye movements contribute to everyday activities?}},
url = {http://sro.sussex.ac.uk/26787/},
volume = {41},
year = {2001}
}
@article{Griffiths2004,
abstract = {Objects are the building blocks of experience, but what do we mean by an object? Increasingly, neuroscientists refer to 'auditory objects', yet it is not clear what properties these should possess, how they might be represented in the brain, or how they might relate to the more familiar objects of vision. The concept of an auditory object challenges our understanding of object perception. Here, we offer a critical perspective on the concept and its basis in the brain.},
author = {Griffiths, Timothy D and Warren, Jason D},
doi = {10.1038/nrn1538},
file = {:Users/pkmital/Documents/Mendeley Desktop/Griffiths, Warren/Griffiths, Warren - 2004 - What is an auditory object - Nature reviews. Neuroscience.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Animals,Auditory Perception,Humans,Models, Neurological,Neurosciences,Neurosciences: methods,Sound,Terminology as Topic},
month = nov,
number = {11},
pages = {887--92},
pmid = {15496866},
title = {{What is an auditory object?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15496866},
volume = {5},
year = {2004}
}
@article{Lee2012,
author = {Lee, Hochang and Seo, Sanghyun and Ryoo, Seungtaek and Ahn, Keejoo and Yoon, Kyunghyun},
doi = {10.1007/s11042-012-1036-x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lee et al/Lee et al. - 2012 - A multi-level depiction method for painterly rendering based on visual perception cue - Multimedia Tools and Applica.pdf:pdf},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
keywords = {image saliency,non-photorealistic rendering,painting technique},
month = feb,
title = {{A multi-level depiction method for painterly rendering based on visual perception cue}},
url = {http://www.springerlink.com/index/10.1007/s11042-012-1036-x},
year = {2012}
}
@article{Bohme2006,
author = {Bohme, M and Meyer, Andr\'{e} and Martinetz, Thomas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bohme, Meyer, Martinetz/Bohme, Meyer, Martinetz - 2006 - Remote eye tracking State of the art and directions for future development - Communication by Gaze.pdf:pdf},
journal = {Communication by Gaze},
keywords = {eye model,free head motion,remote eye tracking},
pages = {2--6},
title = {{Remote eye tracking: State of the art and directions for future development}},
url = {http://www.inb.uni-luebeck.de/publikationen/pdfs/BoMeMaBa06.pdf},
year = {2006}
}
@article{Rao1999a,
abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
author = {Rao, R P and Ballard, D H},
doi = {10.1038/4580},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rao, Ballard/Rao, Ballard - 1999 - Predictive coding in the visual cortex a functional interpretation of some extra-classical receptive-field effects. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Feedback,Forecasting,Models, Neurological,Neural Networks (Computer),Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology},
month = jan,
number = {1},
pages = {79--87},
pmid = {10195184},
title = {{Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10195184},
volume = {2},
year = {1999}
}
@article{Antani2002,
author = {Antani, Sameer and Kasturi, Rangachar and Jain, Ramesh},
doi = {10.1016/S0031-3203(01)00086-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Antani, Kasturi, Jain/Antani, Kasturi, Jain - 2002 - A survey on the use of pattern recognition methods for abstraction, indexing and retrieval of images and video - Pattern Recognition.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {content-based retrieval,image databases,pattern recognition,video databases},
month = apr,
number = {4},
pages = {945--965},
title = {{A survey on the use of pattern recognition methods for abstraction, indexing and retrieval of images and video}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301000863},
volume = {35},
year = {2002}
}
@article{Casey2001a,
author = {Casey, Michael},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey/Casey - 2001 - General sound classification and similarity in MPEG-7 - Organised Sound.pdf:pdf},
issn = {1469-8153},
journal = {Organised Sound},
keywords = {de-correlated features,finite-sate model,generalized timbre,sound classification,sound similarity},
number = {02},
pages = {153--164},
publisher = {Cambridge Univ Press},
title = {{General sound classification and similarity in MPEG-7}},
url = {http://journals.cambridge.org/abstract\_S1355771801002126},
volume = {6},
year = {2001}
}
@article{Einhauser2008,
author = {Einh\"{a}user, Wolfgang and Perona, Pietro},
doi = {10.1167/8.14.18.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Einh\"{a}user, Perona/Einh\"{a}user, Perona - 2008 - Objects predict fixations better than early saliency - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,1167,14,18,2008,26,8,attention,citation,doi,einh\"{a}user,eye movements,http,journal of vision,journalofvision,m,object recognition,objects predict fixations better,org,p,perona,scene recognition,spain,than early saliency,w},
pages = {1--26},
title = {{Objects predict fixations better than early saliency}},
volume = {8},
year = {2008}
}
@phdthesis{DeLaRiviere2001,
author = {{De La Rivi\`{e}re}, Jean-Baptiste},
file = {::},
title = {{Interaction 3D : Utilisations Conjointes d’un pointeur Laser et d’un Grand Ecran}},
year = {2001}
}
@article{Leung2007a,
author = {Leung, Clement and Kimura, Akisato and Takeuchi, Tatsuto and Kashino, Kunio},
doi = {10.1109/ICME.2007.4284646},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leung et al/Leung et al. - 2007 - A Computational Model of Saliency DepletionRecovery Phenomena for the Salient Region Extraction of Videos - Multimedia and Expo, 2007 IEEE International Conference on(2).pdf:pdf},
isbn = {1-4244-1016-9},
journal = {Multimedia and Expo, 2007 IEEE International Conference on},
keywords = {early human visual system,inhibition of return,saliency depletion,video processing,visual attention},
month = jul,
pages = {300--303},
publisher = {Ieee},
title = {{A Computational Model of Saliency Depletion/Recovery Phenomena for the Salient Region Extraction of Videos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4284646},
year = {2007}
}
@article{FeiFei2005,
author = {Fei-Fei, L and Perona, P.},
doi = {10.1109/CVPR.2005.16},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fei-Fei, Perona/Fei-Fei, Perona - 2005 - A bayesian hierarchical model for learning natural scene categories - Computer Vision and Pattern Recognition (.pdf:pdf},
isbn = {0-7695-2372-2},
journal = {Computer Vision and Pattern Recognition (CVPR), 2005 IEEE Conference on},
pages = {524--531},
publisher = {Ieee},
title = {{A bayesian hierarchical model for learning natural scene categories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467486 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1467486},
volume = {2},
year = {2005}
}
@article{Kanwisher2000,
author = {Kanwisher, N},
doi = {10.1038/77664},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kanwisher/Kanwisher - 2000 - Domain specificity in face perception. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Brain,Brain Mapping,Brain: physiology,Face,Form Perception,Form Perception: physiology,Humans,Neurons,Neurons: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology},
month = aug,
number = {8},
pages = {759--63},
pmid = {10903567},
title = {{Domain specificity in face perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10903567},
volume = {3},
year = {2000}
}
@article{Pang2008,
author = {Pang, Derek and Kimura, Akisato and Takeuchi, Tatsuto and Yamato, Junji and Kashino, Kunio},
doi = {10.1109/ICME.2008.4607624},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pang et al/Pang et al. - 2008 - A stochastic model of selective visual attention with a dynamic Bayesian network - 2008 IEEE International Conference on Multimedia and Expo.pdf:pdf},
isbn = {978-1-4244-2570-9},
journal = {2008 IEEE International Conference on Multimedia and Expo},
month = jun,
number = {3},
pages = {1073--1076},
publisher = {Ieee},
title = {{A stochastic model of selective visual attention with a dynamic Bayesian network}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4607624},
year = {2008}
}
@article{Zhang2008,
author = {Zhang, Lingyun and Tong, Matthew H and Marks, Tim K and Cottrell, Garrison W},
doi = {10.1167/8.7.32.Introduction},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang et al/Zhang et al. - 2008 - SUN A Bayesian framework for saliency using natural statistics - Journal of Vision.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,1167,20,2008,32,7,8,a bayesian framework for,attention,citation,computational modeling,cottrell,doi,eye movements,g,h,http,journal of vision,journalofvision,k,l,m,marks,org,saliency,shan,sun,t,tong,using natural statistics,w,zhang},
pages = {1--20},
title = {{SUN : A Bayesian framework for saliency using natural statistics}},
volume = {8},
year = {2008}
}
@article{Mitchell2004,
author = {Mitchell, Tom M. and Hutchinson, Rebecca and Niculescu, Radu S. and Pereira, Francisco and Wang, Xuerui and Just, Marcel and Newman, Sharlene},
doi = {10.1023/B:MACH.0000035475.85309.1b},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mitchell et al/Mitchell et al. - 2004 - Learning to Decode Cognitive States from Brain Images - Machine Learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {bayesian classifier,brain image analysis,feature,functional magnetic resonance imaging,high dimensional data,nearest neighbor,scientific data analysis,selection,support vector machine},
month = oct,
number = {1/2},
pages = {145--175},
title = {{Learning to Decode Cognitive States from Brain Images}},
url = {http://link.springer.com/10.1023/B:MACH.0000035475.85309.1b},
volume = {57},
year = {2004}
}
@article{Nurminen2008d,
author = {Nurminen, Antti},
journal = {IEEE Computer Graphics and Applications},
title = {{Mobile 3D City Maps}},
year = {2008}
}
@article{Inhoff1982,
abstract = {Three experiments were performed to explore the processing of parafoveal information. A foveal and a parafoveal word pair were presented within the time frame of a single fixation, but short enough to prevent successful refixation of the parafoveal word. Subjects reporting partial parafoveal word information were not able to use this information to bias their choice in a forced-choice task requiring some semantic information from the parafoveal word for correct performance. This result was observed even though correct parafoveal word identification was facilitated if the foveal stimulus was related to the parafoveal word. Further, the data strongly suggest that information is obtained initially from the fixated words, regardless of whether foveal word presentation precedes or follows the parafoveal stimulus.},
author = {Inhoff, a W},
file = {:Users/pkmital/Documents/Mendeley Desktop/Inhoff/Inhoff - 1982 - Parafoveal word perception a further case against semantic preprocessing. - Journal of experimental psychology. Human perception and performance.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Discrimination Learning,Discrimination Learning: physiology,Form Perception,Form Perception: physiology,Fovea Centralis,Fovea Centralis: physiology,Humans,Macula Lutea,Macula Lutea: physiology,Reading,Semantics,Visual Fields},
month = feb,
number = {1},
pages = {137--45},
pmid = {6460079},
title = {{Parafoveal word perception: a further case against semantic preprocessing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6460079},
volume = {8},
year = {1982}
}
@article{Siebert2009,
author = {Siebert, Xavier and Dupont, St\'{e}phane and Fortemps, Philippe and Tardieu, Damien},
file = {:Users/pkmital/Documents/Mendeley Desktop/Siebert et al/Siebert et al. - 2009 - Mediacycle browsing and performing with sound and image libraries - QPSR of the numediart research program.pdf:pdf},
journal = {QPSR of the numediart research program},
keywords = {content-based navigation,mediacycle,multimedia databases},
number = {1},
pages = {19--22},
title = {{Mediacycle: browsing and performing with sound and image libraries}},
url = {http://www.numediart.org/docs/numediart\_2009\_s05\_p3\_report.pdf},
volume = {2},
year = {2009}
}
@article{Marr1978,
author = {Marr, D and Nishihara, H K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marr, Nishihara/Marr, Nishihara - 1978 - Representation and recognition of the spatial organization of three-dimensional shapes. - Proceedings of the Ro.pdf:pdf},
issn = {0080-4649},
journal = {Proceedings of the Royal Society of London. Series B, Containing papers of a Biological character. Royal Society (Great Britain)},
keywords = {Form Perception,Humans,Models, Structural},
month = feb,
number = {1140},
pages = {269--94},
pmid = {24223},
title = {{Representation and recognition of the spatial organization of three-dimensional shapes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24223},
volume = {200},
year = {1978}
}
@article{Humphreys2002a,
author = {Humphreys, Greg and Houston, Mike and Ng, Ren and Frank, Randall and Ahern, Sean and Kirchner, Peter D. and Klosowski, James T.},
file = {::},
journal = {ACM Transactions on Graphics},
keywords = {cluster rendering,dering,parallel ren-,remote graphics,scalable rendering,stream,tiled displays,virtual graphics},
month = jul,
number = {3},
title = {{Chromium: a stream-processing framework for interactive rendering on clusters}},
url = {http://portal.acm.org/citation.cfm?doid=566654.566639},
volume = {21},
year = {2002}
}
@article{Collins2008,
author = {Collins, N},
file = {:Users/pkmital/Documents/Mendeley Desktop/Collins/Collins - 2008 - Audiovisual concatenative synthesis - Proc. Int. Computer Music Conf.pdf:pdf},
journal = {Proc. Int. Computer Music Conf},
title = {{Audiovisual concatenative synthesis}},
url = {http://en.cnki.com.cn/Article\_en/CJFDTOTAL-DNDX200201001.htm http://portal.acm.org/citation.cfm?id=258880 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.5534\&amp;rep=rep1\&amp;type=pdf},
year = {2008}
}
@article{Viola2001,
author = {Viola, Paul},
file = {:Users/pkmital/Documents/Mendeley Desktop/Viola/Viola - 2001 - Rapid object detection using a boosted cascade of simple features - , 2001. CVPR 2001. Proceedings of the.pdf:pdf},
journal = {, 2001. CVPR 2001. Proceedings of the},
title = {{Rapid object detection using a boosted cascade of simple features}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=990517},
year = {2001}
}
@article{Ninness2008,
author = {Ninness, Brett and Henriksen, Soren John},
doi = {10.1109/TSP.2007.909350},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ninness, Henriksen/Ninness, Henriksen - 2008 - Time-Scale Modification of Speech Signals - IEEE Transactions on Signal Processing.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = apr,
number = {4},
pages = {1479--1488},
title = {{Time-Scale Modification of Speech Signals}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4471887},
volume = {56},
year = {2008}
}
@article{Brockmole2006,
abstract = {In contextual cueing, the position of a target within a group of distractors is learned over repeated exposure to a display with reference to a few nearby items rather than to the global pattern created by the elements. The authors contrasted the role of global and local contexts for contextual cueing in naturalistic scenes. Experiment 1 showed that learned target positions transfer when local information is altered but not when global information is changed. Experiment 2 showed that scene-target covariation is learned more slowly when local, but not global, information is repeated across trials than when global but not local information is repeated. Thus, in naturalistic scenes, observers are biased to associate target locations with global contexts.},
author = {Brockmole, James R and Castelhano, Monica S and Henderson, John M},
doi = {10.1037/0278-7393.32.4.699},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brockmole, Castelhano, Henderson/Brockmole, Castelhano, Henderson - 2006 - Contextual cueing in naturalistic scenes Global and local contexts. - Journal of experimental psychology. Learning, memory, and cognition.pdf:pdf},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Association Learning,Attention,Concept Formation,Cues,Depth Perception,Discrimination Learning,Field Dependence-Independence,Humans,Orientation,Pattern Recognition, Visual,Psychophysics,Reaction Time,Semantics,Students,Students: psychology,Transfer (Psychology)},
month = jul,
number = {4},
pages = {699--706},
pmid = {16822141},
title = {{Contextual cueing in naturalistic scenes: Global and local contexts.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16822141},
volume = {32},
year = {2006}
}
@article{Lane2010,
author = {Lane, Nicholas D and Miluzzo, Emiliano and Lu, Hong and Peebles, Daniel and Choudhury, Tanzeem and Campbell, Andrew T and College, Dartmouth},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lane et al/Lane et al. - 2010 - AD-HOC AND SENSOR NETWORKS A Survey of Mobile Phone Sensing - IEEE Communications Magazine.pdf:pdf},
journal = {IEEE Communications Magazine},
number = {September},
pages = {140--150},
title = {{AD-HOC AND SENSOR NETWORKS A Survey of Mobile Phone Sensing}},
year = {2010}
}
@article{Vedaldi2010,
author = {Vedaldi, Andrea and Ling, Haibin and Soatto, Stefano},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vedaldi, Ling, Soatto/Vedaldi, Ling, Soatto - 2010 - Knowing a Good Feature When You See It Ground Truth and Methodology to Evaluate Local Features for Recogn.pdf:pdf},
journal = {Computer Vision},
pages = {27--49},
title = {{Knowing a Good Feature When You See It: Ground Truth and Methodology to Evaluate Local Features for Recognition}},
url = {http://www.springerlink.com/index/X31351274188483V.pdf},
year = {2010}
}
@article{D'Angelo2011,
author = {D'Angelo, E and Paratte, J and Puy, Gilles and Vandergheynst, Pierre},
file = {:Users/pkmital/Documents/Mendeley Desktop/D'Angelo et al/D'Angelo et al. - 2011 - Fast TV-L1 optical flow for interactivity - Proceedings of the 18th IEEE International Conference on Image Proc.pdf:pdf},
journal = {Proceedings of the 18th IEEE International Conference on Image Processing (ICIP) 2011},
pages = {1885--1888},
title = {{Fast TV-L1 optical flow for interactivity}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6115836},
year = {2011}
}
@inproceedings{Taylor2009a,
abstract = {We present an algorithm for fast computation of diffraction paths for geometric-acoustics in complex environments based on theUTD formulation. Our method extends ray-frustum tracing to efficiently compute paths in the shadow region caused by long diffracting edges. Our approach can handle general scenes withmoving sources, receivers, and dynamic objects. We evaluate the accuracy through comparisons with physically validated geometric simulations. In practice, our edge diffraction algorithm can perform sound propa- gation at nearly interactive rates in dynamic scenarios on a multi- core PC.},
author = {Taylor, Micah and Chandak, Anish and Zhimin, Ren and Lauterbach, Christian and Manocha, Dinesh},
booktitle = {Proceedings of the EAA Symposium on Auralization.},
file = {::},
number = {June},
pages = {15--17},
title = {{Fast Edge-Diffraction for Sound Propagation in Complex Virtual Environments}},
year = {2009}
}
@incollection{Findlay2003a,
author = {Findlay, John M and Gilchrist, Iain D},
booktitle = {Cognitive Processes in Eye Guidance},
editor = {Underwood, Geoffrey},
file = {:Users/pkmital/Documents/Mendeley Desktop/Findlay, Gilchrist/Findlay, Gilchrist - 2003 - Eye Guidance and Visual Search - Cognitive Processes in Eye Guidance.pdf:pdf},
pages = {1--22},
title = {{Eye Guidance and Visual Search}},
year = {2003}
}
@article{Freeman,
author = {Freeman, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Freeman/Freeman - Unknown - MetaMix A Symbiosis of Familiar Content With Generative Form - distributedmusic.gatech.edu.pdf:pdf},
journal = {distributedmusic.gatech.edu},
number = {1},
pages = {1--4},
title = {{MetaMix: A Symbiosis of Familiar Content With Generative Form}},
url = {http://distributedmusic.gatech.edu/jason/publications/pdf\_files\_of\_publications/metamix\_a\_symbiosis\_of\_fami.pdf}
}
@article{Merrill1968,
author = {Merrill, RG and Metcalf, DR},
file = {:Users/pkmital/Documents/Mendeley Desktop/Merrill, Metcalf/Merrill, Metcalf - 1968 - COGNITIVE STYLES OF VISUAL PERCEPTION IN THE EVALUATION OF TELEVISION SYSTEMS - Perceptual and Motor Skills.pdf:pdf},
journal = {Perceptual and Motor Skills},
pages = {1043--1046},
title = {{COGNITIVE STYLES OF VISUAL PERCEPTION IN THE EVALUATION OF TELEVISION SYSTEMS}},
url = {http://www.amsciepub.com/doi/abs/10.2466/pms.1968.26.3c.1043},
year = {1968}
}
@article{Park2008,
author = {Park, Youngmin and Lepetit, Vincent},
doi = {10.1109/ISMAR.2008.4637336},
file = {:Users/pkmital/Documents/Mendeley Desktop/Park, Lepetit/Park, Lepetit - 2008 - Multiple 3D Object tracking for augmented reality - 2008 7th IEEEACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-2840-3},
journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
month = sep,
pages = {117--120},
publisher = {Ieee},
title = {{Multiple 3D Object tracking for augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637336},
year = {2008}
}
@article{Teh2009a,
author = {Teh, Yee Whye and Jordan, Michael I},
file = {:Users/pkmital/Documents/Mendeley Desktop/Teh, Jordan/Teh, Jordan - 2009 - Hierarchical Bayesian Nonparametric Models with Applications - Unknown.pdf:pdf},
pages = {1--48},
title = {{Hierarchical Bayesian Nonparametric Models with Applications}},
year = {2009}
}
@article{Brudera,
author = {Bruder, Gerd},
file = {::},
journal = {Image (Rochester, N.Y.)},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
title = {{A Natural User Interface for Immersive Architectural Walkthroughs}}
}
@article{Smith2009,
author = {Smith, Tim and Henderson, John},
doi = {10.1080/13506280802678557},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Henderson/Smith, Henderson - 2009 - Facilitation of return during scene viewing - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1083--1108},
title = {{Facilitation of return during scene viewing}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280802678557\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Huang2011a,
address = {New York, New York, USA},
author = {Huang, Hua and Zhang, Lei and Zhang, Hong-Chao},
doi = {10.1145/2024156.2024189},
file = {:Users/pkmital/Documents/Mendeley Desktop/Huang, Zhang, Zhang/Huang, Zhang, Zhang - 2011 - Arcimboldo-like collage using internet images - Proceedings of the 2011 SIGGRAPH Asia Conference on - SA '1.pdf:pdf},
isbn = {9781450308076},
journal = {Proceedings of the 2011 SIGGRAPH Asia Conference on - SA '11},
keywords = {Arcimboldo collage, internet image, segmentation, ,arcimboldo collage,internet image,segmentation},
number = {6},
pages = {1},
publisher = {ACM Press},
title = {{Arcimboldo-like collage using internet images}},
url = {http://dl.acm.org/citation.cfm?doid=2024156.2024189},
volume = {30},
year = {2011}
}
@article{Hopfinger2001,
abstract = {Previously, we demonstrated that reflexive attention facilitates early visual processing during form discrimination (Hopfinger \& Mangun, 1998). In the present study, we tested whether reflexive facilitation of early visual processing will be generated when task load is low (simple luminance detection). Target stimuli that were preceded at short cue-to-target intervals by irrelevant visual events (cues) elicited an enhanced sensory (P1) event-related potential (ERP) component as well as an enhanced longer latency, cognitive ERP component (P300). At long cue-to-target intervals, facilitation in these ERP components was no longer observed, and, although inhibition of return (IOR) was observed in reaction times, the ERPs did not show an inhibition of sensory processing. These results provide converging evidence that reflexive attention transiently facilitates neural processing of visual inputs at multiple stages of analysis (i.e., sensory processing and higher order cognitive processing) but question the view that IOR is manifest at the earliest visual cortical stages of analysis.},
author = {Hopfinger, J B and Mangun, G R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hopfinger, Mangun/Hopfinger, Mangun - 2001 - Tracking the influence of reflexive attention on sensory and cognitive processing. - Cognitive, affective \& behavioral neuroscience.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective \& behavioral neuroscience},
keywords = {Adolescent,Adult,Arousal,Arousal: physiology,Attention,Attention: physiology,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Electroencephalography,Event-Related Potentials, P300,Event-Related Potentials, P300: physiology,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Orientation,Orientation: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reaction Time,Reaction Time: physiology,Reflex,Reflex: physiology,Retention (Psychology),Retention (Psychology): physiology},
month = mar,
number = {1},
pages = {56--65},
pmid = {12467103},
title = {{Tracking the influence of reflexive attention on sensory and cognitive processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12467103},
volume = {1},
year = {2001}
}
@inproceedings{Smith2011a,
author = {Smith, Tim and Mital, Parag Kumar},
booktitle = {Vision Sciences Society (abstract)},
title = {{Watching the world go by: Attentional prioritization of social motion during dynamic scene viewing}},
year = {2011}
}
@article{Tatler2007b,
author = {Tatler, Benjamin W and Melcher, David},
doi = {10.1068/p5592},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Melcher/Tatler, Melcher - 2007 - Pictures in mind Initial encoding of object properties varies with the realism of the scene stimulus - Percepti.pdf:pdf},
issn = {0301-0066},
journal = {Perception},
number = {12},
pages = {1715--1729},
title = {{Pictures in mind: Initial encoding of object properties varies with the realism of the scene stimulus}},
url = {http://www.perceptionweb.com/abstract.cgi?id=p5592},
volume = {36},
year = {2007}
}
@incollection{Heslenfeld2003,
address = {Boston, MA},
author = {{Dirk J. Heslenfeld}},
booktitle = {Detection of Change},
doi = {10.1007/978-1-4615-0294-4},
editor = {Polich, John},
isbn = {978-1-4613-5008-8},
publisher = {Springer US},
title = {{Visual Mismatch Negativity}},
url = {http://www.springerlink.com/index/10.1007/978-1-4615-0294-4},
year = {2003}
}
@article{Posner1985,
abstract = {Abstract A goal of neuropsychology is to connect cognitive functions with underlying neural systems. Posner (1984; in press) has proposed a framework for doing so in which elementary mental operations in cognitive models are expressed in terms of component facilitations and inhibitions in the performance of normal persons. Studies of brain-injured patients are used to link these components to underlying neural systems. In the area of spatial attention one such component is the tendency to inhibit orienting towards visual locations which have been previously attended (inhibition of return). Here we report studies in patients and normals which demonstrate the relationship of this component to neural systems which generate saccades. The first experiment showed that midbrain lesions impairing saccade generation produced a concurrent loss of the inhibition of return, whereas cortical components shown to impair facilitatory components did not. The second and third experiments show that the inhibition of return is associated with a bias in eye movements against returning to a previously inhibited location and indicate that inhibition of return occurs even when the eyes are moved to an unchanging visual target. The deficits found in patients and the conditions under which the inhibition is found in normals suggest that inhibition of return may function to favour foveation of information at new locations.
Abstract A goal of neuropsychology is to connect cognitive functions with underlying neural systems. Posner (1984; in press) has proposed a framework for doing so in which elementary mental operations in cognitive models are expressed in terms of component facilitations and inhibitions in the performance of normal persons. Studies of brain-injured patients are used to link these components to underlying neural systems. In the area of spatial attention one such component is the tendency to inhibit orienting towards visual locations which have been previously attended (inhibition of return). Here we report studies in patients and normals which demonstrate the relationship of this component to neural systems which generate saccades. The first experiment showed that midbrain lesions impairing saccade generation produced a concurrent loss of the inhibition of return, whereas cortical components shown to impair facilitatory components did not. The second and third experiments show that the inhibition of return is associated with a bias in eye movements against returning to a previously inhibited location and indicate that inhibition of return occurs even when the eyes are moved to an unchanging visual target. The deficits found in patients and the conditions under which the inhibition is found in normals suggest that inhibition of return may function to favour foveation of information at new locations.},
author = {Posner, Michael I. and Rafal, Robert D. and Choate, Lisa S. and Vaughan, Jonathan},
doi = {10.1080/02643298508252866},
issn = {0264-3294},
journal = {Cognitive Neuropsychology},
month = aug,
number = {3},
pages = {211--228},
publisher = {Routledge},
title = {{Inhibition of return: Neural basis and function}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02643298508252866},
volume = {2},
year = {1985}
}
@article{Zelinsky2009,
author = {Zelinsky, Gregory and Schmidt, Joseph},
doi = {10.1080/13506280902764315},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zelinsky, Schmidt/Zelinsky, Schmidt - 2009 - An effect of referential scene constraint on search implies scene segmentation - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {6},
pages = {1004--1028},
title = {{An effect of referential scene constraint on search implies scene segmentation}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280902764315\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {17},
year = {2009}
}
@article{Rothganger2007,
abstract = {This paper presents a novel representation for dynamic scenes composed of multiple rigid objects that may undergo different motions and are observed by a moving camera. Multiview constraints associated with groups of affine-covariant scene patches and a normalized description of their appearance are used to segment a scene into its rigid components, construct three-dimensional models of these components, and match instances of models recovered from different image sequences. The proposed approach has been applied to the detection and matching of moving objects in video sequences and to shot matching, i.e., the identification of shots that depict the same scene in a video clip.},
author = {Rothganger, Fred and Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
doi = {10.1109/TPAMI.2007.57},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rothganger et al/Rothganger et al. - 2007 - Segmenting, modeling, and matching video clips containing multiple moving objects. - IEEE transactions on pat.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Theoretical,Motion,Movement,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique,Video Recording,Video Recording: methods},
month = mar,
number = {3},
pages = {477--91},
pmid = {17224617},
title = {{Segmenting, modeling, and matching video clips containing multiple moving objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17224617},
volume = {29},
year = {2007}
}
@article{Barrington2010,
author = {Barrington, L and Chan, A B and Lanckriet, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barrington, Chan, Lanckriet/Barrington, Chan, Lanckriet - 2010 - Modeling Music as a Dynamic Texture - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {602--612},
title = {{Modeling Music as a Dynamic Texture}},
volume = {18},
year = {2010}
}
@article{Weiss1996,
author = {Weiss, AS},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weiss/Weiss - 1996 - Experimental sound \&amp radio - Lingua.pdf:pdf},
isbn = {0262731304},
journal = {Lingua},
title = {{Experimental sound \&amp; radio}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=IIT2OiKDBhAC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=experimental+sound+and+radio\&amp;ots=r6dgd2MO-k\&amp;sig=e0IXHs-Gfx\_ArTSilC-betePWvs},
year = {1996}
}
@article{Leslie2010,
author = {Leslie, Grace and Schwarz, Diemo and Warusfel, Olivier and Bevilacqua, Frederic and Zamborlin, Bruno and Jodlowski, Pierre and Schnell, Norbert and Cnrs, Ircam},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leslie et al/Leslie et al. - 2010 - GRAINSTICK A COLLABORATIVE , INTERACTIVE SOUND INSTALLATION - Unknown.pdf:pdf},
number = {Icmc},
pages = {3--6},
title = {{GRAINSTICK : A COLLABORATIVE , INTERACTIVE SOUND INSTALLATION}},
year = {2010}
}
@book{Manjunath2002,
booktitle = {WWW-address: http://ipsi. fhg. de/delite/Projects/},
editor = {Manjunath, BS and Salembier, P and Sikora, Thomas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Unknown/Unknown - 2002 - Introduction to MPEG-7 Multimedia Content Description Interface - WWW-address httpipsi. fhg. dedeliteProjects.pdf:pdf},
publisher = {John Wiley and Sons},
title = {{Introduction to MPEG-7: Multimedia Content Description Interface}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Introduction+to+MPEG-7\#1 http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Introduction+to+MPEG-7+Multimedia+Content+Description+Interface\#0},
year = {2002}
}
@article{Wang2006b,
address = {New York, New York, USA},
author = {Wang, Jue and Drucker, Steven M. and Agrawala, Maneesh and Cohen, Michael F.},
doi = {10.1145/1179352.1142010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang et al/Wang et al. - 2006 - The cartoon animation filter - ACM SIGGRAPH 2006 Papers on - SIGGRAPH '06.pdf:pdf},
isbn = {1595933646},
journal = {ACM SIGGRAPH 2006 Papers on - SIGGRAPH '06},
pages = {1169},
publisher = {ACM Press},
title = {{The cartoon animation filter}},
url = {http://portal.acm.org/citation.cfm?doid=1179352.1142010},
year = {2006}
}
@incollection{McLeod2011b,
author = {McLeod, Kembrew},
booktitle = {Cutting Across Media. Appropriation Art, Interventionist Collage, and Copyright Law},
editor = {McLeod, Kembrew and Kuenzli, Rudolf},
file = {::},
pages = {164--177},
publisher = {Duke University Press},
title = {{Crashing the Spectacle}},
year = {2011}
}
@article{Hayhoe2011,
author = {Hayhoe, Mary M. and Rothkopf, Constantin a.},
doi = {10.1002/wcs.113},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hayhoe, Rothkopf/Hayhoe, Rothkopf - 2011 - Vision in the natural world - Wiley Interdisciplinary Reviews Cognitive Science.pdf:pdf},
issn = {19395078},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
month = mar,
number = {2},
pages = {158--166},
title = {{Vision in the natural world}},
url = {http://doi.wiley.com/10.1002/wcs.113},
volume = {2},
year = {2011}
}
@article{Fried2013,
author = {Fried, Ohad and Fiebrink, Rebecca},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fried, Fiebrink/Fried, Fiebrink - 2013 - Cross-modal Sound Mapping Using Deep Learning - Proceedings of the 2013 New Interfaces for Musical Expression C.pdf:pdf},
journal = {Proceedings of the 2013 New Interfaces for Musical Expression Conference (NIME2013)},
keywords = {3,comparing the original input,deep learning,feature learning,gestural control,mapping,more powerful than,other,section 3,since we are working,vectors,which is easier and},
title = {{Cross-modal Sound Mapping Using Deep Learning}},
url = {http://www.cs.princeton.edu/~fiebrink/publications/FriedFiebrink\_NIME2013.pdf},
year = {2013}
}
@article{Rinne2010,
abstract = {The present study was designed to directly test the hypothesis that suppression of activations to task-irrelevant sounds contributes to the attention-related modulations of auditory cortex (AC) activations observed in previous fMRI studies. Subjects selectively attended to auditory (broadband noise bursts with pitch) or visual (Gabor gratings) asynchronous fast-rate stimulus streams concurrently presented to left-ear, right-ear, above-fixation, or below-fixation. Auditory and visual task difficulty was parametrically manipulated in three levels. Behavioral data obtained during fMRI indicated that subjects achieved acceptable performance levels in all tasks and that the task-difficulty manipulation was effective. Consistent with previous studies, AC activations strongly depended on the direction of attention. AC activations to sounds were higher during auditory than during visual tasks and AC activations were higher in the hemisphere contralateral to the attended ear. However, the effects of task difficulty on AC activations were weak or non-existent. In particular, increasing task difficulty was not associated with a systematic decrease of AC activations in areas that were modulated by attention. These results suggest that suppression of AC activations to task-irrelevant sounds is likely to be small or negligible as compared with the strong activation enhancements observed in fMRI during active auditory tasks.},
author = {Rinne, Teemu},
doi = {10.2174/1874440001004010187},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rinne/Rinne - 2010 - Activations of human auditory cortex during visual and auditory selective attention tasks with varying difficulty. - The.pdf:pdf},
issn = {1874-4400},
journal = {The open neuroimaging journal},
keywords = {auditory cortex,fmri,human,selective attention,suppression},
month = jan,
pages = {187--93},
pmid = {21760872},
title = {{Activations of human auditory cortex during visual and auditory selective attention tasks with varying difficulty.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3134945\&tool=pmcentrez\&rendertype=abstract},
volume = {4},
year = {2010}
}
@book{Hughes1991,
author = {Hughes, Robert},
title = {{Shock of the New}},
year = {1991}
}
@article{Baddeley2002,
author = {Baddeley, Alan D.},
doi = {10.1027//1016-9040.7.2.85},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baddeley/Baddeley - 2002 - Is Working Memory Still Working - European Psychologist.pdf:pdf},
issn = {1016-9040},
journal = {European Psychologist},
month = jun,
number = {2},
pages = {85--97},
title = {{Is Working Memory Still Working?}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027//1016-9040.7.2.85},
volume = {7},
year = {2002}
}
@article{Shanken2013,
author = {Shanken, EA},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shanken/Shanken - 2002 - Art in the information age Technology and conceptual art - Leonardo.pdf:pdf},
journal = {Leonardo},
number = {4},
pages = {433--438},
title = {{Art in the information age: Technology and conceptual art}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/002409402760181259},
volume = {35},
year = {2002}
}
@article{Buettner1986,
author = {Buettner, Martin and Krischer, C C and Meissen, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Buettner, Krischer, Meissen/Buettner, Krischer, Meissen - 1986 - Characterization of gliding text as a reading stimulus - Text.pdf:pdf},
journal = {Text},
number = {6},
pages = {479--482},
title = {{Characterization of gliding text as a reading stimulus}},
volume = {23},
year = {1986}
}
@article{Tatler2005,
abstract = {What distinguishes the locations that we fixate from those that we do not? To answer this question we recorded eye movements while observers viewed natural scenes, and recorded image characteristics centred at the locations that observers fixated. To investigate potential differences in the visual characteristics of fixated versus non-fixated locations, these images were transformed to make intensity, contrast, colour, and edge content explicit. Signal detection and information theoretic techniques were then used to compare fixated regions to those that were not. The presence of contrast and edge information was more strongly discriminatory than luminance or chromaticity. Fixated locations tended to be more distinctive in the high spatial frequencies. Extremes of low frequency luminance information were avoided. With prolonged viewing, consistency in fixation locations between observers decreased. In contrast to [Parkhurst, D. J., Law, K., \& Niebur, E. (2002). Modeling the role of salience in the allocation of overt visual attention. Vision Research, 42 (1), 107-123] we found no change in the involvement of image features over time. We attribute this difference in our results to a systematic bias in their metric. We propose that saccade target selection involves an unchanging intermediate level representation of the scene but that the high-level interpretation of this representation changes over time.},
author = {Tatler, Benjamin W and Baddeley, Roland J and Gilchrist, Iain D},
doi = {10.1016/j.visres.2004.09.017},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tatler, Baddeley, Gilchrist/Tatler, Baddeley, Gilchrist - 2005 - Visual correlates of fixation selection effects of scale and time. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Models, Statistical,Saccades,Time Factors},
month = mar,
number = {5},
pages = {643--59},
pmid = {15621181},
title = {{Visual correlates of fixation selection: effects of scale and time.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15621181},
volume = {45},
year = {2005}
}
@article{Krauzlis1999,
author = {Krauzlis, R. J.},
doi = {10.1162/089892999563706},
file = {:Users/pkmital/Documents/Mendeley Desktop/Krauzlis/Krauzlis - 1999 - Target Selection for Pursuit and Saccadic Eye Movements in Humans - Journal of Cognitive Neuroscience.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = nov,
number = {6},
pages = {475--649},
title = {{Target Selection for Pursuit and Saccadic Eye Movements in Humans}},
volume = {38},
year = {1999}
}
@article{Stacy1973,
author = {Stacy, E Webb and Road, Ridge Lea},
file = {:Users/pkmital/Documents/Mendeley Desktop/Stacy, Road/Stacy, Road - 1973 - Short reports - Journal of Experimental Psychology.pdf:pdf},
journal = {Journal of Experimental Psychology},
title = {{Short reports}},
year = {1973}
}
@article{Schmalstieg2007c,
author = {Schmalstieg, D. and Schall, G. and Wagner, D. and Barakonyi, I. and Reitmayr, G. and Newman, J. and Ledermann, F.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
number = {August},
pages = {48--57},
publisher = {IEEE Computer Society},
title = {{Managing complex augmented reality models}},
url = {http://doi.ieeecomputersociety.org/10.110910.1109/MCG.2007.85},
year = {2007}
}
@article{Weinberger2011,
address = {Boston, MA},
author = {Weinberger, Norman M},
doi = {10.1007/978-1-4419-0074-6},
editor = {Winer, Jeffery A. and Schreiner, Christoph E.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weinberger/Weinberger - 2011 - The Auditory Cortex - Unknown.pdf:pdf},
isbn = {978-1-4419-0073-9},
publisher = {Springer US},
title = {{The Auditory Cortex}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-0074-6},
year = {2011}
}
@article{Henderson1989,
abstract = {Three experiments are reported that examined the relationship between covert visual attention and a viewer's ability to use extrafoveal visual information during object identification. Subjects looked at arrays of four objects while their eye movements were recorded. Their task was to identify the objects in the array for an immediate probe memory test. During viewing, the number and location of objects visible during given fixations were manipulated. In Experiments 1 and 2, we found that multiple extrafoveal previews of an object did not afford any more benefit than a single extrafoveal preview, as assessed by means of time of fixation on the objects. In Experiment 3, we found evidence for a model in which extrafoveal information acquired during a fixation derives primarily from the location toward which the eyes will move next. The results are discussed in terms of their implications for the relationship between covert visual attention and extrafoveal information use, and a sequential attention model is proposed.},
author = {Henderson, J M and Pollatsek, a and Rayner, K},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Pollatsek, Rayner/Henderson, Pollatsek, Rayner - 1989 - Covert visual attention and extrafoveal information use during object identification. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Fixation, Ocular,Form Perception,Humans,Pattern Recognition, Visual,Reaction Time,Visual Fields},
month = mar,
number = {3},
pages = {196--208},
pmid = {2710617},
title = {{Covert visual attention and extrafoveal information use during object identification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2710617},
volume = {45},
year = {1989}
}
@article{Winkler2003,
abstract = {The effects of auditory context on the preattentive and perceptual organization of tone sequences were investigated. Two sets of experiments were conducted in which the pitch of contextual tones was varied, bringing about two different contextual manipulations. Preattentive auditory organization was indexed by the mismatch negativity event-related potential, which is elicited by violations of auditory regularities even when participants ignore the sounds (e.g., by reading a book). The perceptual effects of the contextual manipulations on auditory grouping were assessed using target-detection and order-judgment tasks. The close correspondence found between the effects of auditory context on the perceptual and preattentive measures of auditory grouping suggests that a large part of contextual processing is preattentive.},
author = {Winkler, Istv\'{a}n and Sussman, Elyse and Tervaniemi, Mari and Horv\'{a}th, J\'{a}nos and Ritter, Walter and N\"{a}\"{a}t\"{a}nen, Risto},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler et al/Winkler et al. - 2003 - Preattentive auditory context effects. - Cognitive, affective \& behavioral neuroscience.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective \& behavioral neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: psychology,Adolescent,Adult,Attention,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Pitch Discrimination,Pitch Discrimination: physiology,Reference Values},
month = mar,
number = {1},
pages = {57--77},
pmid = {12822599},
title = {{Preattentive auditory context effects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12822599},
volume = {3},
year = {2003}
}
@article{Piazza2013,
abstract = {In vision, humans use summary statistics (e.g., the average facial expression of a crowd) to efficiently perceive the gist of groups of features. Here, we present direct evidence that ensemble coding is also important for auditory processing. We found that listeners could accurately estimate the mean frequency of a set of logarithmically spaced pure tones presented in a temporal sequence (Experiment 1). Their performance was severely reduced when only a subset of tones from a given sequence was presented (Experiment 2), which demonstrates that ensemble coding is based on a substantial number of the tones in a sequence. This precise ensemble coding occurred despite very limited representation of individual tones from the sequence: Listeners were poor at identifying specific individual member tones (Experiment 3) and at determining their positions in the sequence (Experiment 4). Together, these results indicate that summary statistical coding is not limited to visual processing and is an important auditory mechanism for extracting ensemble frequency information from sequences of sounds.},
author = {Piazza, Elise a and Sweeny, Timothy D and Wessel, David and Silver, Michael a and Whitney, David},
doi = {10.1177/0956797612473759},
file = {:Users/pkmital/Documents/Mendeley Desktop/Piazza et al/Piazza et al. - 2013 - Humans Use Summary Statistics to Perceive Auditory Sequences. - Psychological science.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {12,26,5,auditory perception,ensemble coding,frequency,humans frequently encounter ensembles,or groups of,perception,received 2,revision accepted 11,statistical summary,visual perception},
month = jun,
pmid = {23761928},
title = {{Humans Use Summary Statistics to Perceive Auditory Sequences.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23761928},
year = {2013}
}
@inproceedings{VandenDoel2004,
abstract = {A physically based liquid sound synthesis methodology is developed. The fundamental mechanism for the produc- tion of liquid sounds is identified as the acoustic emission of bubbles. After reviewing the physics of vibrating bubbles as it is relevant to audio synthesis, a sound model for iso- lated single bubbles is developed and validated with a small user study. A stochastic model for the real-time interac- tive synthesis of complex liquid sounds such as produced by streams, pouring water, rivers, rain, and breaking waves is based on the synthesis of single bubble sounds. It is shown how realistic complex high dimensional sound spaces can be synthesized in this manner.},
author = {van den Doel, Kees},
booktitle = {Proceedings of ICAD 04 - Tenth Meeting of the International Conference on Auditory Display.},
file = {::},
pages = {1--8},
title = {{Physically-based Models for Liquid Sounds}},
year = {2004}
}
@article{Broll2008a,
author = {Broll, Wolfgang and Lindt, Irma and Herbst, Iris and Ohlenburg, Jan and Braun, Anne-kathrin and Wetzel, Richard},
file = {::},
journal = {Advances},
title = {{Toward Next-Gen Mobile AR Games}},
year = {2008}
}
@article{Dobashi2003,
author = {Dobashi, Yoshinori and Yamamoto, Tsuyoshi and Nishita, Tomoyuki},
doi = {10.1145/882262.882339},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {--------------------------------------------------,aerodynamic sound,animation,computational fluid dynamics,simulation,sound synthesis},
month = jul,
number = {3},
pages = {732},
title = {{Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics}},
url = {http://portal.acm.org/citation.cfm?doid=882262.882339},
volume = {22},
year = {2003}
}
@article{Raj2005,
abstract = {The human visual system combines a wide field of view with a high-resolution fovea and uses eye, head, and body movements to direct the fovea to potentially relevant locations in the visual scene. This strategy is sensible for a visual system with limited neural resources. However, for this strategy to be effective, the visual system needs sophisticated central mechanisms that efficiently exploit the varying spatial resolution of the retina. To gain insight into some of the design requirements of these central mechanisms, we have analyzed the effects of variable spatial resolution on local contrast in 300 calibrated natural images. Specifically, for each retinal eccentricity (which produces a certain effective level of blur), and for each value of local contrast observed at that eccentricity, we measured the probability distribution of the local contrast in the unblurred image. These conditional probability distributions can be regarded as posterior probability distributions for the "true" unblurred contrast, given an observed contrast at a given eccentricity. We find that these conditional probability distributions are adequately described by a few simple formulas. To explore how these statistics might be exploited by central perceptual mechanisms, we consider the task of selecting successive fixation points, where the goal on each fixation is to maximize total contrast information gained about the image (i.e., minimize total contrast uncertainty). We derive an entropy minimization algorithm and find that it performs optimally at reducing total contrast uncertainty and that it also works well at reducing the mean squared error between the original image and the image reconstructed from the multiple fixations. Our results show that measurements of local contrast alone could efficiently drive the scan paths of the eye when the goal is to gain as much information about the spatial structure of a scene as possible.},
author = {Raj, Raghu and Geisler, Wilson S and Frazor, Robert a and Bovik, Alan C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Raj et al/Raj et al. - 2005 - Contrast statistics for foveated visual systems fixation selection by minimizing contrast entropy. - Journal of the Optical Society of America. A, Optics, image science, and vision.pdf:pdf},
issn = {1084-7529},
journal = {Journal of the Optical Society of America. A, Optics, image science, and vision},
keywords = {Algorithms,Computer Simulation,Contrast Sensitivity,Contrast Sensitivity: physiology,Entropy,Fixation, Ocular,Fixation, Ocular: physiology,Fovea Centralis,Fovea Centralis: physiology,Humans,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Models, Biological,Models, Statistical,Visual Perception,Visual Perception: physiology},
month = oct,
number = {10},
pages = {2039--49},
pmid = {16277275},
title = {{Contrast statistics for foveated visual systems: fixation selection by minimizing contrast entropy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16277275},
volume = {22},
year = {2005}
}
@article{Hand2009,
author = {Hand, David J.},
doi = {10.1007/s10994-009-5119-5},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hand/Hand - 2009 - Measuring classifier performance a coherent alternative to the area under the ROC curve - Machine Learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {auc,classification,cost,error rate,loss,misclassification,rate,roc curves,sensitivity,specificity},
month = jun,
number = {1},
pages = {103--123},
title = {{Measuring classifier performance: a coherent alternative to the area under the ROC curve}},
url = {http://www.springerlink.com/index/10.1007/s10994-009-5119-5},
volume = {77},
year = {2009}
}
@article{Brady2011,
abstract = {Influential models of visual working memory treat each item to be stored as an independent unit and assume that there are no interactions between items. However, real-world displays have structure that provides higher-order constraints on the items to be remembered. Even in the case of a display of simple colored circles, observers can compute statistics, such as mean circle size, to obtain an overall summary of the display. We examined the influence of such an ensemble statistic on visual working memory. We report evidence that the remembered size of each individual item in a display is biased toward the mean size of the set of items in the same color and the mean size of all items in the display. This suggests that visual working memory is constructive, encoding displays at multiple levels of abstraction and integrating across these levels, rather than maintaining a veridical representation of each item independently.},
author = {Brady, Timothy F and Alvarez, George a},
doi = {10.1177/0956797610397956},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brady, Alvarez/Brady, Alvarez - 2011 - Hierarchical encoding in visual working memory ensemble statistics bias memory for individual items. - Psycholog.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {Attention,Color Perception,Concept Formation,Generalization, Stimulus,Humans,Memory, Short-Term,Models, Psychological,Models, Statistical,Orientation,Pattern Recognition, Visual,Retention (Psychology),Size Perception},
month = mar,
number = {3},
pages = {384--92},
pmid = {21296808},
title = {{Hierarchical encoding in visual working memory: ensemble statistics bias memory for individual items.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21296808},
volume = {22},
year = {2011}
}
@article{Rosenblueth1943,
author = {Rosenblueth, Arturo and Wiener, Norbert and Bigelow, Julian},
doi = {10.1086/286788},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rosenblueth, Wiener, Bigelow/Rosenblueth, Wiener, Bigelow - 1943 - Behavior, Purpose and Teleology - Philosophy of Science.pdf:pdf},
issn = {0031-8248},
journal = {Philosophy of Science},
month = jan,
number = {1},
pages = {18},
title = {{Behavior, Purpose and Teleology}},
url = {http://www.journals.uchicago.edu/doi/abs/10.1086/286788},
volume = {10},
year = {1943}
}
@article{Prinz2007a,
author = {Prinz, Jesse J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prinz/Prinz - 2007 - When is Film Art - Most.pdf:pdf},
journal = {Most},
pages = {1--10},
title = {{When is Film Art ?}},
year = {2007}
}
@article{Nurminen2008c,
author = {Nurminen, Antti},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {20--31},
title = {{Mobile 3D City Maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557952},
volume = {28},
year = {2008}
}
@article{Hurlbert2003,
abstract = {New results have revealed that neurons in visual area V1 are influenced by chromatic context, in a way consistent with colour constancy. Other studies have mapped the internal cone-input structure of V1 receptive fields. Put together, these findings suggest important dual roles for V1 in colour perception.},
author = {Hurlbert, Anya},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hurlbert/Hurlbert - 2003 - Colour vision primary visual cortex shows its influence. - Current biology CB.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Animals,Color Perception,Color Perception: physiology,Macaca,Macaca: physiology,Retinal Cone Photoreceptor Cells,Retinal Cone Photoreceptor Cells: physiology,Visual Cortex,Visual Cortex: physiology},
month = apr,
number = {7},
pages = {R270--2},
pmid = {12676104},
title = {{Colour vision: primary visual cortex shows its influence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12676104},
volume = {13},
year = {2003}
}
@inproceedings{Farnell2007a,
author = {Farnell, Andy},
booktitle = {Audio Mostly Conference},
file = {::},
number = {September},
pages = {1--31},
title = {{An introduction to procedural audio and its application in computer games}},
url = {http://obiwannabe.co.uk/html/papers/proc-audio/proc-audio.pdf},
year = {2007}
}
@article{Hansen2006,
author = {Hansen, Frank Allan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hansen/Hansen - 2006 - Ubiquitous Annotation Systems Technologies and Challenges - Challenges.pdf:pdf},
journal = {Challenges},
keywords = {and as communication,annotation,as,computing,context-aware computing,glance while marginalia and,mobile,personal discussions,reminders,sketches have been used,ubiquitous hypermedia},
title = {{Ubiquitous Annotation Systems : Technologies and Challenges}},
year = {2006}
}
@article{Rosenholtz1999,
author = {Rosenholtz, Ruth},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rosenholtz/Rosenholtz - 1999 - Rapid communication A simple saliency model predicts a number of motion popout phenomena - Vision Research.pdf:pdf},
journal = {Vision Research},
keywords = {distractor velocity,linear separability,motion search,popout phenomena,stationary target},
pages = {3157--3163},
title = {{Rapid communication A simple saliency model predicts a number of motion popout phenomena}},
volume = {39},
year = {1999}
}
@article{Zhang2006,
abstract = {This work investigated the role of cognitive control functions in selective attention when task-relevant and -irrelevant stimuli come from different sensory modalities. We parametrically manipulated the load of an attentive tracking task and investigated its effect on irrelevant acoustic change-related processing. While subjects were performing the visual attentive tracking task, event-related potentials (ERPs) were recorded for frequent standard tones and rare deviant tones presented as auditory distractors. The deviant tones elicited two change-related ERP components: the mismatch negativity (MMN) and the P3a. The amplitude of the MMN, which indexes the early detection of irregular changes, increased with increasing attentional load, whereas the subsequent P3a component, which indicates the involuntary orienting of attention to deviants, was significant only in the lowest load condition. These findings suggest that active exclusion of the early detection process of irrelevant acoustic changes depends on available resources of cognitive control, whereas the late involuntary orienting of attention to deviants can be passively suppressed by high demand on central attentional resources. The present study thus reveals opposing visual attentional load effects at different temporal and functional stages in the rejection of deviant auditory distractors and provides a new perspective on the resolution of the long-standing early versus late attention selection debate.},
author = {Zhang, Peng and Chen, Xiangchuan and Yuan, Peng and Zhang, Daren and He, Sheng},
doi = {10.1016/j.neuroimage.2006.07.015},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang et al/Zhang et al. - 2006 - The effect of visuospatial attentional load on the processing of irrelevant acoustic distractors. - NeuroImage.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adult,Attention,Brain Mapping,Evoked Potentials,Evoked Potentials, Visual,Female,Humans,Male,Photic Stimulation,Psychomotor Performance,Reaction Time,Reference Values,Signal Detection, Psychological,Space Perception,Visual Perception},
month = dec,
number = {2},
pages = {715--24},
pmid = {16956775},
title = {{The effect of visuospatial attentional load on the processing of irrelevant acoustic distractors.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16956775},
volume = {33},
year = {2006}
}
@article{Menzies2007,
abstract = {Exterior expansions of complex sound sources are presented as flexible objects for producing Ambisonic soundfield encodings. The sources can be synthesized or recorded directly, rotated and positioned in space. Related techniques can also be used to efficiently add high quality reverberation depending on the orientation and location of the source and listener.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--28},
title = {{Ambisonic Synthesis of Complex Sources}},
year = {2007}
}
@inproceedings{James2006,
author = {James, D.L. and Barbi\v{c}, J. and Pai, D.K.},
booktitle = {ACM Transactions on Graphics (TOG)},
file = {::},
isbn = {1595933646},
issn = {0730-0301},
keywords = {acoustic radiation,boundary element method,equiva-,helmholtz,lent sources,modal vibration,multipole,sound synthesis,source simulation,trefftz},
number = {3},
pages = {987--995},
publisher = {ACM},
title = {{Precomputed Acoustic Transfer : Output-sensitive , accurate sound generation for geometrically complex vibration sources}},
url = {http://portal.acm.org/citation.cfm?id=1141983},
volume = {25},
year = {2006}
}
@article{Ozg2005,
author = {\"{O}zg\"{u}r, A and \"{O}zg\"{u}r, L and G\"{u}ng\"{o}r, T},
file = {:Users/pkmital/Documents/Mendeley Desktop/\"{O}zg\"{u}r, \"{O}zg\"{u}r, G\"{u}ng\"{o}r/\"{O}zg\"{u}r, \"{O}zg\"{u}r, G\"{u}ng\"{o}r - 2005 - Text categorization with class-based and corpus-based keyword selection - Computer and Information.pdf:pdf},
journal = {Computer and Information Sciences-ISCIS \ldots},
keywords = {a single set of,all,approaches for keyword selection,in corpus-based approach,in terms,instead of all words,keywords is selected for,of accuracy and time,selection metrics,that focus on keyword,unlike the previous studies,we compare the two,yields better performance both},
pages = {606--615},
title = {{Text categorization with class-based and corpus-based keyword selection}},
url = {http://www.springerlink.com/index/y7548844p838924k.pdf},
year = {2005}
}
@article{Koch1994,
author = {Koch, R},
doi = {10.1016/0924-2716(94)90021-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Koch/Koch - 1994 - Model-based 3-D scene analysis from stereoscopic image sequences - ISPRS Journal of Photogrammetry and Remote Sensing.pdf:pdf},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
month = oct,
number = {5},
pages = {23--30},
title = {{Model-based 3-D scene analysis from stereoscopic image sequences}},
volume = {49},
year = {1994}
}
@article{Riesenhuber1999,
abstract = {Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function.},
author = {Riesenhuber, M and Poggio, T},
doi = {10.1038/14819},
file = {:Users/pkmital/Documents/Mendeley Desktop/Riesenhuber, Poggio/Riesenhuber, Poggio - 1999 - Hierarchical models of object recognition in cortex. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Computer Simulation,Form Perception,Form Perception: physiology,Macaca,Mental Recall,Mental Recall: physiology,Models, Neurological,Neurons,Neurons: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology},
month = nov,
number = {11},
pages = {1019--25},
pmid = {10526343},
title = {{Hierarchical models of object recognition in cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10526343},
volume = {2},
year = {1999}
}
@article{Bergeron2003,
abstract = {The superior colliculus (SC) is important for generating coordinated eye-head gaze saccades. Its deeper layers contain a retinotopically organized motor map in which each site is thought to encode a specific gaze saccade vector. Here we show that this fundamental assumption in current models of collicular function does not hold true during horizontal multi-step gaze shifts in darkness that are directed to a goal and composed of a sequence of gaze saccades separated by periods of steady fixation. At the start of a multi-step gaze shift in cats, neural activity on the SC's map was located caudally to encode the overall amplitude of the gaze displacement, not the first saccade in the sequence. As the gaze shift progressed, the locus of activity moved to encode the error between the goal and the current gaze position. Contrary to common belief, the locus of activity never encoded gaze saccade amplitude, except for the last saccade in the sequence.},
author = {Bergeron, Andr\'{e} and Matsuo, Satoshi and Guitton, Daniel},
doi = {10.1038/nn1027},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bergeron, Matsuo, Guitton/Bergeron, Matsuo, Guitton - 2003 - Superior colliculus encodes distance to target, not saccade amplitude, in multi-step gaze shifts. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cats,Dark Adaptation,Dark Adaptation: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Models, Neurological,Neurons,Neurons: cytology,Neurons: physiology,Normal Distribution,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Saccades,Saccades: physiology,Superior Colliculi,Superior Colliculi: cytology,Superior Colliculi: physiology},
month = apr,
number = {4},
pages = {404--13},
pmid = {12627166},
title = {{Superior colliculus encodes distance to target, not saccade amplitude, in multi-step gaze shifts.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12627166},
volume = {6},
year = {2003}
}
@article{Witten2005a,
author = {Witten, Ilana B and Knudsen, Eric I},
doi = {10.1016/j.neuron.2005.10.020},
file = {:Users/pkmital/Documents/Mendeley Desktop/Witten, Knudsen/Witten, Knudsen - 2005 - Why Seeing Is Believing Merging Auditory and Visual Worlds - Review Literature And Arts Of The Americas.pdf:pdf},
journal = {Review Literature And Arts Of The Americas},
pages = {489--496},
title = {{Why Seeing Is Believing : Merging Auditory and Visual Worlds}},
volume = {48},
year = {2005}
}
@article{Coding2000,
author = {Coding, Weak Variable-length Slepian-wolf},
file = {:Users/pkmital/Documents/Mendeley Desktop/Coding/Coding - 2000 - Advisor Professor Tomohiko UYEMATSU - System.pdf:pdf},
journal = {System},
number = {February},
title = {{Advisor : Professor Tomohiko UYEMATSU}},
year = {2000}
}
@article{Boucher2007,
abstract = {The stop-signal task has been used to study normal cognitive control and clinical dysfunction. Its utility is derived from a race model that accounts for performance and provides an estimate of the time it takes to stop a movement. This model posits a race between go and stop processes with stochastically independent finish times. However, neurophysiological studies demonstrate that the neural correlates of the go and stop processes produce movements through a network of interacting neurons. The juxtaposition of the computational model with the neural data exposes a paradox-how can a network of interacting units produce behavior that appears to be the outcome of an independent race? The authors report how a simple, competitive network can solve this paradox and provide an account of what is measured by stop-signal reaction time.},
author = {Boucher, Leanne and Palmeri, Thomas J and Logan, Gordon D and Schall, Jeffrey D},
doi = {10.1037/0033-295X.114.2.376},
file = {:Users/pkmital/Documents/Mendeley Desktop/Boucher et al/Boucher et al. - 2007 - Inhibitory control in mind and brain an interactive race model of countermanding saccades. - Psychological review.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Brain,Brain: physiology,Cognition,Humans,Inhibition (Psychology),Saccades,Saccades: physiology,Signal Detection, Psychological,Stochastic Processes},
month = apr,
number = {2},
pages = {376--97},
pmid = {17500631},
title = {{Inhibitory control in mind and brain: an interactive race model of countermanding saccades.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17500631},
volume = {114},
year = {2007}
}
@article{Sussman2007,
author = {Sussman, Elyse S.},
doi = {10.1027/0269-8803.21.34.164},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sussman/Sussman - 2007 - A New View on the MMN and Attention Debate - Journal of Psychophysiology.pdf:pdf},
issn = {0269-8803},
journal = {Journal of Psychophysiology},
keywords = {attention,auditory,context,erps,mmn,preattentive},
month = jan,
number = {3},
pages = {164--175},
title = {{A New View on the MMN and Attention Debate}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/0269-8803.21.34.164},
volume = {21},
year = {2007}
}
@article{Bach2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0812.1869v1},
author = {Bach, Francis and Mairal, Julien and Ponce, Jean},
eprint = {arXiv:0812.1869v1},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bach, Mairal, Ponce/Bach, Mairal, Ponce - 2008 - Convex sparse matrix factorizations - Arxiv preprint arXiv0812.1869.pdf:pdf},
journal = {Arxiv preprint arXiv:0812.1869},
pages = {1--12},
title = {{Convex sparse matrix factorizations}},
url = {http://arxiv.org/abs/0812.1869},
year = {2008}
}
@article{Kosslyn2003,
author = {Kosslyn, Stephen M},
doi = {10.1038/nn1103-1124},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kosslyn/Kosslyn - 2003 - Understanding the mind's eye...and nose. - Nature neuroscience.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Auditory Perception,Auditory Perception: physiology,Comprehension,Eye,Humans,Imagination,Imagination: physiology,Mental Processes,Mental Processes: physiology,Nose,Nose: physiology,Odors,Visual Perception,Visual Perception: physiology},
month = nov,
number = {11},
pages = {1124--5},
pmid = {14583751},
title = {{Understanding the mind's eye...and nose.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14583751},
volume = {6},
year = {2003}
}
@article{Trapp2012,
abstract = {Within recent years, researchers have proposed the independence of attention and consciousness on both empirical and conceptual grounds. However, the elusive nature of these constructs complicates progress in the investigation of their interaction. We present a framework within which we conceptualize attention and consciousness in computational terms. Here, the concepts are consi-dered as large-scale, functionally and structurally different processes, embedded in a biologically inspired architecture, spanning the full arc from stimulus to response. Our architecture assumes a general independence of attention and consciousness, but supposes strong interactions. Furthermore, it addresses the developmental aspect, stressing that these functions have to gradually develop through learning.},
author = {Trapp, Sabrina and Schroll, Henning and Hamker, Fred H},
doi = {10.2478/v10053-008-0096-y},
file = {:Users/pkmital/Documents/Mendeley Desktop/Trapp, Schroll, Hamker/Trapp, Schroll, Hamker - 2012 - Open and closed loops A computational approach to attention and consciousness. - Advances in cognitive p.pdf:pdf},
issn = {1895-1171},
journal = {Advances in cognitive psychology / University of Finance and Management in Warsaw},
keywords = {attention,consciousness},
month = jan,
number = {1},
pages = {1--8},
pmid = {23853675},
title = {{Open and closed loops: A computational approach to attention and consciousness.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3709102\&tool=pmcentrez\&rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Hohnsbein1991,
abstract = {We studied several effects of dividing attention between visual and acoustic inputs on different processing stages. Simple and choice responses were required to single letter stimuli. RTs and P300 latencies were delayed for divided attention (variable stimulus modality) as compared to focused attention (constant stimulus modality). In all but one condition, RT and P300 delays were similar. The exception was choice tasks to auditory stimuli, in which the RT delay was far larger than the P300 delay. Since the amplitude of the late ERP was larger in choice tasks than in simple tasks, the differences between the ERPs of choice and simple tasks were computed. They revealed that an additional late positive wave ("P-CR") occurred in all choice ERPs. In the divided attention condition the auditory (but not the visual) P-CR showed a longer delay compared to focused attention. We interpret the P-CR to be time-related to the response selection process. Our results suggest that the division of attention causes a slight impairment of stimulus evaluation (shown in P300 latency) and, after auditory stimuli only, a strong impairment of response selection (shown in P-CR latency). We therefore conclude that the observed RT effects are due to a bias of processing resources towards the visual modality, which mainly affects response selection. The results are in accordance with the theory of visual dominance.},
author = {Hohnsbein, J and Falkenstein, M and Hoormann, J and Blanke, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hohnsbein et al/Hohnsbein et al. - 1991 - Effects of crossmodal divided attention on late ERP components. I. Simple and choice reaction tasks. - Electroencephalography and clinical neurophysiology.pdf:pdf},
issn = {0013-4694},
journal = {Electroencephalography and clinical neurophysiology},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Brain,Brain: physiology,Choice Behavior,Choice Behavior: physiology,Electroencephalography,Evoked Potentials,Female,Humans,Male,Reaction Time,Reaction Time: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {6},
pages = {438--46},
pmid = {1712279},
title = {{Effects of crossmodal divided attention on late ERP components. I. Simple and choice reaction tasks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1712279},
volume = {78},
year = {1991}
}
@misc{Mital2011b,
author = {Mital, Parag K},
booktitle = {(video)},
title = {{Dimensions}},
url = {http://vimeo.com/30095044},
urldate = {1 May 2012},
year = {2011}
}
@article{Hayhoe2005,
abstract = {The classic experiments of Yarbus over 50 years ago revealed that saccadic eye movements reflect cognitive processes. But it is only recently that three separate advances have greatly expanded our understanding of the intricate role of eye movements in cognitive function. The first is the demonstration of the pervasive role of the task in guiding where and when to fixate. The second has been the recognition of the role of internal reward in guiding eye and body movements, revealed especially in neurophysiological studies. The third important advance has been the theoretical developments in the fields of reinforcement learning and graphic simulation. All of these advances are proving crucial for understanding how behavioral programs control the selection of visual information.},
author = {Hayhoe, Mary and Ballard, Dana},
doi = {10.1016/j.tics.2005.02.009},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hayhoe, Ballard/Hayhoe, Ballard - 2005 - Eye movements in natural behavior. - Trends in cognitive sciences.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Behavior,Behavior: physiology,Cognition,Cognition: physiology,Eye Movements,Eye Movements: physiology,Humans,Monitoring, Ambulatory,Monitoring, Ambulatory: instrumentation,Monitoring, Ambulatory: methods,Vision, Ocular,Vision, Ocular: physiology},
month = apr,
number = {4},
pages = {188--94},
pmid = {15808501},
title = {{Eye movements in natural behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15808501},
volume = {9},
year = {2005}
}
@inproceedings{Livingstone2005,
author = {Livingstone, S. and Brown, A.},
booktitle = {Australasian Conference On Interactive Entertainment},
file = {::},
keywords = {and film scoring having,computer games,computer music,emotion,matured into the essential,plays,role that it now,story-telling,the current generation of},
pages = {105--111},
title = {{Dynamic response: real-time adaptation for music emotion}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=rhKGK\_c7T70C\&amp;oi=fnd\&amp;pg=PA105\&amp;dq=Dynamic+Response+:+Real-Time+Adaptation+for+Music+Emotion\&amp;ots=kyH58b-ddK\&amp;sig=OoEHYuihKRMeRPDFZA17gHnScd4},
volume = {2},
year = {2005}
}
@inproceedings{Mesaros2010,
author = {Mesaros, Annamaria and Heittola, Toni and Eronen, Antti and Virtanen, Tuomas},
booktitle = {18th European Signal Processing Conference},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mesaros et al/Mesaros et al. - 2010 - Acoustic event detection in real-life recordings - 18th European Signal Processing Conference.pdf:pdf},
title = {{Acoustic event detection in real-life recordings}},
url = {http://www.eurasip.org/Proceedings/Eusipco/Eusipco2010/Contents/papers/1569292627.pdf},
year = {2010}
}
@inproceedings{Pati1993,
address = {Pacific Grove, CA},
author = {Pati, Y and Rezaiifar, R and Krishnaprasad, P},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pati, Rezaiifar, Krishnaprasad/Pati, Rezaiifar, Krishnaprasad - 1993 - Orthogonal Matching Pursuit Recursive Function Approximation with Applications to Wavelet Decomp.pdf:pdf},
keywords = {MP},
pages = {40--44},
title = {{Orthogonal Matching Pursuit: Recursive Function Approximation with Applications to Wavelet Decomposition}},
volume = {1},
year = {1993}
}
@article{Ahlberg1995,
author = {Ahlberg, Christopher and Wistrand, Erik},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ahlberg, Wistrand/Ahlberg, Wistrand - 1995 - IVEE An Information Visualization \& Exploration Environment Exploration Environment - Proceedings of IEEE Viz.pdf:pdf},
journal = {Proceedings of IEEE Viz'95},
title = {{IVEE: An Information Visualization \& Exploration Environment Exploration Environment}},
year = {1995}
}
@misc{Mital2011e,
author = {Mital, Parag K},
booktitle = {(audio)},
title = {{Michael Jackson's Beat It w/ Resynthesized Audio using Chris Watson}},
url = {http://vimeo.com/30484820},
urldate = {1 May 2012},
year = {2011}
}
@article{Gribonval2001b,
author = {Gribonval, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gribonval/Gribonval - 2001 - Fast matching pursuit with a multiscale dictionary of Gaussian chirps - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
month = may,
number = {5},
pages = {994--1001},
title = {{Fast matching pursuit with a multiscale dictionary of Gaussian chirps}},
volume = {49},
year = {2001}
}
@article{Wang2006a,
author = {Wang, Avery},
file = {:Users/pkmital/Documents/Mendeley Desktop/Wang/Wang - 2006 - The Shazam Music Recognition Service - Communications of the ACM.pdf:pdf},
journal = {Communications of the ACM},
number = {8},
title = {{The Shazam Music Recognition Service}},
volume = {49},
year = {2006}
}
@article{Klier2001,
author = {Klier, EM and Wang, Hongying and Crawford, JD},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klier, Wang, Crawford/Klier, Wang, Crawford - 2001 - The superior colliculus encodes gaze commands in retinal coordinates - Nature neuroscience.pdf:pdf},
journal = {Nature neuroscience},
pages = {627--632},
title = {{The superior colliculus encodes gaze commands in retinal coordinates}},
url = {http://www.nature.com/neuro/journal/v4/n6/abs/nn0601\_627.html},
year = {2001}
}
@article{Bentley2013,
author = {Bentley, Peter J and Paolo, Ezequiel Di and Edmonds, Ernest and Giannachi, Gabriella and Hall, Gary and Harris, Craig and Irzık, Sibel and Jirotka, Marina and Lotto, Beau and Malina, Roger and Masson, Terrence and Mccormack, Jon and Nash, Mark and Norman, Sally Jane and Penny, Simon and Prophet, Jane and Shaw, Jeffrey},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bentley et al/Bentley et al. - 2013 - Not Here Not There - Leonardo Electronic Alamanac.pdf:pdf},
isbn = {9781906897239},
journal = {Leonardo Electronic Alamanac},
number = {2},
pages = {2--7},
title = {{Not Here Not There}},
volume = {19},
year = {2013}
}
@article{Campbell2007,
abstract = {Event-related potentials (ERPs) were recorded for ignored tones presented during the retention interval of a delayed serial recall task. The mismatch negativity (MMN) and N1 ERP components were measured to discern spatiotemporal and functional properties of their generation. A nine-token sequence with nine different tone pitches was more disruptive than an oddball (two-token) sequence, yet this oddball sequence was no more disruptive than a single repeating tone (one-token). Tones of the nine-token sequence elicited augmented N1 amplitudes compared to identical tones delivered in the one-token sequence, yet deviants elicited an additional component (MMN) with distinct temporal properties and topography. These results suggested that MMN and N1 are separate, functionally distinct components. Implications are discussed for the N1 hypothesis and the changing-state hypothesis of the disruption of serial recall performance by auditory distraction.},
author = {Campbell, Tom and Winkler, Istv\'{a}n and Kujala, Teija},
doi = {10.1111/j.1469-8986.2007.00529.x},
issn = {0048-5772},
journal = {Psychophysiology},
keywords = {Acoustic Stimulation,Adult,Attention,Attention: physiology,Electroencephalography,Evoked Potentials,Evoked Potentials: physiology,Female,Humans,Male,Memory,Memory: physiology,Mental Recall,Mental Recall: physiology},
month = jul,
number = {4},
pages = {530--40},
pmid = {17532805},
title = {{N1 and the mismatch negativity are spatiotemporally distinct ERP components: disruption of immediate memory by auditory distraction can be related to N1.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17532805},
volume = {44},
year = {2007}
}
@article{Leung,
author = {Leung, Clement and Kimura, Akisato and Takeuchi, Tatsuto and Kashino, Kunio},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leung et al/Leung et al. - Unknown - for the salient region extraction of videos • We use the strategy of focusing on more relevant regions and - Science.pdf:pdf},
journal = {Science},
pages = {1--9},
title = {{for the salient region extraction of videos • We use the strategy of focusing on more relevant regions and}}
}
@article{Port1995,
author = {Port, RF},
file = {:Users/pkmital/Documents/Mendeley Desktop/Port/Port - 1995 - Explorations in the dynamics of cognition Mind as motion - Most.pdf:pdf},
journal = {Most},
title = {{Explorations in the dynamics of cognition: Mind as motion}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Explorations+in+the+Dynamics+of+Cognition.+Mind+as+Motion\#2},
year = {1995}
}
@article{Sutton1965,
author = {Sutton, S and Braren, M and Zubin, Joseph and John, ER},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sutton et al/Sutton et al. - 1965 - Evoked-potential correlates of stimulus uncertainty - Science.pdf:pdf},
journal = {Science},
title = {{Evoked-potential correlates of stimulus uncertainty}},
url = {http://www.sciencemag.org/content/150/3700/1187.short},
year = {1965}
}
@book{Breton1969,
abstract = {Andre Breton discusses the meaning, aims, and political position of the Surrealist movement},
author = {Breton, Andr\'{e}},
isbn = {0472061828},
pages = {304},
publisher = {University of Michigan Press},
title = {{Manifestoes of Surrealism}},
url = {http://books.google.co.uk/books/about/Manifestes\_Du\_Surr\'{e}alisme.html?id=12TuC9IkxKIC\&pgis=1},
year = {1969}
}
@article{Weller2009,
author = {Weller, Adrian and Ellis, Daniel and Jebara, Tony},
doi = {10.1109/ICMLA.2009.132},
file = {:Users/pkmital/Documents/Mendeley Desktop/Weller, Ellis, Jebara/Weller, Ellis, Jebara - 2009 - Structured Prediction Models for Chord Transcription of Music Audio - 2009 International Conference on Machine Learning and Applications.pdf:pdf},
isbn = {978-0-7695-3926-3},
journal = {2009 International Conference on Machine Learning and Applications},
month = dec,
pages = {590--595},
publisher = {Ieee},
title = {{Structured Prediction Models for Chord Transcription of Music Audio}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5381404},
year = {2009}
}
@article{Sestieri2010,
abstract = {Posterior parietal cortex has been traditionally associated with perceptual attention and sensory-motor processing, but recent studies also indicate a potential role in episodic memory retrieval. Here, we developed a new paradigm to isolate top-down attention-related activity directed to either memory or perceptual information. We demonstrated a robust topographic separation in human posterior parietal cortex associated with searching for task-relevant information in episodic memory or in the environment. Control analyses confirmed that this difference was not dependent on differences in sensory stimulation or eye movements across tasks. Notably, we observed in memory- and perception-related regions a mechanism of reciprocal dynamic competition that was related to behavioral performance. These results provide the first evidence for a double dissociation between parietal networks involved in top-down attention to memory and the environment and support the idea of neural competition between perception and memory.},
author = {Sestieri, C. and Shulman, G. L. and Corbetta, M.},
doi = {10.1523/JNEUROSCI.4719-09.2010},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sestieri, Shulman, Corbetta/Sestieri, Shulman, Corbetta - 2010 - Attention to Memory and the Environment Functional Specialization and Dynamic Competition in Human Posterior Parietal Cortex - Journal of Neuroscience.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Adult,Analysis of Variance,Attention,Attention: physiology,Brain Mapping,Environment,Female,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Mental Recall,Mental Recall: physiology,Parietal Lobe,Parietal Lobe: physiology,Reaction Time,Reaction Time: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {25},
pages = {8445--8456},
pmid = {20573892},
title = {{Attention to Memory and the Environment: Functional Specialization and Dynamic Competition in Human Posterior Parietal Cortex}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2906749\&tool=pmcentrez\&rendertype=abstract},
volume = {30},
year = {2010}
}
@article{Loy2003,
author = {Loy, G. and Zelinsky, a.},
doi = {10.1109/TPAMI.2003.1217601},
file = {:Users/pkmital/Documents/Mendeley Desktop/Loy, Zelinsky/Loy, Zelinsky - 2003 - Fast radial symmetry for detecting points of interest - IEEE Transactions on Pattern Analysis and Machine Intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = aug,
number = {8},
pages = {959--973},
title = {{Fast radial symmetry for detecting points of interest}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1217601},
volume = {25},
year = {2003}
}
@article{Leung2007b,
author = {Leung, Clement and Kimura, Akisato and Takeuchi, Tatsuto and Kashino, Kunio},
doi = {10.1109/ICME.2007.4284646},
file = {:Users/pkmital/Documents/Mendeley Desktop/Leung et al/Leung et al. - 2007 - A Computational Model of Saliency DepletionRecovery Phenomena for the Salient Region Extraction of Videos - Multim.pdf:pdf},
isbn = {1-4244-1016-9},
journal = {Multimedia and Expo, 2007 IEEE International Conference on},
month = jul,
pages = {300--303},
publisher = {Ieee},
title = {{A Computational Model of Saliency Depletion/Recovery Phenomena for the Salient Region Extraction of Videos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4284646},
year = {2007}
}
@article{Kidmose2010,
abstract = {This paper presents an analysis of the merits of the original Yarbus experiment on eye movements with respect to judgments on differences in cognitive layer processes. The principles thus derived are applied to the development of an equivalent auditory experiment where, instead of eye movements, the response of the subject is observed by EEG measurements. Results from a preliminary trial are also included in which EEG analysis is used to ascertain the attended sound source in a multiple sound source environment. The investigation is part of ongoing research to improve the usefulness of hearing instruments and is also relevant in relation to other scientific investigations concerning the processing of sounds in complex acoustical environments by the human brain.},
author = {Kidmose, P and Rank, M L and Ungstrup, M and Looney, D and Park, C and Mandic, D P},
doi = {10.1109/IEMBS.2010.5626441},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kidmose et al/Kidmose et al. - 2010 - A Yarbus-style experiment to determine auditory attention. - Conference proceedings ... Annual International Co.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Algorithms,Attention,Attention: physiology,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Research Design},
month = jan,
pages = {4650--3},
pmid = {21096238},
title = {{A Yarbus-style experiment to determine auditory attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21096238},
volume = {2010},
year = {2010}
}
@article{Lyon1984,
author = {Lyon, R.},
doi = {10.1109/ICASSP.1984.1172756},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lyon/Lyon - 1984 - Computational models of neural auditory processing - ICASSP '84. IEEE International Conference on Acoustics, Speech, and S.pdf:pdf},
journal = {ICASSP '84. IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {41--44},
publisher = {Institute of Electrical and Electronics Engineers},
title = {{Computational models of neural auditory processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1172756},
volume = {9},
year = {1984}
}
@article{Ni2006b,
author = {Ni, T and Schmidt, G S and Staadt, O G and Livingston, M A and Ball, R and May, R},
journal = {Virtual Reality},
title = {{A Survey of Large High-Resolution Display Technologies, Techniques, and Applications}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Survey+of+Large+High-Resolution+Display+Technologies,+Techniques,+and+Applications\#0},
year = {2006}
}
@misc{Hermann2011,
author = {Hermann, T. and Neuhoff, J. and Hunt, A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hermann, Neuhoff, Hunt/Hermann, Neuhoff, Hunt - 2011 - The Sonification Handbook - Unknown.pdf:pdf},
isbn = {9783832528195},
publisher = {Logos Verlag, Berlin, Germany},
title = {{The Sonification Handbook}},
url = {http://sonification.de/handbook/download/TheSonificationHandbook-chapter18.pdf},
year = {2011}
}
@book{Roads1996a,
author = {Roads, Curtis},
isbn = {0262680823},
pages = {1234},
publisher = {The MIT Press},
title = {{The Computer Music Tutorial}},
url = {http://www.amazon.com/Computer-Music-Tutorial-Curtis-Roads/dp/0262680823},
year = {1996}
}
@article{Fiser2002,
author = {Fiser, J\'{o}zsef and Aslin, Richard N.},
doi = {10.1037//0278-7393.28.3.458},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fiser, Aslin/Fiser, Aslin - 2002 - Statistical learning of higher-order temporal structure from visual shape sequences. - Journal of Experimental Psy.pdf:pdf},
issn = {0278-7393},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
number = {3},
pages = {458--467},
title = {{Statistical learning of higher-order temporal structure from visual shape sequences.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0278-7393.28.3.458},
volume = {28},
year = {2002}
}
@inproceedings{Bartsch2001,
abstract = {An important application for use with multimedia databases is a browsing aid, which allows a user to quickly and efficiently pre- view selections from either a database or from the results of a database query. Methods for facilitating browsing, though, are necessarily media dependent. We present one such method that produces short, representative samples (or “audio thumbnails”) of selections of popular music. This method attempts to identify the chorus or refrain of a song by identifying repeated sections of the audiowaveform. Areduced spectral representation of the selection based on a chroma transformation of the spectrum is used to find repeating patterns. This representation encodes harmonic relation- ships in a signal and thus is ideal for popular music, which is often characterized by prominent harmonic progressions. The method is evaluated over a sizable database of popular music and found to perform well, with most of the errors resulting from songs that do not meet our structural assumptions.},
author = {Bartsch, Mark A. and Wakefield, Gregory H},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
file = {:Users/pkmital/Documents/Mendeley Desktop/Avenue, Wakefield/Avenue, Wakefield - 2001 - TO CATCH A CHORUS USING CHROMA-BASED REPRESENTATIONS FOR AUDIO THUMBNAILING - IEEE Workshop on Applications.pdf:pdf},
title = {{To Catch a Chorus: Using Chroma-based Representations for Audio Thumbnailing}},
year = {2001}
}
@article{Lewis2011,
abstract = {In two experiments, we used a temporal integration task to investigate visual mental images based on information in short-term memory or generated from information stored in long-term memory (LTM). We specifically asked whether the two sorts of images rely on depictive representations. If mental images rely on depictive representations, then it should be possible to combine mental images and visual percepts into a single representation that preserves the spatial layout of the display. To demonstrate this, participants were asked to generate mental images and then combine them with visual percepts of grids that were partially filled with different numbers of dots. Participants were asked to determine which cell remained empty when the two grids were combined. We contrasted predictions of propositional or verbal description theories with those of depictive theories, and report findings that support the claim that mental images-based on either short-term or LTM-depict information.},
author = {Lewis, Katie J S and Borst, Gr\'{e}goire and Kosslyn, Stephen M},
doi = {10.1007/s00426-010-0304-5},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lewis, Borst, Kosslyn/Lewis, Borst, Kosslyn - 2011 - Integrating visual mental images and visual percepts new evidence for depictive representations. - Psycho.pdf:pdf},
issn = {1430-2772},
journal = {Psychological research},
keywords = {Adolescent,Adult,Analysis of Variance,Female,Humans,Imagination,Imagination: physiology,Male,Memory,Memory, Long-Term,Memory, Long-Term: physiology,Memory, Short-Term,Memory, Short-Term: physiology,Memory: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reaction Time,Reaction Time: physiology,Task Performance and Analysis,Young Adult},
month = jul,
number = {4},
pages = {259--71},
pmid = {20734062},
title = {{Integrating visual mental images and visual percepts: new evidence for depictive representations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20734062},
volume = {75},
year = {2011}
}
@inproceedings{Cohen2000,
author = {Cohen, MF and Shade, J and Hiller, S and Deussen, O},
booktitle = {ACM SIGGRAPH 2003 Papers},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cohen et al/Cohen et al. - 2003 - Wang tiles for image and texture generation - ACM SIGGRAPH 2003 Papers.pdf:pdf},
keywords = {non-periodic tiling,poisson distributions,texture syn-},
title = {{Wang tiles for image and texture generation}},
url = {http://dl.acm.org/citation.cfm?id=882265},
year = {2003}
}
@inproceedings{Cartwright,
author = {Cartwright, Mark and Rafii, Zafar and Han, Jinyu and Pardo, Bryan},
booktitle = {Proceedings of the 2011 AAAI Workshop on Human Computation, San Francisco, USA.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cartwright et al/Cartwright et al. - 2011 - Making searchable melodies Human vs. machine - Proceedings of the 2011 AAAI Workshop on Human Computation, Sa.pdf:pdf},
title = {{Making searchable melodies: Human vs. machine}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Making+Searchable+Melodies+:+Human+vs+.+Machine\#1},
year = {2011}
}
@article{Prenger2004,
abstract = {A key goal in the study of visual processing is to obtain a comprehensive description of the relationship between visual stimuli and neuronal responses. One way to guide the search for models is to use a general nonparametric regression algorithm, such as a neural network. We have developed a multilayer feed-forward network algorithm that can be used to characterize nonlinear stimulus-response mapping functions of neurons in primary visual cortex (area V1) using natural image stimuli. The network is capable of extracting several known V1 response properties such as: orientation and spatial frequency tuning, the spatial phase invariance of complex cells, and direction selectivity. We present details of a method for training networks and visualizing their properties. We also compare how well conventional explicit models and those developed using neural networks can predict novel responses to natural scenes.},
author = {Prenger, Ryan and Wu, Michael C-K and David, Stephen V and Gallant, Jack L},
doi = {10.1016/j.neunet.2004.03.008},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prenger et al/Prenger et al. - 2004 - Nonlinear V1 responses to natural scenes revealed by neural network analysis. - Neural networks the official jo.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Action Potentials,Algorithms,Animals,Computer Simulation,Feedback,Feedback: physiology,Humans,Models, Neurological,Neural Networks (Computer),Neurons,Neurons: physiology,Orientation,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Space Perception,Space Perception: physiology,Visual Cortex,Visual Cortex: cytology,Visual Fields},
number = {5-6},
pages = {663--79},
pmid = {15288891},
title = {{Nonlinear V1 responses to natural scenes revealed by neural network analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15288891},
volume = {17},
year = {2004}
}
@article{Yang2006,
author = {Yang, HL and Yang, CK},
file = {:Users/pkmital/Documents/Mendeley Desktop/Yang, Yang/Yang, Yang - 2006 - A Non-Photorealistic Rendering of Seurat's Pointillism - Advances in Visual Computing.pdf:pdf},
journal = {Advances in Visual Computing},
pages = {760--769},
title = {{A Non-Photorealistic Rendering of Seurat's Pointillism}},
url = {http://www.springerlink.com/index/c6716253868g8438.pdf},
year = {2006}
}
@article{Srinivasan2008,
address = {New York, New York, USA},
author = {Srinivasan, S H. and Sawant, Neela},
doi = {10.1145/1459359.1459512},
file = {:Users/pkmital/Documents/Mendeley Desktop/Srinivasan, Sawant/Srinivasan, Sawant - 2008 - Finding near-duplicate images on the web using fingerprints - Proceeding of the 16th ACM international conference on Multimedia - MM '08.pdf:pdf},
isbn = {9781605583037},
journal = {Proceeding of the 16th ACM international conference on Multimedia - MM '08},
keywords = {fourier-mellin transform,near-duplicate image detection},
pages = {881},
publisher = {ACM Press},
title = {{Finding near-duplicate images on the web using fingerprints}},
url = {http://portal.acm.org/citation.cfm?doid=1459359.1459512},
year = {2008}
}
@article{Shi1994,
author = {Shi, Jianbo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shi/Shi - 1994 - Good Features to Track 2 Two Models of Image Motion 3 Computing Image Motion - Pattern Recognition.pdf:pdf},
journal = {Pattern Recognition},
number = {June},
title = {{Good Features to Track 2 Two Models of Image Motion 3 Computing Image Motion}},
year = {1994}
}
@article{Liu2007,
author = {Liu, Ying and Zhang, Dengsheng and Lu, Guojun and Ma, Wei-ying},
doi = {10.1016/j.patcog.2006.04.045},
file = {:Users/pkmital/Documents/Mendeley Desktop/Liu et al/Liu et al. - 2007 - A survey of content-based image retrieval with high-level semantics - Pattern Recognition.pdf:pdf},
journal = {Pattern Recognition},
keywords = {content-based image retrieval,high-level semantics,semantic gap,survey},
pages = {262--282},
title = {{A survey of content-based image retrieval with high-level semantics}},
volume = {40},
year = {2007}
}
@article{Vroomen2000,
abstract = {Six experiments demonstrated cross-modal influences from the auditory modality on the visual modality at an early level of perceptual organization. Participants had to detect a visual target in a rapidly changing sequence of visual distractors. A high tone embedded in a sequence of low tones improved detection of a synchronously presented visual target (Experiment 1), but the effect disappeared when the high tone was presented before the target (Experiment 2). Rhythmically based or order-based anticipation was unlikely to account for the effect because the improvement was unaffected by whether there was jitter (Experiment 3) or a random number of distractors between successive targets (Experiment 4). The facilitatory effect was greatly reduced when the tone was less abrupt and part of a melody (Experiments 5 and 6). These results show that perceptual organization in the auditory modality can have an effect on perceptibility in the visual modality.},
author = {Vroomen, J and de Gelder, B},
file = {:Users/pkmital/Documents/Mendeley Desktop/Vroomen, de Gelder/Vroomen, de Gelder - 2000 - Sound enhances visual perception cross-modal effects of auditory organization on vision. - Journal of experi.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Humans,Random Allocation,Vision, Ocular,Vision, Ocular: physiology,Visual Perception,Visual Perception: physiology},
month = oct,
number = {5},
pages = {1583--90},
pmid = {11039486},
title = {{Sound enhances visual perception: cross-modal effects of auditory organization on vision.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11039486},
volume = {26},
year = {2000}
}
@article{Itti2009,
abstract = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72\% of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84\% when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.},
author = {Itti, Laurent and Baldi, Pierre},
doi = {10.1016/j.visres.2008.09.007},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti, Baldi/Itti, Baldi - 2009 - Bayesian surprise attracts human attention. - Vision research.pdf:pdf},
issn = {1878-5646},
journal = {Vision research},
keywords = {Adult,Attention,Attention: physiology,Bayes Theorem,Exploratory Behavior,Exploratory Behavior: physiology,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Models, Psychological,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysics,Television,Young Adult},
month = jun,
number = {10},
pages = {1295--306},
pmid = {18834898},
title = {{Bayesian surprise attracts human attention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2782645\&tool=pmcentrez\&rendertype=abstract},
volume = {49},
year = {2009}
}
@book{Wolfe2008,
author = {Wolfe, Tom},
isbn = {031242759X},
pages = {432},
publisher = {Picador},
title = {{The Electric Kool-Aid Acid Test}},
url = {http://www.amazon.com/The-Electric-Kool-Aid-Acid-Test/dp/031242759X},
year = {2008}
}
@article{Dick1977,
abstract = {AUTHOR'S NOTE This has been a novel about some people who were punished entirely too much for what they did. They wanted to have a good time, but they were like children playing in the street; they could see one after another of them being killed-run over, maimed, destroyed-but they continued to play anyhow. We really all were very happy for a while, sitting around not toiling but just bullshitting and playing, but it was for such a terrible brief time, and then the punishment was beyond belief: even when we could see it, we could not believe it. For example, while I was writing this I learned that the person on whom the character Jerry Fabin is based killed himself. My friend on whom I based the character Ernie Luckman died before I began the novel. For a while I myself was one of these children playing in the street; I was, like the rest of them, trying to play instead of being grown up, and I was punished. I am on the list below, which is a list of those to whom this novel is dedicated, and what became of each. Drug misuse is not a disease, it is a decision, like the decision to step out in front of a moving car. You would call that not a disease but an error in judgment. When a bunch of people begin to do it, it is a social error, a life-style. In this particular life-style the motto is "Be happy now because tomorrow you are dying," but the dying begins almost at once, and the happiness is a memory. It is, then, only a speeding up, an intensifying, of the ordinary human existence. It is not different from your life-style, it is only faster. It all takes place in days or weeks or months instead of years. "Take the cash and let the credit go," as Villon said in 1460. But that is a mistake if the cash is a penny and the credit a whole lifetime. There is no moral in this novel; it is not bourgeois; it does not say they were wrong to play when they should have toiled; it just tells what the consequences were. In Greek drama they were beginning, as a society, to discover science, which means causal law. Here in this novel there is Nemesis: not fate, because any one of us could have chosen to stop playing in the street, but, as I narrate from the deepest part of my life and heart, a dreadful Nemesis for those who kept on playing. I myself, I am not a character in this novel; I am the novel. So, though, was our entire nation at this time. This novel is about more people than I knew personally. Some we all read about in the newspapers. It was, this sitting around with our buddies and bullshitting while making tape recordings, the bad decision of the decade, the sixties, both in and out of the establishment. And nature cracked down on us. We were forced to stop by things dreadful. If there was any "sin," it was that these people wanted to keep on having a good time forever, and were punished for that, but, as I say, I feel that, if so, the punishment was far too great, and I prefer to think of it only in a Greek or morally neutral way, as mere science, as deterministic impartial cause-and-effect. I loved them all.},
author = {Dick, Philip K},
journal = {Brain},
pages = {1--151},
publisher = {Phillip\_K\_Dick\_Society},
title = {{A scanner darkly 1977}},
year = {1977}
}
@inproceedings{Forssen2007a,
author = {Forss\'{e}n, P.E. and Lowe, D.G.},
booktitle = {11th IEEE International Conference on Computer Vision, 2007. ICCV 2007.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Forss\'{e}n, Lowe/Forss\'{e}n, Lowe - 2007 - Shape descriptors for maximally stable extremal regions - 11th IEEE International Conference on Computer Vision, 2007. ICCV 2007.pdf:pdf},
pages = {1--8},
publisher = {Ieee},
title = {{Shape descriptors for maximally stable extremal regions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4409025},
year = {2007}
}
@article{Hile2008a,
author = {Hile, Harlan and Borriello, Gaetano},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {32--39},
title = {{Positioning and Orientation in Indoor Environments Using Camera Phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557953},
volume = {28},
year = {2008}
}
@article{Antonelo2012a,
abstract = {This work proposes a hierarchical biologically-inspired architecture for learning sensor-based spatial representations of a robot environment in an unsupervised way. The first layer is comprised of a fixed randomly generated recurrent neural network, the reservoir, which projects the input into a high-dimensional, dynamic space. The second layer learns instantaneous slowly-varying signals from the reservoir states using Slow Feature Analysis (SFA), whereas the third layer learns a sparse coding on the SFA layer using Independent Component Analysis (ICA). While the SFA layer generates non-localized activations in space, the ICA layer presents high place selectivity, forming a localized spatial activation, characteristic of place cells found in the hippocampus area of the rodent's brain. We show that, using a limited number of noisy short-range distance sensors as input, the proposed system learns a spatial representation of the environment which can be used to predict the actual location of simulated and real robots, without the use of odometry. The results confirm that the reservoir layer is essential for learning spatial representations from low-dimensional input such as distance sensors. The main reason is that the reservoir state reflects the recent history of the input stream. Thus, this fading memory is essential for detecting locations, mainly when locations are ambiguous and characterized by similar sensor readings.},
author = {Antonelo, Eric and Schrauwen, Benjamin},
doi = {10.1016/j.neunet.2011.08.004},
file = {:Users/pkmital/Documents/Mendeley Desktop/Antonelo, Schrauwen/Antonelo, Schrauwen - 2012 - Learning slow features with reservoir computing for biologically-inspired robot localization. - Neural netw.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Animals,Learning,Learning: physiology,Models, Biological,Neural Networks (Computer),Rats,Robotics,Robotics: methods,Robotics: statistics \& numerical data,Time Factors},
month = jan,
number = {1},
pages = {178--90},
pmid = {21945043},
title = {{Learning slow features with reservoir computing for biologically-inspired robot localization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21945043},
volume = {25},
year = {2012}
}
@article{Tajadura-Jimenez2012,
author = {Tajadura-Jim\'{e}nez, Ana and V\"{a}ljam\"{a}e, Aleksander and Toshima, Iwaki and Kimura, Toshitaka and Tsakiris, Manos and Kitagawa, Norimichi},
doi = {10.1016/j.cub.2012.04.028},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tajadura-Jim\'{e}nez et al/Tajadura-Jim\'{e}nez et al. - 2012 - Action sounds recalibrate perceived tactile distance. - Current biology CB.pdf:pdf},
issn = {1879-0445},
journal = {Current biology : CB},
keywords = {Arm,Auditory Perception,Distance Perception,Humans,Nontherapeutic Human Experimentation,Touch Perception},
month = jul,
number = {13},
pages = {R516--7},
pmid = {22789996},
title = {{Action sounds recalibrate perceived tactile distance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22789996},
volume = {22},
year = {2012}
}
@article{O'Donovan2012,
abstract = {This paper presents an interactive system for creating painterly animation from video sequences. Previous approaches to painterly animation typically emphasize either purely automatic stroke synthesis or purely manual stroke key framing. Our system supports a spectrum of interaction between these two approaches which allows the user more direct control over stroke synthesis. We introduce an approach for controlling the results of painterly animation: keyframed Control Strokes can affect automatic stroke's placement, orientation, movement, and color. Furthermore, we introduce a new automatic synthesis algorithm that traces strokes through a video sequence in a greedy manner, but, instead of a vector field, uses an objective function to guide placement. This allows the method to capture fine details, respect region boundaries, and achieve greater temporal coherence than previous methods. All editing is performed with a WYSIWYG interface where the user can directly refine the animation. We demonstrate a variety of examples using both automatic and user-guided results, with a variety of styles and source videos.},
author = {O'Donovan, Peter and Hertzmann, Aaron},
doi = {10.1109/TVCG.2011.51},
file = {:Users/pkmital/Documents/Mendeley Desktop/O'Donovan, Hertzmann/O'Donovan, Hertzmann - 2012 - AniPaint interactive painterly animation from video. - IEEE transactions on visualization and computer gra.pdf:pdf},
issn = {1941-0506},
journal = {IEEE transactions on visualization and computer graphics},
month = mar,
number = {3},
pages = {475--87},
pmid = {21383408},
title = {{AniPaint: interactive painterly animation from video.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21383408},
volume = {18},
year = {2012}
}
@article{Hillstrom1994,
abstract = {Previous work has shown that abrupt visual onsets capture attention. This occurs even with stimuli that are equiluminant with the background, which suggests that the appearance of a new perceptual object, not merely a change in luminance, captures attention. Three experiments are reported in which this work was extended by investigating the possible role of visual motion in attentional capture. Experiment 1 revealed that motion can efficiently guide attention when it is perfectly informative about the location of a visual search target, but that it does not draw attention when it does not predict the target's position. This result was obtained with several forms of motion, including oscillation, looming, and nearby moving contours. To account for these and other results, we tested a new-object account of attentional capture in Experiment 2 by using a global/local paradigm. When motion segregated a local letter from its perceptual group, the local letter captured attention as indexed by an effect on latency of response to the task-relevant global configuration. Experiment 3 ruled out the possibility that the motion in Experiment 2 captured attention merely by increasing the salience of the moving object. We argue instead that when motion segregates a perceptual element from a perceptual group, a new perceptual object is created, and this event captures attention. Together, the results suggest that motion as such does not capture attention but that the appearance of a new perceptual object does.},
author = {Hillstrom, a P and Yantis, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Hillstrom, Yantis/Hillstrom, Yantis - 1994 - Visual motion and attentional capture. - Perception \& psychophysics.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Female,Humans,Male,Motion Perception,Photic Stimulation,Reaction Time,Visual Perception},
month = apr,
number = {4},
pages = {399--411},
pmid = {8036120},
title = {{Visual motion and attentional capture.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8036120},
volume = {55},
year = {1994}
}
@article{Rensink1997,
abstract = {When looking at a scene, observers feel that they see its entire structure in great detail and can immediately notice any changes in it However, when brief blank fields are placed between alternating displays of an original and a modified scene, a striking failure of perception is induced Identification of changes becomes extremely difficult, even when changes are large and made repeatedly Identification is much faster when a verbal cue is provided showing that poor visibility is not the cause of this difficulty Identification is also faster for objects considered to be important in the scene These results support the idea that observers never form a complete, detailed representation of their surroundings In addition, the results indicate that attention is required to perceive change, and that in the absence of localized motion signals attention is guided on the basis of high-level interest},
author = {Rensink, R A and O'Regan, J K and Clark, J J},
doi = {10.1111/j.1467-9280.1997.tb00427.x},
isbn = {0002764207305},
issn = {09567976},
journal = {Psychological Science},
number = {5},
pages = {368--373},
publisher = {SAGE Publications},
title = {{To See or not to See: The Need for Attention to Perceive Changes in Scenes}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.1997.tb00427.x},
volume = {8},
year = {1997}
}
@article{Hari1984,
abstract = {Auditory evoked magnetic fields of the human brain were recorded with a four-channel 1st order gradiometer. Pitch deviance in a sequence of repetitive tone pips elicited magnetic evoked-response changes with a topography suggesting that a neuronal mismatch process to the deviant tones activates the primary auditory cortex.},
author = {Hari, R and H\"{a}m\"{a}l\"{a}inen, M and Ilmoniemi, R and Kaukoranta, E and Reinikainen, K and Salminen, J and Alho, K and N\"{a}\"{a}t\"{a}nen, R and Sams, M},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Auditory Cortex,Auditory Cortex: physiology,Brain Mapping,Evoked Potentials, Auditory,Humans,Magnetics,Pitch Perception,Pitch Perception: physiology},
month = sep,
number = {1-3},
pages = {127--32},
pmid = {6493619},
title = {{Responses of the primary auditory cortex to pitch changes in a sequence of tone pips: neuromagnetic recordings in man.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6493619},
volume = {50},
year = {1984}
}
@article{Knees2006,
author = {Knees, Peter and Schedl, Markus and Pohle, Tim},
file = {:Users/pkmital/Documents/Mendeley Desktop/Knees, Schedl, Pohle/Knees, Schedl, Pohle - 2006 - An innovative three-dimensional user interface for exploring music collections enriched with meta-informat.pdf:pdf},
isbn = {1595934472},
journal = {Proceedings of the ACM},
keywords = {an island landscape created,clustering,exploration of the collection,figure 1,from a mu-,is en-,music information retrieval,music similarity,sic collection,user interface,visualization,web mining},
title = {{An innovative three-dimensional user interface for exploring music collections enriched with meta-information from the web}},
url = {http://www.liacs.nl/~mlew/mir/session1/An Innovative Three-Dimensional User Interface for Exploring Music Collections.pdf},
year = {2006}
}
@article{Melucci2000,
author = {Melucci, Massimo and Orio, Nicola},
file = {:Users/pkmital/Documents/Mendeley Desktop/Melucci, Orio/Melucci, Orio - 2000 - SMILE A system for content-based musical information retrieval environments - RIAO'2000 Conference proceedings.pdf:pdf},
journal = {RIAO'2000 Conference proceedings},
title = {{SMILE: A system for content-based musical information retrieval environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.4720\&amp;rep=rep1\&amp;type=pdf},
year = {2000}
}
@article{Brady2008,
abstract = {One of the major lessons of memory research has been that human memory is fallible, imprecise, and subject to interference. Thus, although observers can remember thousands of images, it is widely assumed that these memories lack detail. Contrary to this assumption, here we show that long-term memory is capable of storing a massive number of objects with details from the image. Participants viewed pictures of 2,500 objects over the course of 5.5 h. Afterward, they were shown pairs of images and indicated which of the two they had seen. The previously viewed item could be paired with either an object from a novel category, an object of the same basic-level category, or the same object in a different state or pose. Performance in each of these conditions was remarkably high (92\%, 88\%, and 87\%, respectively), suggesting that participants successfully maintained detailed representations of thousands of images. These results have implications for cognitive models, in which capacity limitations impose a primary computational constraint (e.g., models of object recognition), and pose a challenge to neural models of memory storage and retrieval, which must be able to account for such a large and detailed storage capacity.},
author = {Brady, Timothy F and Konkle, Talia and Alvarez, George a and Oliva, Aude},
doi = {10.1073/pnas.0803390105},
file = {:Users/pkmital/Documents/Mendeley Desktop/Brady et al/Brady et al. - 2008 - Visual long-term memory has a massive storage capacity for object details. - Proceedings of the National Academy o.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Humans,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Recognition (Psychology),Recognition (Psychology): physiology,Time Factors},
month = sep,
number = {38},
pages = {14325--9},
pmid = {18787113},
title = {{Visual long-term memory has a massive storage capacity for object details.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2533687\&tool=pmcentrez\&rendertype=abstract},
volume = {105},
year = {2008}
}
@article{Harma2005,
author = {Harma, A and McKinney, MF},
file = {:Users/pkmital/Documents/Mendeley Desktop/Harma, McKinney/Harma, McKinney - 2005 - Automatic surveillance of the acoustic activity in our living environment - Multimedia and Expo, 2005 IEEE International Conference on.pdf:pdf},
isbn = {0780393325},
journal = {Multimedia and Expo, 2005 IEEE International Conference on},
number = {1},
title = {{Automatic surveillance of the acoustic activity in our living environment}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1521503},
volume = {1},
year = {2005}
}
@article{Serre2007,
abstract = {We introduce a new general framework for the recognition of complex visual scenes, which is motivated by biology: We describe a hierarchical system that closely follows the organization of visual cortex and builds an increasingly complex and invariant feature representation by alternating between a template matching and a maximum pooling operation. We demonstrate the strength of the approach on a range of recognition tasks: From invariant single object recognition in clutter to multiclass categorization problems and complex scene understanding tasks that rely on the recognition of both shape-based as well as texture-based objects. Given the biological constraints that the system had to satisfy, the approach performs surprisingly well: It has the capability of learning from only a few training examples and competes with state-of-the-art systems. We also discuss the existence of a universal, redundant dictionary of features that could handle the recognition of most object categories. In addition to its relevance for computer vision, the success of this approach suggests a plausibility proof for a class of feedforward models of object recognition in cortex.},
author = {Serre, Thomas and Wolf, Lior and Bileschi, Stanley and Riesenhuber, Maximilian and Poggio, Tomaso},
doi = {10.1109/TPAMI.2007.56},
file = {:Users/pkmital/Documents/Mendeley Desktop/Serre et al/Serre et al. - 2007 - Robust object recognition with cortex-like mechanisms. - IEEE transactions on pattern analysis and machine intelligence.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Biomimetics,Biomimetics: methods,Computer Simulation,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Models, Biological,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reproducibility of Results,Sensitivity and Specificity,Visual Cortex,Visual Cortex: physiology},
month = mar,
number = {3},
pages = {411--26},
pmid = {17224612},
title = {{Robust object recognition with cortex-like mechanisms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17224612},
volume = {29},
year = {2007}
}
@article{Sensomotorik1997,
author = {Sensomotorik, Visuelle and Universita, Neurologische and Str, Hoppe-seyler},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sensomotorik, Universita, Str/Sensomotorik, Universita, Str - 1997 - Fine Fourier motion - Progress in Neurobiology.pdf:pdf},
journal = {Progress in Neurobiology},
title = {{Fine Fourier motion}},
volume = {53},
year = {1997}
}
@article{Li2002a,
author = {Li, Zhaoping},
file = {:Users/pkmital/Documents/Mendeley Desktop/Li/Li - 2002 - A saliency map in primary visual cortex - Trends in cognitive sciences(2).pdf:pdf},
journal = {Trends in cognitive sciences},
number = {1},
pages = {9--16},
title = {{A saliency map in primary visual cortex}},
url = {http://www.sciencedirect.com/science/article/pii/S1364661300018179},
volume = {6},
year = {2002}
}
@article{Kohli2012,
author = {Kohli, P. and Shotton, J.},
doi = {10.1109/CVPR.2012.6248079},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kohli, Shotton/Kohli, Shotton - 2012 - Conditional regression forests for human pose estimation - 2012 IEEE Conference on Computer Vision and Pattern R.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {3394--3401},
publisher = {Ieee},
title = {{Conditional regression forests for human pose estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6248079},
year = {2012}
}
@article{Astikainen2004,
abstract = {Event-related potentials (ERPs) to visual stimuli were recorded from the scalp of eight adult humans performing a task in which they counted vowels from a heard story. In the oddball condition, a repeated (standard) light bar of 50 ms in duration was rarely (P = 0.1) replaced by a (deviant) one differing in orientation from the standard. In the control condition, standards were simply omitted from the series and only (alone-) deviants retained. In both conditions, visual stimuli were asynchronous with auditory-task-relevant stimuli. ERPs to deviants significantly differed in amplitude from those to standards in the midline electrodes centrally, parietally and occipitally at 160-200 ms from stimulus onset. Occipitally, such a difference was absent between ERPs to alone-deviants and those to standards. The occipital differential ERPs to deviants, which thus could be found only when standards were present in the series, are discussed in the context of the mismatch negativity (MMN).},
author = {Astikainen, Piia and Ruusuvirta, Timo and Wikgren, Jan and Korhonen, Tapani},
doi = {10.1016/j.neulet.2004.07.025},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adolescent,Adult,Analysis of Variance,Attention,Attention: physiology,Cerebellar Cortex,Cerebellar Cortex: physiology,Cues,Electrodes,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Mental Processes,Mental Processes: physiology,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology},
month = sep,
number = {2},
pages = {231--4},
pmid = {15351455},
title = {{The human brain processes visual changes that are not cued by attended auditory stimulation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15351455},
volume = {368},
year = {2004}
}
@article{Shamma2010,
author = {Shamma, SA and Micheyl, Christophe},
doi = {10.1016/j.conb.2010.03.009.Behind},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shamma, Micheyl/Shamma, Micheyl - 2010 - Behind the scenes of auditory perception - Current opinion in neurobiology.pdf:pdf},
journal = {Current opinion in neurobiology},
number = {3},
pages = {361--366},
title = {{Behind the scenes of auditory perception}},
url = {http://www.sciencedirect.com/science/article/pii/S0959438810000474},
volume = {20},
year = {2010}
}
@article{No\\e2004,
author = {No$\backslash$$\backslash$"e, A. and Thompson, Evan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Noe, Thompson/Noe, Thompson - 2004 - Are there neural correlates of consciousness - Journal of Consciousness studies.pdf:pdf},
journal = {Journal of Consciousness studies},
number = {1},
pages = {3--28},
publisher = {Imprint Academic},
title = {{Are there neural correlates of consciousness?}},
url = {http://www.ingentaconnect.com/content/imp/jcs/2004/00000011/00000001/1400},
volume = {11},
year = {2004}
}
@article{Schwarz2006,
author = {Schwarz, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2006 - Concatenative Sound Synthesis The Early Years - J. New Music Research.pdf:pdf},
journal = {J. New Music Research},
keywords = {CSS},
number = {1},
title = {{Concatenative Sound Synthesis: The Early Years}},
volume = {35},
year = {2006}
}
@article{Casey2008,
author = {Casey, M and Rhodes, C and Slaney, M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey, Rhodes, Slaney/Casey, Rhodes, Slaney - 2008 - Analysis of Minimum Distances in High-Dimensional Musical Spaces - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
keywords = { DB,MIR},
month = jul,
number = {5},
pages = {1015--1028},
title = {{Analysis of Minimum Distances in High-Dimensional Musical Spaces}},
volume = {16},
year = {2008}
}
@article{Simsekli2011,
author = {Şimşekli, Umut and Cemgil, Ali Taylan},
doi = {10.1080/09298215.2011.573561},
file = {:Users/pkmital/Documents/Mendeley Desktop/Şimşekli, Cemgil/Şimşekli, Cemgil - 2011 - Probabilistic Models for Real-time Acoustic Event Detection with Application to Pitch Tracking - Journal of New Music Research.pdf:pdf},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = jun,
number = {2},
pages = {175--185},
title = {{Probabilistic Models for Real-time Acoustic Event Detection with Application to Pitch Tracking}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09298215.2011.573561},
volume = {40},
year = {2011}
}
@article{Berlucchi2006,
author = {Berlucchi, Giovanni},
doi = {10.1080/02643290600588426},
file = {:Users/pkmital/Documents/Mendeley Desktop/Berlucchi/Berlucchi - 2006 - Inhibition of return A phenomenon in search of a mechanism and a better name - Cognitive Neuropsychology.pdf:pdf},
issn = {0264-3294},
journal = {Cognitive Neuropsychology},
month = oct,
number = {7},
pages = {1065--1074},
title = {{Inhibition of return: A phenomenon in search of a mechanism and a better name}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/02643290600588426\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {23},
year = {2006}
}
@article{Chang2010,
author = {Chang, IC and Peng, YM and Chen, YS and Wang, SC},
file = {:Users/pkmital/Documents/Mendeley Desktop/Chang et al/Chang et al. - 2010 - Artistic Painting Style Transformation Using a Patch-based Sampling Method - Journal of Information Science and En.pdf:pdf},
journal = {Journal of Information Science and Engineering},
keywords = {image segmentation,mean shift,painting style transformation,patch-based,sampling,texture re-synthesis},
pages = {1443--1458},
title = {{Artistic Painting Style Transformation Using a Patch-based Sampling Method}},
url = {http://www.iis.sinica.edu.tw/page/jise/2010/201007\_18.pdf},
volume = {26},
year = {2010}
}
@book{ARTS1979,
author = {ARTS, ROYAL ACADEMY OF},
isbn = {0297777130},
pages = {303},
publisher = {Weidenfeld Nicolson Illustrated},
title = {{Post-Impressionism: Cross-Currents in European Painting}},
url = {http://www.amazon.co.uk/Post-Impressionism-Cross-Currents-ROYAL-ACADEMY-ARTS/dp/0297777130},
year = {1979}
}
@article{Farnell,
author = {Farnell, Andy James},
file = {::},
keywords = {audio,biomechanics,bipedal motion,computer games,footsteps,procedural,puredata,sound design,synthesis},
title = {{Marching onwards Procedural synthetic footsteps for video games and animation .}}
}
@article{Serre2006,
author = {Serre, Thomas},
file = {:Users/pkmital/Documents/Mendeley Desktop/Serre/Serre - 2006 - Computer Science and Artificial Intelligence Laboratory Technical Report Learning a Dictionary of Shape-Components in Vis.pdf:pdf},
journal = {Learning},
title = {{Computer Science and Artificial Intelligence Laboratory Technical Report Learning a Dictionary of Shape-Components in Visual Cortex : Comparison with Neurons , Humans and Machines by}},
year = {2006}
}
@article{Huth2012,
abstract = {Humans can see and name thousands of distinct object and action categories, so it is unlikely that each category is represented in a distinct brain area. A more efficient scheme would be to represent categories as locations in a continuous semantic space mapped smoothly across the cortical surface. To search for such a space, we used fMRI to measure human brain activity evoked by natural movies. We then used voxelwise models to examine the cortical representation of 1,705 object and action categories. The first few dimensions of the underlying semantic space were recovered from the fit models by principal components analysis. Projection of the recovered semantic space onto cortical flat maps shows that semantic selectivity is organized into smooth gradients that cover much of visual and nonvisual cortex. Furthermore, both the recovered semantic space and the cortical organization of the space are shared across different individuals.},
author = {Huth, Alexander G and Nishimoto, Shinji and Vu, An T and Gallant, Jack L},
doi = {10.1016/j.neuron.2012.10.014},
file = {:Users/pkmital/Documents/Mendeley Desktop/Huth et al/Huth et al. - 2012 - A continuous semantic space describes the representation of thousands of object and action categories across the hu.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Adult,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Concept Formation,Humans,Magnetic Resonance Imaging,Male,Reference Values,Semantics,Verbal Behavior},
month = dec,
number = {6},
pages = {1210--24},
pmid = {23259955},
title = {{A continuous semantic space describes the representation of thousands of object and action categories across the human brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23259955},
volume = {76},
year = {2012}
}
@article{Milborrow,
author = {Milborrow, Stephen and Nicolls, Fred},
file = {:Users/pkmital/Documents/Mendeley Desktop/Milborrow, Nicolls/Milborrow, Nicolls - 2008 - Locating facial features with an extended active shape model - Computer Vision–ECCV 2008.pdf:pdf},
journal = {Computer Vision–ECCV 2008},
pages = {504--513},
publisher = {Springer},
title = {{Locating facial features with an extended active shape model}},
url = {http://www.springerlink.com/index/5T8HJM7J02QX6184.pdf},
year = {2008}
}
@article{Burraston2005,
abstract = {This paper will review electronic music and sonic art applications of Cellular Automata (CA) in a historical and technical context. Algorithmic and computational processes have been of interest to artists for many years, creating an emerging culture of generative electronic art. Creating patterns and sequences is necessary for the creative artist working spatially and temporally within a chosen medium. CA are capable of a wide variety of emergent behaviours and represent an important generative tool for the artist. The sonic artist and musician must be prepared to investigate the theoretical background of CA in order to successfully employ their vast behaviour space within compositional strategy. There is an extensive amount of mathematical and scientific literature relating to CA, however much of this is esoteric or difficult to understand. Important and accessible CA concepts are presented concisely in a non mathematical context to give sufficient background for the review. There have been several approaches at applying CA in the production of electronic music and sonic art. Examples exist in the fields of overall structural composition, MIDI sequencing and sound synthesis/modification techniques. Applications from academic, independent and commercial sectors will be critically reviewed in an artistic, historical and technical context. This will provide the artist and scientist with a balanced view of this emerging field.},
author = {Burraston, Dave and Edmonds, Ernest},
file = {::},
journal = {Digital Creativity},
keywords = {algorithmic composition,cellular automata,electronic music,generative music,sound synthesis},
number = {3},
pages = {165},
title = {{Cellular Automata in Generative Electronic Music and Sonic Art: Historical and Technical Review}},
volume = {16},
year = {2005}
}
@inproceedings{Fontana2003,
abstract = {Three types of ecological events (crushing, walking and running) have been considered. Their acoustic properties have been mod- eled following the physics-based approach. Starting from an ex- isting physically-based impact model, we superimposed to it the dynamic and temporal stochastic characteristics governing crush- ing events. The resulting model was triggered by control rules realizing typical walking and running time patterns. This bottom-up design strategywas made possible because the sound synthesis and sound control models could be directly con- nected each other via a common switchboard of driving and con- trol parameters. The existence of a common interface specification for all the models follows from the application of physics-based modeling, and translates in major advantages when those models are implemented as independent, self-contained blocks and proce- dures connected together in real-time inside a sw architecture like pd.},
address = {Firenze, Italy},
author = {Fontana, F. and Bresin, R.},
booktitle = {Proceedings of the XIV Colloquium on Musical Informatics (XIV CIM 2003)},
file = {::},
pages = {109--114},
title = {{Physics-based Sound Synthesis and Control: Crushing, Walking and Running by Crumpling Sounds}},
url = {http://www.speech.kth.se/prod/publications/files/981.pdf},
year = {2003}
}
@article{Stagg2004,
abstract = {Mismatch negativity is an event related potential generated by a mechanism which detects stimulus change. Such a mechanism is important to enable attention to be switched to important changes in the environment. The effect has been extensively studied in the auditory modality. The present investigation was designed to establish whether the enhanced negativity in the visual event related potential evoked by deviant stimuli presented infrequently among a sequence of repeated standard stimuli is really associated with the detection of stimulus change. The experiment set out to distinguish effects associated with stimulus change from those related to the physical attributes of the stimuli or to differences in the refractory state of receptors or neurons. The findings support the hypothesis that deviance-related negativity reflects the operation of a change detection mechanism and not the refractory state of elements of the visual system.},
author = {Stagg, Charlotte and Hindley, Peter and Tales, Andrea and Butler, Stuart},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Action Potentials,Action Potentials: physiology,Adult,Attention,Attention: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Evoked Potentials,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Evoked Potentials: physiology,Female,Humans,Male,Neuropsychological Tests,Photic Stimulation,Reaction Time,Reaction Time: physiology,Reference Values,Sensory Thresholds,Sensory Thresholds: physiology,Visual Perception,Visual Perception: physiology},
month = mar,
number = {4},
pages = {659--63},
pmid = {15094471},
title = {{Visual mismatch negativity: the detection of stimulus change.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15094471},
volume = {15},
year = {2004}
}
@incollection{Oliva2005,
author = {Oliva, Aude},
booktitle = {Neurobiology of attention},
pages = {251--257},
title = {{Gist of the scene}},
url = {http://cvcl.mit.edu/papers/oliva04.pdf},
year = {2005}
}
@article{Bonitz2008,
abstract = {This study examined the influences of semantic characteristics of objects in real-world scenes on allocation of attention as reflected in eye movement measures. Stimuli consisted of full-color photographic scenes, and within each scene, the semantic salience of two target objects was manipulated while the objects' perceptual salience was kept constant. One of the target objects was either inconsistent or consistent with the scene category. In addition, the second target object was either smoking-related or neutral. Two groups of college students, namely current cigarette smokers (N=18) and non-smokers (N=19), viewed each scene for 10s while their eye movements were recorded. While both groups showed preferential allocation of attention to inconsistent objects, smokers also selectively attended to smoking-related objects. Theoretical implications of the results are discussed.},
author = {Bonitz, Verena S and Gordon, Robert D},
doi = {10.1016/j.actpsy.2008.08.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bonitz, Gordon/Bonitz, Gordon - 2008 - Attention to smoking-related and incongruous objects during scene viewing. - Acta psychologica.pdf:pdf},
issn = {1873-6297},
journal = {Acta psychologica},
keywords = {Attention,Cues,Eye Movements,Female,Fixation, Ocular,Humans,Male,Pattern Recognition, Visual,Reaction Time,Semantics,Smoking,Smoking Cessation,Smoking Cessation: psychology,Smoking: psychology,Students,Students: psychology,Young Adult},
month = oct,
number = {2},
pages = {255--63},
pmid = {18804752},
title = {{Attention to smoking-related and incongruous objects during scene viewing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18804752},
volume = {129},
year = {2008}
}
@article{Slaney1995,
author = {Slaney, Malcolm},
file = {:Users/pkmital/Documents/Mendeley Desktop/Slaney/Slaney - 1995 - Pattern Playback in the 90s - Advances in Neural Information.pdf:pdf},
journal = {Advances in Neural Information},
title = {{Pattern Playback in the 90s}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Pattern+Playback+in+the+’+90s\#0},
year = {1995}
}
@article{Baddeley2000,
abstract = {In 1974, Baddeley and Hitch proposed a three-component model of working memory. Over the years, this has been successful in giving an integrated account not only of data from normal adults, but also neuropsychological, developmental and neuroimaging data. There are, however, a number of phenomena that are not readily captured by the original model. These are outlined here and a fourth component to the model, the episodic buffer, is proposed. It comprises a limited capacity system that provides temporary storage of information held in a multimodal code, which is capable of binding information from the subsidiary systems, and from long-term memory, into a unitary episodic representation. Conscious awareness is assumed to be the principal mode of retrieval from the buffer. The revised model differs from the old principally in focussing attention on the processes of integrating information, rather than on the isolation of the subsystems. In doing so, it provides a better basis for tackling the more complex aspects of executive control in working memory.},
author = {Baddeley, a},
file = {:Users/pkmital/Documents/Mendeley Desktop/Baddeley/Baddeley - 2000 - The episodic buffer a new component of working memory - Trends in cognitive sciences.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
month = nov,
number = {11},
pages = {417--423},
pmid = {11058819},
title = {{The episodic buffer: a new component of working memory?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11058819},
volume = {4},
year = {2000}
}
@article{Casey1994,
abstract = {This research report describes an approach to parameter estimation for physical models of sound-generating systems using distal teachers and forward models (Jordan \& Rumelhart, 1992; Jordan, 1990). The general problem is to find an inverse model of a sound-generating system that transforms sounds to action parameters; these parameters constitute a model-based description of the sound. We first show that a two-layer feedforward model is capable of performing inverse mappings for a simple physical model of a violin string. We refer to this learning strategy as direct inverse modeling; it requires an explicit teacher and it is only suitable for convex regions of the parameter space. A model of two strings was implemented that had non-convex regions in its parameter space. We show how the direct modeling strategy failed at the task of learning the inverse model in this case and that forward models can be used, in conjunction with distal teachers, to bias the learning of an inverse model so that non-convex regions are mapped to single-point solutions in the parameter space. Our results show that forward models are appropriate for learning to map sounds to parametric representations.},
author = {Casey, Michael},
doi = {10.1080/09540099408915730},
file = {::},
isbn = {0262071819},
issn = {0954-0091},
journal = {Connection Science},
number = {2},
pages = {355--371},
publisher = {The MIT Press},
title = {{Understanding Musical Sound with Forward Models and Physical Models}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09540099408915730\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {6},
year = {1994}
}
@article{Ciaramelli2008,
abstract = {Recent neuroimaging studies have implicated the posterior parietal cortex in episodic memory retrieval, but there is uncertainty about its specific role. Research in the attentional domain has shown that superior parietal lobe (SPL) regions along the intraparietal sulcus are implicated in the voluntary orienting of attention to relevant aspects of the environment, whereas inferior parietal lobe (IPL) regions at the temporo-parietal junction mediate the automatic allocation of attention to task-relevant information. Here we propose that the SPL and the IPL play conceptually similar roles in episodic memory retrieval. We hypothesize that the SPL allocates top-down attention to memory retrieval, whereas the IPL mediates the automatic, bottom-up attentional capture by retrieved memory contents. By reviewing the existing fMRI literature, we show that the posterior intraparietal sulcus of SPL is consistently active when the need for top-down assistance to memory retrieval is supposedly maximal, e.g., for memories retrieved with low vs. high confidence, for familiar vs. recollected memories, for recognition of high vs. low frequency words. On the other hand, the supramarginal gyrus of IPL is consistently active when the attentional capture by memory contents is supposedly maximal, i.e., for strong vs. weak memories, for vividly recollected vs. familiar memories, for memories retrieved with high vs. low confidence. We introduce a model of episodic memory retrieval that characterizes contributions of posterior parietal cortex.},
author = {Ciaramelli, Elisa and Grady, Cheryl L and Moscovitch, Morris},
doi = {10.1016/j.neuropsychologia.2008.03.022},
issn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Attention,Attention: physiology,Brain Mapping,Cognition,Cognition: physiology,Cues,Decision Making,Decision Making: physiology,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Magnetic Resonance Imaging: statistics \& numerical,Memory,Memory: physiology,Mental Recall,Mental Recall: physiology,Models, Neurological,Neural Pathways,Neural Pathways: physiology,Parietal Lobe,Parietal Lobe: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Temporal Lobe,Temporal Lobe: physiology,Verbal Behavior,Verbal Behavior: physiology},
month = jan,
number = {7},
pages = {1828--51},
pmid = {18471837},
title = {{Top-down and bottom-up attention to memory: a hypothesis (AtoM) on the role of the posterior parietal cortex in memory retrieval.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18471837},
volume = {46},
year = {2008}
}
@article{Shtyrov2002,
abstract = {Mismatch negativity (MMN), an index of experience-dependent memory traces, was used to investigate the processing of grammatical affixes in the human brain. The MMN was elicited by either a verb stem or an inflected verb form, phonetic contrasts being identical in both conditions. The topography of the mismatch responses showed clear left-hemispheric laterality in both conditions. However, the MMN to the inflected form occurred later than that for the stem. Furthermore, the inflected stimulus produced MMN maximal in centroparietal sites, whereas stem-elicited MMN was more profound at more frontal sites. We suggest that these features of the MMN to inflected form indicate delayed activation of left-lateralized perisylvian cell assemblies that function as cortical memory traces of inflectional affixes.},
author = {Shtyrov, Yury and Pulverm\"{u}ller, Friedemann},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shtyrov, Pulverm\"{u}ller/Shtyrov, Pulverm\"{u}ller - 2002 - Memory traces for inflectional affixes as shown by mismatch negativity. - The European journal of neuros.pdf:pdf},
issn = {0953-816X},
journal = {The European journal of neuroscience},
keywords = {Acoustic Stimulation,Adult,Brain Mapping,Cerebral Cortex,Cerebral Cortex: anatomy \& histology,Cerebral Cortex: physiology,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Language Tests,Male,Memory,Memory: physiology,Nerve Net,Nerve Net: anatomy \& histology,Nerve Net: physiology,Reaction Time,Reaction Time: physiology,Speech Perception,Speech Perception: physiology,Verbal Behavior,Verbal Behavior: physiology},
month = mar,
number = {6},
pages = {1085--91},
pmid = {11918667},
title = {{Memory traces for inflectional affixes as shown by mismatch negativity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17412721},
volume = {15},
year = {2002}
}
@article{Kang2009,
author = {Kang, Sang-Ick and Chang, Joon-Hyuk},
doi = {10.1587/elex.6.1374},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kang, Chang/Kang, Chang - 2009 - Discriminative weight training-based optimally weighted MFCC for gender identification - IEICE Electronics Express.pdf:pdf},
issn = {1349-2543},
journal = {IEICE Electronics Express},
keywords = {classification,electronics,gender identification,mce,mfcc,science and engineering for},
number = {19},
pages = {1374--1379},
title = {{Discriminative weight training-based optimally weighted MFCC for gender identification}},
url = {http://joi.jlc.jst.go.jp/JST.JSTAGE/elex/6.1374?from=CrossRef},
volume = {6},
year = {2009}
}
@article{Klein2009a,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2009.5336495},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2009 - Parallel Tracking and Mapping on a camera phone - 2009 8th IEEE International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-5390-0},
journal = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
month = oct,
pages = {83--86},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping on a camera phone}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5336495},
year = {2009}
}
@article{Parikh2011,
author = {Parikh, Devi and Grauman, Kristen},
doi = {10.1109/ICCV.2011.6126281},
file = {:Users/pkmital/Documents/Mendeley Desktop/Parikh, Grauman/Parikh, Grauman - 2011 - Relative attributes - 2011 International Conference on Computer Vision.pdf:pdf},
isbn = {978-1-4577-1102-2},
journal = {2011 International Conference on Computer Vision},
month = nov,
number = {Iccv},
pages = {503--510},
publisher = {Ieee},
title = {{Relative attributes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6126281},
year = {2011}
}
@article{Lowe2004a,
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lowe/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Keypoints - International Journal of Computer Vision.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = nov,
number = {2},
pages = {91--110},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://link.springer.com/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Kiss2008,
abstract = {The N2pc component has recently become a popular tool in attention research. To investigate whether this component exclusively reflects attentional target selection or also prior stages in attentional processing (covert orienting, target-unspecific spatial attention), a spatial cuing procedure was combined with a visual search task. In some blocks, informative cues indicated the side of upcoming singleton targets that were present on most trials among uniform distractors. In other blocks, cues were spatially uninformative, and no preparatory shifts of attention were possible. The N2pc in response to targets was unaffected by this manipulation, showing that this component is not associated with attention shifts. Following informative cues, an attenuated N2pc was elicited by uniform nontarget arrays, suggesting that the N2pc may also reflect spatially specific processing of stimulus features at task-relevant locations prior to target selection.},
author = {Kiss, Monika and {Van Velzen}, Jos\'{e} and Eimer, Martin},
doi = {10.1111/j.1469-8986.2007.00611.x},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kiss, Van Velzen, Eimer/Kiss, Van Velzen, Eimer - 2008 - The N2pc component and its links to attention shifts and spatially selective visual processing. - Psychophysiology.pdf:pdf},
issn = {0048-5772},
journal = {Psychophysiology},
keywords = {Adult,Attention,Attention: physiology,Cues,Data Interpretation, Statistical,Electroencephalography,Evoked Potentials, Visual,Evoked Potentials, Visual: physiology,Female,Humans,Male,Photic Stimulation,Reaction Time,Reaction Time: physiology,Visual Perception,Visual Perception: physiology},
month = mar,
number = {2},
pages = {240--9},
pmid = {17971061},
title = {{The N2pc component and its links to attention shifts and spatially selective visual processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17971061},
volume = {45},
year = {2008}
}
@article{Lucas1981a,
author = {{Lucas, Bruce D; Kanade}, Takeo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lucas, Bruce D Kanade/Lucas, Bruce D Kanade - 1981 - An Iterative Image Registration Technique with an Application to Stereo Vision - Imaging.pdf:pdf},
journal = {Imaging},
pages = {121--130},
title = {{An Iterative Image Registration Technique with an Application to Stereo Vision}},
volume = {130},
year = {1981}
}
@article{Xiong2003,
author = {Xiong, Ziyou and Radhakrishnan, Regunathan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Xiong, Radhakrishnan/Xiong, Radhakrishnan - 2003 - Comparing MFCC and MPEG-7 audio features for feature extraction, maximum likelihood HMM and entropic prior.pdf:pdf},
journal = {, Speech, and Signal},
title = {{Comparing MFCC and MPEG-7 audio features for feature extraction, maximum likelihood HMM and entropic prior HMM for sports audio classification}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1200048},
year = {2003}
}
@misc{Paul,
author = {Paul, Leonard J},
booktitle = {Event (London)},
file = {::},
keywords = {1,adaptive audio,fig,game coding,game prototyping,interactive audio,open sound control,osc,pd,prototyping using,pure data,screenshot of software used,to demonstrate game audio,video game,video game audio},
pages = {3--8},
title = {{Video Game Audio Prototyping with Pure Data}}
}
@article{Fukuchi2009,
author = {Fukuchi, Ken and Miyazato, Kouji and Kimura, Akisato and Takagi, Shigeru and Yamato, Junji},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fukuchi et al/Fukuchi et al. - 2009 - SALIENCY-BASED VIDEO SEGMENTATION WITH GRAPH CUTS AND SEQUENTIALLY UPDATED PRIORS NTT Communication Science Laboratories , NTT Corporation , Japan Department of Information and Communication Systems Engineering , Okinawa Natio.pdf:pdf},
journal = {Communication},
pages = {638--641},
title = {{SALIENCY-BASED VIDEO SEGMENTATION WITH GRAPH CUTS AND SEQUENTIALLY UPDATED PRIORS NTT Communication Science Laboratories , NTT Corporation , Japan Department of Information and Communication Systems Engineering , Okinawa National College of Technology , J}},
year = {2009}
}
@article{DiBlasi2005,
author = {{Di Blasi}, Gianpiero and Gallo, Giovanni},
doi = {10.1007/s00371-005-0292-4},
file = {:Users/pkmital/Documents/Mendeley Desktop/Di Blasi, Gallo/Di Blasi, Gallo - 2005 - Artificial mosaics - The Visual Computer.pdf:pdf},
issn = {0178-2789},
journal = {The Visual Computer},
keywords = {distance transform,image processing and enhancement,istic rendering,mosaic,nonphotoreal-},
month = jun,
number = {6},
pages = {373--383},
title = {{Artificial mosaics}},
url = {http://www.springerlink.com/index/10.1007/s00371-005-0292-4},
volume = {21},
year = {2005}
}
@article{Miyazato2009,
author = {Miyazato, Kouji and Kimura, Akisato and Takagi, Shigeru and Yamato, Junji},
file = {:Users/pkmital/Documents/Mendeley Desktop/Miyazato et al/Miyazato et al. - 2009 - REAL-TIME ESTIMATION OF HUMAN VISUAL ATTENTION WITH DYNAMIC BAYESIAN NETWORK AND MCMC-BASED PARTICLE FILTER NTT Communication Science Laboratories , NTT Corporation , Japan Department of Information and Communication Systems.pdf:pdf},
journal = {Communication},
pages = {250--257},
title = {{REAL-TIME ESTIMATION OF HUMAN VISUAL ATTENTION WITH DYNAMIC BAYESIAN NETWORK AND MCMC-BASED PARTICLE FILTER NTT Communication Science Laboratories , NTT Corporation , Japan Department of Information and Communication Systems Engineering , Okinawa National}},
year = {2009}
}
@article{Shimojo2001,
author = {Shimojo, S. and Shams, L.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shimojo, Shams/Shimojo, Shams - 2001 - Sensory modalities are not separate modalities plasticity and interactions - Current opinion in neurobiology.pdf:pdf},
journal = {Current opinion in neurobiology},
number = {4},
pages = {505--509},
publisher = {Elsevier},
title = {{Sensory modalities are not separate modalities: plasticity and interactions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438800002415},
volume = {11},
year = {2001}
}
@article{Itti2006,
author = {Itti, Laurent},
doi = {10.1080/13506280500195672},
file = {:Users/pkmital/Documents/Mendeley Desktop/Itti/Itti - 2006 - Quantitative modelling of perceptual salience at human eye position - Visual Cognition.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
month = aug,
number = {4-8},
pages = {959--984},
title = {{Quantitative modelling of perceptual salience at human eye position}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/13506280500195672\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {14},
year = {2006}
}
@incollection{Kahneman1984,
author = {Kahneman, D. and Treisman, A.},
booktitle = {Varieties of Attention},
editor = {Parasuraman, R. and Davies, R.},
pages = {29--61},
publisher = {New York: Academic Press},
title = {{Changing views of attention and automaticity}},
year = {1984}
}
@book{Sherrington1906,
author = {Sherrington, Sir Charles Scott},
pages = {411},
publisher = {Yale University Press},
title = {{The Integrative action of the nervous system}},
url = {http://books.google.co.uk/books/about/The\_Integrative\_action\_of\_the\_nervous\_sy.html?id=LxEOeQd7MLkC\&pgis=1},
year = {1906}
}
@article{Blythe2006,
abstract = {Recent evidence indicates that each eye does not always fixate the same letter during reading and there has been some suggestion that processing difficulty may influence binocular coordination. We recorded binocular eye movements from children and adults reading sentences containing a word frequency manipulation. We found disparities of significant magnitude between the two eyes for all participants, with greater disparity magnitudes in children than adults. All participants made fewer crossed than uncrossed fixations. However, children made a higher proportion of crossed fixations than adults. We found no influence of word frequency on children's fixations and on binocular coordination in adults.},
author = {Blythe, Hazel I and Liversedge, Simon P and Joseph, Holly S S L and White, Sarah J and Findlay, John M and Rayner, Keith},
doi = {10.1016/j.visres.2006.06.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Blythe et al/Blythe et al. - 2006 - The binocular coordination of eye movements during reading in children and adults. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Age Factors,Child,Comprehension,Comprehension: physiology,Convergence, Ocular,Convergence, Ocular: physiology,Eye Movements,Eye Movements: physiology,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Photic Stimulation,Photic Stimulation: methods,Psycholinguistics,Reading,Vision Disparity,Vision Disparity: physiology,Vision, Binocular,Vision, Binocular: physiology},
month = oct,
number = {22},
pages = {3898--908},
pmid = {16879851},
title = {{The binocular coordination of eye movements during reading in children and adults.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16879851},
volume = {46},
year = {2006}
}
@article{Thompson2008,
author = {Thompson, W. L. and Kosslyn, S. M. and Hoffman, M. S. and {Van Der Kooij}, K.},
doi = {10.3758/MC.36.5.1024},
file = {:Users/pkmital/Documents/Mendeley Desktop/Thompson et al/Thompson et al. - 2008 - Inspecting visual mental images Can people see implicit properties as easily in imagery and perception - Memory.pdf:pdf},
issn = {0090-502X},
journal = {Memory \& Cognition},
month = jul,
number = {5},
pages = {1024--1032},
title = {{Inspecting visual mental images: Can people "see" implicit properties as easily in imagery and perception?}},
url = {http://www.springerlink.com/index/10.3758/MC.36.5.1024},
volume = {36},
year = {2008}
}
@article{Marat2009,
author = {Marat, Sophie and {Ho Phuoc}, Tien and Granjon, Lionel and Guyader, Nathalie and Pellerin, Denis and Gu\'{e}rin-Dugu\'{e}, Anne},
doi = {10.1007/s11263-009-0215-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Marat et al/Marat et al. - 2009 - Modelling Spatio-Temporal Saliency to Predict Gaze Direction for Short Videos - International Journal of Computer.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {diction,gaze pre-,saliency,spatio-temporal model,video viewing},
month = feb,
number = {3},
pages = {231--243},
title = {{Modelling Spatio-Temporal Saliency to Predict Gaze Direction for Short Videos}},
url = {http://link.springer.com/10.1007/s11263-009-0215-3},
volume = {82},
year = {2009}
}
@article{Fulkerson2012,
author = {Fulkerson, Brian},
doi = {10.1007/978-3-642-35740-4\_27},
file = {:Users/pkmital/Documents/Mendeley Desktop/Fulkerson/Fulkerson - 2012 - Really Quick Shift Image Segmentation on a GPU - Unknown.pdf:pdf},
isbn = {978-3-642-35739-8},
issn = {0302-9743},
keywords = {cuda,gpu programming,segmentation,super-pixels},
pages = {350--358},
title = {{Really Quick Shift: Image Segmentation on a GPU}},
volume = {6554},
year = {2012}
}
@article{Kumar2005,
author = {Kumar, S. and Hebert, M.},
doi = {10.1109/ICCV.2005.9},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kumar, Hebert/Kumar, Hebert - 2005 - A hierarchical field framework for unified context-based classification - Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1.pdf:pdf},
isbn = {0-7695-2334-X},
journal = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
pages = {1284--1291 Vol. 2},
publisher = {Ieee},
title = {{A hierarchical field framework for unified context-based classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544868},
year = {2005}
}
@misc{Rhodes1967,
author = {Rhodes, Richard},
booktitle = {The New York Times},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rhodes/Rhodes - 1967 - Cutting-Up - The New York Times.html:html},
month = jun,
title = {{Cutting-Up}},
url = {http://www.nytimes.com/books/00/02/13/specials/burroughs-ticket.html},
year = {1967}
}
@article{Nirnimesh2007a,
abstract = {Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda is scalable to large tile configurations and massive environments. It can transparently render any application built using the Open Scene Graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the server and network loads grow sublinearly with the increase in the number of tiles, which makes our scheme suitable to construct very large displays.},
author = {Nirnimesh and Harish, Pawan and Narayanan, P J},
file = {::},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Communication Networks,Computer Communication Networks: instrumentation,Computer Graphics,Computer Graphics: instrumentation,Data Display,Equipment Design,Equipment Failure Analysis,Image Enhancement,Image Enhancement: instrumentation,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: instrumen,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Microcomputers,Reproducibility of Results,Sensitivity and Specificity,Signal Processing, Computer-Assisted,Signal Processing, Computer-Assisted: instrumentat,User-Computer Interface},
number = {5},
pages = {864--77},
title = {{Garuda: a scalable tiled display wall using commodity PCs.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19099588},
volume = {13},
year = {2007}
}
@article{Irwin1998,
abstract = {Three experiments examined whether processes devoted to word recognition and word identification are suppressed during saccades, as most eye movement and reading researchers implicitly assume. In the first two experiments, subjects made short or long saccades while performing lexical decisions; lexical decision latency and accuracy were unaffected by saccade distance, and post-saccadic processing time was reduced when a long as opposed to a short saccade was made. Experiment 3 showed that word identification is more accurate when a long as opposed to a short saccade separates the presentation of a word and the presentation of a mask. These results demonstrate that lexical processing is not suppressed during saccades, so saccade durations should be taken into account in eye movement studies of reading. The implications of the results for current theories of cognitive suppression during saccades are discussed.},
author = {Irwin, D E},
doi = {10.1006/cogp.1998.0682},
file = {:Users/pkmital/Documents/Mendeley Desktop/Irwin/Irwin - 1998 - Lexical processing during saccadic eye movements. - Cognitive psychology.pdf:pdf},
issn = {0010-0285},
journal = {Cognitive psychology},
keywords = {Humans,Mental Processes,Mental Processes: physiology,Reaction Time,Saccades,Saccades: physiology,Vocabulary},
month = jun,
number = {1},
pages = {1--27},
pmid = {9679075},
title = {{Lexical processing during saccadic eye movements.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9679075},
volume = {36},
year = {1998}
}
@article{Steels2003,
author = {Steels, Luc},
doi = {10.1016/S1364-6613(03)00129-3},
file = {:Users/pkmital/Documents/Mendeley Desktop/Steels/Steels - 2003 - Evolving grounded communication for robots - Trends in Cognitive Sciences.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = jul,
number = {7},
pages = {308--312},
title = {{Evolving grounded communication for robots}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661303001293},
volume = {7},
year = {2003}
}
@article{Irwin2000,
abstract = {In three experiments we investigated whether attentional and oculomotor capture occur only when object-defining abrupt onsets are used as distractors in a visual search task, or whether other salient stimuli also capture attention and the eyes even when they do not constitute new objects. The results showed that abrupt onsets (new objects) are especially effective in capturing attention and the eyes, but that luminance increments that do not accompany the appearance of new objects capture attention as well. Color singletons do not capture attention unless subjects have experienced the color singleton as a search target in a previous experimental session. Both abrupt onsets and luminance increments elicit reflexive, involuntary saccades whereas transient color changes do not. Implications for theories of attentional capture are discussed.},
author = {Irwin, D E and Colcombe, a M and Kramer, a F and Hahn, S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Irwin et al/Irwin et al. - 2000 - Attentional and oculomotor capture by onset, luminance and color singletons. - Vision research.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Humans,Lighting,Male,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
number = {10-12},
pages = {1443--58},
pmid = {10788651},
title = {{Attentional and oculomotor capture by onset, luminance and color singletons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10788651},
volume = {40},
year = {2000}
}
@article{Kazai2003,
abstract = {The purpose of this study was to compare the lambda response of eye-fixation-related potentials (EFRPs) with the P100 component of pattern-reversal visual-evoked potentials. EFRPs were obtained by averaging EEGs time-locked to the offset of the saccade. The dipole of the lambda response and that of the P100 component were estimated by the dipole-tracing method (Musha \& Homma, 1990). The locations of their dipoles at the occipital sites were very close to each other when the difference waveform, which was calculated by subtracting the EFRP to the patternless stimulus from the EFRP to the patterned stimulus, was used for the lambda response. This finding implies that the lambda response and P100 have a common neural generator in the visual cortex. However, the peak latency of the lambda response was shorter than that of P100. The saccades in the EFRP trial were considered to be the cause of the difference.},
author = {Kazai, Koji and Yagi, Akihiro},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kazai, Yagi/Kazai, Yagi - 2003 - Comparison between the lambda response of eye-fixation-related potentials and the P100 component of pattern-reversal visual evoked potentials. - Cognitive, affective \& behavioral neuroscience.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective \& behavioral neuroscience},
keywords = {Adult,Electroencephalography,Evoked Potentials, Visual,Eye Movements,Humans,Male,Mental Processes,Mental Processes: physiology,Occipital Lobe,Occipital Lobe: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Reaction Time,Reaction Time: physiology,Reference Values,Reversal Learning,Saccades,Visual Perception,Visual Perception: physiology},
month = mar,
number = {1},
pages = {46--56},
pmid = {12822598},
title = {{Comparison between the lambda response of eye-fixation-related potentials and the P100 component of pattern-reversal visual evoked potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12822598},
volume = {3},
year = {2003}
}
@article{Henderson2007,
abstract = {Prior studies identify two cortical areas, posterior parahippocampal cortex and retrosplenial cortex, that preferentially activate to images of real-world scenes compared to images of other meaningful visual stimuli such as objects and faces. Behavioral and computational studies suggest that sub-categories of real-world scenes differ in their visual and semantic properties. It is presently unknown whether the cortical areas that have been implicated in scene analysis similarly activate differentially to behaviorally relevant scene sub-categories. To examine this issue, we directly compared cortical activation to indoor and outdoor scenes in an fMRI study with a large number of non-repeated images in each condition. Activation in posterior parahippocampal cortex, including parahippocampal place area, was significantly greater for indoor than outdoor scenes. In contrast, no such difference was observed in retrosplenial cortex, though this region preferentially activated to scenes over faces. These findings suggest differences in function in these two areas. The results are consistent with the view that posterior parahippocampal cortex is functional in processing local space.},
author = {Henderson, John M and Larson, Christine L and Zhu, David C},
doi = {10.1007/s00221-006-0766-2},
file = {:Users/pkmital/Documents/Mendeley Desktop/Henderson, Larson, Zhu/Henderson, Larson, Zhu - 2007 - Cortical activation to indoor versus outdoor scenes an fMRI study. - Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale.pdf:pdf},
issn = {0014-4819},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adolescent,Adult,Brain Mapping,Cues,Face,Female,Functional Laterality,Functional Laterality: physiology,Humans,Magnetic Resonance Imaging,Male,Neuropsychological Tests,Parahippocampal Gyrus,Parahippocampal Gyrus: anatomy \& histology,Parahippocampal Gyrus: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Space Perception,Space Perception: physiology,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Pathways,Visual Pathways: anatomy \& histology,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = may,
number = {1},
pages = {75--84},
pmid = {17123070},
title = {{Cortical activation to indoor versus outdoor scenes: an fMRI study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17123070},
volume = {179},
year = {2007}
}
@article{Bem2011,
abstract = {The term psi denotes anomalous processes of information or energy transfer that are currently unexplained in terms of known physical or biological mechanisms. Two variants of psi are precognition (conscious cognitive awareness) and premonition (affective apprehension) of a future event that could not otherwise be anticipated through any known inferential process. Precognition and premonition are themselves special cases of a more general phenomenon: the anomalous retroactive influence of some future event on an individual's current responses, whether those responses are conscious or nonconscious, cognitive or affective. This article reports 9 experiments, involving more than 1,000 participants, that test for retroactive influence by "time-reversing" well-established psychological effects so that the individual's responses are obtained before the putatively causal stimulus events occur. Data are presented for 4 time-reversed effects: precognitive approach to erotic stimuli and precognitive avoidance of negative stimuli; retroactive priming; retroactive habituation; and retroactive facilitation of recall. The mean effect size (d) in psi performance across all 9 experiments was 0.22, and all but one of the experiments yielded statistically significant results. The individual-difference variable of stimulus seeking, a component of extraversion, was significantly correlated with psi performance in 5 of the experiments, with participants who scored above the midpoint on a scale of stimulus seeking achieving a mean effect size of 0.43. Skepticism about psi, issues of replication, and theories of psi are also discussed.},
author = {Bem, Daryl J},
doi = {10.1037/a0021524},
file = {:Users/pkmital/Documents/Mendeley Desktop/Bem/Bem - 2011 - Feeling the future experimental evidence for anomalous retroactive influences on cognition and affect. - Journal of personality and social psychology.pdf:pdf},
issn = {1939-1315},
journal = {Journal of personality and social psychology},
month = mar,
number = {3},
pages = {407--25},
pmid = {21280961},
title = {{Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21280961},
volume = {100},
year = {2011}
}
@book{Fiebrink:2011:HME:1978942.1978965,
address = {New York, New York, USA},
author = {Fiebrink, Rebecca and Cook, Perry R. and Trueman, Dan},
booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11},
doi = {10.1145/1978942.1978965},
file = {::},
isbn = {9781450302289},
keywords = {evaluation,gesture,interactive machine learning,music},
pages = {147},
publisher = {ACM Press},
series = {CHI '11},
title = {{Human model evaluation in interactive supervised learning}},
url = {http://doi.acm.org/10.1145/1978942.1978965},
year = {2011}
}
@article{Prinz,
author = {Prinz, Jesse J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prinz/Prinz - Unknown - Sensation and Perception - Unknown.pdf:pdf},
title = {{Sensation and Perception}}
}
@article{Panin2007,
author = {Panin, Giorgio and Knoll, Alois},
doi = {10.1007/s11263-007-0083-7},
file = {:Users/pkmital/Documents/Mendeley Desktop/Panin, Knoll/Panin, Knoll - 2007 - Mutual Information-Based 3D Object Tracking - International Journal of Computer Vision.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {3d tracking,b-spline,information,interpolation,multiresolution,mutual,nonlinear optimization,surface-image alignment,template},
month = oct,
number = {1},
pages = {107--118},
title = {{Mutual Information-Based 3D Object Tracking}},
url = {http://www.springerlink.com/index/10.1007/s11263-007-0083-7},
volume = {78},
year = {2007}
}
@article{Mital2010,
author = {Mital, Parag K. and Smith, Tim J. and Hill, Robin L. and Henderson, John M.},
doi = {10.1007/s12559-010-9074-z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mital et al/Mital et al. - 2011 - Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion - Cognitive Computation.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {eye movements \'{a} dynamic,scenes \'{a} features \'{a},visual attention \'{a} clustering},
month = oct,
title = {{Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion}},
url = {http://www.springerlink.com/index/10.1007/s12559-010-9074-z},
year = {2010}
}
@article{Prinz2007,
author = {Prinz, Jesse J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Prinz/Prinz - 2007 - When is Film Art - Most.pdf:pdf},
journal = {Most},
pages = {1--10},
title = {{When is Film Art ?}},
year = {2007}
}
@article{Rasmussen2007,
author = {Rasmussen, Carl Edward},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasmussen/Rasmussen - 2007 - Bayesian Inference and Gaussian Processes - Unknown.pdf:pdf},
title = {{Bayesian Inference and Gaussian Processes}},
year = {2007}
}
@article{Fiebrink2010,
address = {New York, New York, USA},
author = {Fiebrink, Rebecca},
doi = {10.1145/1753846.1753889},
isbn = {9781605589305},
journal = {Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10},
keywords = {2,5,6,acm classification keywords,computer music,graphical user interface,h,human computer interaction,i,interface design,machine learning,music performance,user interfaces},
mendeley-tags = {computer music,human computer interaction},
pages = {2935},
publisher = {ACM Press},
title = {{Real-time interaction with supervised learning}},
url = {http://portal.acm.org/citation.cfm?doid=1753846.1753889},
year = {2010}
}
@book{Fiebrink:2011:HME:1978942.1978965,
address = {New York, New York, USA},
author = {Fiebrink, Rebecca and Cook, Perry R. and Trueman, Dan},
booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11},
doi = {10.1145/1978942.1978965},
file = {::},
isbn = {9781450302289},
keywords = {evaluation,gesture,interactive machine learning,music},
pages = {147},
publisher = {ACM Press},
series = {CHI '11},
title = {{Human model evaluation in interactive supervised learning}},
url = {http://doi.acm.org/10.1145/1978942.1978965},
year = {2011}
}
@article{Noe2002,
author = {No\"{e}, Alva},
file = {:Users/pkmital/Documents/Mendeley Desktop/No\"{e}/No\"{e} - 2002 - Is the Visual World - Unknown.PDF:PDF},
number = {5},
pages = {1--12},
title = {{Is the Visual World}},
year = {2002}
}
@article{Cahtarevic2008,
author = {Cahtarevic, Rada},
doi = {10.2298/FUACE0802235C},
file = {:Users/pkmital/Documents/Mendeley Desktop/Cahtarevic/Cahtarevic - 2008 - Virtuality in architecture From perspective representation to augmented reality - Facta universitatis - series Architecture and Civil Engineering.pdf:pdf},
issn = {0354-4605},
journal = {Facta universitatis - series: Architecture and Civil Engineering},
keywords = {architectural representation,information,virtual space},
number = {2},
pages = {235--241},
title = {{Virtuality in architecture: From perspective representation to augmented reality}},
url = {http://www.doiserbia.nb.rs/Article.aspx?ID=0354-46050802235C},
volume = {6},
year = {2008}
}
@article{Couturier2002,
author = {Couturier, D and Kessous, J M and Verfaille, L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Couturier, Kessous, Verfaille/Couturier, Kessous, Verfaille - 2002 - Parameters using Perceptual Spaces - Organised Sound.pdf:pdf},
journal = {Organised Sound},
number = {2},
pages = {135--152},
title = {parameters using perceptual spaces},
volume = {7},
year = {2002}
}
@article{Klein2007,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspaces - 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@article{Lucas1981,
author = {Lucas, Bruce D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lucas, Bruce D Kanade/Lucas, Bruce D Kanade - 1981 - An Iterative Image Registration Technique with an Application to Stereo Vision - Imaging.pdf:pdf},
journal = {Imaging},
pages = {121--130},
title = {{An Iterative Image Registration Technique with an Application to Stereo Vision}},
volume = {130},
year = {1981}
}
@article{Filimowicz2010,
author = {Filimowicz, M. and Stockholm, J.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Filimowicz, Stockholm/Filimowicz, Stockholm - 2010 - Towards a phenomenology of the acoustic image - Organised Sound.pdf:pdf},
issn = {1469-8153},
journal = {Organised Sound},
number = {01},
pages = {5--12},
publisher = {Cambridge Univ Press},
title = {{Towards a phenomenology of the acoustic image}},
url = {http://journals.cambridge.org/abstract\_S1355771809990215},
volume = {15},
year = {2010}
}
@article{Mairal2009,
author = {Mairal, Julien and Bach, Francis and Ponce, J and Sapiro, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mairal et al/Mairal et al. - 2009 - Online dictionary learning for sparse coding - \ldots Conference on Machine Learning.pdf:pdf},
journal = {\ldots Conference on Machine Learning},
title = {{Online dictionary learning for sparse coding}},
url = {http://dl.acm.org/citation.cfm?id=1553463},
year = {2009}
}
@article{Klein2009,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2009.5336495},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klein, Murray/Klein, Murray - 2009 - Parallel Tracking and Mapping on a camera phone - 2009 8th IEEE International Symposium on Mixed and Augmented Reality.pdf:pdf},
isbn = {978-1-4244-5390-0},
journal = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
month = oct,
pages = {83--86},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping on a camera phone}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5336495},
year = {2009}
}
@article{Duan2012,
author = {Duan, Zhiyao and Mysore, Gautham J and Smaragdis, Paris},
file = {:Users/pkmital/Documents/Mendeley Desktop/Duan, Mysore, Smaragdis/Duan, Mysore, Smaragdis - 2012 - Online PLCA for Real-time Semi-supervised Source Separation - Proceedings of the international conferen.pdf:pdf},
journal = {Proceedings of the international conference on Latent Variable Analysis / Independent Component Analysis},
pages = {1--8},
title = {{Online PLCA for Real-time Semi-supervised}},
year = {2012}
}
@book{Fails:2003:IML:604045.604056,
address = {New York, New York, USA},
author = {Fails, Jerry Alan and Olsen, Dan R.},
booktitle = {Proceedings of the 8th international conference on Intelligent user interfaces - IUI '03},
doi = {10.1145/604045.604056},
file = {::},
isbn = {1581135866},
keywords = {classification,image processing,interaction,machine learning,perceptive user interfaces},
pages = {39},
publisher = {ACM Press},
series = {IUI '03},
title = {{Interactive machine learning}},
url = {http://doi.acm.org/10.1145/604045.604056},
year = {2003}
}
@inproceedings{Ashbrook2010,
author = {Ashbrook, Daniel and Starner, Thad},
booktitle = {Proceedings of the 28th international conference on Human factors in computing systems},
file = {::},
keywords = {gesture recognition,human computer interaction},
mendeley-tags = {gesture recognition,human computer interaction},
pages = {2159--2168},
publisher = {ACM},
title = {{MAGIC: a motion gesture design tool}},
url = {http://portal.acm.org/citation.cfm?id=1753653},
year = {2010}
}
@book{Kapoor:2010:IOS:1753326.1753529,
address = {New York, New York, USA},
author = {Kapoor, Ashish and Lee, Bongshin and Tan, Desney and Horvitz, Eric},
booktitle = {Proceedings of the 28th international conference on Human factors in computing systems - CHI '10},
doi = {10.1145/1753326.1753529},
file = {::},
isbn = {9781605589299},
keywords = {decision theory,interactive machine learning,interactive optimization,visualization},
pages = {1343},
publisher = {ACM Press},
series = {CHI '10},
title = {{Interactive optimization for steering machine classification}},
url = {http://doi.acm.org/10.1145/1753326.1753529},
year = {2010}
}
@article{Noe2004,
author = {No\"{e}, Alva and Thompson, Evan},
file = {:Users/pkmital/Documents/Mendeley Desktop/Noe, Thompson/Noe, Thompson - 2004 - Are there neural correlates of consciousness - Journal of Consciousness studies.pdf:pdf},
number = {1},
pages = {3--28},
title = {{Are There Neural Correlates 1 of Consciousness?}},
year = {2004}
}
@article{Mairal2010,
author = {Mairal, Julien and Bach, Francis and Ponce, J and Sapiro, Guillermo},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mairal et al/Mairal et al. - 2010 - Online learning for matrix factorization and sparse coding - The Journal of Machine Learning \ldots.pdf:pdf},
journal = {The Journal of Machine Learning \ldots},
keywords = {basis pursuit,dictionary learning,ing,matrix factorization,negative matrix factorization,non-,online learning,sparse cod-,sparse principal component analysis,stochastic approximations,stochastic optimization},
pages = {19--60},
title = {{Online learning for matrix factorization and sparse coding}},
url = {http://dl.acm.org/citation.cfm?id=1756008},
volume = {11},
year = {2010}
}
@article{Wanderley2005a,
author = {Wanderley, M.M. and Depalle, P.},
doi = {10.1109/JPROC.2004.825882},
file = {::},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {audio systems,music,signal synthesis,user inter-},
month = apr,
number = {4},
pages = {632--644},
publisher = {IEEE},
title = {{Gestural control of sound synthesis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1278687},
volume = {92},
year = {2005}
}
@article{Rasmussen2000,
author = {Rasmussen, Carl Edward},
file = {:Users/pkmital/Documents/Mendeley Desktop/Rasmussen/Rasmussen - 2000 - The Infinite Gaussian Mixture Model - Processing.pdf:pdf},
journal = {Processing},
pages = {554--560},
title = {{The Infinite Gaussian Mixture Model}},
year = {2000}
}
@article{Zhang2004a,
author = {Zhang, D},
doi = {10.1016/j.patcog.2003.07.008},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zhang, Lu/Zhang, Lu - 2004 - Review of shape representation and description techniques - Pattern recognition.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {cbir,image retrieval,review,shape,shape descriptor},
month = jan,
number = {1},
pages = {1--19},
title = {{Review of shape representation and description techniques}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320303002759},
volume = {37},
year = {2004}
}
@article{Nam2009,
author = {Nam, Tek-Jin and Sakong, Kyung},
file = {::},
journal = {International Journal of Design},
keywords = {augmented reality,collaborative design,interaction,shared 3d workspace,tangible interaction,tele presence},
number = {1},
pages = {43--55},
title = {{Collaborative 3D Workspace and Interaction Techniques for Synchronous Distributed Product Design Reviews}},
url = {http://www.ijdesign.org/ojs/index.php/IJDesign/article/view/387/240},
volume = {3},
year = {2009}
}
@inproceedings{Starner2000,
abstract = {Computer gaming offers a unique test-bed and market for advanced concepts in computer science, such as Human Computer Interaction (HCI), computer-supported collaborative work (CSCW), intelligent agents, graphics, and sensing technology. In addition, computer gaming is especially wellsuited for explorations in the relatively young fields of wearable computing and augmented reality (AR). This paper presents a developing multi-player augmented reality game, patterned as a cross between a martial arts fighting game and an agent controller, as implemented using the Wearable Augmented Reality for Personal, Intelligent, and Networked Gaming (WARPING) system. Through interactions based on gesture, voice, and head movement input and audio and graphical output, the WARPING system demonstrates how computer vision techniques can be exploited for advanced, intelligent interfaces. Keywords Augmented reality, wearable computing, computer vision 1. INTRODUCTION: WHY GAMES? Computer gaming provides...},
author = {Starner, Thad and Leibe, Bastian and Singletary, Brad and Pair, Jarrell},
booktitle = {Interface},
doi = {10.1145/325737.325864},
file = {::},
isbn = {1581131348},
keywords = {augmented reality,computer vision,wearable computing},
pages = {256--259},
publisher = {ACM},
title = {{MIND-WARPING : Towards Creating a Compelling Collaborative Augmented Reality Game}},
url = {http://portal.acm.org/citation.cfm?id=325737.325864},
year = {2000}
}
@article{Comport2006,
abstract = {Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a "video see through" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. Here, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.},
author = {Comport, A.I. and Marchand, Eric and Pressigout, Muriel and Chaumette, Fran\c{c}ois},
doi = {10.1109/TVCG.2006.78},
file = {::},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms,Computer Graphics,Computer Systems,Computer-Assisted,Computer-Assisted: methods,Feedback,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Signal Processing,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface},
number = {4},
pages = {615--628},
pmid = {16805268},
publisher = {IEEE Computer Society},
title = {{Real-time markerless tracking for augmented reality: the virtual visual servoing framework}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16805268 http://www.computer.org/portal/web/csdl/doi/10.1109/tvcg.2006.78},
volume = {12},
year = {2006}
}
@article{Bajuraa,
author = {Bajura, Michael and Hill, U N C Chapel and Neumann, Ulrich and Reality, Keywords Augmented},
file = {::},
keywords = {augmented reality,reality,registration,virtual},
title = {{Dynamic Registration Correction in Video-Based Augmented Reality Systems}}
}
@article{Knoerlein2007,
address = {New York, New York, USA},
author = {Knoerlein, Benjamin},
doi = {10.1145/1255047.1255065},
file = {::},
isbn = {9781595936400},
journal = {Proceedings of the},
keywords = {augmented reality,collaboration,haptics},
pages = {91},
publisher = {ACM Press},
title = {{Visuo-haptic collaborative augmented reality ping-pong}},
url = {http://portal.acm.org/citation.cfm?doid=1255047.1255065 http://portal.acm.org/citation.cfm?id=1255065},
year = {2007}
}
@article{DeBoer2011,
author = {de Boer, Jelle and a.M. Kommers, Piet and de Brock, Bert},
doi = {10.1016/j.compedu.2010.10.015},
file = {::},
issn = {03601315},
journal = {Computers \& Education},
month = apr,
number = {3},
pages = {727--735},
publisher = {Elsevier Ltd},
title = {{Using learning styles and viewing styles in streaming video}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131510003003},
volume = {56},
year = {2011}
}
@incollection{Khoo2010,
abstract = {This chapter presents steps for designing an intergenerational mixed reality entertainment system, which focuses on physical and social interactions using a mixed reality floor system. The main design goals include the following: facilitating interactions between users with varied levels of skill in utilizing technology, utilizing the familiar physical motions from other activities to make an intuitive physical interface, and encouraging social interactions among families and friends. Detailed implementation of these steps is presented in the design of our intergenerational entertainment system, Age Invaders. Our design process is based on user-centered design. The results of the study help to focus the refinements of the existing platform from a usability standpoint and also aid in the development of new physical entertainment and interactive applications. This study provides insights into user issues including how users interact in a complex mixed reality experience.},
author = {Khoo, Eng Tat and Merritt, Tim and Cheok, Adrian David},
booktitle = {The Engineering of Mixed Reality Systems},
chapter = {7},
doi = {10.1007/978-1-84882-733-2},
editor = {Dubois, Emmanuel and Gray, Philip and Nigay, Laurence},
file = {::},
isbn = {9781848827349},
pages = {121--141},
publisher = {Springer London},
series = {Human-Computer Interaction Series},
title = {{Designing a Mixed Reality Intergenerational Entertainment System}},
url = {http://www.springerlink.com/content/r60h1v521r572j71},
year = {2010}
}
@article{Barakonyi2003,
author = {Barakonyi, I. and Fahmy, T. and Schmalstieg, Dieter},
file = {::},
isbn = {0769520065},
journal = {and Augmented Reality},
keywords = {augmented reality,computer supported col-,laborative work,videoconferencing,volume rendering},
pages = {333},
publisher = {IEEE Computer Society},
title = {{Collaborative work with volumetric data using augmented reality videoconferencing}},
url = {http://portal.acm.org/citation.cfm?id=946833},
year = {2003}
}
@article{Dunston2003,
abstract = {Design visualization is key to the communication and shared perception of designs and is essential for meaningful design development and collaborations. The initial development of an Augmented Reality Computer Aided Drawing (AR CAD) system for enhancing visualization of models created in standard CAD was presented at the 17th ISARC. AR CAD features a more natural mode for changing views of the model and completely understanding the model content. Expected benefits are improved efficiency in the design detailing function, both for the individual detailer and for design collaborations where maintaining an accurate shared understanding of the design model is critical. An experimental program is under way to examine the impact of AR CAD upon a users perception and recall of a design model. Related experiments with desktop and immersive virtual environments have found that motion cues can indeed markedly improve spatial cognition. It is expected that we will see the same benefits in our AR CAD system, although until now such studies have not been conducted in an AR environment. This paper presents the rationale for experiments to measure the impact of AR CAD in terms of cognition cost, and it lays the foundation for further application of Mixed Reality (MR) technology to the design, construction, and maintenance phases of a facilitys life cycle. MR applications may prove promising for effective communication of designs for prefabrication, site installation, and the planning and excecution of maintenance operations.},
author = {Dunston, P and Wang, X and Billinghurst, M and Hampson, B},
file = {::},
journal = {NIST SPECIAL PUBLICATION SP},
keywords = {3d cad,augmented reality,mixed reality,spatial cognition,visualization},
pages = {1--6},
publisher = {NATIONAL INSTIUTE OF STANDARDS \& TECHNOLOGY},
title = {{Mixed Reality benefits for design perception}},
url = {http://www.hitlabnz.org/publications/2002-ISARC-MixedReality.pdf},
year = {2003}
}
@article{Nilsson2009,
author = {Nilsson, Susanna and Gustafsson, Torbj\"{o}rn and Carleberg, Per},
file = {::},
journal = {PsychNology Journal},
keywords = {augmented reality,gaze,gaze controlled augmented reality,mixed reality},
number = {2},
pages = {175 -- 196},
publisher = {Citeseer},
title = {{Hands Free Interaction with Virtual Information in a Real Environment : Eye Gaze as an Interaction Tool in an Augmented Reality System}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Hands+Free+Interaction+with+Virtual+Information+in+a+Real+Environment+:+Eye+Gaze+as+an+Interaction+Tool+in+an+Augmented+Reality+System\#0},
volume = {7},
year = {2009}
}
@article{Vasilakos2008,
abstract = {Our system of Mixed Reality and 3D Live with Ambient Intelligence (AmI) is indented to bring performance art to the people while offering to the performance artists a creative tool to extend the grammar of the traditional theatre. Actors and dancers at different places are captured by multiple cameras and their images are rendered in 3D form in such a way that they can play and dance together on the same place in real-time. Our Quanticum Man is an allegory of the time of the General Relativity and the matter of the Quantum Mechanics. The new type of interactive theatre enables social networking by supporting simultaneous participants in human-to-human social manner.},
author = {Vasilakos, A and Wei, L and Nguyen, T and Thienqui, T and Chen, L and Boj, C and Diaz, D and Cheok, A and Marentakis, G},
doi = {10.1016/j.ins.2007.08.029},
file = {::},
issn = {00200255},
journal = {Information Sciences},
keywords = {3d live,ambient intelligence,interactive theatre,mixed reality,performance art},
number = {3},
pages = {679--693},
publisher = {Elsevier Science Inc.},
title = {{Interactive theatre via mixed reality and Ambient Intelligence}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025507004033},
volume = {178},
year = {2008}
}
@article{Juan2010,
author = {Juan, Carmen M. and Llop, Edith and Abad, Francisco and Lluch, Javier},
doi = {10.1109/ICALT.2010.123},
file = {::},
isbn = {978-1-4244-7144-7},
journal = {2010 10th IEEE International Conference on Advanced Learning Technologies},
keywords = {augmented reality,edutainment,learning words},
month = jul,
pages = {422--426},
publisher = {Ieee},
title = {{Learning Words Using Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5572407},
year = {2010}
}
@article{Martens2004,
author = {Martens, Jean-Bernard and Qi, Wen and Aliakseyeu, Dima and Kok, Arjan J F and {Van Liere}, Robert},
doi = {10.1145/1031419.1031425},
file = {::},
isbn = {1581139926},
journal = {Proceedings of the 2nd European Union symposium on Ambient intelligence EUSAI 04},
keywords = {3d interaction,augmented reality,human computer interaction,natural,optical tracking,virtual reality},
number = {November},
pages = {25},
publisher = {ACM Press},
title = {{Experiencing 3D interactions in virtual reality and augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1031419.1031425},
volume = {telligence},
year = {2004}
}
@article{Shin2009,
author = {Shin, Do Hyoung and Jang, Won-Suk},
doi = {10.1016/j.autcon.2009.06.001},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
month = dec,
number = {8},
pages = {1063--1069},
publisher = {Elsevier B.V.},
title = {{Utilization of ubiquitous computing for construction AR technology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580509000922},
volume = {18},
year = {2009}
}
@article{Park2006,
author = {Park, Sang-cheol and Lee, Sang-woong and Lee, Seong-whan},
doi = {10.1109/ICPR.2006.1093},
file = {::},
isbn = {0-7695-2521-0},
journal = {18th International Conference on Pattern Recognition (ICPR'06)},
pages = {897--900},
publisher = {Ieee},
title = {{Superimposing 3D Virtual Objects using Markerless Tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1699670},
year = {2006}
}
@inproceedings{Reitmayr2004,
abstract = {Augmented reality (AR) can provide an excellent user interface for visualization in a mobile computing application. The user's view is augmented with location based information at the correct spatial location, thus providing an intuitive way of presenting such information. In this work we demonstrate the use of AR for collaborative navigation and information browsing tasks in an urban environment. A navigation function allows one or more users to roam through a city and guides them to selected destinations. Information browsing presents users with information about objects in their surrounding. Both functions feature support for collaboration. The developed system does not only concentrate on the user interface aspects but also provides a scalable infrastructure to support mobile applications. To this end we developed a 3-tier architecture to manage a common data model for a set of applications. It is inspired by current Internet application frameworks and consists of a central storage layer using a common data model, a transformation layer responsible for filtering and adapting the data to the requirements of a particular applications on request, and finally of the applications itself.},
author = {Reitmayr, Gerhard and Schmalstieg, Dieter},
booktitle = {Science},
file = {::},
pages = {31--41},
publisher = {Citeseer},
title = {{Collaborative augmented reality for outdoor navigation and information browsing}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.1864\&amp;rep=rep1\&amp;type=pdf},
volume = {66},
year = {2004}
}
@article{Bradley2007,
author = {Bradley, Derek and Roth, Gerhard and Bose, Prosenjit},
doi = {10.1007/s00138-007-0108-9},
file = {::},
isbn = {0013800701},
issn = {0932-8092},
journal = {Machine Vision and Applications},
keywords = {augmented reality,common illumination,marker systems,non-rigid object,tracking},
month = nov,
number = {2},
pages = {85--92},
title = {{Augmented reality on cloth with realistic illumination}},
url = {http://www.springerlink.com/index/10.1007/s00138-007-0108-9},
volume = {20},
year = {2007}
}
@article{Anastassova2009,
abstract = {The paper presents an ergonomic analysis carried out in the early phases of an R\&D project. The purpose was to investigate the functioning of today's Automotive Service Technicians (ASTs) training in order to inform the design of an Augmented Reality (AR) teaching aid. The first part of the paper presents a literature review of some major problems encountered by ASTs today. The benefits of AR as technological aid are also introduced. Then, the methodology and the results of two case studies are presented. The first study is based on interviews with trainers and trainees; the second one on observations in real training settings. The results support the assumption that today's ASTs' training could be regarded as a community-of-practice (CoP). Therefore, AR could be useful as a collaboration tool, offering a shared virtual representation of real vehicle's parts, which are normally invisible unless dismantled (e.g. the parts of a hydraulic automatic transmission). We conclude on the methods and the technologies to support the automotive CoP.},
author = {Anastassova, Margarita and Burkhardt, Jean-Marie},
doi = {10.1016/j.apergo.2008.06.008},
file = {::},
issn = {1872-9126},
journal = {Applied ergonomics},
keywords = {Adult,Automobiles,Human Engineering,Humans,Male,Middle Aged,Task Performance and Analysis,Teaching,Teaching: methods,Technology,User-Computer Interface,Workplace,Young Adult},
month = jul,
number = {4},
pages = {713--21},
pmid = {18703179},
title = {{Automotive technicians' training as a community-of-practice: implications for the design of an augmented reality teaching aid.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18703179},
volume = {40},
year = {2009}
}
@article{Attfield2005,
author = {Attfield, S and Blandford, A and Mottram, C and Penn, A and {Fatah Gen Schieck}, A},
file = {::},
publisher = {Key Centre of Design Computing and Cognition, University of Sydney},
title = {{Exploring the effects of introducing real-time simulation on collaborative urban design in augmented reality}},
url = {http://discovery.ucl.ac.uk/1472/},
year = {2005}
}
@article{Zhou2008a,
author = {Zhou, F. and Duh, H.B.L. and Billinghurst, Mark},
doi = {10.1109/ISMAR.2008.4637362},
file = {::},
isbn = {978-1-4244-2840-3},
journal = {2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
month = sep,
pages = {193--202},
publisher = {IEEE},
title = {{Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4637362 http://www.computer.org/portal/web/csdl/doi/10.1109/ISMAR.2008.4637362},
year = {2008}
}
@phdthesis{DeLaRiviere2001,
author = {{De La Rivi\`{e}re}, Jean-Baptiste},
file = {::},
title = {{Interaction 3D : Utilisations Conjointes d’un pointeur Laser et d’un Grand Ecran}},
year = {2001}
}
@article{Fischer2005,
author = {Fischer, J. and Bartz, D. and Strasser, W.},
doi = {10.1109/VR.2005.1492774},
file = {::},
isbn = {0-7803-8929-8},
journal = {IEEE Proceedings. VR 2005. Virtual Reality, 2005.},
keywords = {augmented reality,immersion,non-,painterly filtering,photorealistic rendering},
pages = {195--325},
publisher = {Ieee},
title = {{Stylized augmented reality for improved immersion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1492774},
volume = {2005},
year = {2005}
}
@inproceedings{Kurz2011a,
author = {Kurz, Daniel and Benhimane, Selim},
booktitle = {IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {Handheld Augmented Reality Inertial Sensors Gravit},
pages = {111--120},
title = {{Gravity-Aware Handheld Augmented Reality}},
url = {http://da.nielkurz.de/content/Gravity-Aware\_Handheld\_Augmented\_Reality},
year = {2011}
}
@article{Chen2009a,
author = {Chen, David M. and Tsai, Sam S. and Vedantham, Ramakrishna and Grzeszczuk, Radek and Girod, Bernd},
doi = {10.1109/ISMAR.2009.5336472},
file = {::},
isbn = {978-1-4244-5390-0},
journal = {2009 8th IEEE International Symposium on Mixed and Augmented Reality},
month = oct,
pages = {181--182},
publisher = {Ieee},
title = {{Streaming mobile augmented reality on mobile phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5336472},
year = {2009}
}
@article{Systems2003,
author = {Systems, Interactive Graphics},
file = {::},
journal = {Science},
publisher = {Citeseer},
title = {{Storytelling in Collaborative Augmented Reality Environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.1924\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{Langlotz2011,
author = {Langlotz, Tobias and Degendorfer, Claus and Mulloni, Alessandro and Schall, Gerhard and Reitmayr, Gerhard and Schmalstieg, Dieter},
doi = {10.1016/j.cag.2011.04.004},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Annotation,Augmented reality,Mobile phone,Tracking},
month = aug,
number = {4},
pages = {831--840},
publisher = {Elsevier},
title = {{Robust detection and tracking of annotations for outdoor augmented reality browsing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001075},
volume = {35},
year = {2011}
}
@article{Siegl2007,
author = {Siegl, H and Hanheide, M and Wrede, S and Pinz, a},
doi = {10.1016/j.imavis.2006.04.027},
file = {::},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {3d cursor,cognitive vision system,computer interaction,human,mobile augmented reality},
month = dec,
number = {12},
pages = {1895--1903},
title = {{An augmented reality human–computer interface for object localization in a cognitive vision system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885606002873},
volume = {25},
year = {2007}
}
@article{Cheok2002,
abstract = {This paper presents an interactive theatre based on an embodied mixed reality space and wearable computers. Embodied computing mixed reality spaces integrate ubiquitous computing, tangible interaction and social computing within a mixed reality space, which enables intuitive interaction with physical world and virtual world. We believe it has potential advantages to support novel interactive theatre experiences. Therefore, we explored the novel interactive theatre experience supported in the embodied mixed reality space, and implemented live 3D characters to interact with user in such a system.},
author = {Cheok, A D and Weihua, Wang and Yang, Xubo and Prince, S and Wan, Fong Siew and Billinghurst, M and Kato, H},
doi = {10.1109/ISMAR.2002.1115073},
file = {::},
isbn = {0769517811},
journal = {Proceedings International Symposium on Mixed and Augmented Reality},
pages = {59--317},
publisher = {IEEE Computer Society},
title = {{Interactive theatre experience in embodied + wearable mixed reality space}},
url = {http://portal.acm.org/citation.cfm?id=850976.854978},
year = {2002}
}
@article{Lamboray2004,
author = {Lamboray, E. and Wurmlin, S. and Gross, M.},
doi = {10.1109/VR.2004.1310060},
file = {::},
isbn = {0-7803-8415-6},
journal = {IEEE Virtual Reality 2004},
pages = {91--281},
publisher = {Ieee},
title = {{Real-time streaming of point-based 3D video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1310060},
year = {2004}
}
@article{Thomas2010,
abstract = {The use of Virtual Environments has been widely reported as a method of teaching anatomy. Generally such environments only convey the shape of the anatomy to the student. We present the Bangor Augmented Reality Education Tool for Anatomy (BARETA), a system that combines Augmented Reality (AR) technology with models produced using Rapid Prototyping (RP) technology, to provide the student with stimulation for touch as well as sight. The principal aims of this work were to provide an interface more intuitive than a mouse and keyboard, and to evaluate such a system as a viable supplement to traditional cadaver based education.},
author = {Thomas, Rhys Gethin and John, Nigel William and Delieu, John Michael},
doi = {10.3109/17453050903557359},
file = {::},
issn = {1745-3062},
journal = {Journal of visual communication in medicine},
keywords = {Anatomy,Anatomy: education,Cadaver,Computer Simulation,Consumer Satisfaction,Female,Humans,Magnetic Resonance Imaging,Male,Models, Biological,Pilot Projects,Sex Factors,User-Computer Interface},
month = mar,
number = {1},
pages = {6--15},
pmid = {20297908},
title = {{Augmented reality for anatomical education.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20297908},
volume = {33},
year = {2010}
}
@article{Wrzesien2010,
abstract = {Recent research presents Augmented Reality Exposure Therapy (ARET) for treatment of phobia of cockroaches as a potentially effective technique. However, to the authors' knowledge no studies have been published concerning the Human-Computer-Interaction issues of such a system. The aim of this paper is to report some preliminary data on how patients, therapists and an Augmented Reality system collaborate and interact during the therapeutic process. The results show that the therapeutic process is distributed between individuals (patient and therapist) and artifacts (e.g. AR cockroaches, a computer screen, a Head Mounted Display (HMD), a keyboard, a swatter and therapists' notes on paper). The results are discussed in terms of possible improvement of the ARET system.},
author = {Wrzesien, Maja and Burkhardt, Jean-Marie and {Alca\~{n}iz Raya}, Mariano and Botella, Cristina and {Bret\'{o}n L\'{o}pez}, Juana Maria},
file = {::},
institution = {Instituto Interuniversitario de Investigaci\'{o}n en Bioingenier\'{\i}a y Tecnolog\'{\i}a Orientada al Ser Humano, Universidad Polit\'{e}cnica de Valencia (I3BH), (UPV), 46022 Valencia, Espa\~{n}a. mwrzesien@labhuman.i3bh.es},
journal = {Studies In Health Technology And Informatics},
pages = {134--139},
pmid = {20543285},
title = {{Analysis of distributed-collaborative activity during augmented reality exposure therapy for cockroach phobia.}},
volume = {154},
year = {2010}
}
@inproceedings{Kurz2012,
author = {Kurz, Daniel and Olszamowski, Thomas and Benhimane, Selim},
booktitle = { IEEE and ACM International Symposium on Mixed and Augmented Reality},
title = {{Representative Feature Descriptor Sets for Robust Handheld Camera Localization}},
url = {http://da.nielkurz.de/content/Representative\_Feature\_Descriptor\_Sets\_for\_Robust\_Handheld\_Camera\_Localization},
year = {2012}
}
@article{Pan2006,
author = {Pan, Z and Cheok, a and Yang, H and Zhu, J and Shi, J},
doi = {10.1016/j.cag.2005.10.004},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {collaborative,cooperative,edutainment,mixed reality,virtual learning environment,virtual reality,vle},
month = feb,
number = {1},
pages = {20--28},
title = {{Virtual reality and mixed reality for virtual learning environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849305002025},
volume = {30},
year = {2006}
}
@article{Klineca,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
journal = {ifp.uni-stuttgart.de},
pages = {1--12},
title = {{POSITIONING AND LOCATION SERVICES}},
url = {http://www.ifp.uni-stuttgart.de/publications/2001/Klinec\_Indoornav2001.pdf}
}
@article{Broll2004,
author = {Broll, Wolfgang and Lindt, Irma and Ohlenburg, J and Wittkamper, Michael and Yuan, C and Novotny, T and Schieck, A F and Mottram, C and Strothman, A},
file = {::},
issn = {18602037},
journal = {Journal of Virtual Reality and Broadcasting},
keywords = {architectural design,augmented reality,simu,tangible user,terfaces,urban planning},
number = {1},
pages = {1--10},
publisher = {Citeseer},
title = {{ARTHUR: A Collaborative Augmented Environment for Architectural Design and Urban Planning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.184\&amp;rep=rep1\&amp;type=pdf},
volume = {1},
year = {2004}
}
@article{Steinicke2008a,
author = {Steinicke, Frank and Bruder, Gerd and Ropinski, Timo and Hinrichs, Klaus},
file = {::},
journal = {Proceedings of IEEE VRIC 2008 : 10th International Conference on Virtual Reality},
title = {{Moving Towards Generally Applicable Redirected Walking}},
url = {http://viscg.uni-muenster.de/publications/2008/SBRH08/},
year = {2008}
}
@article{Ong2007,
author = {Ong, S.K. and Pang, Y. and a.Y.C. Nee},
doi = {10.1016/j.cirp.2007.05.014},
file = {::},
issn = {00078506},
journal = {CIRP Annals - Manufacturing Technology},
keywords = {assembly design,augmented reality,product evaluation},
number = {1},
pages = {49--52},
title = {{Augmented Reality Aided Assembly Design and Planning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007850607000145},
volume = {56},
year = {2007}
}
@article{Kurz2012a,
author = {Kurz, Daniel and Benhimane, Selim},
journal = {Computers \& Graphics},
number = {7},
pages = {866--883},
title = {{Handheld Augmented Reality involving gravity measurements}},
url = {http://da.nielkurz.de/content/Handheld\_Augmented\_Reality\_involving\_gravity\_measurements},
volume = {36},
year = {2012}
}
@article{Kaufmann2003a,
abstract = {Construct3D is a 3D geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system Studierstube. We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a testbed for future evaluations. Means of application and integration in mathematics and geometry education at high school as well as university level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions and improves spatial skills.},
author = {Kaufmann, Hannes and Schmalstieg, Dieter},
doi = {10.1016/S0097-8493(03)00028-1},
file = {::},
isbn = {1581135254},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {augmented reality,geometry education,mathematics education,spatial intelligence},
number = {3},
pages = {339--345},
publisher = {ACM Press},
title = {{Mathematics and geometry education with collaborative augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849303000281},
volume = {27},
year = {2003}
}
@article{Newman2006a,
author = {Newman, J. and Schall, G. and Barakonyi, I. and Schurzinger, A. and Schmalstieg, D.},
file = {::},
journal = {Advances in Pervasive Computing},
pages = {3--6},
title = {{Wide-Area Tracking Tools for Augmented Reality}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Wide-Area+Tracking+Tools+for+Augmented+Reality\#0},
volume = {207},
year = {2006}
}
@article{Hile2008a,
author = {Hile, Harlan and Borriello, Gaetano},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {32--39},
title = {{Positioning and Orientation in Indoor Environments Using Camera Phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557953},
volume = {28},
year = {2008}
}
@article{Bruder2009a,
author = {Bruder, G. and Steinicke, F. and Hinrichs, K.H.},
file = {::},
journal = {2009 IEEE Symposium on 3D User Interfaces},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
month = mar,
pages = {75--82},
publisher = {Ieee},
title = {{Arch-Explore: A natural user interface for immersive architectural walkthroughs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4811208},
year = {2009}
}
@article{Liarokapis2002a,
abstract = {An interactive Multimedia Augmented Reality Interface for E-Learning (MARIE) is presented in the article. Its application for engineering education is discussed in order to enhance traditional teaching and learning methods; however, it is equally applicable to other areas. The authors have developed and implemented a user-friendly interface to experimentally explore the potential of augmented reality by superimposing Virtual Multimedia Content (VMC) information in an Augmented Reality (AR) tabletop environment, such as a student desk workspace. The user can interact with the VMC, which is composed of threedimensional objects, images, animations, text (ASCII or three-dimensional) and sound. To prove the feasibility of the system only a small part of the teaching material was digitised and some experimental results are presented in the article.},
author = {Liarokapis, F and Petridis, P and Lister, P F and White, M},
file = {::},
journal = {World Transactions on Engineering and Technology Education},
keywords = {l education (general),qa75 electronic computers. computer science,qa76 computer software},
number = {2},
pages = {173--176},
publisher = {Citeseer},
title = {{Multimedia Augmented Reality Interface for E-Learning (MARIE)}},
url = {http://eprints.sussex.ac.uk/1088/},
volume = {1},
year = {2002}
}
@article{Kala2010,
abstract = {Handwriting Recognition enables a person to scribble something on a piece of paper and then convert it into text. If we look into the practical reality there are enumerable styles in which a character may be written. These styles can be self combined to generate more styles. Even if a small child knows the basic styles a character can be written, he would be able to recognize characters written in styles intermediate between them or formed by their mixture. This motivates the use of Genetic Algorithms for the problem. In order to prove this, we made a pool of images of characters. We converted them to graphs. The graph of every character was intermixed to generate styles intermediate between the styles of parent character. Character recognition involved the matching of the graph generated from the unknown character image with the graphs generated by mixing. Using this method we received an accuracy of 98.44\%.},
author = {Kala, Rahul and Vazirani, Harsh and Shukla, Anupam and Tiwari, Ritu},
file = {::},
journal = {International Journal of Computer Science},
number = {2},
pages = {16--25},
title = {{Offline Handwriting Recognition using Genetic Algorithm}},
url = {http://arxiv.org/abs/1004.3257},
volume = {7},
year = {2010}
}
@article{Geller2008b,
author = {Geller, T.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {11--17},
publisher = {IEEE Computer Society Press},
title = {{Overcoming the uncanny valley}},
url = {http://www.computer.org/portal/cms\_docs\_cga/cga/content/mcg2008040011.pdf},
volume = {28},
year = {2008}
}
@article{Do-Lenh2010,
abstract = {Tangible User Interfaces (TUIs) offer the potential to facilitate collaborative learning in new ways. This paper presents an empirical study that investigated the effects of a TUI in a classroom setting on task performance and learning outcomes. In the tangible condition, apprentices worked together around an interactive tabletop warehouse simulation using tangible inputs. In the paper condition, they performed the same activity with only paper and pens. Results showed that the tangible condition resulted in better task performance (more alternative solutions explored and better final solution) but did not affect learning outcomes, i.e. understanding of important concepts and applying them to a problem-solving question. We discuss reasons for this in terms of task structure and type, nature of tangible user interfaces and effective interaction requirements.},
author = {Do-Lenh, Son and Jermann, Patrick},
doi = {10.1007/978-3-642-16020-2},
editor = {Wolpers, Martin and Kirschner, Paul A and Scheffel, Maren and Lindstaedt, Stefanie and Dimitrova, Vania},
file = {::},
isbn = {9783642160196},
journal = {Learning},
keywords = {augmented reality,collaborative learning,human computer,tabletop,tangible user interface,technology enhanced learning},
pages = {78--92},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Task Performance vs . Learning Outcomes : A Study of a Tangible User Interface in the Classroom}},
url = {http://www.springerlink.com/content/dt71j12632438276/},
volume = {6383},
year = {2010}
}
@article{Barakonyi2007,
author = {Barakonyi, Istvan and Prendinger, Helmut and Schmalstieg, Dieter and Ishizuka, Mitsuru},
doi = {10.1109/3DUI.2007.340777},
file = {::},
isbn = {1-4244-0907-1},
journal = {2007 IEEE Symposium on 3D User Interfaces},
keywords = {augmented reality,eye tracking,multimodal interaction,remote collaboration,tangible interface},
pages = {71--78},
publisher = {Ieee},
title = {{Cascading Hand and Eye Movement for Augmented Reality Videoconferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4142848},
year = {2007}
}
@article{Krohn2005a,
author = {Krohn, a. and Beigl, M. and Hazas, M. and Gellersen, H.-W.},
file = {::},
journal = {25th IEEE International Conference on Distributed Computing Systems Workshops},
pages = {463--468},
publisher = {Ieee},
title = {{Using Fine-Grained Infrared Positioning to Support the Surface-Based Activities of Mobile Users}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1437212},
year = {2005}
}
@article{Shih2003,
author = {Shih, T.K. and Lin, N.H.},
doi = {10.1109/ICDCSW.2003.1203626},
file = {::},
isbn = {0-7695-1921-0},
journal = {23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.},
keywords = {analog technology,communication will replace traditional,distance learning,mpeg,multimedia communication system,synchronization,video conferencing},
pages = {646--651},
publisher = {Ieee},
title = {{Augmented video conferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1203626},
year = {2003}
}
@phdthesis{Milvich2004b,
author = {Milvich, Michael Lazar},
number = {July},
title = {{JavaCave: A 3D Immersive Environment in Java}},
year = {2004}
}
@article{Regenbrecht2002a,
author = {Regenbrecht, H and Wagner, M and Baratoff, G},
doi = {10.1007/s100550200016},
file = {::},
issn = {13594338},
journal = {Virtual Reality},
number = {3},
pages = {151--166},
publisher = {Springer},
title = {{Magicmeeting: A collaborative tangible augmented reality system}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s100550200016},
volume = {6},
year = {2002}
}
@article{Billinghurst2002,
author = {Billinghurst, Mark and Kato, Hirokazu},
doi = {10.1145/514236.514265},
issn = {00010782},
journal = {Communications of the ACM},
month = jul,
number = {7},
pages = {64--70},
publisher = {ACM},
title = {{Collaborative augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=514236.514265 http://portal.acm.org/citation.cfm?id=514265},
volume = {45},
year = {2002}
}
@article{Platonov2006,
author = {Platonov, Juri and Heibel, Hauke and Meier, Peter},
doi = {10.1109/ISMAR.2006.297800},
file = {::},
isbn = {1-4244-0650-1},
journal = {of the 5th IEEE and ACM},
keywords = {17,a laptop,and the user,augmented reality,augmented video stream are,computer,e,g,has been inspired by,lessly transmitted between a,maintenance,markerless tracking,our markerless tracking algorithm,solution both,the raw and the,wire-},
month = oct,
pages = {105--108},
publisher = {Ieee},
title = {{A mobile markerless AR system for maintenance and repair}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4079262 http://portal.acm.org/citation.cfm?id=1514222},
year = {2006}
}
@article{Baudin2004,
abstract = {This paper presents'LabFuture', an advanced e-learning platform that uses novel Information and Communication Technologies to support and expand laboratory teaching practices. For this purpose, LabFuture uses real and computer-generated objects that are interfaced using mechatronic systems,augmented reality, mobile technologies and 3D multi user environments. The main aim is to develop and demonstrate technological support for practical experiments in the following focused subjects namely: Fluid Dynamics -Science subject in Germany, Geometry - Mathematics subject in Austria,History and Environmental Awareness - Arts and Humanities subjects in Greece and Slovenia. In order to pedagogically enhance the design and functional aspects of this e-learning technology, we are investigating the dialogical operationalisation of learning theories so as to leverage our understanding of teaching and learning practices in the targeted context of deployment.},
author = {Baudin, Veronique and Faust, Martin and Kaufmann, Hannes and Litsa, Vivian and Mwanza, Daisy and Pierre, Arnaud and Totter, Alexandra},
file = {::},
publisher = {Springer Boston},
title = {{The Lab@Future Project: ‘Moving towards the future of e-Learning}},
url = {http://www.ims.tuwien.ac.at/publication\_detail.php?ims\_id=152},
year = {2004}
}
@inproceedings{Wagner2007,
abstract = {In this paper we present ARToolKitPlus, a successor to the popular ARToolKit pose tracking library. ARToolKitPlus has been optimized and extended for the usage on mobile devices such as smartphones, PDAs and Ultra Mobile PCs (UMPCs). We explain the need and specific requirements of pose tracking on mobile devices and how we met those requirements. To prove the applicability we performed an extensive benchmark series on a braod range of off-the-shelf handhelds.},
author = {Wagner, Daniel and Schmalstieg, Dieter},
booktitle = {Proceedings of 12th Computer Vision Winter Workshop CVWW07},
doi = {10.1.1.157.1879},
file = {::},
pages = {139--146},
publisher = {Citeseer},
title = {{ARToolKitPlus for Pose Tracking on Mobile Devices ARToolKit}},
url = {http://www.icg.tu-graz.ac.at/Members/daniel/ARToolKitPlusMobilePoseTracking},
year = {2007}
}
@article{Guan2010,
abstract = {This paper focuses on online scene learning and fast camera relocalisation which are two key problems currently limiting the performance of wide area augmented reality systems. Firstly, we propose to use adaptive random trees to deal with the online scene learning problem. The algorithm can provide more accurate recognition rates than traditional methods, especially with large scale workspaces. Secondly, we use the enhanced PROSAC algorithm to obtain a fast camera relocalisation method. Compared with traditional algorithms, our method can significantly reduce the computation complexity, which facilitates to a large degree the process of online camera relocalisation. Finally, we implement our algorithms in a multithreaded manner by using a parallel-computing scheme. Camera tracking, scene mapping, scene learning and relocalisation are separated into four threads by using multi-CPU hardware architecture. While providing real-time tracking performance, the resulting system also possesses the ability to track multiple maps simultaneously. Some experiments have been conducted to demonstrate the validity of our methods.},
author = {Guan, Tao and Duan, Liya and Chen, Yongjian and Yu, Junqing},
doi = {10.3390/s100606017},
file = {::},
issn = {1424-8220},
journal = {Sensors},
month = jun,
number = {6},
pages = {6017--6043},
title = {{Fast Scene Recognition and Camera Relocalisation for Wide Area Augmented Reality Systems}},
url = {http://www.mdpi.com/1424-8220/10/6/6017/},
volume = {10},
year = {2010}
}
@article{Papagiannakis2008,
abstract = {Recent advances in hardware and software for mobile computing have enabled a new breed of mobile AR systems and applications. A new breed of computing called augmented ubiquitous computing has resulted from the convergence of wearable computing, wireless networking and mobile AR interfaces. In this paper we provide a survey of different mobile and wireless technologies and how they have impact AR. Our goal is to place them into different categories so that it becomes easier to understand the state of art and to help identify new directions of research.},
author = {Papagiannakis, George and Singh, Gurminder and Magnenat-Thalmann, Nadia},
doi = {10.1002/cav.221},
file = {::},
institution = {MIRALab, University of Geneva},
issn = {15464261},
journal = {Computer Animation And Virtual Worlds},
keywords = {augmented mixed reality,mobile systems,wireless networking},
number = {1},
pages = {3--22},
publisher = {Wiley Online Library},
title = {{A survey of mobile and wireless technologies for augmented reality systems}},
url = {http://doi.wiley.com/10.1002/cav.221},
volume = {19},
year = {2008}
}
@article{Gelb2010,
author = {Gelb, Dan and Subramanian, A},
file = {::},
isbn = {9781612840352},
journal = {Person-Oriented Vision (POV),},
pages = {1--6},
title = {{Augmented reality for immersive remote collaboration}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5712368},
year = {2010}
}
@article{Lee2009,
abstract = {We describe a novel markerless camera tracking approach and user interaction methodology for augmented reality (AR) on unprepared tabletop environments. We propose a real-time system architecture that combines two types of feature tracking. Distinctive image features of the scene are detected and tracked frame-to-frame by computing optical flow. In order to achieve real-time performance, multiple operations are processed in a synchronized multi-threaded manner: capturing a video frame, tracking features using optical flow, detecting distinctive invariant features, and rendering an output frame. We also introduce user interaction methodology for establishing a global coordinate system and for placing virtual objects in the AR environment by tracking a user's outstretched hand and estimating a camera pose relative to it. We evaluate the speed and accuracy of our hybrid feature tracking approach, and demonstrate a proof-of-concept application for enabling AR in unprepared tabletop environments, using bare hands for interaction.},
author = {Lee, Taehee and H\"{o}llerer, Tobias},
doi = {10.1109/TVCG.2008.190},
file = {::},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Artificial Intelligence,Computer Graphics,Computer Simulation,Hand,Hand: anatomy \& histology,Hand: physiology,Humans,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Models, Biological,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,User-Computer Interface},
number = {3},
pages = {355--68},
pmid = {19282544},
title = {{Multithreaded hybrid feature tracking for markerless augmented reality.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19282544},
volume = {15},
year = {2009}
}
@article{Lee2011,
author = {Lee, Jae Yeol and Seo, Dong Woo and Rhee, Gue Won},
doi = {10.1016/j.compind.2010.07.003},
file = {::},
issn = {01663615},
journal = {Computers in Industry},
month = jan,
number = {1},
pages = {107--119},
publisher = {Elsevier B.V.},
title = {{Tangible authoring of 3D virtual scenes in dynamic augmented reality environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166361510001077},
volume = {62},
year = {2011}
}
@article{Malkawi2005,
author = {Malkawi, a and Srinivasan, R},
doi = {10.1016/j.autcon.2004.08.001},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
keywords = {augmented reality,building interaction,cfd,gesture recognition,hci,human,speech recognition,visualization},
month = jan,
number = {1},
pages = {71--84},
title = {{A new paradigm for Human-Building Interaction: the use of CFD and Augmented Reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580504000998},
volume = {14},
year = {2005}
}
@article{Nilsson2009a,
abstract = {This paper presents results from a study on using an AR application to support collaborative command and control activities requiring the collaboration of three different civil service organisations. The technology is used to create a common ground between the organisations and allows the users to interact, plan resources and react to the ongoing events on a digital map. The AR application was developed and evaluated in a study where a forest fire scenario was simulated. Participants from the involved organisations acted as command and control teams in the simulated scenario and both quantitative and qualitative results were obtained. The results show that AR can become a useful tool in these situations in the future.},
author = {Nilsson, Susanna and Johansson, Bj\"{o}rn J E and J\"{o}nsson, Arne},
doi = {10.1145/1670252.1670291},
file = {::},
isbn = {9781605589121},
journal = {Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry VRCAI 09},
pages = {179},
publisher = {ACM Press},
series = {VRCAI '09},
title = {{A co-located collaborative augmented reality application}},
url = {http://portal.acm.org/citation.cfm?doid=1670252.1670291},
year = {2009}
}
@article{Thomas2006,
author = {Thomas, GA},
doi = {10.1109/MCG.2010.23},
file = {::},
issn = {0272-1716},
journal = {Visual Media Production, 2006. CVMP 2006. 3rd},
month = may,
number = {3},
pages = {56--68},
title = {{Real-time camera pose estimation for augmenting sports scenes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5396282 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4156005},
volume = {31},
year = {2006}
}
@incollection{Costanza2009,
abstract = {This chapter presents an overview of the Mixed Reality (MR) paradigm, which proposes to overlay our real-world environment with digital, computer-generated objects. It presents example applications and outlines limitations and solutions for their technical implementation. In MR systems, users perceive both the physical environment around them and digital elements presented through, for example, the use of semitransparent displays. By its very nature, MR is a highly interdisciplinary field engaging signal processing, computer vision, computer graphics, user interfaces, human factors, wearable computing, mobile computing, information visualization, and the design of displays and sensors. This chapter presents potential MR applications, technical challenges in realizing MR systems, as well as issues related to usability and collaboration in MR. It separately presents a section offering a selection of MR projects which have either been partly or fully undertaken at Swiss universities and rounds off with a section on current challenges and trends.},
author = {Costanza, Enrico and Kunz, Andreas and Fjeld, Morten},
booktitle = {Human Machine Interaction},
file = {::},
pages = {47--68},
publisher = {Springer-Verlag},
title = {{Mixed Reality: A Survey}},
url = {http://eprints.ecs.soton.ac.uk/20953/},
volume = {LNCS 5440},
year = {2009}
}
@article{Klein2007,
author = {Klein, Georg and Murray, David},
doi = {10.1109/ISMAR.2007.4538852},
file = {::},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
month = nov,
pages = {1--10},
publisher = {Ieee},
title = {{Parallel Tracking and Mapping for Small AR Workspaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538852},
year = {2007}
}
@inproceedings{Jin2007,
author = {Jin, Yoon-suk and Kim, Yang-wook and Park, Jun},
booktitle = {Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2007.4538863},
file = {::},
isbn = {978-1-4244-1749-0},
keywords = {augmented reality,design evaluation,mock-up},
month = nov,
pages = {1--2},
publisher = {IEEE Computer Society},
title = {{ARMO: Augmented Reality based Reconfigurable MOck-up}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538863 http://portal.acm.org/citation.cfm?id=1514374},
year = {2007}
}
@article{Regenbrecht2006,
author = {Regenbrecht, H. and Ott, C. and Wagner, M. and Lum, T. and Kohler, P. and Wilke, W. and Mueller, E.},
doi = {10.1109/ISMAR.2003.1240725},
file = {::},
isbn = {0-7695-2006-5},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {290--291},
publisher = {IEEE Comput. Soc},
title = {{An augmented virtuality approach to 3D videoconferencing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240725},
year = {2006}
}
@article{Capin2008b,
author = {Capin, Tolga and Pulli, Kari and Akenine-M\"{o}ller, Tomas},
file = {::},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {74--84},
title = {{The State of the Art in Mobile Graphics Research}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557959},
volume = {28},
year = {2008}
}
@article{Bajura1995a,
author = {Bajura, M. and Neumann, U.},
file = {::},
journal = {IEEE Computer Graphics and Applications},
keywords = {augmented reality,reality,registration,virtual},
number = {5},
pages = {52--60},
title = {{Dynamic registration correction in video-based augmented reality systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=403828},
volume = {15},
year = {1995}
}
@article{Ziaei2011,
author = {Ziaei, Z. and Hahto, a. and Mattila, J. and Siuko, M. and Semeraro, L.},
doi = {10.1016/j.fusengdes.2010.12.082},
file = {::},
issn = {09203796},
journal = {Fusion Engineering and Design},
month = feb,
publisher = {Elsevier B.V.},
title = {{Real-time markerless Augmented Reality for Remote Handling system in bad viewing conditions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0920379611000160},
year = {2011}
}
@article{Ni2006b,
author = {Ni, T and Schmidt, G S and Staadt, O G and Livingston, M A and Ball, R and May, R},
journal = {Virtual Reality},
title = {{A Survey of Large High-Resolution Display Technologies, Techniques, and Applications}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Survey+of+Large+High-Resolution+Display+Technologies,+Techniques,+and+Applications\#0},
year = {2006}
}
@article{Pasman2006a,
author = {Woodward, Charles and Pasman, W.},
file = {::},
journal = {The Second IEEE and ACM International Symposium on Mixed and Augmented Reality, 2003. Proceedings.},
pages = {276--277},
publisher = {IEEE Comput. Soc},
title = {{Implementation of an Augmented Reality System on a PDA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240718},
year = {2006}
}
@inproceedings{Buscher2000,
address = {New York, New York, USA},
author = {B\"{u}scher, Monika and Christensen, Michael and Gr\o nb\ae k, Kaj and Krogh, Peter and Mogensen, Preben and Shapiro, Dan and \O rb\ae k, Peter},
booktitle = {Proceedings of the third international conference on Collaborative virtual environments - CVE '00},
doi = {10.1145/351006.351012},
file = {::},
isbn = {1581133030},
pages = {47--56},
publisher = {ACM Press},
title = {{Collaborative augmented reality environments}},
url = {http://portal.acm.org/citation.cfm?id=351012 http://portal.acm.org/citation.cfm?doid=351006.351012},
year = {2000}
}
@article{Pilet2005,
author = {Pilet, J. and Lepetit, V. and Fua, P.},
doi = {10.1109/ISMAR.2005.18},
file = {::},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
pages = {134--137},
publisher = {Ieee},
title = {{Augmenting deformable objects in real-time}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544675},
volume = {1},
year = {2005}
}
@article{Wang2009a,
author = {Wang, Xiangyu and Chen, Rui (Irene)},
doi = {10.1080/15710880903320020},
file = {::},
issn = {1571-0882},
journal = {CoDesign},
keywords = {augmented reality,collaborative design,urban design,virtual reality},
month = dec,
number = {4},
pages = {229--244},
title = {{An experimental study on collaborative effectiveness of augmented reality potentials in urban design}},
url = {http://www.tandfonline.com/doi/abs/10.1080/15710880903320020},
volume = {5},
year = {2009}
}
@phdthesis{Systeme2004a,
author = {Systeme, Interaktive and Universit, Technischen and Schmalstieg, Dieter and Reitmayr, Gerhard},
file = {::},
title = {{XML Databases for Augmented Reality}},
year = {2004}
}
@article{Sheng2010,
author = {Sheng, Yu and Yapo, Theodore C. and Cutler, Barbara},
doi = {10.1111/j.1467-8659.2009.01608.x},
file = {::},
issn = {01677055},
journal = {Computer Graphics Forum},
month = jun,
number = {2},
pages = {387--396},
title = {{Global Illumination Compensation for Spatially Augmented Reality}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2009.01608.x},
volume = {29},
year = {2010}
}
@article{Schmalstieg2007e,
author = {Schmalstieg, Dieter and Wagner, Daniel},
file = {::},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality games,cultural heritage,mobile augmented reality,wearable computing},
month = nov,
pages = {1--13},
publisher = {Ieee},
title = {{Experiences with Handheld Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538819},
year = {2007}
}
@article{Nirnimesh2007a,
abstract = {Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda is scalable to large tile configurations and massive environments. It can transparently render any application built using the Open Scene Graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the server and network loads grow sublinearly with the increase in the number of tiles, which makes our scheme suitable to construct very large displays.},
author = {Nirnimesh, Harish P. and Narayanan, Pawan J.},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Communication Networks,Computer Communication Networks: instrumentation,Computer Graphics,Computer Graphics: instrumentation,Computer-Assisted,Computer-Assisted: instrumen,Computer-Assisted: instrumentat,Computer-Assisted: methods,Data Display,Equipment Design,Equipment Failure Analysis,Image Enhancement,Image Enhancement: instrumentation,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Microcomputers,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,User-Computer Interface},
number = {5},
pages = {864--77},
title = {{Garuda: A Scalable Tiled Display Wall Using Commodity PCs}},
volume = {13},
year = {2007}
}
@article{Mower2009,
author = {Mower, James E.},
doi = {10.1080/13658810802001313},
file = {::},
issn = {1365-8816},
journal = {International Journal of Geographical Information Science},
keywords = {augmented reality,dem,perspective imaging,tin},
month = aug,
number = {8},
pages = {993--1011},
title = {{Creating and delivering augmented scenes}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13658810802001313},
volume = {23},
year = {2009}
}
@article{Bencina2005c,
author = {Bencina, R. and Kaltenbrunner, M. and Jorda, S.},
file = {::},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
pages = {99--99},
publisher = {Ieee},
title = {{Improved Topological Fiducial Tracking in the reacTIVision System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565409},
year = {2005}
}
@article{Rekimoto1995a,
author = {Rekimoto, Jun and Nagao, Katashi},
file = {::},
journal = {Proc. 8th Ann. ACM Symp. User Interface and Software Technology (UIST), ACM Press},
pages = {29--36},
title = {{The World through the Computer: Computer Augmented Interaction with Real World Environments}},
year = {1995}
}
@article{Ag,
author = {Ag, Daimlerchrysler},
file = {::},
journal = {Virtual Reality},
number = {3},
pages = {338--355},
title = {{Using Augmented Virtuality for}},
volume = {13}
}
@incollection{Christian2007,
abstract = {There is evidence that recent developments in Augmented Reality (AR) technology has the potential to be applied as pervasive media on multiple devices in different ways and contexts, especially with low-cost devices including Mobile Augmented Reality (MAR) applications on smart phones or Pocket-PCs. In this paper we present a framework in order to combine the pervasive e-education concept with augmented reality content for e-training. We analyze current research, discuss some examples from ultralight light sport aircraft maintenance and show how to apply this framework generically. We present a learning engine to deliver this special type of content and provide a further outlook of future research. A user-centered approach must ensure that the developments can stimulate motivation and enhance performance of the end users in different training sessions. The main benefit is, that the end users are enabled to better perceive complex, technical facts, systems and components.},
author = {Christian, Johannes and Krieger, Horst and Holzinger, Andreas and Behringer, Reinhold},
booktitle = {Universal Access to Applications and Services Lecture Notes in Computer Science LNCS 4556},
editor = {Stephanidis, C},
file = {::},
isbn = {9783540732822},
keywords = {augmented reality,learning performance,performance},
pages = {520--529},
publisher = {Springer},
title = {{Virtual and mixed reality interface for e-training: examples of applications in ultralight / light sport aircraft maintenance}},
year = {2007}
}
@article{Gee2011,
author = {Gee, Andrew P. and Webb, Matthew and Escamilla-Ambrosio, Jorge and Mayol-Cuevas, Walterio and Calway, Andrew},
doi = {10.1016/j.cag.2011.04.006},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Augmented reality,GPS,Topometric,UWB,Visual SLAM},
month = aug,
number = {4},
pages = {854--868},
publisher = {Elsevier},
title = {{A topometric system for wide area augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001099},
volume = {35},
year = {2011}
}
@article{Teichrieb2007,
author = {Teichrieb, Veronica and Lima, Monte and Lourenc, Eduardo and Bueno, Silva and Kelner, Judith and Santos, Ismael H F},
file = {::},
journal = {International Journal of Modeling and Simulation for the Petroleum Industry},
number = {1},
pages = {1--7},
title = {{A Survey of Online Monocular Markerless Augmented Reality}},
url = {http://rpcmod.ganer.ex-br.com/revista/articles/1.pdf},
volume = {1},
year = {2007}
}
@article{Rashid2006,
abstract = {RFID is often cited as the next big evolution in computing as it effectively enables everyday objects to be connected to the Internet. RFID readers are now available on mobile phones and in this paper we present an example of their use in a location based mobile game. Location based games are a new entertainment genre that allow users to play games in mixed reality in that they incorporate knowledge of their physical location and then provide them with the ability to interact with both real and virtual objects within that location. The game presented in this paper is the first of its kind and shows the potential for using RFID with mobile phones.},
author = {Rashid, Omer and Coulton, Paul and Edwards, Reuben and Bamford, Will},
file = {::},
journal = {Consumer Electronics 2006 ICCE 06 2006 Digest of Technical Papers International Conference on},
keywords = {qa76 computer software},
pages = {459--460},
title = {{Utilising RFID for mixed reality mobile games.}},
url = {http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=1598509},
year = {2006}
}
@article{Gjosaeter2009,
author = {Gjosaeter, Tor},
doi = {10.1109/SocInfo.2009.21},
file = {::},
isbn = {978-0-7695-3706-1},
journal = {2009 International Workshop on Social Informatics},
keywords = {-component,augmented reality,cscd,cscw},
month = jun,
pages = {35--40},
publisher = {Ieee},
title = {{Computer Supported Collaborative Design Using Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5230716},
year = {2009}
}
@article{Ong2009,
author = {Ong, S.K. and Shen, Y.},
doi = {10.1016/j.cirp.2009.03.020},
file = {::},
issn = {00078506},
journal = {CIRP Annals - Manufacturing Technology},
number = {1},
pages = {139--142},
title = {{A mixed reality environment for collaborative product design and development}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0007850609000225},
volume = {58},
year = {2009}
}
@inproceedings{Kurz2011,
author = {Kurz, Daniel and Benhimane, Selim},
booktitle = {IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR2011)},
keywords = {Handheld Augmented Reality Inertial Sensors Gravit},
pages = {111--120},
title = {{Gravity-Aware Handheld Augmented Reality}},
year = {2011}
}
@article{Hachet2008a,
author = {Hachet, M and Kitamura, Y},
file = {::},
journal = {Science},
pages = {1--4},
title = {{3D interaction with and from handheld computers}},
url = {http://www.recolecta.net/buscador/single\_page.jsp?id=oai:hal.archives-ouvertes.fr:hal-00308241\_v1},
year = {2008}
}
@article{Lee2005,
author = {Lee, W and Woo, Woontack and Lee, Jongweon},
file = {::},
journal = {Personal Computing},
keywords = {augmented reality,table top game,tangible user interface},
pages = {0--4},
title = {{TARBoard: Tangible Augmented Reality System for Table-top Game Environment}},
url = {http://www.ipsi.fraunhofer.de/ambiente/pergames2005/papers\_2005/PerGames2005\_TARBoard\_WLee.pdf},
volume = {5},
year = {2005}
}
@article{Klinec1988a,
author = {Klinec, Darko and Leonhardi, Alexander},
file = {::},
number = {19-20},
pages = {xiii},
title = {{Positioning and Location Services for Infoor Areas in neXus}},
volume = {7},
year = {1988}
}
@article{Lamberti2003a,
address = {New York, New York, USA},
author = {Lamberti, Fabrizio and Zunino, Claudio and Sanna, Andrea and Fiume, Antonino and Maniezzo, Marco},
file = {::},
journal = {Proceeding of the eighth international conference on 3D web technology - Web3D '03},
pages = {55},
publisher = {ACM Press},
title = {{An accelerated remote graphics architecture for PDAS}},
url = {http://portal.acm.org/citation.cfm?doid=636593.636602},
year = {2003}
}
@article{Morrison2011,
author = {Morrison, Ann and Mulloni, Alessandro and Lemmel\"{a}, Saija and Oulasvirta, Antti and Jacucci, Giulio and Peltonen, Peter and Schmalstieg, Dieter and Regenbrecht, Holger},
doi = {10.1016/j.cag.2011.04.009},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {mobile augmented reality},
month = aug,
number = {4},
pages = {789--799},
title = {{Collaborative use of mobile augmented reality with paper maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001129},
volume = {35},
year = {2011}
}
@incollection{Liarokapis2002,
abstract = {This paper presents an innovative approach to enhance students learning and understanding of digital design using complex commercial design flows. The architecture of our experimental system is based on new technologies such as Augmented Reality (AR), XML metadata, and an XML integrated database system. The database provides the content for multimedia presentation in a virtual environment, visualised through AR, which enables students to engage effectively in the process of learning. These include textual descriptions, animated videos, auditory information, images and 3D computer generated objects of related diagrams and designs. An XML interface will allow the teacher to input multimedia information into the database remotely in a simple way. Using an AR interface the content of the database will be visualized in real time using state-of-the-art virtual reality technologies, i.e. head mounted displays, tracking devices, etc. Through this interface, users will be able to interact collaboratively. Using collaborative AR the students will also develop team skills that play a significant role in the learning process. Finally, we provide an illustrative description of how our experimental system will operate, and we present some initial results.},
author = {Liarokapis, F and Mourkoussis, N and Petridis, P and Rumsey, S and Lister, P F and White, M},
file = {::},
keywords = {l education (general),qa75 electronic computers. computer science,qa76 computer software},
publisher = {UICEE},
title = {{An Interactive Augmented Reality System for Engineering Education}},
url = {http://eprints.sussex.ac.uk/1176/},
year = {2002}
}
@article{Jiang2004a,
author = {Jiang, B. and Neumann, U. and You, S.},
file = {::},
journal = {IEEE Virtual Reality, 2004. Proceedings},
pages = {3--275},
title = {{A robust hybrid tracking system for outdoor augmented reality}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1310049},
year = {2004}
}
@inproceedings{Fuhrmann1997,
author = {Fuhrmann, Anton and Liiffelmamr, Helwig and Schmalstieg, Dieter},
booktitle = {IEEE Visualization},
file = {::},
isbn = {0818682620},
pages = {459--462},
publisher = {IEEE Computer Society Press},
title = {{Collaborative augmented reality: exploring dynamical systems}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Collaborative+Augmented+Reality+:+Exploring+Dynamical+Systems\#0},
volume = {97},
year = {1997}
}
@article{Wither2011,
author = {Wither, Jason and Tsai, Yun-Ta and Azuma, Ronald},
doi = {10.1016/j.cag.2011.04.010},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Evaluation,Information Presentation,Mixed Reality,User Interface},
month = aug,
number = {4},
pages = {810--822},
publisher = {Elsevier},
title = {{Indirect augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849311001130},
volume = {35},
year = {2011}
}
@article{Ahn,
author = {Ahn, M.H.},
doi = {10.1109/ICPR.1998.712048},
file = {::},
isbn = {0-8186-8512-3},
journal = {Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)},
pages = {1694--1696},
publisher = {IEEE Comput. Soc},
title = {{Video augmentation by image-based rendering under the perspective camera model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=712048},
volume = {2}
}
@article{Chen2008,
author = {Chen, R and Wang, X},
doi = {10.1016/S1007-0214(08)70120-2},
file = {::},
issn = {10070214},
journal = {Tsinghua Science \& Technology},
keywords = {augmented reality,design learning,physicality,tangible augmented reality,tangible interface},
month = oct,
number = {October},
pages = {13--18},
publisher = {Tsinghua University Press},
title = {{An Empirical Study on Tangible Augmented Reality Learning Space for Design Skill Transfer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1007021408701202},
volume = {13},
year = {2008}
}
@article{Fuge2011,
author = {Fuge, Mark and Yumer, Mehmet Ersin and Orbay, Gunay and Kara, Levent Burak},
doi = {10.1016/j.cad.2011.05.009},
file = {::},
issn = {00104485},
journal = {Computer-Aided Design},
month = jun,
pages = {1--13},
publisher = {Elsevier Ltd},
title = {{Conceptual design and modification of freeform surfaces using dual shape representations in augmented reality environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S001044851100128X},
year = {2011}
}
@inproceedings{Field2004a,
address = {Hobart, Tasmania},
author = {Field, Tom and Bay, Sandy and Vamplew, Peter},
booktitle = {AISAT2004: International Conference on Artificial Intelligence in Science and Technology},
file = {::},
title = {{Generalised Algorithms for Redirected Walking in Virtual Environments}},
url = {http://eprints.utas.edu.au/109/},
year = {2004}
}
@article{Broll2008a,
author = {Broll, Wolfgang and Lindt, Irma and Herbst, Iris and Ohlenburg, Jan and Braun, Anne-kathrin and Wetzel, Richard},
file = {::},
journal = {Advances},
title = {{Toward Next-Gen Mobile AR Games}},
year = {2008}
}
@article{Tian2010,
abstract = {To produce a realistic augmentation in Augmented Reality, the correct relative positions of real objects and virtual objects are very important. In this paper, we propose a novel real-time occlusion handling method based on an object tracking approach. Our method is divided into three steps: selection of the occluding object, object tracking and occlusion handling. The user selects the occluding object using an interactive segmentation method. The contour of the selected object is then tracked in the subsequent frames in real-time. In the occlusion handling step, all the pixels on the tracked object are redrawn on the unprocessed augmented image to produce a new synthesized image in which the relative position between the real and virtual object is correct. The proposed method has several advantages. First, it is robust and stable, since it remains effective when the camera is moved through large changes of viewing angles and volumes or when the object and the background have similar colors. Second, it is fast, since the real object can be tracked in real-time. Last, a smoothing technique provides seamless merging between the augmented and virtual object. Several experiments are provided to validate the performance of the proposed method.},
author = {Tian, Yuan and Guan, Tao and Wang, Cheng},
doi = {10.3390/s100402885},
file = {::},
issn = {1424-8220},
journal = {Sensors},
keywords = {augmented reality,graph cuts,mean shift,occlusion,optical flow,tracking},
month = mar,
number = {4},
pages = {2885--2900},
title = {{Real-Time Occlusion Handling in Augmented Reality Based on an Object Tracking Approach}},
url = {http://www.mdpi.com/1424-8220/10/4/2885/},
volume = {10},
year = {2010}
}
@article{Kroeker2010,
author = {Kroeker, Kirk L.},
doi = {10.1145/1785414.1785422},
file = {::},
issn = {00010782},
journal = {Communications of the ACM},
month = jul,
number = {7},
pages = {19},
title = {{Mainstreaming augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1785414.1785422},
volume = {53},
year = {2010}
}
@article{Wang2008,
author = {Wang, X and Dunston, P},
doi = {10.1016/j.autcon.2007.07.002},
file = {::},
issn = {09265805},
journal = {Automation in Construction},
keywords = {3d models,computer supported cooperative work,cscw,design review,mixed reality,usability},
month = may,
number = {4},
pages = {399--412},
title = {{User perspectives on mixed reality tabletop visualization for face-to-face collaborative design review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0926580507000933},
volume = {17},
year = {2008}
}
@article{Courtiat2004,
abstract = {This paper presents LabFuture, an advanced e-learning platform that uses novel Information and Communication Technologies to support and expand laboratory teaching practices. For this purpose, LabFuture uses real and computer generated objects that are interfaced using mechatronic systems, augmented reality, mobile technologies and 3D multi user environments. The main aim is to develop and demonstrate technological support for practical experiments in the following focused disciplines namely: Fluid Dynamics - Science subject in Germany, Geometry - Mathematics subject in Austria, History and Environmental Awareness Arts and Humanities subjects in Greece and Slovenia. In order to pedagogically enhance the design and functional aspects of this e-learning technology, we are investigating the dialogical operationalisation of learning theories so as to leverage our understanding of teaching and learning practices in the targeted context of deployment. To be able to evaluate the labfuture system in its entire complexity an evaluation methodology including several phases has been developed, performing formative as well as summative evaluations.},
author = {Courtiat, Jean-Pierre and Davarakis, Costas and Totter, Alexandra and Mwanza, Daisy and Faust, Martin and Kaufmann, Hannes},
file = {::},
journal = {Learning},
title = {{Evaluating LAB@FUTURE, a Collaborative E-Learning Laboratory Experiments Platform}},
url = {http://www.eden-online.org/eden.php?menuId=222\&contentId=285},
year = {2004}
}
@article{Regenbrecht2002,
address = {New York, New York, USA},
author = {Regenbrecht, HT},
doi = {10.1145/506444.506451},
file = {::},
isbn = {1581134541},
journal = {CHI\&\#39;02 extended abstracts on},
keywords = {augmented reality,collaboration,cscw,tangible user},
number = {figure 3},
pages = {504},
publisher = {ACM Press},
title = {{Interaction in a collaborative augmented reality environment}},
url = {http://portal.acm.org/citation.cfm?doid=506443.506451 http://portal.acm.org/citation.cfm?id=506451},
year = {2002}
}
@article{Reitmayr2005,
author = {Reitmayr, G. and Eade, E. and Drummond, T.},
doi = {10.1109/ISMAR.2005.39},
file = {::},
isbn = {0-7695-2459-1},
journal = {Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05)},
keywords = {a control,a user interacting with,augmented,device to pick up,figure 1,maps using a pda,optical tracking,plays,projection dis-,spatially augmented reality,tangible user interfaces},
pages = {120--129},
publisher = {Ieee},
title = {{Localisation and interaction for augmented maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544673},
year = {2005}
}
@article{Godet-Bar2010,
abstract = {Context: Every interactive system is composed of a functional core and a user interface. However, the software engineering (SE) and human-computer interaction (HCI) communities do not share the same methods, models or tools. This usually induces a large work overhead when specialists from the two domains try to connect their applicative studies, especially when developing augmented reality systems that feature complex interaction cores. Objective: We present in this paper the essential activities and concepts of a development method integrating the SE and HCI development practices, from the specifications down to the design, as well as their application on a case study. Method: The efficiency of the method was tested in a qualitative study involving four pairs of SE and HCI experts in the design of an application for which an augmented reality interaction would provide better user performance than a classic interactive system. The effectivity of the method was evaluated in a qualitative study comparing the quality of three implementations of the same application fragment (based on the same analysis model), using software engineering metrics. Results: The first evaluation confirmed the ease of use of our method and the relevance of our tools for guiding the design process, but raised concerns on the handling of conflicting collaborative activities. The second evaluation gave indications that the structure of the analysis model facilitates the implementation of quality software (in terms of coupling, stability and complexity). Conclusion: It is concluded that our method enables design teams with different backgrounds in application development to collaborate for integrating augmented reality applications with information systems. Areas of improvement are also described. 2009 Elsevier B.V. All rights reserved.},
author = {Godet-Bar, G and Rieu, D and Dupuy-Chessa, S},
doi = {10.1016/j.infsof.2009.11.007},
file = {::},
issn = {09505849},
journal = {Information and Software Technology},
number = {5},
pages = {492--505},
publisher = {Elsevier B.V.},
title = {{HCI and business practices in a collaborative method for augmented reality systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584909002079},
volume = {52},
year = {2010}
}
@article{Azuma1997,
abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
author = {Azuma, Ronald T},
doi = {10.1.1.30.4999},
file = {::},
issn = {10547460},
journal = {Media},
number = {4},
pages = {355--385},
publisher = {Citeseer},
title = {{A Survey of Augmented Reality}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5387\&amp;rep=rep1\&amp;type=pdf},
volume = {6},
year = {1997}
}
@article{Watsen1999a,
author = {Watsen, K and Darken, R and Capps, M},
file = {::},
journal = {3rd International Immersive Projection Technology Workshop (IPTW'},
publisher = {Citeseer},
title = {{A Handheld Computer as an Interaction Device to a Virtual Environment}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Handheld+Computer+as+an+Interaction+Device+to+a+Virtual+Environment\#0},
volume = {99},
year = {1999}
}
@article{Nini2004,
author = {Nini, B and Batouche, M C},
doi = {10.1109/ICIT.2004.1490732},
file = {::},
isbn = {0780386620},
journal = {2004 IEEE International Conference on Industrial Technology 2004 IEEE ICIT 04},
keywords = {augmented reality,collaboration,departure,do,encrustation,manipulation,network,object,pattern,supposed superposed,used,virtual object},
pages = {1204--1208},
publisher = {Ieee},
title = {{Virtual object manipulation in collaborative augmented reality environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1490732},
year = {2004}
}
@article{Chen2009,
abstract = {This paper combines Tangible Augmented Reality and shape grammar into collaborative design learning to bridge the gaps such as the difficulties of imaging the spatial form in a complex content and the obstacle of communication during the collaborative design. This work has been successful in mapping out a space of technical possibilities and providing a possible system setup to pursue the innovative idea. It not only describes the latent trends and assumptions that might be used to motivate and guide the design in cooperative work, but also makes links with existing research in cognitive science and education.},
author = {Chen, I R and Wang, X and Wang, W},
doi = {10.1109/CSCWD.2009.4968103},
file = {::},
isbn = {9781424435340},
journal = {2009 13th International Conference on Computer Supported Cooperative Work in Design},
keywords = {augmented reality,shape grammar,tangible augmented reality,tangible user},
pages = {468--473},
publisher = {IEEE Comput. Soc},
title = {{Bridging shape grammar and Tangible Augmented Reality into collaborative design learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4968103},
year = {2009}
}
@phdthesis{Flintham2009,
abstract = {Mobile mixed-reality experiences mix physical and digital spaces, enabling participants to simultaneously inhabit a shared environment online and on the streets. These experiences take the form of games, educational applications and new forms of performance and art, and engender new opportunities for interaction, collaboration and play. As mobile mixed-reality experiences move out of the laboratory and into more public settings they raise new challenges concerning how to support these experiences in the wild. This thesis argues that mobile mixed-reality experiences in which artists retain creative control over the content and operation of each experience, particularly those that are deployed as theatrical performances, require dedicated support for content authoring and reactive orchestration tools and paradigms in order to be successfully and robustly operated in public settings. These requirements are examined in detail, drawing on the experience of supporting four publicly toured mobile mixed-reality experiences; Can You See Me Now?, Uncle Roy All Around You, I Like Frank in Adelaide and Savannah, which have provided a platform to practically develop, refine and evaluate new solutions to answer these challenges in the face of presenting the experiences to many thousands of participants over a four year period. This thesis presents two significant supporting frameworks. The ColourMaps system enables designers to author location-based content by directly colouring over maps; providing a simple, familiar and yet highly flexible approach to matching location-triggers to complex physical spaces. It provides support for multiple and specialised content layers, and the ability to configure and manage other aspects of an experience, including filtering inaccurate position data and underpinning orchestration tools. Second, the Orchestration framework supports the day-to-day operation of public experiences; providing dedicated control-room tools for monitoring that reveal the content landscape and historical events, intervention and improvisation techniques for steering and shaping each participant's experience as it unfolds both physically and virtually, and processes to manage a constant flow of participants.},
author = {Flintham, Martin},
booktitle = {Computing Systems},
file = {::},
keywords = {qa 75 electronic computers. computer science},
number = {December},
pages = {234},
school = {University of Nottingham},
title = {{Supporting mobile mixed-reality experiences}},
url = {http://etheses.nottingham.ac.uk/632/},
year = {2009}
}
@article{Kiyokawa2002,
author = {Kiyokawa, K. and Billinghurst, M. and Hayes, S.E. and Gupta, a. and Sannohe, Y. and Kato, H.},
doi = {10.1109/ISMAR.2002.1115083},
file = {::},
isbn = {0-7695-1781-1},
journal = {Proceedings. International Symposium on Mixed and Augmented Reality},
pages = {139--148},
publisher = {IEEE Comput. Soc},
title = {{Communication behaviors of co-located users in collaborative AR interfaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1115083},
year = {2002}
}
@article{Rosenblum2008a,
author = {Rosenblum, Editors Lawrence and Julier, Simon and Bruns, Erich},
file = {::},
journal = {IEEE Computer Graphics and Applications},
pages = {98--102},
publisher = {IEEE Computer Society},
title = {{Projects in VR}},
url = {http://doi.ieeecomputersociety.org/10.1109/MCG.2008.77},
year = {2008}
}
@article{Juillet2003a,
author = {Juillet, Roberto Ortelli and Mireille, Jury and Nova, Nicolas and Schneider, Daniel K},
file = {::},
journal = {Recherche},
title = {{Styles d’interaction dans les PocketPC: analyses et comparaisons}},
year = {2003}
}
@article{Badeche2006,
author = {Badeche, M. and Benmohamed, M.},
doi = {10.1109/ICTTA.2006.1684654},
file = {::},
isbn = {0-7803-9521-2},
journal = {2006 2nd International Conference on Information \& Communication Technologies},
keywords = {augmented reality,corner detection,corner tracking,in certain applications of,is very critical,kalman filter,process of tracking,real-,s factor,time,time tracking,what impose that the},
pages = {1773--1778},
publisher = {Ieee},
title = {{Real-Time Tracking for Augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1684654},
volume = {1},
year = {2006}
}
@article{Jung2010,
author = {Jung, Sungmo and Song, Jae-gu and Hwang, Dae-Joon and Ahn, Jae Young and Kim, Seoksoo},
doi = {10.3390/s101109857},
file = {::},
issn = {1424-8220},
journal = {Sensors},
month = nov,
number = {11},
pages = {9857--9871},
title = {{A Study on Software-based Sensing Technology for Multiple Object Control in AR Video}},
url = {http://www.mdpi.com/1424-8220/10/11/9857/},
volume = {10},
year = {2010}
}
@article{Abdullah2002,
abstract = {Camera calibration is an essential and important part of an Augmented Reality (AR) system. The use of a planebased calibration technique can give a good accuracy, which can be important for AR applications. The calibration technique used in the current ARToolKit requires user intervention, which is prone to error and involves a lengthy calibration time. The camera has to be recalibrated every time the focal length changes which is cumbersome and less suitable for applications where a more automated and easier approach is needed. This paper investigates the use of camera self-calibration for the ARToolKit, which has the advantage of simplicity of implementation. In order to improve its accuracy, a distortion model is also investigated. In this context several interesting results are presented.},
author = {Abdullah, Junaidi and Martinez, Kirk},
file = {::},
title = {{Camera Self-Calibration for the ARToolkit}},
url = {http://eprints.ecs.soton.ac.uk/8885/},
year = {2002}
}
@article{Conole2004a,
abstract = {This paper considers the increasing impact of Information and Communication Technologies (ICT) and the associated rise in e-learning as a recognised and respected research area. The paper provides a summary of some of the current research areas under investigation and provides a list of characteristics of the area. The paper goes on to consider the professional identities of researchers in the area and the tensions which have resulted in terms of aligning with this new emergent group of professionals within existing institutional structures.},
author = {Conole, Grainne},
file = {::},
journal = {Journal of Interactive Media in Education},
pages = {1--18},
title = {{E-Learning: The Hype and the Reality}},
url = {http://www-jime.open.ac.uk/2004/12/},
volume = {2004},
year = {2004}
}
@article{Nurminen2008c,
author = {Nurminen, Antti},
journal = {IEEE Computer Graphics and Applications},
month = jul,
number = {4},
pages = {20--31},
title = {{Mobile 3D City Maps}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557952},
volume = {28},
year = {2008}
}
@article{Juan2011,
author = {Juan, M. Carmen and Joele, Dennis},
doi = {10.1016/j.ijhcs.2011.03.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {augmented reality,invisible markers,phobia towards small animals},
month = jun,
number = {6},
pages = {440--453},
publisher = {Elsevier},
title = {{A comparative study of the sense of presence and anxiety in an invisible marker versus a marker augmented reality system for the treatment of phobia towards small animals}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S107158191100036X},
volume = {69},
year = {2011}
}
@article{Brudera,
author = {Bruder, Gerd},
file = {::},
journal = {Image (Rochester, N.Y.)},
keywords = {3d user interfaces,architectural walkthroughs,locomotion,passive haptic feed-,redirected walking,virtual environments},
title = {{A Natural User Interface for Immersive Architectural Walkthroughs}}
}
@phdthesis{Bimber2005a,
author = {Bimber, O. and Raskar, R.},
file = {::},
publisher = {Peters},
title = {{Spatial augmented reality}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Spatial+Augmented+Reality\#0},
year = {2005}
}
@article{Butz1999,
author = {Butz, A and H\"{o}llerer, T and Feiner, S and MacIntyre, B and Beshers, C},
doi = {10.1109/IWAR.1999.803804},
file = {::},
isbn = {0769503594},
journal = {Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality IWAR99},
pages = {35--44},
publisher = {IEEE Comput. Soc},
title = {{Enveloping users and computers in a collaborative 3D augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=803804},
volume = {99},
year = {1999}
}
@article{Schmalstieg2002,
author = {Schmalstieg, Dieter and Fuhrmann, Anton and Hesina, Gerd and Szalav\'{a}ri, Zsolt and Encarna\c{c}\~{a}o, L. Miguel and Gervautz, Michael and Purgathofer, Werner},
doi = {10.1162/105474602317343640},
file = {::},
issn = {1054-7460},
journal = {Presence: Teleoperators and Virtual Environments},
month = feb,
number = {1},
pages = {33--54},
title = {{The Studierstube Augmented Reality Project}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/105474602317343640},
volume = {11},
year = {2002}
}
@article{Martin-Gutierrez2010,
author = {Mart\'{\i}n-Guti\'{e}rrez, Jorge and {Lu\'{\i}s Saor\'{\i}n}, Jos\'{e} and Contero, Manuel and Alca\~{n}iz, Mariano and P\'{e}rez-L\'{o}pez, David C. and Ortega, Mario},
doi = {10.1016/j.cag.2009.11.003},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
month = feb,
number = {1},
pages = {77--91},
title = {{Design and validation of an augmented book for spatial abilities development in engineering students}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849309001514},
volume = {34},
year = {2010}
}
@article{Green2008,
abstract = {Future space exploration will demand the cultivation of human-robotic systems, however, little attention has been paid to the development of human-robot teams. Current methods for autonomous plan creation are often complex and difficult to use. So a system is needed that enables humans and robotic systems to naturally and effectively collaborate. Effective collaboration takes place when the participants are able to communicate in a natural and effective manner. Grounding, the common understanding between conversational participants, shared spatial referencing and situational awareness, are crucial components of communication and collaboration. This paper briefly reviews the fields of human-robot interaction and Augmented Reality (AR), the overlaying of computer graphics onto the real worldview. The strengths of AR are discussed and how they might be used for human-robot collaboration is described. Then a description of an architecture that we have developed is given that uses AR as a means for real time understanding of the shared spatial scene. This architecture enables grounding and enhances situational awareness, thus laying the necessary groundwork for natural and effective human-robot collaboration.},
author = {Green, Scott A and Billinghurst, Mark and Chen, Xiaoqi and Chase, J Geoffrey},
file = {::},
journal = {International Journal of Advanced Robotic Systems},
keywords = {augmented reality,collaboration,communication,computer interaction,human,robot,robot interaction,robotics},
number = {1},
pages = {1--18},
publisher = {ASME},
title = {{Human-robot collaboration: A literature review and augmented reality approach in design}},
url = {http://ir.canterbury.ac.nz/handle/10092/2262},
volume = {5},
year = {2008}
}
@article{ElSayed2011,
author = {a.M. {El Sayed}, Neven and Zayed, Hala H. and Sharawy, Mohamed I.},
doi = {10.1016/j.compedu.2010.10.019},
file = {::},
isbn = {0101355491},
issn = {03601315},
journal = {Computers \& Education},
month = may,
number = {4},
pages = {1045--1061},
publisher = {Elsevier Ltd},
title = {{ARSC: Augmented reality student card}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131510003040},
volume = {56},
year = {2011}
}
@article{Kaufmann2003,
author = {Kaufmann, Hannes and Schmalstieg, Dieter},
doi = {10.1016/S0097-8493(03)00028-1},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {augmented reality,geometry education,mathematics education,spatial intelligence},
month = jun,
number = {3},
pages = {339--345},
title = {{Mathematics and geometry education with collaborative augmented reality}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849303000281},
volume = {27},
year = {2003}
}
@article{Carmigniani2010,
author = {Carmigniani, Julie and Furht, Borko and Anisetti, Marco and Ceravolo, Paolo and Damiani, Ernesto and Ivkovic, Misa},
doi = {10.1007/s11042-010-0660-6},
file = {::},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
keywords = {ar,augmented,augmented reality,augmented reality applications,augmented reality iphone4,augmented reality technologies,b,carmigniani,furht,j,reality on mobile devices,systems},
month = dec,
number = {1},
pages = {341--377},
title = {{Augmented reality technologies, systems and applications}},
url = {http://www.springerlink.com/index/10.1007/s11042-010-0660-6},
volume = {51},
year = {2010}
}
@article{RobinKirk2005,
author = {{Robin Kirk}, Jan Newmarch},
file = {::},
journal = {Second IEEE Consumer Communications and Networking Conference, 2005. CCNC. 2005},
keywords = {- home networks,interoperability,location-based services,middleware,mobility,multimedia distribution protocols,multimedia technologies,network architecture,pervasive computing,session user and device},
number = {C},
pages = {343--347},
publisher = {Ieee},
title = {{A location-aware, service-based audio system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1405194},
volume = {00},
year = {2005}
}
@article{Pape1999a,
author = {Pape, Dave},
file = {::},
journal = {Proceedings of SPIE},
keywords = {application framework,stereo perspective},
number = {Figure 1},
pages = {346--353},
publisher = {Spie},
title = {{Transparently supporting a wide range of VR and stereoscopic display devices}},
url = {http://link.aip.org/link/?PSI/3639/346/1\&Agg=doi},
year = {1999}
}
@article{Castle2011,
abstract = {We show how a system for video-rate parallel camera tracking and 3D map-building can be readily extended to allow one or more cameras to work in several maps, separately or simultaneously. The ability to handle several thousand features per map at video-rate, and for the cameras to switch automatically between maps, allows spatially localized AR workcells to be constructed and used with very little intervention from the user of a wearable vision system. The user can explore an environment in a natural way, acquiring local maps in real-time. When revisiting those areas the camera will select the correct local map from store and continue tracking and structural acquisition, while the user views relevant AR constructs registered to that map. The method is shown working in a progressively larger environments, from desktop to large building.},
author = {Castle, Robert O and Klein, Georg and Murray, David W},
doi = {10.1016/j.cviu.2011.02.007},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {augmented reality},
number = {6},
pages = {854--867},
publisher = {Elsevier Inc.},
title = {{Wide-area Augmented Reality using Camera Tracking and Mapping in Multiple Regions}},
url = {http://www.sciencedirect.com/science/article/B6WCX-528YXFJ-1/2/34212f30c9fe494b6317046adfc20777},
volume = {In Press,},
year = {2011}
}
@article{Shen2010,
author = {Shen, Y. and Ong, S.K. and a.Y.C. Nee},
doi = {10.1016/j.destud.2009.11.001},
file = {::},
issn = {0142694X},
journal = {Design Studies},
keywords = {collaborative design,interface design,product design,virtual reality},
month = mar,
number = {2},
pages = {118--145},
publisher = {Elsevier Ltd},
title = {{Augmented reality for collaborative product design and development}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0142694X0900091X},
volume = {31},
year = {2010}
}
@article{Schmalstieg2007c,
author = {Schmalstieg, Dieter and Schall, Gerhard and Wagner, Daniel and Barakonyi, Istv\'{a}n and Reitmayr, Gerhard and Newman, Joseph and Ledermann, Florian},
journal = {IEEE Computer Graphics and Applications},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Database Management Systems,Databases,Ecosystem,Factual,Geographic Information Systems,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Pattern Recognition,Theoretical,Three-Dimensional,Three-Dimensional: methods,User-Computer Interface},
number = {4},
pages = {48--57},
publisher = {IEEE Computer Society},
title = {{Managing complex augmented reality models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17713234 http://doi.ieeecomputersociety.org/10.110910.1109/MCG.2007.85},
volume = {27},
year = {2007}
}
@article{Klopfer2005,
address = {Morristown, NJ, USA},
author = {Klopfer, Eric and Perry, Judy and Squire, Kurt and Jan, Ming-Fong},
doi = {10.3115/1149293.1149333},
file = {::},
isbn = {0805857826},
journal = {Proceedings of the 2005 conference on Computer support for collaborative learning learning 2005: the next 10 years! - CSCL '05},
keywords = {games,handhelds,pda,role play,simulations},
pages = {311--315},
publisher = {Association for Computational Linguistics},
title = {{Collaborative learning through augmented reality role playing}},
url = {http://portal.acm.org/citation.cfm?doid=1149293.1149333},
year = {2005}
}
@article{Fjeld2004,
author = {Fjeld, Morten},
doi = {10.1145/1029036.1029044},
file = {::},
issn = {10725520},
journal = {Interactions},
month = nov,
number = {6},
pages = {11},
title = {{Usability and collaborative aspects of augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1029036.1029044},
volume = {11},
year = {2004}
}
@inproceedings{You2010,
author = {You, Suya and Neumann, Ulrich},
booktitle = {Internet Technology and Applications 2010 International Conference on},
file = {::},
keywords = {augmented reality,e,e business,image reacognition,internet,learning,mobile augmented reality enhancing e learning},
pages = {1--4},
publisher = {IEEE},
title = {{Mobile Augmented Reality for Enhancing E-Learning and E-Business}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5566168},
year = {2010}
}
@article{Adcock2004,
author = {Adcock, Matt and Hutchins, Matthew and Gunn, Chris},
doi = {10.1145/1186415.1186463},
file = {::},
isbn = {1581138962},
journal = {ACM SIGGRAPH 2004 Posters on SIGGRAPH 04},
pages = {41},
publisher = {ACM Press},
title = {{Haptic collaboration with augmented reality}},
url = {http://portal.acm.org/citation.cfm?doid=1186415.1186463},
year = {2004}
}
@article{Rohs2007,
abstract = {A user study was conducted to compare the performance of three methods for map navigation with mobile devices. These methods are joystick navigation, the dynamic peep- hole method without visual context, and the magic lens paradigm using external visual context. The joystick method is the familiar scrolling and panning of a virtual map keep- ing the device itself static. In the dynamic peephole method the device is moved and the map is fixed with respect to an external frame of reference, but no visual information is present outside the devices display. The magic lens method augments an external content with graphical overlays, hence providing visual context outside the device display. Here too motion of the device serves to steer navigation. We compare these methods in a study measuring user performance, mo- tion patterns, and subjective preference via questionnaires. The study demonstrates the advantage of dynamic peephole and magic lens interaction over joystick interaction in terms of search time and degree of exploration of the search space.},
author = {Rohs, Michael and Sch\"{o}ning, Johannes and Raubal, Martin and Essl, Georg and Kr\"{u}ger, A},
doi = {10.1145/1322192.1322219},
file = {::},
isbn = {9781595938176},
journal = {Computing},
keywords = {augmented reality,camera based interaction,camera phones,handheld displays,interac,maps,mobile devices,navigation,spatially aware displays,tion techniques},
pages = {146--153},
publisher = {ACM Press},
title = {{Map navigation with mobile devices: virtual versus physical movement with and without visual context}},
url = {http://portal.acm.org/citation.cfm?id=1322219},
year = {2007}
}
@article{Choi2010,
author = {Choi, Jinhyuk and Jang, Bongkyu and Kim, Gerard J.},
doi = {10.1007/s00779-010-0343-3},
file = {::},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {augmented reality,geospatial tags,mobile interface},
month = nov,
pages = {641--647},
title = {{Organizing and presenting geospatial tags in location-based augmented reality}},
url = {http://www.springerlink.com/index/10.1007/s00779-010-0343-3},
year = {2010}
}
@article{Schall2008,
abstract = {In this paper we present a natural feature tracking algorithm based on on-line boosting used for localizing a mobile computer. Mobile augmented reality requires highly accurate and fast six degrees of freedom tracking in order to provide registered graphical overlays to a mobile user. With advances in mobile computer hardware, vision-based tracking approaches have the potential to provide efficient solutions that are non-invasive in contrast to the currently dominating marker-based approaches. We propose to use a tracking approach which can use in an unknown environment, i.e. the target has not be known beforehand. The core of the tracker is an on-line learning algorithm, which updates the tracker as new data becomes available. This is suitable in many mobile augmented reality applications. We demonstrate the applicability of our approach on tasks where the target objects are not known beforehand, i.e. interactive planing.},
author = {Schall, Gerhard and Grabner, Helmut and Grabner, Michael and Wohlhart, Paul and Schmalstieg, Dieter and Bischof, Horst},
doi = {10.1109/CVPRW.2008.4563134},
file = {::},
isbn = {9781424423392},
journal = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
number = {c},
pages = {1--8},
publisher = {Ieee},
title = {{3D tracking in unknown environments using on-line keypoint learning for mobile augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4563134},
year = {2008}
}
@inproceedings{Prince2002,
abstract = {We present a complete system for live capture of 3D content and simultaneous presentation in augmented reality. The user sees the real world from his viewpoint, but modified so that the image of a remote collaborator is rendered into the scene. Fifteen cameras surround the collaborator, and the resulting video streams are used to construct a three-dimensional model of the subject using a shape-from-silhouette algorithm. Users view a two-dimensional fiducial marker using a video-see-through augmented reality interface. The geometric relationship between the marker and head-mounted camera is calculated, and the equivalent view of the subject is computed and drawn into the scene. Our system can generate 384 288 pixel images of the models at 25 fps, with a latency of < 100 ms. The result gives the strong impression that the subject is a real part of the 3D scene. We demonstrate applications of this system in 3D videoconferencing and entertainment.},
author = {Prince, S J D and Cheok, A D and Farbiz, F and Williamson, T and Johnson, N and Billinghurst, M and Kato, H},
booktitle = {International Symposium on Mixed and Augmented Reality ISMAR},
doi = {10.1109/ISMAR.2002.1115062},
file = {::},
isbn = {0769517811},
pages = {7--13},
publisher = {IEEE Comput. Soc},
title = {3d live: real time captured content for mixed reality},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1115062},
year = {2002}
}
@article{Hirakawa2004,
author = {Hirakawa, Masahito and Koike, Satoshi},
file = {::},
journal = {Proceedings of the IEEE},
keywords = {augmented reality,collaboration,single camera tracking,transparent},
title = {{A Collaborative Augmented Reality System using Transparent Display}},
year = {2004}
}
@article{Reitmayr2001,
abstract = {The combination of mobile computing and collaborative augmented reality into a single system makes the power of computer enhanced interaction and communication in the real world accessible anytime and everywhere. The paper describes our work to build a mobile collaborative augmented reality system that supports true stereoscopic 3D graphics, a pen and pad interface and direct interaction with virtual objects. The system is assembled from off-the-shelf hardware components and serves as a basic test bed for user interface experiments related to computer supported collaborative work in augmented reality. A mobile platform implementing the described features and collaboration between mobile and stationary users are demonstrated},
author = {Reitmayr, G and Schmalstieg, D},
doi = {10.1109/ISAR.2001.970521},
file = {::},
isbn = {0769513751},
journal = {Proceedings IEEE and ACM International Symposium on Augmented Reality},
keywords = {3d interaction,a user wearing,able computing,augmented reality,computer supported collaborative work,figure 1,hybrid tracking,mobile aug,mobile computing,wear},
pages = {114--123},
publisher = {IEEE Comput. Soc},
title = {{Mobile collaborative augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=970521},
year = {2001}
}
@phdthesis{Glenncross2002a,
author = {Glenncross, Masshuda},
file = {::},
school = {University of Manchester},
title = {{A Framework for Physically Based Modelling in Virtual Reality}},
year = {2002}
}
@article{Gintautas2006,
abstract = {We present experimental data on the limiting behavior of an interreality system comprising a virtual horizontally driven pendulum coupled to its real-world counterpart, where the interaction time scale is much shorter than the time scale of the dynamical system. We present experimental evidence that if the physical parameters of the simplified virtual system match those of the real system within a certain tolerance, there is a transition from an uncorrelated dual reality state to a mixed reality state of the system in which the motion of the two pendula is highly correlated. The region in parameter space for stable solutions has an Arnold tongue structure for both the experimental data and for a numerical simulation. As virtual systems better approximate real ones, even weak coupling in other interreality systems may produce sudden changes to mixed reality states.},
author = {Gintautas, Vadas and Hubler, Alfred},
file = {::},
pages = {4},
title = {{Mixed Reality States in a Bidirectionally Coupled Interreality System}},
url = {http://arxiv.org/abs/physics/0611293},
year = {2006}
}
@inproceedings{Buchmann2004,
author = {Buchmann, Volkert and Violich, S. and Billinghurst, M. and Cockburn, A.},
booktitle = {Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and South East Asia},
file = {::},
keywords = {augmented reality,gesture interaction,occlusion},
pages = {212--221},
publisher = {ACM},
title = {{FingARtips: gesture based direct manipulation in Augmented Reality}},
url = {http://portal.acm.org/citation.cfm?id=988871},
year = {2004}
}
@article{Kim2010,
author = {Kim, Seungjun and Dey, Anind K.},
doi = {10.1016/j.cad.2008.10.009},
file = {::},
issn = {00104485},
journal = {Computer-Aided Design},
month = may,
number = {5},
pages = {373--386},
publisher = {Elsevier Ltd},
title = {{AR interfacing with prototype 3D applications based on user-centered interactivity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S001044850800198X},
volume = {42},
year = {2010}
}
@article{Pilet2010,
author = {Pilet, Julien and Saito, Hideo},
doi = {10.1109/VR.2010.5444811},
file = {::},
isbn = {978-1-4244-6237-7},
journal = {2010 IEEE Virtual Reality Conference (VR)},
month = mar,
pages = {71--78},
publisher = {Ieee},
title = {{Virtually augmenting hundreds of real pictures: An approach based on learning, retrieval, and tracking}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5444811},
year = {2010}
}
@article{Humphreys2002a,
author = {Humphreys, Greg and Houston, Mike and Ng, Ren and Frank, Randall and Ahern, Sean and Kirchner, Peter D. and Klosowski, James T.},
journal = {Work},
keywords = {cluster rendering,dering,parallel ren-,remote graphics,scalable rendering,stream,tiled displays,virtual graphics},
month = jul,
number = {3},
title = {{Chromium: a stream-processing framework for interactive rendering on clusters}},
url = {http://portal.acm.org/citation.cfm?doid=566654.566639},
volume = {21},
year = {2002}
}
@article{Coiras2007,
abstract = {A proof of concept for a model-less target detection and classification system for side-scan imagery is presented. The system is based on a supervised approach that uses augmented reality (AR) images for training computer added detection and classification (CAD/CAC) algorithms, which are then deployed on real data. The algorithms are able to generalise and detect real targets when trained on AR ones, with performances comparable with the state-of-the-art in CAD/CAC. To illustrate the approach, the focus is on one specific algorithm, which uses Bayesian decision and the novel, purpose-designed central filter feature extractors. Depending on how the training database is partitioned, the algorithm can be used either for detection or classification. Performance figures for these two modes of operation are presented, both for synthetic and real targets. Typical results show a detection rate of more that 95\% and a false alarm rate of less than 5\%. The proposed supervised approach can be directly applied to train and evaluate other learning algorithms and data representations. In fact, a most important aspect is that it enables the use of a wealth of legacy pattern recognition algorithms for the sonar CAD/CAC applications of target detection and target classification},
author = {Coiras, E and Mignotte, P Y and Petillot, Y and Bell, J and Lebart, K},
doi = {10.1049/iet-rsn:20060098},
file = {::},
issn = {17518784},
journal = {Radar Sonar Navigation IET},
number = {1},
pages = {83--90},
title = {{Supervised target detection and classification by training on augmented reality data}},
volume = {1},
year = {2007}
}
@inproceedings{Wang2009,
author = {Wang, R.Y. and Popovi\'{c}, Jovan},
booktitle = {ACM SIGGRAPH 2009 papers},
doi = {10.1145/1531326.1531369},
file = {::},
issn = {07300301},
keywords = {augmented reality,hand tracking,motion capture,user},
month = jul,
number = {3},
pages = {1--8},
publisher = {ACM},
title = {{Real-time hand-tracking with a color glove}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531369 http://portal.acm.org/citation.cfm?id=1531369},
volume = {28},
year = {2009}
}
@article{Nakanishi2008,
author = {Nakanishi, Miwa and Ozeki, Mugihiko and Akasaka, Toshiya and Okada, Yusaku},
doi = {10.4304/jmm.3.3.34-43},
file = {::},
issn = {17962048},
journal = {Journal of Multimedia},
number = {3},
pages = {34--43},
title = {{What Conditions are Required to Effectively Use Augmented Reality for Manuals in Actual Work}},
url = {http://ojs.academypublisher.com/index.php/jmm/article/view/2204},
volume = {3},
year = {2008}
}
@article{Xu2008,
author = {Xu, K},
doi = {10.1016/j.imavis.2007.08.015},
file = {::},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {augmented reality,fundamental matrix,homography,optical flow,vision based tracking},
month = may,
number = {5},
pages = {673--689},
title = {{Real-time camera tracking for marker-less and unprepared augmented reality environments}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885607001266},
volume = {26},
year = {2008}
}
@article{Schmalstieg2000,
abstract = {Studierstube is an experimental user integace system, which uses collaborative augmented reality to incorporate true 30 interaction into a productivity environment. This concept is extended to bridge multiple user integace dimensions by including multiple users, multiple host platforms, multiple display types, multiple concurrent applications, and a multi-context (i. e., 30 document) integace into a heterogeneous distributed environment. With this architecture, we can explore the user integace design space between pure augmented reality and the popular ubiquitous computing paradigm. We report on our design philosophy centered around the notion of contexts and locales, as well as the underlying sofhare and hardware architecture. Contexts encapsulate a live application together with 30 (visual) and other data, while locales are used to organize geometric reference systems. By separating geometric relationships (locales) from semantic relationships (contexts), we achieve a great amount of flexibility in the configuration of displays. To illustrate our claims, we present several applications including a cinematographic design tool which showcases many features of our system},
author = {Schmalstieg, D and Fuhrmann, A and Hesina, G},
doi = {10.1109/ISAR.2000.880919},
file = {::},
isbn = {0769508464},
journal = {Proceedings IEEE and ACM International Symposium on Augmented Reality ISAR 2000},
pages = {20--29},
publisher = {Ieee},
title = {{Bridging multiple user interface dimensions with augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=880919},
year = {2000}
}
@article{Lee2009a,
author = {Lee, Sang and Choi, Junyeong and Park, Jong-il},
doi = {10.1109/TCE.2009.5174470},
file = {::},
issn = {0098-3063},
journal = {IEEE Transactions on Consumer Electronics},
month = may,
number = {2},
pages = {883--890},
title = {{Interactive e-learning system using pattern recognition and augmented reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5174470},
volume = {55},
year = {2009}
}
@book{Beck2006,
address = {Cambridge, MA},
author = {Beck, John C and Wade, Mitchell},
publisher = {Harvard Business School Press},
title = {{The Kids are Alright: How the Gamer Generation is Changing the Workplace}},
year = {2006}
}
@article{Kolos2010,
author = {Kolos, HHA},
file = {::},
journal = {Media},
title = {{Not just in it to win it: inclusive game play in an MIT dorm}},
url = {http://dspace.mit.edu/handle/1721.1/59731},
year = {2010}
}
@article{Fields2010,
abstract = {Little is known concerning how young players learn to participate in various activities in virtual worlds. We use a new integrative approach called connective ethnography that focuses on how a gaming practice spread across a network of youth at an after school club that simultaneously participated in a virtual world, Whyville.net. To trace youth participation in online and offline social contexts, we draw on multiple sources of information: observations, interviews, videos, online tracking and chat data, and hundreds of hours of play in Whyville ourselves. One gaming practice – the throwing of projectiles and its social uses and nuances – became the focal point of our analyses. The discussions address the methodolo- gical challenges underlying the synthesis of diverse types of data that allowed us to follow youth across multiple spaces as well as initial insights into how this practice was used to negotiate relationships in multiple spaces through play.},
author = {Fields, Deborah A. and Kafai, Yasmin B.},
doi = {10.1177/1555412009351263},
file = {::},
journal = {Games and Culture},
keywords = {ethnography,insider knowledge,participatory culture,social practices,tracking data,tweens,virtual worlds},
mendeley-tags = {ethnography,participatory culture},
number = {88},
title = {{Knowing and Throwing Mudballs, Hearts, Pies, and Flowers: A Connective Ethnography of Gaming Practices}},
url = {http://gac.sagepub.com/cgi/content/abstract/5/1/88},
volume = {5},
year = {2010}
}
@book{Shaffer2006,
author = {Shaffer, David Williamson},
isbn = {1403975051},
keywords = {learning sciences,media production,participatory culture,video games},
mendeley-tags = {learning sciences,media production,participatory culture,video games},
pages = {256},
publisher = {Palgrave Macmillan},
title = {{How Computer Games Help Children Learn}},
url = {http://www.amazon.com/Computer-Games-Help-Children-Learn/dp/1403975051},
year = {2006}
}
@article{Steinkuehler2008,
author = {Steinkuehler, Constance},
issn = {0013-1962},
journal = {Educational Technology Magazine: The Magazine for Managers of Change in Education},
number = {1},
pages = {10 -- 21},
title = {{Massively Multiplayer Online Games as an Educational Technology: An Outline for Research}},
url = {https://vpn.nacs.uci.edu/+CSCO+dh756767633A2F2F6870762E6A62657971706E672E626574++/title/massively-multiplayer-online-games-as-an-educational-technology-an-outline-for-research/oclc/424875321\&referer=brief\_results},
volume = {48},
year = {2008}
}
@article{Golub2008,
abstract = {This article examines discourse about Internet addiction and video–game–related sui- cide in the People’s Republic of China. Through an analysis of media reportage, inter- view transcripts, and chat rooms, a preliminary account of the origins of contemporary Chinese concerns with Internet addiction is provided. This approach differs from biomedical models, which see Internet suicide as a form of mental illness, similar to drug or gambling addiction. This approach draws on anthropological and sociological models of the cultural construction of social problems and argues that concerns with Internet addiction are part of a more general moral crisis faced by Chinese, in response to rapid consumerism, the medicalization of mental illness, and new forms of public and publicity.},
author = {Golub, Alex and Lingley, Kate},
doi = {10.1177/1555412007309526},
file = {::},
journal = {Games and Culture},
keywords = {China,Internet addiction,MMOG,addiction,consumerism,popular culture,suicide,video games},
mendeley-tags = {China,addiction,suicide,video games},
number = {1},
pages = {59--75},
title = {{"Just Like the Qing Empire": Internet Addiction, MMOGs, and Moral Crisis in Contemporary China}},
volume = {3},
year = {2008}
}
@book{Vinge1993,
author = {Vinge, Vernor},
publisher = {Tor Science Fiction},
title = {{A Fire Upon The Deep (Zones of Thought)}},
url = {http://www.amazon.com/Fire-Upon-Deep-Zones-Thought/dp/0812515285},
year = {1993}
}
@misc{GDC,
author = {GDC},
title = {{Game Developers Conference}},
url = {http://www.gdconf.com/aboutgdc/index.html},
urldate = {1/12/2010}
}
@book{Turkle2011,
author = {Turkle, Sherry},
isbn = {1459609026},
keywords = {technology},
mendeley-tags = {technology},
pages = {762},
publisher = {ReadHowYouWant},
title = {{Alone Together: Why We Expect More from Technology and Less from Each Other (Large Print 16pt)}},
year = {2011}
}
@book{McGonigal2011,
address = {New York},
annote = {Comments:
Interventions - 
* she nullifies the play vs. work debate. 
* introduction of Fiero
Critiques - 
* oversimplifies and idealizes game developers
* focuses on satisfying work more than social elements of play? -> she does: we want to share our successes (76)
* what about addressing what has changed? maybe the medium of the internet is giving people a wider pool of people to compare themselves to?... achievements in real life dont garner immediate recognition?
        
Herodotus: first talk about games as a distraction from hunger and kept people's minds off of hunger for 18  years of famine. (p. 5, 10, etc)
        
She has a lot of good stuff in the introduction about how history shows us that games will be a big thing in the future. 
        
meaningful work (she doesnt use this term, but it reminds me of Malcolm Gladwell's use of it): she instead talks about intense engagement, active engagement with our work, good hard work, etc. (p. 35, 
* voluntary workload (39)
* flow; being focused, motivated, charged; (35-36, 42, )
        
the opposite of play is not work, it's depression. (28)
        
eustress (32)
        
types of work (29-32)
* high-stakes work, busy work, mental work, physical work, discovery work, teamwork, creative work.
        
FIERO (p. 33): Italian word for "pride" that describes a type of emotional high. a feeling of triumph. desire to overcome challenges, win battles, etc.   
        
failure is fun (p. 64)
        
the hope of success (p. 68)
        
        
        
      },
author = {McGonigal, Jane},
isbn = {1594202850},
keywords = {flow,game design,game development,game history,happiness,positive psychology,video games},
mendeley-tags = {flow,game design,game development,game history,happiness,positive psychology,video games},
pages = {400},
publisher = {Penguin Press HC, The},
title = {{Reality Is Broken: Why Games Make Us Better and How They Can Change the World}},
year = {2011}
}
@article{Chee2006,
abstract = {This article presents an ethnographic analysis of case studies derived from fieldwork thatwas designed to consider the differentwaysKorean game players establish com- munity online and offline. I consider ways Korean youth participate in activities at Korean computer game rooms, which can be thought of as “third places.”Asynthesis of theKorean conceptWang-tta provides extra insight into the motivations to excel at digital games and one of the strong drivers of such community membership.Korea’s gaming society has many unique elements within the interplay of culture, social structure, and infrastructure.},
author = {Chee, Florence},
file = {::},
journal = {Popular Communication},
number = {3},
pages = {225--239},
title = {{The Games We Play Online and Offline: Making Wang-tta in Korea}},
volume = {4},
year = {2006}
}
@book{Taylor2006a,
address = {Cambridge},
author = {Taylor, T.L.},
keywords = {EverQuest,MMOG,actual players,casual gamer,community,dark elves,family guilds,fan fiction,game knowledge,game space,graphical worlds,offline life,online games,owned,player base,player communities,player community,power gamer,power gaming,power garners,raiding guilds},
mendeley-tags = {EverQuest,MMOG,actual players,casual gamer,community,dark elves,family guilds,fan fiction,game knowledge,game space,graphical worlds,offline life,online games,owned,player base,player communities,player community,power gamer,power gaming,power garners,raiding guilds},
publisher = {The MIT Press},
title = {{Play Between Worlds: Exploring Online Game Culture}},
year = {2006}
}
@techreport{Compaine2001,
address = {Cambridge, MA},
author = {Compaine, Benjamin},
file = {::},
institution = {Internet and Telecoms Convergence Consortium, MIT},
keywords = {digital divide},
mendeley-tags = {digital divide},
number = {July},
title = {{Re-Examining the Digital Divide}},
year = {2001}
}
@article{Williams2003,
abstract = {New media technologies have long tapped into social hopes and anxieties, and the turmoil that follows their appearance offers a window into the social tensions of the time. Clashing sets of utopian and dystopian visions have typically resulted in an ambivalent portrayal of such technologies. Video games prove to be no exception. Through a content analysis of media frames in the USA’s three leading news magazines, the reception and presentation of video-game technology was tracked over a thirty-year period, 1970–2000. The resulting patterns tell a story of vilification and partial redemption, owing to the main- stream acceptance of the medium and the aging user base. Fears of the negative effects from the new technology were hypothesized to come from a routine set of conservative worries. The results support this hypothesis. Moreover, the frames surrounding games, especially in the 1980s, reveal many of the key social tensions of the times, primarily those surrounding gender roles, the separation of age and racial groups, and the role of female parents within an increasingly technological society. The place of video games within the larger context of media history, and the social causes of the frames are discussed.},
author = {Williams, Dmitri},
doi = {10.1080/1369118032000163240},
file = {::},
issn = {1369-118X},
journal = {Information, Communication \& Society},
keywords = {Video games,age,content analysis,frame analysis,gender,media,media frames,media history,popular culture,video games},
mendeley-tags = {age,gender,media,popular culture,video games},
month = dec,
number = {4},
pages = {523--550},
title = {{The Video Game Lightning Rod}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/1369118032000163240\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {6},
year = {2003}
}
@book{McLuhan1962,
abstract = {This book is intended to trace the ways in which the forms of experiences and of mental outlook and expression have been modified, first by the phonetic alphabet and then by printing. McLuhan looks at how "forms of thought" and social organization restulgin from phonetic alphabet has parallels in socio-economic history. He emphasizes that these transitions are important to understand if we are to understand how digital media (or new media, at his time) is changing the shapes of sociality.},
author = {McLuhan, Marshall},
keywords = {collective consciousness,communications,language,linguistics,media,technology},
mendeley-tags = {collective consciousness,communications,language,linguistics,media,technology},
publisher = {University of Toronto Press},
title = {{The Gutenberg Galaxy: The Making of Typographic Man}},
url = {http://www.amazon.com/Gutenberg-Galaxy-Making-Typographic-Man/dp/0802060412},
year = {1962}
}
@book{Traweek1988,
address = {Cambridge, MA},
annote = {The way the author addresses her strategy for ethnographic writing positions her clearly in the time period when Writing Culture marked a changing point in anthropology. 
        
Summary (preface x)
Prologue - Introduces actors, including herself
        
Chapter 1 - spaces of the laboratory
        
Chapter 2 - introduces and describes some detectors, "the devices whose design is at the heart of the experimental process".
        
* "Like the environments we build, the artifacts we make remind us of who we are, how we are expected to act, and what we value" (Traweek 1988:x).
        
"The detector is a research group's means of production of knowledge, the tool the group builds and uses to make its livelihood. To the experimentalists each detector has its physiognomy, full of meaning and value. In the features of a detector we can learn to read a group's history, its division of labor, its strategy for discovery" (Traweek 1988:x).
        
Chatper 3 - how physicists are made:
"Novices must learn what sorts of things they need to know to be taken seriously; they must become unselfconscious practitionesr of the culture, feeling the appropriate desires and anxieties, thinking about the world in a characteristic way" (Traweek 1988:x-xi).
        
Chapter 4 - stable features in the way physicists act toward each other. "The community has a relatively fixed and highly articulated hierarchical structure
        
Chapter 5 - about change and trying to stay at "the cutting edge". They need priority access to accelerators and therefore negotiate with one another for them...
        
Epilogue - Relation between the physicists' theories of time and their experience of time in their working lives. The conclusion: the tension in these attitudes and actions towards time is reflected in the social world of high energy physics.
        
"Ironically, the denial of human agency in the construction of science coexists with the imaging of scientists as male and nature as female" (Traweek 1988:158).
        
"The physicists are engaged in the incessant production and reading of machines in which neither the machine-text nor their reading of it is ever fixed. These texts and readings are imbedded in community traditions about how to interpret nature and identify discovery" (Traweek 1988:161).
        
"Phallic imagery is found in much of the informal discourse of the male particle physicists" (Traweek 1988:79).},
author = {Traweek, Sharon},
keywords = {agency,ethnography,gender,imaginary,knowledge production,laboratory science,science,space,time},
mendeley-tags = {agency,ethnography,gender,imaginary,knowledge production,laboratory science,science,space,time},
publisher = {Harvard University Press},
title = {{Beamtimes and Lifetimes: The World of High Energy Physicists}},
year = {1988}
}
@article{Escobar1994,
author = {Escobar, Arturo},
file = {::},
journal = {Current Anthropology},
month = jun,
number = {3},
pages = {211},
title = {{Welcome to Cyberia: Notes on the Anthropology of Cyberculture}},
url = {http://www.journals.uchicago.edu/doi/abs/10.1086/204266},
volume = {35},
year = {1994}
}
@book{Anderson2006,
author = {Anderson, Benedict},
keywords = {Indonesia,capitalism,community,nationalism,owned,print capitalism,print media,read,state},
mendeley-tags = {Indonesia,capitalism,community,nationalism,owned,print capitalism,print media,read,state},
publisher = {Verso},
title = {{Imagined Communities: Reflections on the Origin and Spread of Nationalism, New Edition}},
url = {http://www.amazon.com/Imagined-Communities-Reflections-Origin-Nationalism/dp/1844670864},
year = {2006}
}
@article{Malaby2006,
abstract = {Games have intruded into popular, academic, and policy-maker awareness to an unprecedented level, and this creates new opportunities for advancing our understand- ing of the relationship of games to society. The author offers a new approach to games that stresses them as characterized by process. Games, the author argues, are domains of contrived contingency, capable of generating emergent practices and interpretations, and are intimately connected with everyday life to a degree heretofore poorly understood. This approach is both consistent with a range of existing social theory and avoids many of the limitations that have characterized much games scholarship to date, in particular its tendency toward unsustainable formalism and exceptionalism. Rather than seeing gaming as a subset of play, and therefore as an activity that is inherently separable, safe, and pleasurable, the author offers a pragmatic rethinking of games as social artifacts in their own right that are always in the process of becoming. This view both better accords with the experience of games by participants cross-culturally and bears the weight of the new questions being asked about games and about society.},
author = {Malaby, Thomas},
file = {::},
journal = {Games and Culture},
keywords = {contingency,games,play,practice theory,process},
mendeley-tags = {contingency,games,play,practice theory,process},
number = {2},
title = {{Beyond Play: A New Approach to Games}},
url = {http://gac.sagepub.com/cgi/content/abstract/1/1/17},
volume = {2},
year = {2006}
}
@book{Dibbell2006,
address = {New York},
author = {Dibbell, Julian},
keywords = {online games},
mendeley-tags = {online games},
publisher = {Basic Books},
title = {{Play Money. Or, How I Quit my Day Job and Made Millions Trading Virtual Loot}},
year = {2006}
}
@book{Ito2009,
address = {Cambridge, MA},
author = {Ito, Mizuko},
keywords = {children's software,design,education,edutainment,new media,technology},
mendeley-tags = {children's software,design,education,edutainment,new media,technology},
publisher = {MIT Press},
title = {{Engineering Play: A Cultural History of Children's Software}},
year = {2009}
}
@article{Andrejevic2005,
abstract = {This article explores a range of technologies for ‘lateral surveillance’ or peer monitoring arguing that in a climate of perceived risk and savvy skepticism individuals are increasingly adopting practices associated with marketing and law enforcement to gain information about friends, family members, and prospective love interests. The article argues that the adoption of such technologies corresponds with an ideology of ‘responsibilization’ associated with the risk society: that consumers need training in the consumption of services and the development of expertise to monitor one another. Rather than displacing ‘top-down’ forms of monitoring, such practices emulate and amplify them, fostering the internalization of government strategies and their deployment in the private sphere. In an age in which everyone is to be considered potentially suspect, all are simultaneously urged to become spies.},
author = {Andrejevic, Mark},
file = {::},
journal = {Surveillance \& Society},
keywords = {governance,government,lateral surveillance,owned,panopticon,peer monitoring,responsibilization,risk,social networking,surveillance},
mendeley-tags = {governance,government,owned,panopticon,peer monitoring,risk,social networking,surveillance},
pages = {479--497},
title = {{The work of watching one another: Lateral surveillance, risk, and governance}},
url = {http://www.surveillance-and-society.org},
volume = {2},
year = {2005}
}
@article{Chen2008,
abstract = {In applying traditional game theory to multiplayer computer games, not enough attention has been given to actual player practice in local settings. To do this, the author describes a team of players in the massively multiplayer online role-playing game World of Warcraft. This motley group learned how to defeat an end-game dungeon through collaborative improvements on communication and coordina- tion. It focused on sustaining and building player relationships and learning together rather than the accepted norm of obtaining magical items. Trust was forged through a desire to ‘‘hang out and have fun’’ and was evidenced by the joviality of their communication. The group’s ability to reflect and be consistent about its desires for camaraderie allowed it to recover from a poor performing night, which threatened to disband the group. The team’s success depended on its ability to define and retain a coherent group identity and establish shared social incentives rather than individual incentives for participation.},
author = {Chen, Mark G.},
file = {::},
journal = {Games and Culture},
keywords = {collaboration},
mendeley-tags = {collaboration},
number = {1},
pages = {47--73},
title = {{Communication, Coordination, and Camaraderie in World of Warcraft}},
url = {http://gac.sagepub.com/cgi/doi/10.1177/1555412008325478},
volume = {4},
year = {2008}
}
@misc{Reeves2007,
abstract = {Complex multiplayer online games foreshadow new possibilities for effective leadership and the future of work. An increasingly large portion of game play is collaborative and strategic, and it requires sustained interactions with several players. The engagement of games and the lessons they foster may influence a new gamer generation to expect real work that better resembles the structure of complex play. This project observed leadership in complex online games to allow a comparison between current leadership models and leadership in the games. We began with a contemporary model of leadership, The Sloan Leadership Model, which defines leadership in four dimensions Sensemaking, Inventing, Relating and Visioning. The project goal was to see if the Sloan model, and by extension, other traditional models of leadership, need to be changed to account for game play. Observations included 50+ hours of game play, compiled into 11 movies illustrating different leadership issues. We also included first-hand reports from 6 expert players, 10 interviews with recognized guild leaders, and 171 respondents to an online open-ended survey about leadership in games. Conclusions include the following: leadership in the games includes all skills currently identified in the Sloan model, but puts a premium on the dimensions of Relating and Inventing. Leadership in the games happens fast, it encourages risk taking, it promotes temporary rather than permanent leadership roles, and there are numerous opportunities for leadership practice. The most important conclusion, however, was that game environments make leadership easier. Critical leadership features in game environments include virtual economies, transparency of metrics, and connection methods for inter-group communication. We conclude with predictions about the future of games and leadership in the enterprise, including comments about how games will highlight qualities of digital interactions increasingly important for online leadership, and qualities of leadership unique to games.},
author = {Reeves, Byron and Malone, Thomas},
title = {{Leadership in Games and at Work: Implications for the Enterprise of Massively Multiplayer Online Role-playing Games}},
url = {http://www.seriosity.com/downloads/Leadership\_In\_Games\_Seriosity\_and\_IBM.pdf},
year = {2007}
}
@inproceedings{Ducheneaut2009,
abstract = {An increasingly large number of users connect to virtual worlds on a regular basis to conduct activities ranging from gaming to business meetings. In all these worlds, users project themselves into the environment via an avatar: a 3D body which they control and whose appearance is often customizable. However, considering the prevalence of this form of embodiment, there is a surprising lack of data about how and why users customize their avatar, as well as how easy and satisfying the existing avatar creation tools are. In this paper, we report on a study investigating these issues through a questionnaire administered to more than hundred users of three a virtual worlds offering widely different avatar creation and customization systems (Maple Story, World of Warcraft, and Second Life). We illustrate the often-surprising choices users make when creating their digital representation and discuss the impact of our findings for the design of future avatar creation systems.},
author = {Ducheneaut, Nicolas and Yee, Nicholas and Wadley, Greg and Wen, Ming-Hui "Don"},
booktitle = {ACM Conference on Computer-Human Interaction},
file = {::},
keywords = {Maple Story,Second Life,World of Warcraft,avatar,avatars,customization,design,embodiment,online games,personality,virtual worlds},
mendeley-tags = {Maple Story,Second Life,World of Warcraft,avatar,design,embodiment,online games},
pages = {1--10},
title = {{Body and Mind: A Study of Avatar Personalization in Three Virtual Worlds}},
year = {2009}
}
@article{Driskell2002,
abstract = {Critiques of modern societies often cite the loss of community as a result of weak connections with local places and changing modes of social interactions.We will ar- gue that both the loss of community and attempts to regain community can be understood as a series of debates progressing from one environment to another. Specifically, community was seen as being lost from its original environment, the local place, typically a village or a residential neighborhood. Then came the claim that community could be regained in the environment of shared space, typically vol- untary associations or work groups. The most recent candidate for regaining com- munity is the digital environment of cyberspace. Using existing research, we seek to determine if virtual communities are indeed true communities. Can the virtual community provide two of the core elements—common ties and social interaction— without identification with place? We explore each of these environments as we search for community and the qualities necessary to establish community, finding that virtual communities are spatially liberated, socially ramified, topically fused, and psychologically detached, with a limited liability. In this sense, ifwe understand community to include the close, emotional, holistic ties of Gemeinschaft, then the virtual community is not true community. That does not necessarily imply, how- ever, that Internet relationships are the antithesis of true community relationships. The Internet may either reduce community, reinforce community, or provide a weak replacement.},
author = {Driskell, Robyn Bateman and Lyon, Larry},
file = {::},
journal = {City \& Community},
keywords = {Gemeinschaft,Gesellschaft,community,cyberspace,online,online community,virtual,virtual community},
mendeley-tags = {Gemeinschaft,Gesellschaft,community,cyberspace,online,online community,virtual,virtual community},
number = {December},
pages = {373--390},
title = {{Are Virtual Communities True Communities? Examining the Environments and Elements of Community}},
volume = {1:4},
year = {2002}
}
@article{Williams2010,
author = {Williams, D. and Kennedy, T. L. M. and Moore, R. J.},
doi = {10.1177/1555412010364983},
file = {::},
issn = {1555-4120},
journal = {Games and Culture},
month = may,
title = {{Behind the Avatar: The Patterns, Practices, and Functions of Role Playing in MMOs}},
url = {http://gac.sagepub.com/cgi/doi/10.1177/1555412010364983},
year = {2010}
}
@book{Lastowka2010,
address = {New Haven, CT},
author = {Lastowka, Greg},
keywords = {copyright,law,mmorpgs,virtual property,virtual worlds},
publisher = {Yale University Press},
title = {{Virtual Justice}},
url = {http://bit.ly/virtualjustice},
year = {2010}
}
@book{Jenkins2008,
author = {Jenkins, Henry},
keywords = {ARG,Lost,forums,media,owned,read,technology},
mendeley-tags = {ARG,Lost,forums,media,owned,read,technology},
publisher = {NYU Press},
title = {{Convergence Culture: Where Old and New Media Collide}},
url = {http://www.amazon.com/Convergence-Culture-Where-Media-Collide/dp/0814742955},
year = {2008}
}
@book{Stephenson1995,
abstract = {In Snow Crash, Neal Stephenson took science fiction to dazzling new levels. Now, in The Diamond Age, he delivers another stunning tale. Set in twenty-first century Shanghai, it is the story of what happens when a state-of-the-art interactive device falls in the hands of a street urchin named Nell. Her life\^{a}and the entire future of humanity\^{a}is about to be decoded and reprogrammed\^{a}¦},
address = {New York},
author = {Stephenson, Neal},
publisher = {Bantam Books},
title = {{The Diamond Age}},
year = {1995}
}
@article{Boellstorff2010,
abstract = {The goal of this speculative essay is to ask after potential consequences of the emerging notion of “cloud computing” not only for virtual worlds, but also for human sociality in general. I explore the short history of cloud computing and some presuppositions that shape construals of “cloud computing” and its consequences. I examine convergences and distinctions between cloud computing and virtual worlds, and what this tells us about new forms of computer-mediated culture.},
annote = {Parts:
        
1 - evaporation: questions of inquiry
* rethinking notions of place and connection; possiibilities of connection \& empowerment, as well as the risk of centralization and alienation.
        
2 - history and current usages of the phrase "cloud computing" 
** upload \& download?
* transition from imagination of "the net" or "matrix", to "cloud"
* intensification or condensation of Internet mediation.
        
3 - presuppositions shaping construals of "cloud computing" and its consequences.
4 - convergences \& distinctions between cloud computing and virtual worlds.},
author = {Boellstorff, Tom},
file = {::},
journal = {Journal of Virtual Worlds Research},
keywords = {cloud computing,computer-mediated culture,connection,cybersociality,network,place,power,social networks,virtual worlds},
mendeley-tags = {cloud computing,computer-mediated culture,connection,cybersociality,network,place,power,virtual worlds},
number = {5},
title = {{Culture of the Cloud}},
volume = {2},
year = {2010}
}
@book{Anderson1995a,
author = {Anderson, Robert H. and Bikson, Tora K. and Law, Sally Ann and Mitchell, Bridger M.},
booktitle = {Main},
file = {::},
keywords = {digital divide},
mendeley-tags = {digital divide},
publisher = {RAND},
title = {{Universal Access to E-mail: Feasibility and Societal Implications}},
year = {1995}
}
@book{Gilsdorf2010,
author = {Gilsdorf, Ethan},
pages = {336},
publisher = {Lyons Press},
title = {{Fantasy Freaks and Gaming Geeks: An Epic Quest for Reality Among Role Players, Online Gamers, and Other Dwellers of Imaginary Realms}},
url = {http://www.amazon.com/Fantasy-Freaks-Gaming-Geeks-Imaginary/dp/1599219948},
year = {2010}
}
@article{Williams2006,
abstract = {Researchers are encouraged to study the social uses and effects of gaming before stereotypes form and guide both their own and the public’s thinking. The rise of online games comes at a particular historical moment for social reasons as well as technological ones and prompts a wide array of questions. The transition of public life from common spaces to private ones is exemplified in the move of game play from arcades to homes. As our real-world civic and social institutions experience steady decay, what is the impact of transferring our social networks and communities into virtual spaces? Will games become our new third places, and how will that affect us? These are questions researchers can answer but ones that need to be addressed before ideologues, defenders, and attackers muddle empiricism.},
author = {Williams, Dmitri},
file = {::},
journal = {Games and Culture},
keywords = {MMOG,community,massively multiplayer,online games,social capital,social networks},
mendeley-tags = {MMOG,community,massively multiplayer,online games,social capital,social networks},
number = {13},
title = {{Why Game Studies Now? Gamers Don't Bowl Alone}},
url = {http://gac.sagepub.com/cgi/content/abstract/1/1/13},
volume = {1},
year = {2006}
}
@incollection{Ito2006,
abstract = {The integration of mobile phones into social life is still in its infancy in most parts of the world, triggering a set of sociocultural convulsions as institutions, people, and places adapt to and regulate its use. As is typical with technologies that alter patterns of social life, the keitai has been subjected to an onslaught of criticism for the ways in which it disrupts existing norms of propriety and social boundaries (Matsuda Introduction, this volume). While celebrated as a technology that liberates users from the constraints of place and time, it has equally been reviled as a technology that disrupts the integrity of places and face-to-face social encounters. Sadie Plant (2002: 30) writes that "even a silent mobile can make its presence felt as though it were an addition to a social group, and . . . many people feel that just the knowledge that a call might intervene tends to divert attention from those present at the time.” 

The case of heavy keitai email users in urban Japan provides one window into the new kinds of social situations (taking a chapter from Goffman, 1963), or more precisely, technosocial situations (adding a chapter from technology studies) emerging with the advent of widespread keitai use. This chapter reports on an ethnographic study of keitai users in the greater Tokyo area, examining new social practices in keitai email communication, and how they are constituting technosocial situations that alter definitions of co-presence and the experience of urban space. The central argument is that keitai participate in the construction of social order as much as they participate in its destabilization. After first presenting the methodological and theoretical framework for this study, this chapter presents three technosocial situations enabled by keitai email: keitai text chat, ambient virtual co-presence, and the augmented flesh meet.ii},
author = {Ito, Mizuko and Okabe, Daisuke},
booktitle = {Personal, Portable, Pedestrian: Mobile Phones in Japanese Life},
file = {::},
keywords = {Japan,email,ethnography,keitai,mobile phones,technology,technosocial situations},
mendeley-tags = {Japan,email,ethnography,keitai,mobile phones,technology,technosocial situations},
number = {2001},
pages = {1--16},
publisher = {MIT Press},
title = {{Technosocial Situations: Emergent Structurings of Mobile Email Use}},
year = {2006}
}
@incollection{Bartle2003,
author = {Bartle, Richard},
booktitle = {Developing Online Games: An Insider's Guide},
editor = {Mulligan, Jessica and Patrovsky, Bridgette},
file = {::},
keywords = {game development,player types,virtual world},
mendeley-tags = {game development,player types,virtual world},
pages = {1--25},
publisher = {New Riders Games; illustrated edition},
title = {{Hearts, Clubs, Diamonds, Spades: Players Who Suit MUDs}},
year = {2003}
}
@book{DeKoven2002,
author = {DeKoven, Bernie},
publisher = {IUniverse},
title = {{The Well-Played Game: A Playful Path to Wholeness}},
url = {http://www.amazon.com/Well-Played-Game-Playful-Path-Wholeness/dp/0595217907},
year = {2002}
}
@incollection{Boyd2009,
abstract = {"I illustrate how distinctions in social network site adoption and the perceptions teens – and adults – have about these sites and their users reflect broader narratives of race and class in American society."},
annote = {small school outside of Boston, teenagers started out on myspace, then split between myspace and facebook along divisional race lines. 
        
      },
author = {Boyd, Danah},
booktitle = {Digital Race Anthology},
editor = {Nakamura, Lisa and Chow-White, Peter},
file = {::},
keywords = {class,divisions,race,social network sites,social networking},
mendeley-tags = {class,divisions,race,social network sites,social networking},
pages = {1--44},
publisher = {Routledge},
title = {{White Flight in Networked Publics ? How Race and Class Shaped American Teen Engagement with MySpace and Facebook}},
year = {2009}
}
@article{Ducheneaut2005a,
abstract = {Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players’ social experiences. In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft. Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity. We discuss the implications of our findings for the design of future games and other online social spaces.},
author = {Ducheneaut, Nicolas},
file = {::},
journal = {Interface},
keywords = {MMOG,Massively Multiplayer Online Games,Online communities,WoW,achievement system,activity metrics,social dynamics,technosociality},
mendeley-tags = {MMOG,WoW,achievement system,technosociality},
number = {March},
pages = {1--10},
title = {{“Alone Together?” Exploring the Social Dynamics of Massively Multiplayer Online Games}},
year = {2005}
}
@book{Huizinga1950,
address = {Boston},
author = {Huizinga, Johan},
keywords = {magic circle},
mendeley-tags = {magic circle},
publisher = {The Beacon Press},
title = {{Homo Ludens: a study of the play element in culture}},
year = {1950}
}
@book{Kushner2003,
author = {Kushner, David},
keywords = {Doom,John Romero,game history,video games},
mendeley-tags = {Doom,John Romero,game history,video games},
title = {{Masters of Doom: how Two Guys Created an Empire and Transformed Pop Culture}},
year = {2003}
}
@article{Taylor2003b,
abstract = {While shows like The X-Files and 24 have merged conspiracy theories with popular science (fictions), some video games have been pushing the narrative even further. Electronic Art’s Majestic game was released in July 2001 and quickly generated media buzz with its unusual multi-modal gameplay. Mixing phone calls, faxes, instant messaging, real and ‘fake’ websites, and email, the game provides a fascinating case of an attempt at new directions for gaming communities. Through story, mode of playing, and use of technology, Majestic highlights the uncertain status of knowledge, community and self in a digital age; at the same time, it allows examination of alternativeways of understanding games’ role and purpose in the larger culture. Drawing on intricate storylines involving government conspiracies, techno-bio warfare, murder and global terror, players were asked to solve mysteries in the hopes of preventing a devastating future of domination. Because the game drew in both actual and Majestic-owned/-designedwebsites, it constantly pushed those playing the game right to borders where simulation collides with ‘factuality’. Given the wide variety of ‘legitimate’ conspiracy theory, alien encounters and alternative science web pages, users often could not distinguish when they were leaving the game’s pages and venturing into ‘real’ World Wide Web sites. Its further use of AOL’s instant messenger system, in which gamers spoke not only to bots but to other players, pushed users to evaluate constantly both the status of those they were talking to and the information being provided. Additionally, the game required players to occupy unfamiliar subject positions, ones where agencywas attenuated, and which subsequently generated amulti-layered sense of unease among players. This mix of authentic and staged information in conjunction with technologically mediated roles highlights what are often seen as phenomenon endemic to the Internet itself ; that is, the destabilization of categories of knowing, relating, and being.},
author = {Taylor, T.L. and Kolko, Beth E.},
file = {::},
journal = {Information, Communication \& Society},
keywords = {Internet,Majestic,games,identity,multi-player,pervasive},
number = {4},
pages = {497--522},
title = {{Boundary Spaces: Majestic and the uncertain status of knowledge, community and self in a digital age}},
url = {http://www.tandf.co.uk/journals},
volume = {6},
year = {2003}
}
@book{Consalvo2007,
address = {Cambridge},
author = {Consalvo, Mia},
keywords = {cheating},
mendeley-tags = {cheating},
publisher = {The MIT Press},
title = {{Cheating: Gaining Advantage in Videogames}},
year = {2007}
}
@article{Bettelheim1987,
annote = {Play: "Generallyspeaking, play refers to the young child's activities characterized by freedom from all but person ally -
imposed rules (which are changed at will), by free wheeling fantasy involvement, and by the absence of any goals outside the activity itself. "
        
Games: "Games, however, are usually competitive and are characterized by agreed-upon, often externally imposed, rules, by a requirement to use the implements of the activity in the manner for which they are intended and not as fancy suggests, and frequently by a goal or purpose outside the activity, such as winning the game." (page 4 of my version)
        
"Children recognize early on that play is an opportunity for pure enjoyment, whereas games may involve considerable stress." (4)},
author = {Bettelheim, Bruno},
file = {::},
journal = {The Atlantic},
keywords = {child development,children,developmental psychology,play},
mendeley-tags = {child development,children,developmental psychology,play},
title = {{Bettelheim - The Importance of Play.pdf}},
year = {1987}
}
@book{Galloway2006,
abstract = {Preface: "Philosophy, Gilles Deleuze and Felix Guattary wrote late in life, is about the creation of concepts. To them a concept is always a type of vector for thought, a cognitive vehicle designed to move things from one p lace to another. In the five essays in this book, I try to formulate a few conceptual movements, a few conceptual algorithms, for thinking about video games. What is an algorithm if no a machine for the motion of parts? And it is the artfulness of the motiong that matters most. Following Deluze and Guattar, I wish my conceptual algorithms to be as ad hoc, as provisional, as cobbled together as theirs were. Let them be what Northrop Frye once called "an interconnected group of suggestions." Video games have been central to mass culture for more than twenty years, yet surprisingly few books today attempt a critical analysis of the medium. In this study, I try not to reduce video game studies to other fields, such as literary criticism or cinema studies, nor do I attempt to dissect games as mere data for sociological or anthropological research. Instead, I attempt an analysis of what Fredric Jameson calls "the poetics of social forms," that is, the aesthetic and political impact of video games as a formal medium. So, at the end of the day, this book is not a book about video games, just as Jameson's Signatures of the Visible is not a book about film in any narrow sense. The text by Jameson offers instead certain conceptual algorithms for modernity, the information age, and the various aesthetic and political realities at play within them. I hope that my book will approximate something similar. "No more vapor theory anymore," wrote Geert Lovink. This applies to the video game generation as much as anyone else. Our generation needs to shrug off the contributions of those who view this as all so new and shocking. They came from somewhere else and are still slightly unnerved by digital technology. We were born here and love it. Short attention spans, cultural fragmentation, the speeding up of life, identifying change in every nook and cranny - these are neuroses in the imagination of the doctor, not the life of the patient. So, above all, this book is about loving video games. It's about exploring their artistry, their political possibility, their uniqueness. The first question is: Do you play video games? Then next we may explore what they do.},
annote = {"A video game is a cultural object, bound by history and materiality, consisting of an electronic computational device and a game simulated in software." (1)
        
"The player, or operator, is an individual agent who communicates with the software and hardware of the machine, sending codified messages via input devices and receiving codified messages via output devices. Taking these elements in sum, I use the term "gaming" to reer to the entire apparatus of the video game. It is a massive cultural medium involving large numbers of organic machines and inorganic machines. Embedded as it is in the information systems of the millenary society, this medium will likely remain signifiant for some time to come." (2)
        
"If photographs are images, and films are moving images, then video games are actions.... WIthout action, games remain only in the pages of an abstract rule book. Without the active participation of players and machines, video games exist only as static computer code. Video games come into being when the machine is powered up and the software is executed; they exist when enacted." (2)
        
"...the video game Dope Wars has more in common with the finance software Quicken that it does with traditional games like chess, roulette, or billiards." (6)
        
diegesis, narrative (7)
likens narrative to Caillois's "second reality," reality outside of normal life (?) 
* is this like virtual reality, too? Is there a narrative for Second Life which is not itself a game? Does this apply for virtual worlds too, or just for games? Is the narrative an essential part of the game?
        
gamic apparatus (7-8) made up of diegetic and non-diegetic elements.
* diegetic: narrative, story-telling, world-creating elements.
* non-diegetic: I don't understand this fully, but he uses the HUD and Pause button as an examples. Absent of narrative meaning. It's then like a tool or game element that isnt necessarily part of the narrative. Would it be there irrespective of the particular narrative? We could have any story going on and be in any kind of world but still have a HUD?
        
 Four quandrants created by the superimposition of two axes: machine \& operator, diegetic \& non-diegetic. (8)
        
Pure Process: diegetic machine acts (10-12)
* ambience act: sounds similar to Tom's AFK. does this ability mean that there is a virtual world involved? -> renders the world as an aesthetic object or experience being performed by the machine. the player is absent.
* "There is always a kind of "charged expectation" in the ambience act" (11).
* also includes cinematic or machinima interludes.
        
Subjective Algorithm: non-deigetic operator acts (12- )
        
        
        
        
        
      },
author = {Galloway, Alexander},
keywords = {Lara Croft,action,agency,avatar,code,cyberculture,language,narrative,network,network society,posthumanism,programming,software,techne,technology,video games},
mendeley-tags = {Lara Croft,action,agency,avatar,code,cyberculture,language,narrative,network,network society,posthumanism,programming,software,techne,technology,video games},
publisher = {University of Minnesota Press},
title = {{Gaming: Essays on Algorithmic Culture}},
year = {2006}
}
@article{Boellstorff2006,
abstract = {The information age has, under our noses, become the gaming age. It appears likely that gaming and its associated notion of play may become a master metaphor for a range of human social relations, with the potential for newfreedoms and newcreativity as well as newoppressions and inequality. Although no methodological or theoretical approach can represent a cure-all for any discipline, in this article the author discusses how anthro- pological approaches can contribute significantly to a game studies nimble enough to respond to the unanticipated, conjunctural, and above all rapidly changing cyberworlds through which everyone in some way is now in the process of redefining the human project.},
author = {Boellstorff, Tom},
file = {::},
journal = {Games and Culture},
keywords = {anthropology,culture,ethnography,game studies,methodology},
mendeley-tags = {anthropology,culture,ethnography,game studies,methodology},
number = {1},
pages = {29--35},
title = {{A Ludicrous Discipline?}},
volume = {1},
year = {2006}
}
@article{Consalvo2009,
abstract = {Games are created through the act of gameplay, which is contingent on player acts. However, to understand gameplay, we must also investigate contexts, justifications, and limitations. Cheating can be an excellent path into studying the gameplay situation, because it lays bare player’s frustrations and limitations. It points to ludic hopes and activities, and it causes us to question our values, our ethics. In comparison, the concept of the magic circle seems static and overly formalist. Structures may be necessary to begin gameplay, but we cannot stop at structures as a way of understanding the gameplay experience. Because of that, we cannot say that games are magic circles, where the ordinary rules of life do not apply. Of course they apply, but in addition to, in competition with, other rules and in relation to multiple contexts, across varying cultures, and into different groups, legal situations, and homes.},
author = {Consalvo, Mia},
file = {::},
journal = {Games and Culture},
keywords = {game studies,game theory,magic circle,real-money trade,video games},
mendeley-tags = {game studies,game theory,magic circle,real-money trade,video games},
number = {4},
pages = {408--417},
title = {{There is No Magic Circle}},
volume = {4},
year = {2009}
}
@book{Nardi2010,
address = {Ann Arbor},
author = {Nardi, Bonnie},
isbn = {0472050982},
keywords = {World of Warcraft,collaboration,ethnography,guilds,mmogs,video games,virtual worlds},
mendeley-tags = {World of Warcraft,collaboration,ethnography,guilds,mmogs,video games,virtual worlds},
pages = {248},
publisher = {University of Michigan Press},
title = {{My Life as a Night Elf Priest: An Anthropological Account of World of Warcraft (Technologies of the Imagination: New Media in Everyday Life)}},
year = {2010}
}
@book{Koster2004,
author = {Koster, Raph},
keywords = {design,owned,unread},
mendeley-tags = {design,owned,unread},
publisher = {Paraglyph},
title = {{Theory of Fun for Game Design}},
year = {2004}
}
@article{Hotchkiss2003a,
author = {Hotchkiss, L.M.},
file = {::},
journal = {The Velvet Light Trap},
number = {1},
pages = {15--32},
publisher = {University of Texas Press},
title = {{"Still in the game:" Cybertransformations}},
url = {http://muse.jhu.edu/journals/vlt/summary/v052/52.1hotchkiss.html},
volume = {52},
year = {2003}
}
@book{Stephenson2000,
author = {Stephenson, Neal},
publisher = {Spectra},
title = {{Snow Crash (Bantam Spectra Book)}},
url = {http://www.amazon.com/Snow-Crash-Bantam-Spectra-Book/dp/0553380958},
year = {2000}
}
@article{Ash2010,
author = {Ash, James},
file = {::},
journal = {Environment and Planning D: Society and Space},
number = {4},
pages = {653--671},
title = {{Architectures of affect: anticipating and manipulating the event in processes of videogame design and testing}},
url = {http://www.envplan.com/abstract.cgi?id=d9309},
volume = {28},
year = {2010}
}
@book{Boellstorff2008,
address = {Princeton},
author = {Boellstorff, Tom},
file = {::},
keywords = {Second Life,actual,creative capitalism,digital human,owned,read,social form,tinkering,virtual,virtual world},
mendeley-tags = {Second Life,actual,creative capitalism,digital human,owned,read,social form,tinkering,virtual,virtual world},
publisher = {Princeton University Press},
title = {{Coming of Age in Second Life: An Anthropologist Explores the Virtually Human}},
year = {2008}
}
@article{Bardzell2008,
abstract = {Few people would say that they wished their romantic lives were more like computing: effi- cient, automated, inorganic, and lightning fast. Yet technology is becoming increasingly implicated in the most intimate aspects of our lives and selves. At the same time we see calls in HCI to make technology more human scaled, everyday, domestic, and emotionally competent. Both of these trends are evidence that technology and cultural prac- tices are still calibrating to one another. As a result, paying spe- cial attention to the intersections of technology and symbolically and emotionally dense cultural experiences, such as sex, food, and art, can be especially illumi- nating. We use the term “intimacy” as opposed to “sexuality” to empha- size the broadest and most inclu- sive notions of human sexuality as they have been explored in psychology, women’s studies, phi- losophy, sociology, and literary theory, among other fields. This more expansive conceptualization of sexuality goes far beyond acts of physical sex to include a wide range of human relation- ships, such as friendship and romantic attachment; categories of experience, from pleasure to anxiety; and philosophically rich conceptual domains, such as embodiment and identity. To be sure, technology has created abundant opportunity for emotionally vacuous sexual content. However, we bracket such content aside, not because it lacks social or technical sig- nificance, but rather because undue emphasis on it potentially forecloses more nuanced understandings of how everyday people find emotional fulfillment in online social spaces. Research on positive aspects of intimacy online has the potential to give interaction designers insight into the relationships between tech- nology and some of the deepest and most meaningful dimensions of human experience.},
author = {Bardzell, Jeffrey and Bardzell, Shaowen},
file = {::},
journal = {interactions},
keywords = {HCI,identity,intimacy,online,owned,representation,romance,second life,self,software,subjectivity,technology},
mendeley-tags = {HCI,identity,intimacy,online,owned,representation,romance,second life,self,software,subjectivity,technology},
pages = {11--15},
title = {{Intimate Interactions: Online Representation and Software of the Self}},
year = {2008}
}
@book{Castronova2005,
abstract = {Note: Castronova refers to achievement systems as advancement systems.},
address = {Chicago},
author = {Castronova, Edward},
keywords = {EverQuest,FUN,MMORPGs,Second Life,achievement system,cooperation,design,economics,games,magic circle,reputation,rewards,value},
mendeley-tags = {EverQuest,FUN,MMORPGs,Second Life,achievement system,cooperation,design,economics,games,magic circle,reputation,rewards,value},
publisher = {University Of Chicago Press},
title = {{Synthetic Worlds: The Business and Culture of Online Games}},
year = {2005}
}
@article{Grace2003,
author = {Grace, D.M.},
file = {::},
journal = {Extrapolation},
number = {3},
pages = {344--355},
publisher = {UNIVERSITY OF TEXAS},
title = {{From Videodrome to Virtual Light: David Cronenberg and William Gibson}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:from+videodrome+to+virtual+light\#0},
volume = {44},
year = {2003}
}
@book{Gibson2004,
author = {Gibson, William},
publisher = {Ace Hardcover},
title = {{Neuromancer}},
url = {http://www.amazon.com/Neuromancer-William-Gibson/dp/0441012035},
year = {2004}
}
@article{Steinkuehler2006,
abstract = {In this essay, I discuss the ways in which, in the context of Lineage, the game that’s actually played by participants is not the game that designers originally had in mind, but rather one that is the outcome of an interactively stabilized (Pickering, 1995) “mangle of practice” of designers, players, in-game currency farmers, and broader social norms.},
author = {Steinkuehler, Constance},
file = {::},
journal = {Games and Culture},
keywords = {Chinese gold farming,MMOG,community,economics,game culture,games,massively multiplayer online games,play},
mendeley-tags = {Chinese gold farming,MMOG,community,economics,game culture,games,massively multiplayer online games,play},
number = {3},
title = {{The Mangle of Play}},
url = {http://gac.sagepub.com/cgi/content/abstract/1/3/199},
volume = {1},
year = {2006}
}
@book{Kafai1994,
author = {Kafai, Yasmin B.},
isbn = {0805815139},
pages = {360},
publisher = {Routledge},
title = {{Minds in Play: Computer Game Design As A Context for Children's Learning}},
url = {http://www.amazon.com/Minds-Play-Computer-Childrens-Learning/dp/0805815139},
year = {1994}
}
@book{Mulligan2003,
author = {Mulligan, Jessica},
keywords = {game development,online games},
mendeley-tags = {game development,online games},
publisher = {New Riders Games; illustrated edition},
title = {{Developing Online Games: An Insider's Guide}},
year = {2003}
}
@inproceedings{Ducheneaut2004,
abstract = {Playing computer games has become a social experience. Hundreds of thousands of players interact in massively multiplayer online games (MMORPGs), a recent and successful genre descending from the pioneering multi-user dungeons (MUDs). These new games are purposefully designed to encourage interactions among players, but little is known about the nature and structure of these interactions. In this paper, we analyze player-to-player interactions in two locations in the game Star Wars Galaxies. We outline different patterns of interactivity, and discuss how they are affected by the structure of the game. We conclude with a series of recommendations for the design and support of social activities within multiplayer games.},
author = {Ducheneaut, Nicolas and Moore, Robert J.},
booktitle = {Proceedings of CSCW},
file = {::},
publisher = {Chicago: ACM Press},
title = {{The social side of gaming: a study of interaction patterns in a massively multiplayer online game}},
year = {2004}
}
@incollection{Chee2005,
author = {Chee, Florence and Smith, Richard},
booktitle = {Interactive Convergence : Critical Issues in Multimedia},
editor = {Schaffer, S and Price, M},
file = {::},
publisher = {Inter-Disciplinary Press},
title = {{Is Electronic Community an Addictive Substance? An ethnographic offering from the EverQuest Community.}},
year = {2005}
}
@misc{GamePolitics.com2010,
author = {GamePolitics.com, Staff},
booktitle = {GamePolitics.com},
title = {{Stolen Console and Games Lead to Homicide}},
url = {http://gamepolitics.com/2010/03/19/stolen-console-and-games-lead-homicide},
urldate = {3/19/2010},
year = {2010}
}
@article{Silverman2010,
abstract = {This article discusses the origins and development of the player-innovated dragon kill point (DKP) system as an example for thinking about Foucauldian conceptions of disciplinary power and the production of gamer subjectivity in the contexts of massively multiplayer online game (MMOG) power gaming. The argument considers the generalized hyperrationalism of DKP-based gaming as both an ideal digital form of panoptic control as well as a kind of ironic form of play with the limits of the pos- sibility of control within digital culture.},
author = {Silverman, Mark and Simon, Bart},
doi = {10.1177/1555412009343572},
file = {::},
journal = {Games and Culture},
keywords = {Foucault,MMOGs,achievement system,play,power gaming,subjectivity,video games,work},
mendeley-tags = {Foucault,MMOGs,achievement system,play,power gaming,subjectivity,video games,work},
title = {{Discipline and Dragon Kill Points in the Online Power Game}},
year = {2010}
}
@article{Computer2010,
author = {Computer, About T H E and Game, Video},
file = {::},
journal = {Computer},
title = {{ESSENTIAL FACTS ABOUT THE COMPUTER AND VIDEO GAME}},
year = {2010}
}
@techreport{Lastowka2003,
abstract = {What if you could check out of your world, and enter a place where the social environment was different, where real world laws didn’t apply, and where the political system could be anything you wanted it to be? What if you could socialize there with family and friends, build your own palace, go skiing, and even hold down a job there? And what if there wasn’t one alternate world, there were hundreds, and what if millions of people checked out of Earth and went there every day? Virtual worlds—online worlds where millions of people come to interact, play, and socialize—are a new type of social order. In this Article, we examine the implications of virtual worlds for our understanding of law, and demonstrate how law affects the interests of those within the world. After providing an extensive primer on virtual worlds, including their history and function, we examine two fundamental issues in detail. First, we focus on property, and ask whether it is possible to say that virtual world users have real world property interests in virtual objects. Adopting economic accounts that demonstrate the real world value of these objects and the exchange mechanisms for trading these objects, we show that, descriptively, these types of objects are indistinguishable from real world property interests. Further, the normative justifications for property interests in the real world apply—sometime more strongly—in the virtual worlds. Second, we discuss whether avatars have enforceable legal and moral rights. Avatars, the user-controlled entities that interact with virtual worlds, are a persistent extension of their human users, and users identify with them so closely that the human-avatar being can be thought of as a cyborg. We examine the issue of cyborg rights within virtual worlds and whether they may have real world significance. The issues of virtual property and avatar rights constitute legal challenges for our online future. Though virtual worlds may be games now, they are rapidly becoming as significant as real-world places where people interact, shop, sell, and work. As society and law begin to develop within virtual worlds, we need to have a better understanding of the interaction of the laws of the virtual worlds with the law of this world.},
author = {Lastowka, F. Gregory and Hunter, Dan},
booktitle = {Social Science Research},
file = {::},
institution = {Institute for Law and Economics},
keywords = {avatar rights,cyborg,economics,ethics,law,morality,property,virtual,virtual property,virtual world,virtual worlds},
mendeley-tags = {avatar rights,cyborg,ethics,law,morality,property,virtual,virtual world},
number = {26},
title = {{The Laws of the Virtual Worlds}},
url = {http://papers.ssrn.com/abstract=402860},
year = {2003}
}
@article{Hantke2004,
author = {Hantke, Steffen},
file = {::},
journal = {Film Criticism},
number = {2},
pages = {34--52},
title = {{Spectacular optics: the deployment of special effects in David Cronenberg’s films}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:spectacular+Optics+:+The+Deployment+of+Special+Effects+in+David+Cronenberg+'+s+Films\#0},
volume = {29},
year = {2004}
}
@article{Taylor2009,
abstract = {This article explores the notion of assemblage for computer game studies. Drawing on this framework, the author proposes a multifaceted methodological approach to the study of games and the play experience. Drawing on user-created mods (mod- ifications) in the game World of Warcraft and an analysis of a raid encounter there, a discussion is undertaken about the relationship between technological artifacts, game experience, and sociality. Primary to the consideration is an argument for the centralizing the interrelation of a variety of actors and nodes when analyzing lived play in computer games.},
author = {Taylor, T.L.},
doi = {10.1177/1555412009343576},
file = {::},
journal = {Games and Culture},
keywords = {MMOG,World of Warcraft,actor network theory,actor-network theory,assemblage,massively multiplayer online game,methodology,mods,play},
mendeley-tags = {MMOG,World of Warcraft,actor-network theory,mods,play},
pages = {331--339},
title = {{The Assemblage of Play}},
volume = {4},
year = {2009}
}
@book{Bartle2004,
address = {Berkeley},
author = {Bartle, Richard},
publisher = {New Riders Games},
title = {{Designing Virtual Worlds}},
year = {2004}
}
@book{McLuhan1964,
author = {McLuhan, Marshall},
file = {::},
keywords = {communications,media},
mendeley-tags = {communications,media},
publisher = {New American Library},
title = {{Understanding Media: The Extensions of Man}},
url = {http://www.amazon.com/Understanding-Media-Extensions-Marshall-McLuhan/dp/8114675357},
year = {1964}
}
@book{Turkle1995,
address = {New York},
author = {Turkle, Sherry},
file = {::},
keywords = {identity,owned,read},
mendeley-tags = {identity,owned,read},
publisher = {Simon \& Schuster},
title = {{Life on the Screen: Identity in the Age of the Internet}},
year = {1995}
}
@article{Williams2006a,
abstract = {A representative sample of players of a popular massively multiplayer online game (World of Warcraft) was interviewed to map out the social dynamics of guilds. An ini- tial survey and network mapping of players and guilds helped form a baseline. Next, the resulting interview transcripts were reviewed to explore player behaviors, atti- tudes, and opinions; the meanings they make; the social capital they derive; and the networks they form and to develop a typology of players and guilds. In keeping with current Internet research findings, players were found to use the game to extend real- life relationships, meet new people, form relationships of varying strength, and also use others merely as a backdrop. The key moderator of these outcomes appears to be the game’s mechanic, which encourages some kinds of interactions while discourag- ing others. The findings are discussed with respect to the growing role of code in shap- ing social interactions.},
author = {Williams, Dmitri and Ducheneaut, Nicolas and Xiong, Li and Zhang, Yuanyuan and Yee, Nick},
file = {::;::},
journal = {Games and Culture},
keywords = {MMO,guilds,online community,social capital,social networks,virtual community},
mendeley-tags = {MMO,guilds,online community,social capital,social networks,virtual community},
number = {4},
title = {{From Tree House to Barracks: The Social Life of Guilds in World of Warcraft}},
url = {http://gac.sagepub.com/cgi/content/abstract/1/4/338},
volume = {1},
year = {2006}
}
@article{Crogan2008,
abstract = {This article introduces and situates the ensuing collection of four essays on the theme of games and technology. It argues the need for videogame studies to develop a more rigorous and focused perspective on the theorization of technology as it relates to research into games and culture. The ‘‘and’’ in games and culture cannot begin to be understood comprehensively without a thinking of the profound reliance of both terms on technology. Players and their cultural and collective involvements should be taken not as stable categories of research and development but as processes of becoming intertwined with lineages of technological development and disjunction which are the condition of these processes. Video games are not the least compo- nent and proponent of these technological lineages today. The essays collected in this section of the journal issue are described and characterized as offering such a focus on ludic technicity through their diverse but intersecting considerations of game hardware, software, game play, and other practices appropriating game technologies.},
annote = {The ‘‘ludological’’ focus on computer games as game forms— often characterized with reference to Espen Aarseth’s (1997) notion of the cyber- text—shares this tendency in their concern to privilege the game as (cybernetic) rule-based system for configurational acts. The aesthetics and even politics of games envisaged in this regard rest on thinking of this system as a kind of tool available for conventional, experimental, or in Gonzalo Frasca’s (2004) estimation, even poten- tially political and critical deployment (p. 89). 
        
James Galloway’s (2006)Gaming: Essays on Algorithmic Culture, Ian Bogost’s (2006)Unit Operations: An Approach to Videogame Criticism, among others.
        
In ‘‘A Technosemiotic Approach to Cheating’’ Julian Ku¨cklich explores the
technicity of the player–game relation through a critique and complication of the configurative discourse of ludological game studies. He sets an ambitious course through several theoretical positions both within and outside digital games scholar- ship as it is currently constituted (inasmuch as this can be delimited in such a prolif- erating and mutating zone of contemporary inquiry) on his way to a proposition about what he calls the ‘‘deludological’’ mode of gameplay. This cross- disciplinary journey reflects Ku
¨cklich’s goal: to argue that cheating in a (video)game
always has a crucially important potential to blur and re-form the boundaries between the gamespace and the cultural, political, and socioeconomic spaces in which games take place. What he calls the ‘‘ludic technicity’’ of contemporary videogaming whereby the player is incorporated (and hence decorporalized in a cer- tain manner) in and as the game machine needs to be addressed more carefully for its potential to ‘‘open up new paths of subjectification.’’ Departing from Espen Aarseth’s influential work on cybertextual forms as ones which are both cybernetic in their operation and semiotic in their productions, Ku¨cklich complicates the classic
ludological position of Aarseth, Juul, and others in which games are essentially abstract machines, instantiated in rules and procedures for generating cybernetic loops of agonistic feedback and hermeneutic discovery. (112)
        
'Cheating and other deludological playings out of the machinic encounter with the game tend to overcome immersion or other modes of accepted functioning in the ludic feedback loops and opens onto a mixed semiotics (Guattari) beyond the magic circle (Huizinga). Ian Bogost’s notion (after Alain Badiou) of ‘‘unit operations’’ is reworked by Ku¨cklich to move toward a thinking of cheating as an abductive, trans-
versal cutting across the normative ludic pathway from unruled to ruled space, from play to (finished) game. Such deludic play would enact a semiotic performativity that deconstructs and reterritorializes the semantic frame of gameplay."
        
Latour’s work on the systemic enchainment of human and nonhuman actors in any cultural activity is mobilized in this venture, along with insights from Donna Haraway’s work on cyborg subjectivities. (113)},
author = {Crogan, Patrick and Kennedy, Helen},
doi = {10.1177/1555412008325482},
file = {::},
journal = {Games and Culture},
keywords = {cyborg,haraway,latour,ludic technicity,social constructivism,subjectification,technicity,technology,video game studies,video games},
mendeley-tags = {cyborg,haraway,latour,ludic technicity,social constructivism,subjectification,technology,video games},
number = {107},
title = {{Technologies Between Games and Culture}},
url = {http://gac.sagepub.com/cgi/content/abstract/4/2/107},
volume = {4},
year = {2008}
}
@incollection{Taylor2002,
abstract = {Designers, and the code they construct, go a long way toward making a virtual world real. They fill it with objects and spaces, properties and behaviors. Sometimes they create imaginative scenes only found in science fiction or fantasy. Other times they help mirror the offline world by creating more straightforward representations of our everyday environments. In each case they significantly provide a means of embodiment for the user. For graphical worlds, this comes in the form of avatars – those pictorial constructs used to actually inhabit the world. It is in large part through these avatars that users can come to bring real life and vibrancy to the spaces. Through avatars, users embody themselves and make real their engagement with a virtual world. They often push back on the system – asking more of it, turning its sometimes limited palettes into something other than what was intended. Avatars, in fact, come to provide access points in the creation of identity and social life. The bodies people use in these spaces provide a means to live digitally – to fully inhabit the world. It is not simply that users exist as just “mind”, but instead construct their identities through avatars. To examine how digital bodies can facilitate life in a virtual world, I am going to focus my attention on a particular graphical multi-user system, The Dreamscape. The environment is a “2 1⁄2 D” world in which the user looks at their avatar from a third person perspective. Although it is not a three dimensional space, I would argue that it still very much constitutes a virtual environment (as text-based MUDs – multi-user dungeons or dimensions – do). Users engage in real time with an immersive simulated world in which objects and others occupy the space. Avatar bodies (of which there are ten varieties in The Dreamscape – five male and five female) can be changed at will by purchasing new ones (both via “inworld” tokens or “real” credit cards). Avatar heads, which are separate and different objects from the rest of the avatar body, more commonly operate as the main means of customization and individuation in the world. They too can be purchased and are also often given as prizes or gifts. These heads and bodies can be further customized through the use of “spray paints” to change the color of the clothes, skin, and hair. Finally, many different accessories (such as hats and jewelry) as well as more mundane “daily” objects (like coffee mugs) can be used by the avatar as well.},
author = {Taylor, T.L.},
booktitle = {The Social Life of Avatars: Presence and Interaction in Shared Virtual Environments},
file = {::},
keywords = {Dreamscape,avatars,embodiment,identity,multi-user worlds,self,subjectivity,virtual worlds},
mendeley-tags = {Dreamscape,avatars,embodiment,identity,multi-user worlds,self,subjectivity,virtual worlds},
pages = {40--62},
title = {{Chapter 3 Living Digitally: Embodiment in Virtual Worlds}},
year = {2002}
}
@inproceedings{Lewis2007,
abstract = {The gaming community currently uses an informal classification of games into genres such as first-person shooters, real-time strategy games, etc. While this classification is generally accepted, producing a more formal taxonomy of game types directly from data has several scholarly and commercial advantages. These include providing a basis for analysis of age- and gender-related data, statistically meaningful grouping in critical literature, improved game recommendations on retail websites, and better evaluation of a game's market potential before production. Mapping the mental space of game genres is challenging, both because it involves subjective evaluations and because there are many axes on which games can vary. We collected pairwise similarity metrics of games from game players through an online survey to build a large similarity matrix that is the projection of a highdimensional space representing the unknown and hypothetical true mental space of game genres. We then applied previous techniques in manifold learning and psychology to the problem of reconstructing the most significant dimensions into maps that can be meaningfully interpreted. We believe this is the first application of these techniques to games and one of the first to work with conceptual (instead of physical) data. The resulting maps arrange related games into spontaneously arising clusters that sometimes contradict current marketing genres. We analyze several of these clusters and propose both interpretations for these "true genres" as well as axes that game players appear to use in discriminating between them. Our initial results indicate that game players tend to primarily distinguish games not by traditional genres but instead by aesthetic and mechanics, which is closely related to how developers construct games.},
author = {Lewis, J P and McGuire, Morgan and Fox, Pamela},
booktitle = {Proceedings of the 2007 ACM SIGGRAPH symposium on Video games Sandbox 07},
doi = {10.1145/1274940.1274962},
file = {::},
isbn = {9781595937490},
keywords = {games,genre,manifold learning,mental map},
number = {212},
pages = {103--108},
publisher = {ACM Press},
title = {{Mapping the mental space of game genres}},
url = {http://portal.acm.org/citation.cfm?doid=1274940.1274962 http://scribblethink.org/Work/Gamespace/gamespace-Sandbox07.pdf},
volume = {1},
year = {2007}
}
@book{Miller2011,
abstract = {ethnographic study of Facebook use in Trinidad},
annote = {3 Truths: by intention; unintentional; by construction. (p. 49-50)
        
Irvin Goffman: self-presentation, performance
        
      },
author = {Miller, Daniel},
file = {::;::},
isbn = {0745652107},
keywords = {Trinidad,private,public,self-representation,social network,social network sites,social networking,truth},
mendeley-tags = {Trinidad,private,public,self-representation,social network,social network sites,social networking,truth},
pages = {220},
publisher = {Polity},
title = {{Tales from Facebook}},
year = {2011}
}
@article{Reeves2009,
author = {Reeves, S. and Brown, B. and Laurier, E.},
file = {::},
journal = {Games and Culture},
number = {3},
pages = {205--227},
title = {{Experts at Play: Understanding Skilled Expertise}},
url = {http://gac.sagepub.com/cgi/doi/10.1177/1555412009339730},
volume = {4},
year = {2009}
}
@book{Card1994,
author = {Card, Orson Scott},
publisher = {Tor Science Fiction},
title = {{Ender's Game (Ender, Book 1)}},
url = {http://www.amazon.com/Enders-Game-Ender-Book-1/dp/0812550706},
year = {1994}
}
@book{Kafai2008,
address = {Cambridge, MA},
author = {Kafai, Yasmin and Heeter, Carrie and Sun, Jennifer Y. and Denner, Jill},
editor = {Kafai, Yasmin and Heeter, Carrie and Sun, Jennifer Y. and Denner, Jill},
publisher = {The MIT Press},
title = {{Beyond Barbie and Mortal Kombat: New Perspectives on Gender and Gaming}},
year = {2008}
}
@book{Kelty2008,
author = {Kelty, Christopher M.},
file = {::},
keywords = {free software,hackers,hacking,open source,owned,read,recursive publics,recursivity},
mendeley-tags = {free software,hackers,hacking,open source,owned,read,recursive publics,recursivity},
publisher = {Duke University Press},
title = {{Two Bits: The Cultural Significance of Free Software}},
url = {http://www.amazon.com/Two-Bits-Cultural-Significance-Software/dp/0822342642},
year = {2008}
}
@inproceedings{Latour2008,
abstract = {Excerpt: "The reason I am interested in the spread in comprehension and extension of the term design is not because of any intimate knowledge of design practice. (I know even less about its history and I hope the many historians of the notion among you will not contradict me too much). Yet I take its expansion as a fascinating tell tale of a change in the ways we deal with objects and action more generally. If it is true as I have claimed that we have never been modern, and if it is true, as a consequence, that matters of fact have now clearly become matters of concern, then there is logic to the following observation: the typically modernist divide between materiality on the one hand and design on the other is slowly being dissolved away. The more objects are turned into things that is, the more matters of facts are turned into matters of concern the more they are rendered into objects of design through and through."},
address = {Falmouth, Cornwall},
author = {Latour, Bruno},
booktitle = {Design History Society},
file = {::},
keywords = {Habermas,Sloterdijk,collaboration,design,matter,meaning,modernism,modernity,redesign},
mendeley-tags = {Habermas,Sloterdijk,collaboration,design,matter,meaning,modernism,modernity,redesign},
title = {{A Cautious Prometheus? A Few Steps Toward a Philosophy of Design (with Special Attention to Peter Sloterdijk)}},
year = {2008}
}
@book{Salen2003,
abstract = {From the Preface - "Our hope is that this book will inform and inspire those interested in designing games. Its purpose is to help game designers create their own games, their own concepts, their own design strategies and methodologies. The ideas and examples we offer represent one way of looking closely at games, with room for more to come. Pong is just the beginning. This is why we were compelled to write this book: not to define, once and for all, what game design is, but to provide critical tools for understanding games. not to claim and colonize the unexplored terrain of game design, but to scout out some of its features so that other game designers can embark on their own expeditions. We hope that this book will be a ctalyst, a facilitator, a kick in the ass. Take these concepts and run with them, quickly, meaningully, with the same kind of joy that the very first players of Pong must have felt."},
annote = {Foreword by Frank Lantz:
* this book speaking to a lack of a basic set of game theory tools, driven by an impatience that the potential of games has only just been superficially tapped. 
* this book is an "attempt to lay out an aesthetic approach to the design of interactive systems" (xi)
* evolution of games
        
PONG:
Why does everyone love Pong?
"“Easy to learn, difficult to master” (Salen \& Zimmerman 2004:xiv) 
        
Game design as a discipline. (1)
        
      },
author = {Salen, Katie and Zimmerman, Eric},
isbn = {0262240459},
keywords = {aesthetics,computer games,design,designers,game design,interactive systems,interactivity,play,rules,video games},
mendeley-tags = {aesthetics,computer games,design,designers,game design,interactive systems,interactivity,play,rules,video games},
pages = {688},
publisher = {The MIT Press},
title = {{Rules of Play: Game Design Fundamentals}},
url = {http://www.amazon.com/Rules-Play-Game-Design-Fundamentals/dp/0262240459},
year = {2003}
}
@article{Ip2008,
abstract = {Convergence has been touted in recent years as the next big leap in the digital era. Having received considerable attention across a wide range of technologies, markets, and economies, there is comparatively little academic research on convergence in the computer and video games industry. This article investigates this issue by drawing attention to three salient areas of gaming convergence—technological, content, and market. A detailed examination is provided, drawing from a broad selection of litera- ture and practical examples of gaming hardware and software to illustrate the preva- lence of convergence in its various forms. The results provide a unique chronological overview of the impact of convergence on the previous and current generations of games and games platforms. The discussion focuses on the new demands placed on the creation of game technology and content, emerging market trends, and the ramifica- tions as a result of the evolving nature of gaming convergence.},
author = {Ip, Barry},
doi = {10.1177/1555412008314128},
file = {::},
journal = {Games and Culture},
keywords = {computer games,content convergence,convergence,games market,market convergence,technological convergence,video games},
mendeley-tags = {convergence},
title = {{Technological, Content, and Market Convergence in the Games Industry}},
volume = {3},
year = {2008}
}
@article{Chee2008,
abstract = {In this article, the authors attempt to ascertain the factors involved in the swift growth of online games in the context of broader sociocultural elements. Through political economy and ethnographic analysis, they show that online games, like other forms of technology, are sociocultural products that have been historically constituted by certain forms of knowledge and social practice. First, they map out the forces driving their development by examining government policies and competition among online games companies in Korea. They then explore capital flow to investigate the major players in the market. Finally, they explore the sociocultural elements contributing to the diffusion of online games in the cultural milieu specific to Korea.},
author = {Chee, Florence and Jin, Dal Yong},
file = {::},
journal = {Games and Culture},
keywords = {Korea,ethnography,online games,policy,political economy},
mendeley-tags = {Korea,ethnography,online games,policy,political economy},
number = {38},
pages = {38--59},
title = {{Age of New Media Empires: A Critical Interpretation of the Korean Online Game Industry}},
url = {http://gac.sagepub.com/cgi/content/abstract/3/1/38},
volume = {3},
year = {2008}
}
@article{Mynatt1997,
address = {New York, New York, USA},
author = {Mynatt, Elizabeth D. and Adler, Annette and Ito, Mizuko and O'Day, Vicki L.},
doi = {10.1145/258549.258707},
file = {::},
isbn = {0897918029},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '97},
keywords = {community,design,identity,media space,metaphor,muds,network,shared space,virtual world},
mendeley-tags = {community,design,identity,media space,metaphor,muds,network,shared space,virtual world},
pages = {210--217},
publisher = {ACM Press},
title = {{Design for network communities}},
url = {http://portal.acm.org/citation.cfm?doid=258549.258707},
year = {1997}
}
@book{Carr2011,
annote = {McLuhan's "the medium is the message"
* the content matters less in influencing how we think and act than the medium itself.
* technology not at the level of opinions or concepts, media work on the nervous system itself.
        
      },
author = {Carr, Nicholas},
isbn = {0393339750},
keywords = {internet,media,technology},
mendeley-tags = {internet,media,technology},
pages = {280},
publisher = {W. W. Norton \& Company},
title = {{The Shallows: What the Internet Is Doing to Our Brains}},
url = {http://www.amazon.com/Shallows-What-Internet-Doing-Brains/dp/0393339750},
year = {2011}
}
@article{Taylor2006,
abstract = {Rather than simply identifying “emergence” as a prime property of massively multiplayer online game life, a better understanding of the complex nature of player-produced culture is needed. Life in game worlds is not exempt from forms of player-based regulation and control. Drawing on ethnographic and interview work within World of Warcraft, the author undertakes initial inquiries on this subject by looking at three areas: nationalism, age, and surveillance. This case study shows systems of stratification and control can arise from the bottom up and be implemented in not only everyday play culture but even player-produced modifications to the game system itself. Due to the ways these systems may simultaneously facilitate play, there is often an ambivalent dynamic at work. This piece also prompts some methodological considerations. By discussing field site choice, the author argues that context is of utmost importance and needs to be more thoughtfully foregrounded within game studies.},
author = {Taylor, T.L.},
file = {::},
journal = {Games and Culture},
keywords = {MMOG,PvP,WoW,computer games,emergence,games,modding,online community},
mendeley-tags = {MMOG,PvP,WoW,computer games,emergence,games,modding,online community},
number = {4},
pages = {318 -- 338},
title = {{Does WoW Change Everything?: How a PvP Server, Multinational Player Base, and Surveillance Mod Scene Caused Me Pause}},
url = {http://gac.sagepub.com/cgi/content/abstract/1/4/318},
volume = {1},
year = {2006}
}
@article{Pearce2007,
author = {Pearce, C. and Fullerton, T. and Fron, J. and Morie, J. F.},
file = {::},
journal = {Games and Culture},
number = {3},
pages = {261--278},
title = {{Sustainable Play: Toward a New Games Movement for the Digital Age}},
url = {http://gac.sagepub.com/cgi/doi/10.1177/1555412007304420},
volume = {2},
year = {2007}
}
@article{Star1999,
annote = {reconstructing narrative from numbers and technical specifications.
        
STANDARDIZATION: author about standardization in terms of codes, to a degree. I am interested in how processes of knowledge production and technical processes become standardized between developers and players. 
        
Infrastructure is usually thought of "as a system of substrates," but this is relative to perspective. A person in a wheelchair does not see stairs and a doorjamb as "seamless subtenders of use, but barriers."
        
PARTICIPATORY DESIGN: Her study was with biologists in labs, done around developing a system that the biologists ended up not wanting to use.
        
Infrastructure has the following properties:
* Embeddedness
* Transparency
* Reach or scope
* Learned as part of membership
* Links with conventions of practice: seems related to familiar affordances of given technologies.
* Embodiment of standards: ie. including map taxonomy, names for genetic strains, photos, etc. into the bio lab system.
* Built on an installed base: built on established infrastructural systems (ie. optical fibers run along old railroad lines.
* Becomes visible upon breakdown: server is down.
* Is fixed in modular increments, not all at once or globally: "nobody is really in charge of infrastructure"
        
Questions of scalability with ethnographic methodology.
* tempting to use this with online data, but no one has been able to satisfactorily analyzed their own logs (she says).
        
Tricks of the Trade:
        
* IDENTIFYING MASTER NARRATIVES AND "OTHERS"
        
* SURFACING INVISIBLE WORK: balancing visibilities
        
* PARADOXES OF INFRASTRUCTURE: observable obstinance in the face of small changes; people do what theyre used to? "At a phenomenol- ogical level, what has happened is that these slight impediments have bccome magnified in the flow of the work process."},
author = {Star, Susan Leigh},
doi = {10.1177/00027649921955326},
file = {::},
issn = {0002-7642},
journal = {American Behavioral Scientist},
keywords = {design,embeddedness,ethnography,infrastructure,methodology,participatory design,scale,standardization},
mendeley-tags = {design,embeddedness,ethnography,infrastructure,methodology,participatory design,scale,standardization},
month = nov,
number = {3},
pages = {377--391},
title = {{The Ethnography of Infrastructure}},
url = {http://abs.sagepub.com/cgi/doi/10.1177/00027649921955326},
volume = {43},
year = {1999}
}
@article{Hotchkiss2003,
author = {Hotchkiss, L.M.},
file = {::},
journal = {The Velvet Light Trap},
number = {1},
pages = {15--32},
publisher = {University of Texas Press},
title = {{ “Still in the Game”: Cybertransformations of the “New Flesh” in David Cronenberg's Existenz}},
url = {http://muse.jhu.edu/journals/vlt/summary/v052/52.1hotchkiss.html},
volume = {52},
year = {2003}
}
@book{Losh2009,
address = {Cambridge, MA},
author = {Losh, Elizabeth},
keywords = {governance,video games},
mendeley-tags = {governance,video games},
publisher = {MIT Press},
title = {{Virtualpolitik: An Electronic History of Media-Making in a Time of War, Scandal, Disaster, Miscommunication, and Mistakes}},
year = {2009}
}
@article{Kucklich2009,
author = {Kucklich, Julian Raul},
file = {::},
journal = {Games and Culture},
keywords = {governmentality,must read,population,precarity,territory,virtual worlds},
mendeley-tags = {governmentality,must read,population,precarity,territory,virtual worlds},
number = {4},
pages = {340--352},
title = {{Virtual Worlds and Their Discontents: Precarious Sovereignty, Governmentality, and the Ideology of Play}},
volume = {4},
year = {2009}
}
@article{Malaby2009a,
abstract = {The rise of virtual worlds and their demonstrated potential to generate new economies, forms of belonging, and learning—all within spaces that are deeply game-like—makes new demands of our thinking about games and society. A number of scholars have recently begun to forge an approach distinct from past efforts, shifting their attention toward broader, contextual understandings of games, communities, and play. Seeking to treat such spaces neither as wholly determined by outside factors nor as utterly sui generis, they aim to account for the contingent and emergent relationship that these spaces have with other domains of human experience.},
author = {Malaby, Thomas and Burke, Timothy},
doi = {10.1177/1555412009343577},
file = {::},
journal = {Games and Culture},
keywords = {game studies,games,interdisciplinarity,methodology,pragmatism,virtual worlds},
number = {323},
title = {{The Short and Happy Life of Interdisciplinarity in Game Studies}},
url = {http://gac.sagepub.com/cgi/content/abstract/4/4/323},
volume = {4},
year = {2009}
}
@book{Malaby2009,
address = {Ithaca, NY},
author = {Malaby, Thomas},
keywords = {Second Life,contingency,contrived contingency,design,owned,unread,virtual world},
mendeley-tags = {Second Life,contingency,contrived contingency,design,owned,unread,virtual world},
publisher = {Cornell University Press},
title = {{Making Virtual Worlds: Linden Lab and Second Life}},
year = {2009}
}
@book{Mellstrom1995,
abstract = {"This thesis deals with engineers. It is an ethnographic study of the life organisation for seventeen engineers with Master's degrees working at two different workplaces, Automobile Inc. and Microcips Inc. The study is based on participant observation and life-history interviews. It is a study of work, careers and life-paths among thirteen men and four women. Underlying questions of this study are what makes sense to these people and how meaning is constructed in their lives as engineers.},
address = {Linkoping},
annote = {Beer heaving - p. VII in the prologue
        
"An ethnography of an occupational group in the midst of technical change, industry, and modernity can convery how important dimensions of our society are deeply rooted and reproduced at a micro-level of social interaction (2).
        
"In accordance with Berger \& Luckman (1966), I prefer to view society as a dynamic socially constructed reality in which people learn about society as they interact and partake in the same. They learn symbols as well as meaning in social interaction and meaning always stems from processes of interaction" (4).
        
"Following Hannerz (1992), culture can be defined as "social organization of meaning" (5). 
        
“Differences in power and rank are to different degrees seen in the social and symbolic mapping of a workplace” (Mellstr\"{o}m 1995:7).
“Technical space connects both personal and social space since the artefact in technical work works as the organising principle and the symbolic framework for the material organisation of the workplace:
        
"Meetings form a specific kind of focused interaction (Goffman 1961, Schwartzmann 1989, 1993)" (Mellstrom 1995:8).
        
Meetings: 
"Meetings form a specific kind of focused interaction (Goffman 1961, Schwartzmann 1989, 1993)" (Mellstrom 1995:8).
“Schwartzmann (1989, 1993) argues that meetings are interesting because they can be seen as communicative events (Hymes 1974) embedded within a sociocultural setting and as both a constituting and constitutive social form” (Mellstrom 1995:9).
        
Shop talk and small talk :
        
“In engineering a good deal of the technical problem solving procedures are normally executed through shop talk, that is thinking through talk” (Mellstrom 1995:9).
        
Stories and jokes:
        
About Schwartzman 1984: “\ldots suggests that sotries are the best model to study organisations as social constructions. She argues that stories are a pervasive social form that generate organisational activity, interpret and sometimes transform work experience. Stories, just like meetings, are about organisational sense-making and produce meaning to members in the organisation” (Mellstrom 1995:10). 
        
“Shared frames of meaning are built through the telling of and listening to stories and jokes, most often ending in joint laughter togteher with colleagues. Stories, as such, are in a constant state of change” (Mellstrom 1995:10).
      },
author = {Mellstrom, Ulf},
keywords = {MSc engineers,career,cars,design,design practice,engineering,ethnography,ethnography of work,horizon,interated circuits,life-histories,life-path,masculinity,methodological eclecticism,microculture,participant observation,perspective,power,practice,socialisation,space,storytelling,technology,time,work},
mendeley-tags = {design,design practice,engineering,ethnography,ethnography of work,microculture,power,practice,storytelling,work},
publisher = {Linkoping University},
title = {{Engineering Lives}},
year = {1995}
}
@article{Nardi2006,
abstract = {We analyze collaborative play in an online video game, World of Warcraft, the most popular personal computer game in the United States, with significant markets in Asia and Europe. Based on an immersive ethnographic study, we describe how the social organization of the game and player culture affect players’ enjoyment and learning of the game. We discovered that play is characterized by a multiplicity of collaborations from brief informal encounters to highly organized play in structured groups. The variety of collaborations makes the game more fun and provides rich learning opportunities. We contrast these varied collaborations, including those with strangers, to the “gold standard” of Gemeinschaft-like communities of close relations in tightknit groups. We suggest populations for whom similar games could be designed.},
author = {Nardi, Bonnie and Harris, Justin},
file = {::},
journal = {Human Factors},
keywords = {Synchronous Interaction,World of Warcraft,collaboration,community,design,gemeinschaft,human factors,learning,mmogs,multiplayer games,play,social isolation,social ties},
mendeley-tags = {Synchronous Interaction,World of Warcraft,collaboration,community,design,gemeinschaft,human factors,learning,mmogs,multiplayer games,play,social isolation,social ties},
title = {{Strangers and Friends: Collaborative Play in World of Warcraft}},
year = {2006}
}
@article{Vint2006,
author = {Vint, Sherryl and Bould, Mark},
doi = {10.1080/08854300600950327},
file = {::},
issn = {0885-4300},
journal = {Socialism and Democracy},
month = nov,
number = {3},
pages = {217--243},
title = {{All that melts into air is solid: Rematerialising capital in Cube and Videodrome}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/08854300600950327\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {20},
year = {2006}
}
@misc{Nutt2008,
author = {Nutt, Christian},
booktitle = {Gamasutra},
title = {{Interview: Red 5's Stealthy Plans, Upcoming MMO}},
url = {http://www.gamasutra.com/php-bin/news\_index.php?story=21575},
urldate = {1/12/2010},
year = {2008}
}
@article{Goyal1998,
author = {Goyal, V K and Vetterli, M and Thao, N T},
journal = {IEEE Trans. Information Theory},
number = {1},
title = {{Quantized Overcomplete Expansions in R\^{}N: Analysis, Synthesis, and Algorithms}},
volume = {44},
year = {1998}
}
@inproceedings{Gribonval1996,
address = {Hong Kong},
author = {Gribonval, R and Depalle, P and Rodet, X and Bacry, E and Mallat, S},
booktitle = {Proc. Int. Comput. Music Conf.},
keywords = {MP},
pages = {293--296},
title = {{Sound signal decomposition using a high resolution matching pursuit}},
year = {1996}
}
@inproceedings{Smola2000,
author = {Smola, Alex J and Sch\"{o}lkopf, Bernhard},
booktitle = {Proc. 17th Int. Conf. on Machine Learning},
pages = {911--918},
publisher = {Morgan Kaufmann, San Francisco, CA},
title = {{Sparse Greedy Matrix Approximation for Machine Learning}},
url = {citeseer.ist.psu.edu/smola00sparse.html},
year = {2000}
}
@article{Gribonval2003,
author = {Gribonval, R and Bacry, E},
journal = {IEEE Trans. Signal Process.},
number = {1},
pages = {101--111},
title = {{Harmonic decompositions of audio signals with matching pursuit}},
volume = {51},
year = {2003}
}
@article{Berenzweig2004,
author = {Berenzweig, A and Logan, B and Ellis, D P W and Whitman, B},
journal = {Computer Music J.},
number = {2},
pages = {63--76},
title = {{A large-scale evaluation of acoustic and subjective music-similarity measures}},
volume = {28},
year = {2004}
}
@article{Lewicki2002,
author = {Lewicki, M S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lewicki/Lewicki - 2002 - Efficient Coding of Natural Sounds - Nature Neuroscience.pdf:pdf},
journal = {Nature Neuroscience},
number = {4},
pages = {356--363},
title = {{Efficient Coding of Natural Sounds}},
volume = {5},
year = {2002}
}
@inproceedings{Faloutsos1994,
address = {Minneapolis, MN},
author = {Faloutsos, C and Ranganathan, M and Manolopoulos, Y},
booktitle = {Proc. ACM SIGMOD Int. Conf. Mgmt. Data},
file = {::},
keywords = {DB},
pages = {419--429},
title = {{Fast subsequence matching in time-series databases}},
year = {1994}
}
@inproceedings{DAguanno2007,
address = {Augsburg, Germany},
author = {D'Aguanno, A and Vercellisi, G},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {153--158},
title = {{Tempo induction algorithm in MP3 compressed domain}},
year = {2007}
}
@article{Andrle2004,
author = {Andrle, M and Rebollo-Neira, L and Sagianos, E},
journal = {\{IEEE\} Signal Process. Lett.},
number = {9},
pages = {705--708},
title = {{Backward-optimized Orthogonal Matching Pursuit Approach}},
volume = {11},
year = {2004}
}
@article{Fitz2002,
author = {Fitz, K and Haken, L},
journal = {J. Audio Eng. Soc.},
number = {11},
pages = {879--893},
title = {{On the use of time-frequency reassignment in additive sound modeling}},
volume = {50},
year = {2002}
}
@inproceedings{Stober2010a,
address = {Linz, Austria},
author = {Stober, S and N\"{u}rnberger, A},
booktitle = {Proc. Int. Workshop Adaptive Multimedia Retrieval},
title = {{Similarity Adaptation in an Exploratory Retrieval Scenario}},
year = {2010}
}
@inproceedings{Ravelli2008a,
address = {Philadelphia, PA},
author = {Ravelli, E and Richard, G and Daudet, L},
booktitle = {Int. Conf. Music Info. Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ravelli, Richard, Daudet/Ravelli, Richard, Daudet - 2008 - Fast MIR in a Sparse Transform Domain - Int. Conf. Music Info. Retrieval.pdf:pdf},
title = {{Fast MIR in a Sparse Transform Domain}},
year = {2008}
}
@article{Donoho2006,
author = {Donoho, D L and Tsaig, Y and Drori, I and Starck, J-L.},
journal = {IEEE Trans. on Info. Theory},
title = {{Sparse Solution of Underdetermined Linear Equations by Stagewise Orthogonal Matching Pursuit}}
}
@inproceedings{Parvaix2008,
address = {Las Vegas, NV},
author = {Parvaix, M and Krishnan, S and Ioana, C},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {1721--1724},
title = {{An Audio Watermarking Method Based on Molecular Matching Pursuit}},
year = {2008}
}
@techreport{Divekar2010,
address = {West Lafayette, IN, USA},
author = {Divekar, A and Ersoy, O},
institution = {Purdue University},
month = may,
title = {{Probabilistic Matching Pursuit for Compressive Sensing}},
year = {2010}
}
@misc{Blumensath2004,
author = {Blumensath, T},
howpublished = {Web, powerpoint presentation},
title = {{Unsupervised learning of shift-invariant over-complete dictionaries for time-series analysis}}
}
@inproceedings{Goodwin1997b,
address = {New Paltz, New York},
author = {Goodwin, M M and Vetterli, M},
booktitle = {Proc. IEEE Workshop Appl. Signal Process. Audio Acoust.},
keywords = {MP},
pages = {4--8},
title = {{Atomic decompositions of audio signals}},
year = {1997}
}
@book{Christensen2003,
address = {Boston, MA},
author = {Christensen, O},
publisher = {Birkh\"{a}user},
series = {Applied and Numerical Harmonic Analysis},
title = {{An Introduction to Frames and Riesz Bases}},
year = {2003}
}
@article{Lewicki2000,
author = {Lewicki, M S and Sejnowski, T J},
journal = {Neural Computation},
pages = {337--365},
title = {{Learning Overcomplete Representations}},
volume = {12},
year = {2000}
}
@inproceedings{Sejdic2008,
address = {Las Vegas, NV},
author = {Sejdi\'{c}, E and Luccini, M and Primak, S and Baddour, K and Willink, T},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {2849--2852},
title = {{Channel estimation using \{DPSS\} Based Frames}},
year = {2008}
}
@phdthesis{Mazhar2009,
address = {Gainesville, FL},
author = {Mazhar, R},
month = may,
school = {University of Florida},
title = {{Optimized Dictionary Design and Classification using the Matching Pursuits Dissimilarity Measure}},
year = {2009}
}
@inproceedings{Xu2004,
author = {Xu, G and Meng, J},
booktitle = {IEEE Vehicular Technology Conf.},
pages = {1986--1990},
title = {{Signal Enhancement with Matching Pursuit}},
volume = {3},
year = {2004}
}
@inproceedings{Mcdonagh2003,
author = {McDonagh, L and Bimbot, F and Gribonval, R},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing},
pages = {469--472},
title = {{A granular approach for the analysis of monophonic audio signals}},
year = {2003}
}
@article{Abdallah2006,
author = {Abdallah, S A and Plumbley, M D},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {179--196},
title = {{Unsupervised Analysis of Polyphonic Music by Sparse Coding}},
volume = {17},
year = {2006}
}
@article{Keogh2001,
address = {Santa Barbara, CA},
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Mehrotra, Sharad and Pazzani, Michael},
journal = {ACM Trans. Database Syst.},
keywords = {DB},
number = {2},
pages = {188--228},
title = {{Locally adaptive dimensionality reduction for indexing large time series databases}},
volume = {27},
year = {2001}
}
@inproceedings{Sturm2009c,
address = {Madrid, Spain},
author = {Sturm, B L and Daudet, L},
booktitle = {Proc. Int. Workshop Adaptive Multimedia Retrieval},
title = {{On Similarity Search in Audio Signals Using Adaptive Sparse Approximations}},
year = {2009}
}
@article{Temlyakov2010,
author = {Temlyakov, V N and Zheltov, P},
journal = {J. Approximation Theory},
title = {{On performance of greedy algorithms}}
}
@article{Jaggi1998,
author = {Jaggi, S and Karl, W C and Mallat, S and Willsky, A S},
journal = {Applied and Computational Harmonic Analysis},
number = {4},
pages = {428--449},
title = {{High resolution pursuit for feature extraction}},
volume = {5},
year = {1998}
}
@inproceedings{Stober2010a,
address = {Linz, Austria},
author = {Stober, S and N\"{u}rnberger, A},
booktitle = {Proc. Int. Workshop Adaptive Multimedia Retrieval},
title = {{Similarity Adaptation in an Exploratory Retrieval Scenario}},
year = {2010}
}
@article{Pielemeier1996,
author = {Pielemeier, W J and Wakefield, G H},
journal = {J. Acoustical Society of America},
number = {4},
pages = {2382--2396},
title = {{A high-resolution time-frequency representation for musical instrument signals}},
volume = {99},
year = {1996}
}
@inproceedings{Korn1997,
address = {Tucson, AZ},
author = {Korn, Flip and Jagadish, H V and Faloutsos, Christos},
booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
keywords = {DB},
pages = {289--300},
publisher = {ACM},
title = {{Efficiently supporting ad hoc queries in large datasets of time sequences}},
year = {1997}
}
@inproceedings{Krishnan1997,
address = {Victoria, BC},
author = {Krishnan, S and Rangayyan, R M},
booktitle = {Proc. IEEE Conf. Commun., Comput., Signal Process.},
pages = {138--141},
title = {{Detection of chirp and other components in the time-frequency plane using the \{H\}ough and \{R\}adon transforms}},
year = {1997}
}
@article{Gjerdingen2008,
author = {Gjerdingen, R O and Perrott, D},
journal = {J. New Music Research},
number = {2},
pages = {93--100},
title = {{Scanning the Dial: The Rapid Recognition of Music Genres}},
volume = {37},
year = {2008}
}
@inproceedings{Jehan2004,
abstract = {This work presents a novel framework for music synthesis, based
on the perceptual structure analysis of pre-existing musical signals,
for example taken from a personal MP3 database. We raise
the important issue of grounding music analysis on perception, and
propose a bottom-up approach to music analysis, as well as modeling,
and synthesis. A model of segmentation for polyphonic
signals is described, and is qualitatively validated through several
artifact-free music resynthesis experiments, e.g., reversing the
ordering of sound events (notes), without reversing their waveforms.
Then, a compact ``timbre'' structure analysis, and a method
for song description in the form of an ``audio DNA'' sequence is
presented. Finally, we propose novel applications, such as music
cross-synthesis, or time-domain audio compression, enabled
through simple sound similarity measures, and clustering.},
address = {Naples, Italy},
author = {Jehan, T},
booktitle = {Proc. COST G-6 Conf. on Digital Audio Effects (DAFx-04)},
keywords = {MIR},
title = {{Event-synchronous Music Analysis/Synthesis}},
year = {2004}
}
@article{Ferrando2000,
author = {Ferrando, S E and Doolittle, E J and Bernal, A J and Bernal, L J},
journal = {Signal Process.},
number = {10},
pages = {2099--2120},
title = {{Probabilistic matching pursuit with Gabor dictionaries}},
volume = {80},
year = {2000}
}
@article{Kaminskyj1996,
author = {Kaminskyj, I. and Voumard, P.},
journal = {1996 Australian New Zealand Conference on Intelligent Information Systems. Proceedings. ANZIIS 96},
number = {November},
pages = {76--79},
publisher = {Ieee},
title = {{Enhanced automatic source identification of monophonic musical instrument sounds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=573893},
year = {1996}
}
@article{Daudet2004b,
author = {Daudet, L and Sandler, M},
journal = {IEEE Trans. Speech Audio Process.},
month = may,
number = {3},
pages = {302--312},
title = {{\{MDCT\} analysis of sinusoids: explicit results and applications to coding artifacts reduction}},
volume = {12},
year = {2004}
}
@article{Chan2003,
author = {Chan, K P and Fu, A W and Yu, C},
journal = {IEEE Trans. Knowledge Data Eng.},
keywords = {DB},
month = may,
number = {3},
pages = {686--705},
title = {{Haar Wavelets for Efficient Similarity Search of Time-Series: With and Without Time Warping}},
volume = {15},
year = {2003}
}
@article{Orio2006,
author = {Orio, N},
file = {::},
journal = {Foundations and Trends in Information Retrieval},
number = {1},
title = {{Music Retrieval: A Tutorial and Review}},
volume = {1},
year = {2006}
}
@phdthesis{Tropp2004a,
author = {Tropp, J},
month = aug,
school = {The University of Texas at Austin},
title = {{Topics in Sparse Approximation}},
year = {2004}
}
@inproceedings{Vlachos2002,
address = {San Francisco, CA},
author = {Vlachos, M and Lin, J and Keogh, E and Gunopulos, D},
booktitle = {Proc. Workshop on Clustering High Dimensionality Data and Its Applications},
keywords = {DB},
month = may,
pages = {23--30},
title = {{A Wavelet-based Anytime Algorithm for K-means Clustering of Time Series}},
year = {2003}
}
@conference{Defrance2008,
author = {Defrance, G and Polack, J.-D.},
booktitle = {Proc. Acoustical Societs of America},
title = {{Estimating the mixing time of concert halls using the eXtensible Fourier Tranform}},
year = {2008}
}
@inproceedings{Barrington2007,
author = {Barrington, L and Chan, A and Turnbull, D and Lanckriet, G},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
title = {{Audio information retrieval using semantic similarity}},
year = {2007}
}
@inproceedings{Pielemeier1996a,
author = {Pielemeier, W J and Wakefield, G H and Simoni, M H},
booktitle = {Proc. IEEE},
number = {9},
pages = {1216--1230},
title = {{Time-frequency analysis of musical signals}},
volume = {84},
year = {1996}
}
@article{Gray1998,
author = {Gray, R M and Neuhoff, D L},
journal = {IEEE Trans. Inf. Theory},
number = {6},
pages = {2325--2383},
title = {{Quantization}},
volume = {44},
year = {1998}
}
@article{Gribonval2006a,
author = {Gribonval, R and Vandergheynst, P},
journal = {IEEE Trans. Information Theory},
number = {1},
pages = {255--261},
title = {{On the exponential convergence of Matching Pursuits in quasi-incoherent dictionaries}},
volume = {52},
year = {2006}
}
@article{Stowell2009,
author = {Stowell, D and Robertson, A and Bryan-Kinns, N and Plumbley, M D},
journal = {Int. J. Human-Computer Studies},
title = {{Evaluation of live human-computer music-making: quantitative and qualitative approaches}},
year = {2009}
}
@article{Portnoff1976,
author = {Portnoff, M R},
journal = {IEEE Trans. Acoustics, Speech, Signal Process.},
month = jun,
number = {3},
pages = {243--248},
title = {{Implementation of the digital phase vocoder using the fast Fourier transform}},
volume = {24},
year = {1976}
}
@book{Rao1990,
address = {Boston, MA},
author = {Rao, K R and Yip, P},
publisher = {Academic Press},
title = {{Discrete Cosine Transform: Algorithms, Advantages, Applications}},
year = {1990}
}
@article{Gribonval2005a,
author = {Gribonval, R},
journal = {IEEE Trans. Neural Networks},
number = {3},
pages = {522--532},
title = {{From Projection Pursuit and CART to Adaptive Discriminant Analysis?}},
volume = {16},
year = {2005}
}
@phdthesis{Escoda2005,
address = {Lausanne, Switzerland},
author = {Escoda, \`{O} D},
month = jun,
school = {\'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne},
title = {{Toward Sparse and Geometry Adapted Video Approximations}},
year = {2005}
}
@article{Kitahara2006,
author = {Kitahara, T. and Komatani, K. and Ogata, T. and Okuno, H.G. and Goto, M.},
journal = {2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings},
pages = {V--229--V--232},
publisher = {Ieee},
title = {{Instrogram: A New Musical Instrument Recognition Technique Without Using Onset Detection NOR F0 Estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1661254},
year = {2006}
}
@article{Vera-Candeas2004a,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Rosa-Zurera, M and Martinez-Mu$\backslash$tildenoz, D and Lopez-Ferreras, F},
journal = {\{IEEE\} Signal Process. Lett.},
number = {3},
pages = {349--352},
title = {{Transient Modeling by Matching Pursuits With a Wavelet Dictionary for Parametric Audio Coding}},
volume = {11},
year = {2004}
}
@article{Preis1999,
author = {Preis, D and Georgopoulos, V C},
journal = {J. Audio Eng. Soc.},
number = {12},
pages = {1043--1053},
title = {{Wigner distribution representation and analysis of audio signals: An illustrated tutorial review}},
volume = {47},
year = {1999}
}
@article{Morvidone2010,
author = {Morvidone, M and Sturm, B L and Daudet, L},
journal = {Patt. Recgn. Lett.},
title = {{Incorporating scale information with cepstral features: experiments on musical instrument recognition}}
}
@article{Durka1995,
author = {Durka, P J and Blinowska, K J},
journal = {Ann. Biomed. Eng.},
number = {5},
pages = {608--611},
title = {{Analysis of EEG transients by means of matching pursuit}},
volume = {23},
year = {1995}
}
@inproceedings{Ke2005,
author = {Ke, Y and Hoiem, D and Sukthankar, R},
booktitle = {Proc. IEEE Conf. Computer Vision Pattern Recog.},
keywords = { TFR,MIR},
month = jun,
pages = {597--604},
title = {{Computer Vision for Music Identification}},
year = {2005}
}
@article{Benar2009,
author = {B\'{e}nar, C G and Papadopoulo, T and Torr\'{e}sani, B and Clerc, M},
journal = {J. Neuroscience Methods},
number = {1},
pages = {161--170},
title = {{Consensus matching pursuit for multi-trial EEG signals}},
volume = {180},
year = {2009}
}
@inproceedings{Aucouturier2002,
address = {Paris, France},
author = {Aucouturier, J-.J. and Pachet, F},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Music Similarity Measures: What's The Use?}},
year = {2002}
}
@inproceedings{Muller2005,
address = {London, U.K.},
author = {M\"{u}ller, M and Kurth, F and Clausen, M},
booktitle = {Proc. Int. Conf. Music Info. Retrieval},
file = {::},
pages = {288--295},
title = {{Audio matching via chroma-based statistical features}},
year = {2005}
}
@article{Donoho2001,
author = {Donoho, D L and Huo, X},
journal = {IEEE Trans. Inform. Theory},
number = {7},
pages = {2845--2862},
title = {{Uncertainty principles and ideal atomic decomposition}},
volume = {47},
year = {2001}
}
@article{Sturm2001,
author = {Sturm, B L},
journal = {Organised Sound},
number = {2},
pages = {131--145},
title = {{Composing for an ensemble of atoms: the metamorphosis of scientific experiment into music}},
volume = {6},
year = {2001}
}
@article{Abdallah2009,
author = {Abdallah, S A and Plumbley, M D},
journal = {Connection Science},
pages = {89--117},
title = {{Information Dynamics: Patterns of expectation and surprise in the perception of music}},
volume = {21},
year = {2009}
}
@article{Donoho2006a,
author = {Donoho, D L and Elad, M and Temlyakov, V N},
journal = {IEEE Trans. Information Theory},
number = {1},
pages = {6--18},
title = {{Stable Recovery of Sparse Overcomplete Representations in the Presence of Noise}},
volume = {52},
year = {2006}
}
@article{Schwarz2006,
author = {Schwarz, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2006 - Concatenative Sound Synthesis The Early Years - J. New Music Research.pdf:pdf},
journal = {J. New Music Research},
keywords = {CSS},
number = {1},
title = {{Concatenative Sound Synthesis: The Early Years}},
volume = {35},
year = {2006}
}
@inproceedings{Gersem1997,
address = {Hellas, Greece},
author = {Gersem, P De and Moor, B De and Moonen, M},
booktitle = {Proc. IEEE Dig. Sig. Process.},
month = jul,
pages = {563--566},
title = {{Applications of the continuous wavelet transform in the processing of musical signals}},
volume = {2},
year = {1997}
}
@inproceedings{Chechik2008,
address = {Vancouver, BC, Canada},
author = {Chechik, G and Bengio, S and Ie, E and Lyon, D and Rehn, M},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {105--112},
title = {{Large-scale Content-based Audio Retrieval from Text Queries}},
year = {2008}
}
@article{Vera-Candeas2004a,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Rosa-Zurera, M and Martinez-Mu$\backslash$tildenoz, D and Lopez-Ferreras, F},
journal = {\{IEEE\} Signal Process. Lett.},
number = {3},
pages = {349--352},
title = {{Transient Modeling by Matching Pursuits With a Wavelet Dictionary for Parametric Audio Coding}},
volume = {11},
year = {2004}
}
@inproceedings{Endelt2005,
address = {Philadelphia, PA},
author = {Endelt, L O and la Cour-Harbo, A},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {13--16},
title = {{Comparison of methods for sparse representation of musical signals}},
volume = {3},
year = {2005}
}
@inproceedings{Dorfler2010,
address = {Barcelona, Spain},
author = {D\"{o}rfler, M and Velasco, G and Flexer, A and Klien, V},
booktitle = {Proc. Sound and Music Computing},
month = jul,
title = {{Sparse Regression in Time-Frequency Representations of Complex Audio}},
year = {2010}
}
@article{Leveau2008,
author = {Leveau, P and Vincent, E and Richard, G and Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {1},
pages = {116--128},
title = {{Instrument-specific Harmonic Atoms for Mid-level Music Representation}},
volume = {16},
year = {2008}
}
@article{Schniter2008,
author = {Schniter, P and Potter, L C and Ziniel, J},
journal = {IEEE Trans. Signal Process.},
title = {{Fast Bayesian matching pursuit: model uncertainty and parameter estimation for sparse linear models}}
}
@inproceedings{Arias2008,
address = {London, U.K.},
author = {Arias, J A and Andr\'{e}-Obrecht, R and Farinas, J},
booktitle = {Proc. Content-based Multimedia Indexing},
month = jun,
pages = {556--559},
title = {{Automatic Low-dimensional Analysis of Audio Databases}},
year = {2008}
}
@conference{Giacobello2010b,
address = {Dallas, TX},
author = {Giacobello, D and Christensen, M and Murthi, M N and Jensen, S H and Moonen, M},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{Enhancing Sparsity in Linear Prediction of Speech by Iteratively Reweighted $\backslash$($\backslash$ell\_1$\backslash$)-norm Minimization}},
year = {2010}
}
@article{Rebollo-Neira2007,
author = {Rebollo-Neira, L},
journal = {\{IEEE\} Signal Proc. Letters},
number = {10},
pages = {703--706},
title = {{Oblique Matching Pursuit}},
volume = {14},
year = {2007}
}
@inproceedings{Verma1999,
address = {Phoenix, Arizona},
author = {Verma, T S and Meng, T H Y},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {981--984},
title = {{Sinusoidal modeling using frame-based perceptually weighted matching pursuits}},
volume = {2},
year = {1999}
}
@article{Ding2007,
author = {Ding, Qian and Zhang, Nian},
journal = {2007 IEEE Symposium on Computational Intelligence in Image and Signal Processing},
keywords = {ann,artificial neural networks,back-,extraction,feature,feed-forward neural network,ffnn,mean-square error,mse,propagation training algorithm,sequential forward selection,sfs},
month = apr,
number = {Ciisp},
pages = {157--162},
publisher = {Ieee},
title = {{Classification of Recorded Musical Instruments Sounds Based on Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4221411},
year = {2007}
}
@phdthesis{Abdallah2002,
address = {London, U.K.},
author = {Abdallah, S A},
month = jun,
school = {King's College London, Department of Electrical Engineering},
title = {{Towards Music Perception by Redundancy Reduction and Unsupervised Learning in Probabilistic Models}},
year = {2002}
}
@phdthesis{Goodwin1997,
address = {Berkeley, CA},
author = {Goodwin, M M},
keywords = {MP},
school = {University of California, Berkeley},
title = {{Adaptive Signal Models: Theory, Algorithms, and Audio Applications}},
year = {1997}
}
@inproceedings{Marques2010,
address = {Barcelona, Spain},
author = {Marques, G and Lopes, M and Sordo, M and Langlois, T and Gouyon, F},
booktitle = {Proc. Sound and Music Computing},
month = jul,
title = {{Additional evidence that common low-level features of individual audio frames are not representative of music genres}},
year = {2010}
}
@article{Bardeli2009,
author = {Bardeli, R},
journal = {IEEE Trans. Multimedia},
keywords = {DB},
number = {1},
pages = {68--76},
title = {{Similarity Search in Animal Sound Databases}},
volume = {11},
year = {2009}
}
@article{Stoica2004,
author = {Stoica, P and Sel\'{e}n, Y},
journal = {IEEE Sig. Process. Mag.},
number = {1},
pages = {112--114},
title = {{Cyclic Minimizers, Majorization Techniques, and the Expectation-Maximization Algorithm: A Refresher}},
volume = {21},
year = {2004}
}
@phdthesis{Chen1995,
author = {Chen, S S},
school = {Stanford University},
title = {{Basis Pursuit}},
year = {1995}
}
@article{FiVentura2006,
author = {{Figueras i Ventura}, R M and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. Image Process.},
number = {3},
pages = {726--739},
title = {{Low-rate and flexible image coding with redundant representations}},
volume = {15},
year = {2006}
}
@article{Davies2006,
author = {Davies, M E and Daudet, L},
journal = {Signal Processing},
number = {3},
pages = {457--470},
title = {{Sparse audio representations using the MCLT}},
volume = {86},
year = {2006}
}
@inproceedings{Lewicki1999,
address = {Denver, CO},
author = {Lewicki, M S and Sejnowski, T J},
booktitle = {Proc. Conf. Advances Neural Infor. Proc. Syst.},
pages = {730--736},
publisher = {MIT Press},
title = {{Coding time-varying signals using sparse, shift-invariant representations}},
volume = {11},
year = {1999}
}
@conference{Sturm2008b,
address = {Princeton, NJ},
author = {Sturm, B L and Shynk, J J and Daudet, L},
booktitle = {Proc. Conf. Info. Sciences Syst.},
pages = {961--966},
title = {{Measuring Interference in Overcomplete Signal Representations}},
year = {2008}
}
@article{Ravelli2008,
author = {Ravelli, E and Richard, G and Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Proc.},
number = {8},
pages = {1361--1372},
title = {{Union of \{MDCT\} Bases for Audio Coding}},
volume = {16},
year = {2008}
}
@inproceedings{Chechik2008,
address = {Vancouver, BC, Canada},
author = {Chechik, G and Bengio, S and Ie, E and Lyon, D and Rehn, M},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {105--112},
title = {{Large-scale Content-based Audio Retrieval from Text Queries}},
year = {2008}
}
@article{Lamel2000,
author = {Lamel, L},
journal = {Speech Communication},
month = jun,
number = {2-3},
pages = {141--154},
title = {{Speaker verification over the telephone}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639399000758},
volume = {31},
year = {2000}
}
@book{Meyer2001,
address = {Philadelphia, PA},
author = {Meyer, C},
publisher = {SIAM: Society for Industrial and Applied Mathematics},
title = {{Matrix Analysis and Applied Linear Algebra}},
year = {2001}
}
@article{Chu2009,
author = {Chu, S and Narayanan, S and Kuo, C.-C. J},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {6},
pages = {1142--1158},
title = {{Environmental Sound Recognition with Time-Frequency Audio Features}},
volume = {17},
year = {2009}
}
@article{Moorer1978,
author = {Moorer, J},
journal = {J. Audio Eng. Soc.},
number = {1},
pages = {42--45},
title = {{The use of the phase vocoder in computer music applications}},
volume = {26},
year = {1978}
}
@inproceedings{Bultan1998,
address = {Pittsburgh, PA},
author = {Bultan, A and Arikan, O},
booktitle = {Proc. Int. Symp. Time-freq. Time-scale Anal.},
pages = {421--424},
title = {{A parallelized matching pursuit algorithm for the four-parameter chirplet decomposition}},
year = {1998}
}
@article{Escoda2006,
author = {Escoda, O D and Granai, L and Vandergheynst, P},
journal = {IEEE Trans. Signal Processing},
number = {9},
pages = {3468--3482},
title = {{On the use of a priori information for sparse signal approximations}},
volume = {54},
year = {2006}
}
@inproceedings{Herrity2006,
author = {Herrity, K K and Gilbert, A C and Tropp, J A},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing},
title = {{Sparse Approximation via Iterative Thresholding}},
year = {2006}
}
@article{Pham2006,
author = {Pham, T V and Smeulders, A},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {4},
pages = {555--567},
title = {{Sparse Representation for Coarse and Fine Object Recognition}},
volume = {28},
year = {2006}
}
@misc{Chang2001,
author = {Chang, C.-C. and Lin, C.-J.},
howpublished = {Software available at: http://www.csie.ntu.edu.tw/\~{}cjlin/libsvm},
title = {{\{LIBSVM\}: a library for support vector machines}},
year = {2001}
}
@article{Sturm2008f,
author = {Sturm, Bob L. and Shynk, John J.},
journal = {2008 42nd Asilomar Conference on Signals, Systems and Computers},
month = oct,
pages = {241--245},
publisher = {Ieee},
title = {{Interference-driven adaptation in sparse approximation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5074400},
year = {2008}
}
@inproceedings{Gilbert2003,
address = {Baltimore, MD},
author = {Gilbert, A C and Muthukrishnan, S and Strauss, M J},
booktitle = {Proc. SIAM Symp. Discrete Algo.},
pages = {243--252},
title = {{Approximation of Functions over Redundant Dictionaries Using Coherence}},
year = {2003}
}
@incollection{Rebollo-Neira2006,
author = {Rebollo-Neira, L},
booktitle = {New Topics in Mathematical Physics Research},
chapter = {7},
editor = {Benton, C V},
pages = {205--239},
publisher = {Nova Science Publishers, Inc.},
title = {{On non-orthogonal signal representations}},
year = {2006}
}
@article{Akcakaya2007b,
author = {Ak\c{c}akaya, M and Tarokh, V},
journal = {\{IEEE\} Signal Process. Lett.},
number = {11},
pages = {777--780},
title = {{Performance of Sparse Representation Algorithms using Randomly Generated Frames}},
volume = {14},
year = {2007}
}
@article{Amatriain2003,
abstract = {Content processing is a vast and growing field that integrates different approaches borrowed from the signal processing, 
information retrieval and machine learning disciplines. In this article we deal with a particular type of content pro- 
cessing: the so-called content-based transformations. We will not focus on any particular application but rather try to give 
an overview of different techniques and conceptual implications. We first describe the transformation process itself, 
including the main model schemes that are commonly used, which lead to the establishment of the formal basis for a 
definition of content-based transformations. Then we take a quick look at a general spectral based analysis/synthesis 
approach to process audio signals and how to extract features that can be used in the content-based transformation context. Using this analysis/synthesis approach we give some examples on how content-based transformations can be applied to modify the basic perceptual axis of a sound and how we can even combine different basic effects in order to perform more meaningful transformations. We finish by going a step further in the abstraction ladder and present transformations that are related to musical (and thus symbolic) properties rather than to those of the sound or the signal itself.},
author = {Amatriain, X and Bonada, J and Loscos, \`{A} and Arcos, J L and Verfaille, V},
journal = {J. New Music Research},
keywords = { synth,MIR},
number = {1},
pages = {95--114},
title = {{Content-Based Transformations}},
url = {http://www.iua.upf.es/mtg/publications/jnmr32-xamat.pdf},
volume = {32},
year = {2003}
}
@inproceedings{Cho2009a,
author = {Cho, Y and Saul, L K},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{Sparse Decomposition of Mixed Audio Signals by Basis Pursuit with Autoregressive Models}},
year = {2009}
}
@article{Gabor1946,
author = {Gabor, D},
journal = {J. IEE},
number = {3},
pages = {429--457},
title = {{Theory of Communication}},
volume = {93},
year = {1946}
}
@article{Tropp2004,
author = {Tropp, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tropp/Tropp - 2004 - Greed is good Algorithmic results for sparse approximation - IEEE Trans. Info. Theory.pdf:pdf},
journal = {IEEE Trans. Info. Theory},
number = {10},
pages = {2231--2242},
title = {{Greed is good: Algorithmic results for sparse approximation}},
volume = {50},
year = {2004}
}
@inproceedings{Krstulovic2006,
abstract = {In the framework of audio signal analysis, it is desired to obtain
sparse representations that are able to reflect the harmonic structures,
e.g., issued from musical instruments. In this paper, we compare
two approaches which introduce some explicit models of harmonic
features into the Matching Pursuit analysis framework. The
first approach is the Harmonic Matching Pursuit (HMP), where the
harmonic structures are modeled by sets of harmonically related
Gabor atoms which are directly optimized in the analysis loop.
The second approach, called Meta-Molecular Matching Pursuit
(M3P), is based on the a posteriori agglomeration of elementary
features coming from a Short Time Fourier Transform. We discuss
the pros and cons of each method through experiments involving
different audio signals, and conclude on possible approaches for
combining the two methods.},
address = {Toulouse, France},
author = {Krstulovic, S and Gribonval, R},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = { MP,TFR},
pages = {496--499},
title = {{\{MPTK\}: Matching Pursuit Made Tractable}},
volume = {3},
year = {2006}
}
@article{Holm-Hudson1997,
author = {Holm-Hudson, K},
journal = {Leonardo Music J.},
pages = {17--25},
title = {{Quotation and Context: Sampling and John Oswald's Plunderphonics}},
volume = {7},
year = {1997}
}
@inproceedings{Ghias1995,
address = {San Francisco, CA},
author = {Ghias, A and Logan, J and Chamberlin, D and Smith, B C},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {231--236},
title = {{Query by humming: musical information retrieval in an audio database}},
year = {1995}
}
@article{Kashino2003,
author = {Kashino, K and Kurozumi, T and Murase, H},
journal = {Multimedia, IEEE Transactions on},
number = {3},
pages = {348--357},
title = {{A quick search method for audio and video signals based on histogram pruning}},
volume = {5},
year = {2003}
}
@inproceedings{Flexer2010,
author = {Flexer, A and Schnitzer, D and Gasser, M and Pohle, T},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Combining Features Reduces Hubness in Audio Similarity}},
year = {2010}
}
@inproceedings{Bray2005,
address = {London, U.K.},
author = {Bray, S and Tzanetakis, G},
booktitle = {Int. Conf. Music Info. Retrieval},
pages = {434--437},
title = {{Distributed audio feature extraction for music}},
year = {2005}
}
@article{Aucouturier2004,
author = {Aucouturier, J-.J. and Pachet, F},
journal = {J. of Negative Results in Speech and Audio Sciences},
number = {1},
title = {{Improving Timbre Similarity: How high is the sky?}},
volume = {1},
year = {2004}
}
@article{Morvidone2010a,
author = {Morvidone, Marcela and Sturm, Bob L. and Daudet, Laurent},
journal = {Pattern Recognition Letters},
keywords = {audio signal classification,frequency,sparse decompositions,time,time-scale features},
month = sep,
number = {12},
pages = {1489--1497},
title = {{Incorporating scale information with cepstral features: Experiments on musical instrument recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865509003778},
volume = {31},
year = {2010}
}
@article{Eggink,
author = {Eggink, J. and Brown, G.J.},
journal = {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {iv--217--iv--220},
publisher = {Ieee},
title = {{Instrument recognition in accompanied sonatas and concertos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1326802}
}
@article{Liu2004,
author = {Liu, Q and Wang, Q and Wu, L},
journal = {IEEE Trans. Signal Processing},
number = {12},
pages = {3403--3408},
title = {{Size of the Dictionary in Matching Pursuit Algorithm}},
volume = {52},
year = {2004}
}
@article{Karabulut2006,
author = {Karabulut, G Z and Moura, L and Panario, D and Yongaco$\backslash$\~{}glu, A},
journal = {IEE Proc.-Vis. Image Signal Processing},
number = {5},
pages = {538--548},
title = {{Integrating flexible tree searches to orthogonal matching pursuit algorithm}},
volume = {153},
year = {2006}
}
@article{Kreutz-Delgado2003,
author = {Kreutz-Delgado, K and Murray, J F and Rao, B D and Engan, K and Lee, T and Sejnowski, T J},
journal = {Neural Computation},
number = {2},
pages = {349--396},
title = {{Dictionary Learning Algorithms for Sparse Representation}},
volume = {15},
year = {2003}
}
@article{Friedman1974,
author = {Friedman, J H and Tukey, J W},
journal = {IEEE Trans. Comput.},
number = {9},
pages = {881--890},
title = {{A Projection Pursuit Algorithm for Exploratory Data Analysis}},
volume = {C-23},
year = {1974}
}
@article{Donoho2006b,
author = {Donoho, D L},
journal = {IEEE Trans. Info. Theory},
number = {4},
pages = {1289--1306},
title = {{Compressed sensing}},
volume = {52},
year = {2006}
}
@article{Roads2001a,
author = {Roads, C},
journal = {J. Audio Eng. Soc.},
number = {3},
pages = {134--147},
title = {{Sound composition with pulsars}},
volume = {49},
year = {2001}
}
@inproceedings{Schwarz2000,
abstract = {In speech synthesis, concatenative data-driven synthesis methods
prevail. They use a database of recorded speech and a unit selection
algorithm that selects the segments that match best the utterance
to be synthesized. Transferring these ideas to musical sound
synthesis allows a new method of high quality sound synthesis.
Usual synthesis methods are based on a model of the sound signal.
It is very difficult to build a model that would preserve the entire
fine details of sound. Concatenative synthesis achieves this by using
actual recordings. This data-driven approach (as opposed to a
rule-based approach) takes advantage of the information contained
in the many sound recordings. For example, very naturally sounding
transitions can be synthesized, since unit selection is aware
of the context of the database units. The CATERPILLAR software
system has been developed to allow data-driven concatenative unit
selection sound synthesis. It allows high-quality instrument synthesis
with high level control, explorative free synthesis from arbitrary
sound databases, or resynthesis of a recording with sounds
from the database. It is based on the new software-engineering
concept of component-oriented software, increasing flexibility and
facilitating reuse.},
address = {Verona, Italy},
author = {Schwarz, D},
booktitle = {Proc. COST G-6 Conf. on Digital Audio Effects},
keywords = {CSS},
title = {{A System for Data-Driven Concatenative Sound Synthesis}},
year = {2000}
}
@article{Rebollo-Neira2002,
author = {Rebollo-Neira, L and Lowe, D},
journal = {\{IEEE\} Signal Process. Lett.},
number = {4},
pages = {137--140},
title = {{Optimized Orthogonal Matching Pursuit Approach}},
volume = {9},
year = {2002}
}
@article{Plumbley02-conditions,
abstract = {We consider the noiseless linear independent component analysis problem,
in the case where the hidden sources s are non-negative. We assume
that the random variables s\_is are \{$\backslash$em well-grounded\} in that
they have a non-vanishing pdf in the (positive) neighbourhood of
zero. For an orthonormal rotation y=Wx of pre-whitened observations
x=QAs, under certain reasonable conditions we show that y is
a permutation of the s (apart from a scaling factor) if and only
if y is non-negative with probability 1. We suggest that this may
enable the construction of practical learning algorithms, particularly
for sparse non-negative sources.},
author = {Plumbley, M D},
journal = {IEEE Signal Processing Letters},
month = jun,
number = {6},
pages = {177--180},
title = {{Conditions for Nonnegative Independent Component Analysis}},
volume = {9},
year = {2002}
}
@mastersthesis{Sturm2004,
address = {Santa Barbara, CA},
author = {Sturm, B L},
month = jun,
school = {University of California},
title = {{Signals and Systems Using \{MATLAB\}: An Effective Application for Teaching Media Signal Processing to Artists and Engineers}},
year = {2004}
}
@inproceedings{Plumbley2007b,
author = {Plumbley, M D},
booktitle = {Proc. Int. Conf. Independent Component Analysis Signal Separation (ICA 2007)},
pages = {406--413},
title = {{Dictionary Learning for L1-Exact Sparse Coding}},
year = {2007}
}
@inproceedings{Shoa2006,
address = {Snowbird, Utah},
author = {Shoa, A and Shirani, S},
booktitle = {Proc. Data Compression Conf.},
pages = {466},
title = {{Distortion of Matching Pursuit: Modeling and Optimization}},
year = {2006}
}
@inproceedings{Melih1997,
author = {Melih, K and Gonzalez, R and Ogubona, P},
booktitle = {Proc. IEEE Tencon},
title = {{An Audio Representation for Content Based Retrieval}},
year = {1997}
}
@article{Goodwin1999,
author = {Goodwin, M M and Vetterli, M},
journal = {IEEE Trans. Signal Process.},
keywords = {MP},
month = jul,
number = {7},
pages = {1890--1902},
title = {{Matching pursuit and atomic signal models based on recursive filter banks}},
volume = {47},
year = {1999}
}
@book{Gersho1991,
address = {Norwell, MA},
author = {Gersho, A and Gray, R M},
publisher = {Kluwer Academic},
title = {{Vector Quantization and Signal Compression}},
year = {1991}
}
@article{Umapathy2007a,
author = {Umapathy, Karthikeyan and Krishnan, Sridhar},
journal = {IEEE Transactions on Signal Processing},
month = mar,
number = {3},
pages = {978--989},
title = {{Time-Width Versus Frequency Band Mapping of Energy Distributions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4099576},
volume = {55},
year = {2007}
}
@article{Noll1997,
author = {Noll, P},
journal = {IEEE Sig. Process. Mag.},
number = {5},
pages = {59--81},
title = {{MPEG Digital Audio Coding}},
volume = {14},
year = {1997}
}
@article{Sturm2009b,
author = {Sturm, B L and Roads, C and McLeran, A and Shynk, J J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm et al/Sturm et al. - 2009 - Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods - J. New Music Researc.pdf:pdf},
journal = {J. New Music Research},
number = {4},
pages = {325--341},
title = {{Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods}},
volume = {38},
year = {2009}
}
@article{Casey2008,
author = {Casey, M and Rhodes, C and Slaney, M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey, Rhodes, Slaney/Casey, Rhodes, Slaney - 2008 - Analysis of Minimum Distances in High-Dimensional Musical Spaces - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
keywords = { DB,MIR},
month = jul,
number = {5},
pages = {1015--1028},
title = {{Analysis of Minimum Distances in High-Dimensional Musical Spaces}},
volume = {16},
year = {2008}
}
@inproceedings{Nakajima1999,
address = {Phoenix, AZ},
author = {Nakajima, Y and Lu, Y and Sugano, M and Yoneyama, A and Yamagihara, H and Kurematsu, A},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {3005--3008},
title = {{A fast audio classification from MPEG coded data}},
volume = {6},
year = {1999}
}
@inproceedings{Aharon2005,
author = {Aharon, M and Elad, M and Bruckstein, A},
booktitle = {?},
keywords = {SA},
title = {{K-SVD: Design of dictionaries for sparse representations}},
year = {2005}
}
@inproceedings{Gilbert2005,
address = {Adelaide, Australia},
author = {Gilbert, A C and Tropp, J A},
booktitle = {Proc. IEEE Int. Symp. Information Theory},
pages = {1000--1004},
title = {{Applications of sparse approximation in communications}},
year = {2005}
}
@article{Blumensath2009,
author = {Blumensath, T and Davies, M E},
journal = {Signal Process. (submitted)},
title = {{Iterative Hard Thresholding for Compressed Sensing}},
year = {2009}
}
@misc{Tropp2006,
author = {Tropp, J A},
howpublished = {Internet},
institution = {Institute for Computational Engineering and Sciences, The University of Texas at Austin},
title = {{Recent Theoretical Advances in Sparse Approximation (presentation slides)}},
url = {http://www-personal.umich.edu/~jtropp/research.html},
year = {2003}
}
@article{Goodwin1999,
author = {Goodwin, M M and Vetterli, M},
journal = {IEEE Trans. Signal Process.},
keywords = {MP},
month = jul,
number = {7},
pages = {1890--1902},
title = {{Matching pursuit and atomic signal models based on recursive filter banks}},
volume = {47},
year = {1999}
}
@inproceedings{Feichtinger1994,
author = {Feichtinger, H and T\"{u}rk, A and Strohmer, T},
booktitle = {Proc. SPIE Int. Soc. Opt. Eng.},
pages = {222--232},
title = {{Hierarchical parallel matching pursuit}},
volume = {2302},
year = {1994}
}
@article{Kashino2003,
author = {Kashino, K and Kurozumi, T and Murase, H},
journal = {Multimedia, IEEE Transactions on},
number = {3},
pages = {348--357},
title = {{A quick search method for audio and video signals based on histogram pruning}},
volume = {5},
year = {2003}
}
@article{Jagadish,
author = {Jagadish, H.V. and Faloutsos, C.},
journal = {Proceedings 14th International Conference on Data Engineering},
pages = {201--208},
publisher = {IEEE Comput. Soc},
title = {{Efficient retrieval of similar time sequences under time warping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=655778}
}
@inproceedings{Zhang2007a,
address = {Washington, DC},
author = {Zhang, X and Ras, Z W},
booktitle = {Proc. Int. Conf. Multimedia Ubiquitous Engineering},
pages = {3--8},
title = {{Analysis of Sound features for Music Timbre Recognition}},
year = {2007}
}
@article{Yu2008a,
author = {Yu, Y and Joe, K and Downie, J S},
journal = {IEICE Trans. Information and Systems},
month = jun,
number = {6},
pages = {1730--1739},
title = {{Efficient Query-by-Content Audio Retrieval by Locality Sensitive Hashing and Partial Sequence Comparison}},
volume = {E91-D},
year = {2008}
}
@inproceedings{Keogh2002,
address = {New York, NY, USA},
author = {Keogh, Eamonn and Kasetty, Shruti},
booktitle = {KDD '02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
pages = {102--111},
publisher = {ACM},
title = {{On the need for time series data mining benchmarks: a survey and empirical demonstration}},
year = {2002}
}
@article{Nuttall1981,
author = {Nuttall, A},
journal = {IEEE Trans. Acoustics, Speech, and Sig. Process.},
number = {1},
pages = {84--91},
title = {{Some Windows with Very Good Sidelobe Behavior}},
volume = {29},
year = {1981}
}
@inproceedings{Parker2007,
address = {Corvallis, OR},
author = {Parker, C and Fern, A and Tadepalli, P},
booktitle = {Proc. Int. Conf. Machine Learning},
title = {{Learning for efficient retrieval of structured data with noisy queries}},
year = {2007}
}
@article{Baraniuk2008,
author = {Baraniuk, R G and Cevher, V and Duarte, M and Hegde, C},
journal = {IEEE Trans. Info. Theory},
title = {{Model-based Compressive Sensing}}
}
@article{Fragoulis2006,
author = {Fragoulis, D. and Papaodysseus, C. and Exarhos, M. and Roussopoulos, G. and Panagopoulos, T. and Kamarotos, D.},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = may,
number = {3},
pages = {1040--1050},
title = {{Automated classification of piano-guitar notes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1621216},
volume = {14},
year = {2006}
}
@article{Benetos2006,
author = {Benetos, E. and Kotti, M. and Kotropoulos, C.},
journal = {2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings},
pages = {V--221--V--224},
publisher = {Ieee},
title = {{Musical Instrument Classification using Non-Negative Matrix Factorization Algorithms and Subset Feature Selection}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1661252},
year = {2006}
}
@article{Peeters2010,
author = {Peeters, G and Deruty, E},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {675--687},
title = {{Sound Indexing Using Morphological Description}},
volume = {18},
year = {2010}
}
@article{Durka2005,
author = {Durka, P J},
journal = {BioMedical Engineering OnLine},
number = {15},
title = {{On the methodological unification in electroencephalography}},
url = {http://www.biomedical-engineering-online.com/content/4/1/15},
volume = {4},
year = {2005}
}
@article{Plumbley2009,
author = {Plumbley, M D and Blumensath, T and Daudet, L and Gribonval, R and Davies., M E},
journal = {Proc. IEEE},
title = {{Sparse representations in audio and music: from coding to source separation.}},
year = {2009}
}
@article{Liu2000,
author = {Liu, C. and Wechsler, H.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = jun,
number = {6},
pages = {570--582},
title = {{Evolutionary pursuit and its application to face recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=862196},
volume = {22},
year = {2000}
}
@article{Schmid1997,
author = {Schmid, C and Mohr, R},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = may,
number = {5},
pages = {530--535},
title = {{Local grayvalue invariants for image retrieval}},
volume = {19},
year = {1997}
}
@inproceedings{Pinquier2004,
address = {Sherbrooke, Canada},
author = {Pinquier, J and Arias, J and Andr\'{e}-Obrecht, R},
booktitle = {Proc. Multidisciplinary Image, Video, and Audio Retrieval and Mining},
title = {{Audio Classification by Search of Primary Components}},
year = {2004}
}
@inproceedings{Morchen2005,
address = {London, U.K.},
author = {M\"{o}rchen, F and Ultsch, A and N\"{o}cker, M and Stamm, C},
booktitle = {Proc. Int. Conf. Music Info. Retrieval},
pages = {396--403},
title = {{Databionic visualization of music collections according to perceptual distance}},
year = {2005}
}
@article{Smith2005b,
author = {Smith, E and Lewicki, M S},
journal = {Nature},
number = {23},
pages = {978--982},
title = {{Efficient Auditory Coding}},
volume = {439},
year = {2005}
}
@inproceedings{Goodwin1997a,
address = {Munich, Germany},
author = {Goodwin, M M and Vetterli, M},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = {MP},
pages = {2037--2040},
title = {{Matching pursuit with damped sinusoids}},
volume = {3},
year = {1997}
}
@article{Aharon2006,
author = {Aharon, M and Elad, M and Bruckstein, A M},
journal = {IEEE Trans. Signal Process.},
keywords = {SA},
month = nov,
number = {11},
pages = {4311--4322},
title = {{K-\{SVD\}: An Algorithm for Designing of Overcomplete Dictionaries for Sparse Representation}},
volume = {54},
year = {2006}
}
@article{Mallat1993,
author = {Mallat, S and Zhang, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mallat, Zhang/Mallat, Zhang - 1993 - Matching Pursuits with Time-Frequency Dictionaries - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
keywords = {MP},
number = {12},
pages = {3397--3415},
title = {{Matching Pursuits with Time-Frequency Dictionaries}},
volume = {41},
year = {1993}
}
@inproceedings{Gribonval1996a,
address = {Paris, France},
author = {Gribonval, R and Bacry, E and Mallat, S and Depalle, Ph. and Rodet, X},
booktitle = {Proc. IEEE-SP Int. Symp. Time-Freq. Time-Scale Anal.},
keywords = {MP},
month = jun,
pages = {125--128},
title = {{Analysis of sound signals with high resolution matching pursuit}},
year = {1996}
}
@article{Green1984,
author = {Green, D N and Bass, S C},
journal = {IEEE Trans. Circuits and Systems},
number = {6},
pages = {518--534},
title = {{Representing Periodic Waveforms with Nonorthogonal Basis Functions}},
volume = {CAS-31},
year = {1984}
}
@article{Mierswa2005a,
author = {Mierswa, Ingo and Morik, Katharina},
journal = {Machine Learning},
month = feb,
number = {2-3},
pages = {127--149},
title = {{Automatic Feature Extraction for Classifying Audio Data}},
url = {http://www.springerlink.com/index/10.1007/s10994-005-5824-7},
volume = {58},
year = {2005}
}
@article{Krishnan2000,
author = {Krishnan, S and Rangayyan, R M and Bell, G D and Frank, C B},
journal = {IEEE Trans. Biomed. Eng.},
month = jun,
number = {6},
pages = {773--783},
title = {{Adaptive time-frequency analysis of knee joint vibroarthrographic signals for noninvasive screening of articular cartilage pathology}},
volume = {47},
year = {2000}
}
@article{Gersho1994,
author = {Gersho, A},
journal = {Proc. IEEE},
number = {6},
pages = {900--918},
title = {{Advances in Speech and Audio Compression}},
volume = {82},
year = {1994}
}
@book{Roads1996,
author = {Roads, C},
publisher = {The MIT Press},
title = {{Computer Music Tutorial}},
year = {1996}
}
@inproceedings{Goodwin2001,
author = {Goodwin, M M},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
title = {{Multiscale overlap-add sinusoidal modeling using matching pursuit and refinements}},
year = {2001}
}
@article{Derrien2006a,
author = {Derrien, O.},
journal = {2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings},
pages = {V--57--V--60},
publisher = {Ieee},
title = {{Multi-Scale Frame-Based Analysis of Audio Signals for Musical Transcription Using a Dictionary of Chromatic Waveforms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1661211},
year = {2006}
}
@article{Kuster2008,
author = {Kuster, M},
journal = {J. Acoust. Soc. of Am.},
number = {2},
pages = {982--993},
title = {{Reliability of estimating the room volume from a single room impulse response}},
volume = {124},
year = {2008}
}
@article{Mallat1993,
author = {Mallat, S and Zhang, Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Mallat, Zhang/Mallat, Zhang - 1993 - Matching Pursuits with Time-Frequency Dictionaries - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
keywords = {MP},
number = {12},
pages = {3397--3415},
title = {{Matching Pursuits with Time-Frequency Dictionaries}},
volume = {41},
year = {1993}
}
@inproceedings{Tropp2006d,
author = {Tropp, J A and Wakin, M B and Duarte, M F and Baron, D and Baraniuk, R G},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing},
pages = {872--875},
title = {{Random Filters for Compressive Sampling and Reconstruction}},
volume = {3},
year = {2006}
}
@article{Candes2006,
author = {Cand\`{e}s, E and Romberg, J and Tao, T},
journal = {IEEE Trans. Inform. Theory},
number = {2},
pages = {489--509},
title = {{Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information}},
volume = {52},
year = {2006}
}
@article{Sturm2009e,
author = {Sturm, Bob and Roads, Curtis and McLeran, Aaron and Shynk, John},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm et al/Sturm et al. - 2009 - Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods - J. New Music Researc.pdf:pdf},
journal = {Journal of New Music Research},
month = dec,
number = {4},
pages = {325--341},
title = {{Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09298210903171178\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {38},
year = {2009}
}
@inproceedings{Rafiei1997,
address = {New York, NY, USA},
author = {Rafiei, Davood and Mendelzon, Alberto},
booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
keywords = {DB},
pages = {13--25},
publisher = {ACM},
title = {{Similarity-based queries for time series data}},
year = {1997}
}
@article{Tropp2006a,
author = {Tropp, J and Gilbert, A C and Strauss, M J},
journal = {Signal Process.},
number = {3},
pages = {572--588},
title = {{Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit}},
volume = {86},
year = {2006}
}
@inproceedings{Grosse2007,
author = {Grosse, R and Raina, R and Kwong, H and Ng, A Y},
booktitle = {Proc. UAI},
title = {{Shift-invariant Sparse Coding for Audio Classification}},
year = {2007}
}
@inproceedings{Duxbury2001,
address = {Limerick, Ireland},
author = {Duxbury, C and Davies, M and Sandler, M},
booktitle = {Proc. Conf. Digital Audio Effects},
title = {{Separation of transient information in musical audio using multiresolution analysis techniques}},
year = {2001}
}
@inproceedings{Gao2003,
address = {Baltimore, Maryland, USA},
author = {Gao, J and Tzanetakis, G and Steenkiste, P},
booktitle = {Proc. Int. Conf. Multimedia Expo},
pages = {309--312},
title = {{Content-based retrieval of music in scalable peer-to-peer networks}},
year = {2003}
}
@inproceedings{Yi2000,
address = {San Francisco, CA, USA},
author = {Yi, Byoung-Kee and Faloutsos, Christos},
booktitle = {VLDB '00: Proceedings of the 26th International Conference on Very Large Data Bases},
pages = {385--394},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Fast Time Sequence Indexing for Arbitrary Lp Norms}},
year = {2000}
}
@article{Tropp2006f,
author = {Tropp, J},
journal = {Signal Processing},
keywords = {combinatorial optimization,convex relaxation,multiple measurement vectors,simultaneous sparse approximation},
month = mar,
number = {3},
pages = {589--602},
title = {{Algorithms for simultaneous sparse approximation. Part II: Convex relaxation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405002239},
volume = {86},
year = {2006}
}
@phdthesis{Davis1994,
address = {New York},
author = {Davis, G},
keywords = {MP},
school = {New York University, Department of Mathematics},
title = {{Adaptive Nonlinear Approximations}},
year = {1994}
}
@inproceedings{Amatriain2001,
author = {Amatriain, X and Bonada, J and Loscos, A and Serra, X},
booktitle = {Proc. MOSART Workshop Current Research Directions Computer Music},
title = {{Spectral Modeling for Higher-level Sound Transformations}},
year = {2001}
}
@inproceedings{Blumensath2004a,
address = {Montreal, Canada},
author = {Blumensath, T and Davies, M},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
month = may,
pages = {497--500},
title = {{Unsupervised learning of sparse and shift-invariant decompositions of polyphonic music}},
volume = {5},
year = {2004}
}
@book{Bosi2003,
address = {Boston, MA},
author = {Bosi, M and Goldberg, R},
publisher = {Kluwer Academic Publishers},
title = {{Introduction to Digital Audio Coding and Standards}},
year = {2003}
}
@techreport{Hsu2003,
address = {Taiwan, China},
author = {Hsu, C W and Chang, C C and Lin, C J},
institution = {National Taiwan University},
month = may,
number = {http://www.csie.ntu.edu.tw/\~{}cjlin},
title = {{A Practical Guide to Support Vector Classification}},
year = {2009}
}
@article{DeGersem,
author = {{De Gersem}, P. and {De Moor}, B. and Moonen, M.},
journal = {Proceedings of 13th International Conference on Digital Signal Processing},
pages = {563--566},
publisher = {Ieee},
title = {{Applications of the continuous wavelet transform in the processing of musical signals}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=628411}
}
@article{Zhang2001,
author = {Zhang, T and Kuo, C.-C. J},
journal = {IEEE Trans. Speech Audio Process.},
month = may,
number = {4},
pages = {441--457},
title = {{Audio content analysis for online audiovisual data segmentation and classification}},
volume = {9},
year = {2001}
}
@article{Guo2003a,
author = {Guo, G and Li, S Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo, Li/Guo, Li - 2003 - Content-Based Audio Classification and Retrieval by Support Vector Machines - IEEE Trans. Neural Networks.pdf:pdf},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {209--215},
title = {{Content-Based Audio Classification and Retrieval by Support Vector Machines}},
volume = {14},
year = {2003}
}
@article{Sturm2006b,
address = {New York, New York, USA},
author = {Sturm, Bob L. and Daudet, Laurent and Roads, Curtis},
journal = {Proceedings of the 1st ACM workshop on Audio and music computing multimedia - AMCMM '06},
keywords = {0221713,audio signals,by nsf grant no,dge-,igert in interactive digital,matching pur-,multimedia,research supported in part,sparse atomic approximation,suit,time-frequency modification},
pages = {45},
publisher = {ACM Press},
title = {{Pitch-shifting audio signals using sparse atomic approximations}},
url = {http://portal.acm.org/citation.cfm?doid=1178723.1178730},
year = {2006}
}
@inproceedings{Rafiei1997,
address = {New York, NY, USA},
author = {Rafiei, Davood and Mendelzon, Alberto},
booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
keywords = {DB},
pages = {13--25},
publisher = {ACM},
title = {{Similarity-based queries for time series data}},
year = {1997}
}
@inproceedings{Maddage2006,
address = {Seattle, WA},
author = {Maddage, N C and Li, H and Kankanhalli, M S},
booktitle = {Proc. Int. ACM SIGIR Conf. Research and Development in Information Retrieval},
file = {::},
pages = {67--74},
title = {{Music Structure based Vector Space Retrieval}},
year = {2006}
}
@article{Krishnan2000,
author = {Krishnan, S and Rangayyan, R M and Bell, G D and Frank, C B},
journal = {IEEE Trans. Biomed. Eng.},
month = jun,
number = {6},
pages = {773--783},
title = {{Adaptive time-frequency analysis of knee joint vibroarthrographic signals for noninvasive screening of articular cartilage pathology}},
volume = {47},
year = {2000}
}
@article{Yaghoobi2009,
author = {Yaghoobi, M and Daudet, L and Davies, M},
journal = {IEEE Trans. Signal Process.},
title = {{Parametric Dictionary Design for Sparse Coding}}
}
@article{Gray1998,
author = {Gray, R M and Neuhoff, D L},
journal = {IEEE Trans. Inf. Theory},
number = {6},
pages = {2325--2383},
title = {{Quantization}},
volume = {44},
year = {1998}
}
@article{Orio2006,
author = {Orio, N},
file = {::},
journal = {Foundations and Trends in Information Retrieval},
number = {1},
title = {{Music Retrieval: A Tutorial and Review}},
volume = {1},
year = {2006}
}
@inproceedings{Gilbert2005,
address = {Adelaide, Australia},
author = {Gilbert, A C and Tropp, J A},
booktitle = {Proc. IEEE Int. Symp. Information Theory},
pages = {1000--1004},
title = {{Applications of sparse approximation in communications}},
year = {2005}
}
@book{Christensen2004,
address = {Boston, MA},
author = {Christensen, O and Christensen, K L},
publisher = {Birkh\"{a}user},
series = {Applied and Numerical Harmonic Analysis},
title = {{Approximation Theory: From Taylor Polynomials to Wavelets}},
year = {2004}
}
@book{Wright1997,
address = {Philadelphia, PA},
author = {Wright, S J},
publisher = {SIAM},
title = {{Primal-dual Interior-point Methods}},
year = {1997}
}
@article{Gabor1947,
author = {Gabor, D},
journal = {Nature},
month = may,
number = {4044},
pages = {591--594},
title = {{Acoustical Quanta and the Theory of Hearing}},
volume = {159},
year = {1947}
}
@inproceedings{Tewfik2006,
author = {Tewfik, A and Alghoniemy, M},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing},
title = {{Polynomial Time and Stack Decoding Solutions to Bounded Error Subset Selection}},
year = {2006}
}
@inproceedings{Gemmeke2009,
address = {Glasgow, Scotland},
author = {Gemmeke, J and ten Bosch, L and L.Boves and Cranen, B},
booktitle = {Proc. EUSIPCO},
pages = {1755--1759},
title = {{Using sparse representations for exemplar based continuous digit recognition}},
year = {2009}
}
@inproceedings{Yi2000,
address = {San Francisco, CA, USA},
author = {Yi, Byoung-Kee and Faloutsos, Christos},
booktitle = {VLDB '00: Proceedings of the 26th International Conference on Very Large Data Bases},
pages = {385--394},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Fast Time Sequence Indexing for Arbitrary Lp Norms}},
year = {2000}
}
@misc{Silver2000,
author = {Silver, R},
howpublished = {United States Patent \#6,137,498},
title = {{Digital Composition of a Mosaic Image}},
year = {2000}
}
@phdthesis{Abdallah2002,
address = {London, U.K.},
author = {Abdallah, S A},
month = jun,
school = {King's College London, Department of Electrical Engineering},
title = {{Towards Music Perception by Redundancy Reduction and Unsupervised Learning in Probabilistic Models}},
year = {2002}
}
@inproceedings{Flexer2010,
author = {Flexer, A and Schnitzer, D and Gasser, M and Pohle, T},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Combining Features Reduces Hubness in Audio Similarity}},
year = {2010}
}
@inproceedings{Logan2000,
address = {Plymouth, MA},
author = {Logan, Beth},
booktitle = {Int. Symp. Music Info. Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Logan/Logan - 2000 - Mel Frequency Cepstral Coefficients for Music Modeling - Int. Symp. Music Info. Retrieval.pdf:pdf},
pages = {1--13},
title = {{Mel Frequency Cepstral Coefficients for Music Modeling}},
year = {2000}
}
@article{Barrington2010,
author = {Barrington, L and Chan, A B and Lanckriet, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barrington, Chan, Lanckriet/Barrington, Chan, Lanckriet - 2010 - Modeling Music as a Dynamic Texture - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {602--612},
title = {{Modeling Music as a Dynamic Texture}},
volume = {18},
year = {2010}
}
@inproceedings{Indyk2000,
address = {Cairo, Egypt},
author = {Indyk, Piotr and Koudas, Nick and Muthukrishnan, S},
booktitle = {Proc. Int. Conf. Very Large Data Bases},
pages = {363--372},
title = {{Identifying Representative Trends in Massive Time Series Data Sets Using Sketches}},
year = {2000}
}
@article{Sturm2009d,
author = {Sturm, B L and Daudet, L},
journal = {Signal Process. (submitted)},
title = {{Audio Similarity in a Multiscale and Sparse Domain}},
year = {2009}
}
@inproceedings{Sturm2006,
address = {Toulouse, France},
author = {Sturm, B L and Gibson, J D},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = {MP},
pages = {456--459},
title = {{Matching Pursuit Decompositions of Non-noisy Speech Signals Using Several Dictionaries}},
volume = {3},
year = {2006}
}
@inproceedings{Gribonval2005,
author = {Gribonval, R and i Ventura, R M Figueras and Vandergheynst, P},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{A simple test to check the optimality of sparse signal approximations}},
year = {2005}
}
@article{Andrle2004,
author = {Andrle, M and Rebollo-Neira, L and Sagianos, E},
journal = {\{IEEE\} Signal Process. Lett.},
number = {9},
pages = {705--708},
title = {{Backward-optimized Orthogonal Matching Pursuit Approach}},
volume = {11},
year = {2004}
}
@inproceedings{Angeles-Yreta2004,
author = {Angeles-Yreta, A and Sol$\backslash$'is-Estrella, H and Landassuri-Moreno, V and Figueroa-Nazuno, J},
booktitle = {Proc. Fifth Mexican Int. Conf. in Computer Science},
keywords = {DB},
title = {{Similarity Search in Seismological Signals}},
year = {2004}
}
@article{PlumbleyOja04-nonnegative,
abstract = {We consider the task of independent component analysis when the independent
sources are known to be nonnegative and well-grounded, so that they
have a nonzero probability density function (pdf) in the region of
zero. We propose the use of a nonnegative principal component analysis
(nonnegative PCA) algorithm, which is a special case of the nonlinear
PCA algorithm, but with a rectification nonlinearity, and we conjecture
that this algorithm will find such nonnegative well-grounded independent
sources, under reasonable initial conditions. While the algorithm
has proved difficult to analyze in the general case, we give some
analytical results that are consistent with this conjecture and some
numerical simulations that illustrate its operation.},
author = {Plumbley, Mark D and Oja, Erkki},
journal = {IEEE Transactions on Neural Networks},
month = jan,
number = {1},
pages = {66--76},
title = {{A ``Nonnegative \{PCA\}'' Algorithm for Independent Component Analysis}},
volume = {15},
year = {2004}
}
@article{Davenport2010,
author = {Davenport, M A and Boufounos, P T and Wakin, M B and Baraniuk, R G},
journal = {IEEE J. Selected Topics in Signal Process.},
number = {2},
pages = {445--460},
title = {{Signal Processing with Compressive Measurements}},
volume = {4},
year = {2010}
}
@inproceedings{Borup2005,
author = {Borup, L and Nielsen, M and Gribonval, R},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing},
pages = {261--264},
title = {{Nonlinear Approximation with Redundant Dictionaries}},
volume = {4},
year = {2005}
}
@inproceedings{Tewfik2006,
author = {Tewfik, A and Alghoniemy, M},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing},
title = {{Polynomial Time and Stack Decoding Solutions to Bounded Error Subset Selection}},
year = {2006}
}
@inproceedings{Amatriain2001,
author = {Amatriain, X and Bonada, J and Loscos, A and Serra, X},
booktitle = {Proc. MOSART Workshop Current Research Directions Computer Music},
title = {{Spectral Modeling for Higher-level Sound Transformations}},
year = {2001}
}
@inproceedings{Yang2001,
author = {Yang, C},
booktitle = {Proc. IEEE Workshop Appl. Signal Process. Audio Acoust.},
title = {{MACS: music audio characteristic sequence indexing for similarity retrieval}},
year = {2001}
}
@article{Elad2006a,
author = {Elad, Michael},
journal = {EURASIP Journal on Advances in Signal Processing},
pages = {1--13},
title = {{Sparse Representations Are Most Likely to Be the Sparsest Possible}},
url = {http://www.hindawi.com/journals/asp/2006/096247.abs.html},
volume = {2006},
year = {2006}
}
@inproceedings{Plumbley2006b,
author = {Plumbley, M D},
booktitle = {Proc. Int. Conf. Independent Component Analysis Blind Source Separation \{(ICA\} 2006), Charleston, \{SC\}, \{USA\}},
pages = {206--213},
title = {{Recovery of Sparse Representations by Polytope Faces Pursuit}},
year = {2006}
}
@book{Taubman2001,
address = {Boston, MA},
author = {Taubman, D and Marcellin, M},
publisher = {Kluwer},
title = {{JPEG2000: Image Compression Fundamentals, Standards and Practice}},
year = {2001}
}
@article{Green1984a,
author = {Green, D N},
journal = {Circuits, Systems, and Signal Processing},
number = {4},
title = {{Generating Nonorthogonal Bases for Signal Representation}},
volume = {3},
year = {1984}
}
@inproceedings{Cho2009,
author = {Cho, Y and Saul, L K},
booktitle = {Proc. Int. Conf. Machine Learning},
title = {{Learning Dictionaries of Stable Autoregressive Models for Audio Scene Analysis}},
year = {2009}
}
@inproceedings{Arias2005,
address = {Istanbul, Turkey},
author = {Arias, J A and Pinquier, J and Andr\'{e}-Obrecht, R},
booktitle = {Proc. European Signal Process. Conf.},
title = {{Evaluation of classification techniques for audio indexing}},
year = {2005}
}
@inproceedings{Rafiei1999,
address = {Washington, DC, USA},
author = {Rafiei, D},
booktitle = {ICDE '99: Proceedings of the 15th International Conference on Data Engineering},
month = mar,
pages = {410--417},
title = {{On Similarity-Based Queries for Time Series Data}},
year = {1999}
}
@inproceedings{Kronland-Martinet2001,
author = {Kronland-Martinet, R and Guillemain, Ph. and Ystad, S},
booktitle = {Workshop on Proceedings of MOSART Current Research Directions in Computer Music Workshop},
title = {{From sound modeling to analysis-synthesis of sounds}},
year = {2001}
}
@book{Gray2008,
address = {New York},
author = {Gray, Robert M},
publisher = {Springer Verlag},
title = {{Probability, Random Processes, and Ergodic Properties}},
year = {2008}
}
@article{Durka2004,
author = {Durka, Piotr J},
journal = {Phys. Rev. E},
month = may,
number = {5},
pages = {51914},
publisher = {American Physical Society},
title = {{Adaptive time-frequency parametrization of epileptic spikes}},
volume = {69},
year = {2004}
}
@article{Lesage2005a,
author = {Lesage, S. and Gribonval, R. and Bimbot, F. and Benaroya, L.},
journal = {Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.},
pages = {293--296},
publisher = {Ieee},
title = {{Learning Unions of Orthonormal Bases with Thresholded Singular Value Decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1416298},
year = {2005}
}
@article{Cohen1997,
author = {Cohen, H},
journal = {Journal of Visual Communication and Image Representation},
month = jun,
number = {2},
pages = {226--234},
title = {{Retrieval and Browsing of Images Using Image Thumbnails}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1047320397903503},
volume = {8},
year = {1997}
}
@inproceedings{Bray2005,
address = {London, U.K.},
author = {Bray, S and Tzanetakis, G},
booktitle = {Int. Conf. Music Info. Retrieval},
pages = {434--437},
title = {{Distributed audio feature extraction for music}},
year = {2005}
}
@incollection{Arfib2002,
author = {Arfib, D and Keiler, F and Z\"{o}lzer, U},
booktitle = {\{DAFx\}: Digital Audio Effects},
editor = {Z\"{o}lzer, U},
publisher = {Wiley},
title = {{Time-frequency Processing}},
year = {2002}
}
@article{Bardeli2009,
author = {Bardeli, R},
journal = {IEEE Trans. Multimedia},
keywords = {DB},
number = {1},
pages = {68--76},
title = {{Similarity Search in Animal Sound Databases}},
volume = {11},
year = {2009}
}
@article{Huggins2007,
author = {Huggins, P S and Zucker, S W},
journal = {IEEE Trans. Signal Process.},
month = jul,
number = {7},
pages = {3760--3772},
title = {{Greedy Basis Pursuit}},
volume = {55},
year = {2007}
}
@misc{Tropp2003b,
author = {Tropp, J and Gilbert, A C and Strauss, M J},
howpublished = {presentation slides},
title = {{An Algorithmic Approach to Sparse Time-frequency Analysis}},
year = {2002}
}
@book{Gray2008b,
address = {New York},
author = {Gray, Robert M},
publisher = {Springer Verlag},
title = {{Entropy and Information Theory}},
year = {2008}
}
@book{Durka2007,
address = {Boston, MA},
author = {Durka, P J},
publisher = {Artech House},
series = {Artech House Engineering in Medicine and Biology Series},
title = {{Matching Pursuit and Unifiction in EEG analysis}},
year = {2007}
}
@article{Makhoul1985a,
author = {Makhoul, J. and Roucos, S. and Gish, H.},
journal = {Proceedings of the IEEE},
number = {11},
pages = {1551--1588},
title = {{Vector quantization in speech coding}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1457608},
volume = {73},
year = {1985}
}
@inproceedings{Wang2001,
address = {Ottawa, Canada},
author = {Wang, Y and Vilermo, M},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {194--202},
title = {{A compressed domain beat detector using \{MP3\} audio bitstreams}},
year = {2001}
}
@inproceedings{Krstulovic2005,
abstract = {In the framework of audio signal analysis, it is desired to obtain
sparse representations that are able to reflect the harmonic structures,
e.g., issued from musical instruments. In this paper, we compare
two approaches which introduce some explicit models of harmonic
features into the Matching Pursuit analysis framework. The
first approach is the Harmonic Matching Pursuit (HMP), where the
harmonic structures are modeled by sets of harmonically related
Gabor atoms which are directly optimized in the analysis loop.
The second approach, called Meta-Molecular Matching Pursuit
(M3P), is based on the a posteriori agglomeration of elementary
features coming from a Short Time Fourier Transform. We discuss
the pros and cons of each method through experiments involving
different audio signals, and conclude on possible approaches for
combining the two methods.},
address = {New Paltz, NY},
author = {Krstulovic, S and Gribonval, R and Leveau, P and Daudet, L},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
keywords = { MP,TFR},
organization = {IEEE},
title = {{A Comparison of Two Extensions of the Matching Pursuit Algorithm for the Harmonic Decomposition of Sounds}},
year = {2005}
}
@article{Bardeli2009,
author = {Bardeli, R},
journal = {IEEE Trans. Multimedia},
keywords = {DB},
number = {1},
pages = {68--76},
title = {{Similarity Search in Animal Sound Databases}},
volume = {11},
year = {2009}
}
@book{Luenberger1984,
address = {Reading, MA},
author = {Luenberger, D G},
edition = {2nd},
publisher = {Addison-Wesley Publishing Company},
title = {{Linear and Nonlinear Programming}},
year = {1984}
}
@incollection{Roads2004,
author = {Roads, C},
booktitle = {Point, Line, Cloud},
publisher = {Asphodel Records},
series = {compact disc and digital video disc},
title = {{Pictor Alpha}},
year = {2004}
}
@inproceedings{Patel2002,
address = {Washington, DC, USA},
author = {Patel, Pranav and Keogh, Eamonn and Lin, Jessica and Lonardi, Stefano},
booktitle = {ICDM '02: Proceedings of the 2002 IEEE International Conference on Data Mining},
keywords = {DB},
pages = {370--377},
publisher = {IEEE Computer Society},
title = {{Mining Motifs in Massive Time Series Databases}},
year = {2002}
}
@article{Ghofrani2009,
author = {Ghofrani, S and McLernon, D C},
journal = {Signal Processing},
number = {8},
pages = {1540--1549},
title = {{Auto-Wigner-Ville distribution via non-adaptive and adaptive signal decomposition}},
volume = {89},
year = {2009}
}
@techreport{Pfeiffer2001,
address = {Australia},
author = {Pfeiffer, S and Vincent, T},
institution = {CSIRO Mathematical and Information Sciences},
keywords = {MIR},
title = {{Formalisation of MPEG-1 compressed domain audio features}},
year = {2001}
}
@article{Yu2009a,
author = {Yu, Y and Oria, K Joe V and M\"{o}rchen, F and Downie, J S and Chen, L},
journal = {Int. J. Semantic Computing},
month = may,
number = {2},
pages = {209--234},
title = {{Multi-Version Music Search Using Acoustic Feature Union and Exact Soft mapping}},
volume = {3},
year = {2009}
}
@inproceedings{Johnson2000,
address = {Istanbul, Turkey},
author = {Johnson, S E and Woodland, P C},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = jun,
pages = {1427--1430},
title = {{A method for direct audio search with applications to indexing and retrieval}},
year = {2000}
}
@article{Vincent2002,
author = {Vincent, P and Bengio, Y},
journal = {Machine Learning},
keywords = {MP},
month = jul,
number = {1},
pages = {165--187},
title = {{Kernel matching pursuit}},
volume = {48},
year = {2002}
}
@inproceedings{Bjornberg2004,
author = {Bjornberg, D B and Agili, S and Morales, A},
booktitle = {Proc. Int. Symp. on Circuits and Systems},
pages = {624--627},
title = {{Decomposition and recognition of a multi-channel audio source using matching pursuit algorithm}},
volume = {5},
year = {2004}
}
@inproceedings{Popivanov2002,
address = {San Jose, CA},
author = {Popivanov, I and Miller, R J},
booktitle = {Proc. IEEE Int. Conf. Data Eng.},
keywords = {DB},
pages = {212--221},
title = {{Similarity Search Over Time-series Data Using Wavelets}},
year = {2002}
}
@electronic{Krstulovic2006b,
author = {Krstulovic, S and Gribonval, R},
title = {{Matching Pursuit Toolkit Usermanual}},
url = {http://mptk.gforge.inria.fr/}
}
@incollection{Arfib2002a,
author = {Arfib, D and Keiler, F and Z\"{o}lzer, U},
booktitle = {\{DAFx\}: Digital Audio Effects},
editor = {Z\"{o}lzer, U},
publisher = {Wiley},
title = {{Source-Filter Processing}},
year = {2002}
}
@article{Kaminsky1995,
author = {Kaminsky, I. and Materka, a.},
journal = {Proceedings of ICNN'95 - International Conference on Neural Networks},
pages = {189--194},
publisher = {Ieee},
title = {{Automatic source identification of monophonic musical instrument sounds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=488091},
year = {1995}
}
@article{Mazhar2009a,
author = {Mazhar, R and Gader, P D and Wilson, J N},
journal = {IEEE Trans. Fuzzy Syst.},
number = {5},
pages = {1175--1188},
title = {{Matching Pursuits Dissimilarity Measure for Shape-based Comparison and Classification of High-dimensional Data}},
volume = {17},
year = {2009}
}
@inproceedings{Adler1996,
address = {Pacific Grove, CA},
author = {Adler, J and Rao, B and Kreutz-Delgado, K},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
pages = {252--257},
title = {{Comparison of basis selection methods}},
volume = {1},
year = {1996}
}
@inproceedings{Rafiei1999,
address = {Washington, DC, USA},
author = {Rafiei, D},
booktitle = {ICDE '99: Proceedings of the 15th International Conference on Data Engineering},
month = mar,
pages = {410--417},
title = {{On Similarity-Based Queries for Time Series Data}},
year = {1999}
}
@article{Cont2004,
author = {Cont, a. and Schwarz, D. and Schnell, N.},
journal = {Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.},
pages = {253--256},
publisher = {Ieee},
title = {{Training Ircam's Score Follower}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1415694},
year = {2004}
}
@article{Rebollo-Neira2007,
author = {Rebollo-Neira, L},
journal = {\{IEEE\} Signal Proc. Letters},
number = {10},
pages = {703--706},
title = {{Oblique Matching Pursuit}},
volume = {14},
year = {2007}
}
@article{Kronland-Martinet1997,
abstract = {Sound modelling is an important part of the analysis--synthesis process since it combines sound processing and algorithmic synthesis within the same formalism. Its aim is to make sound simulators by synthesis methods based on signal models or physical models, the parameters of which are directly extracted from the analysis of natural sounds. In this article the successive steps for making such systems are described. These are numerical synthesis and sound generation methods, analysis of natural sounds, particularly time--frequency and time--scale (wavelet) representations, extraction of pertinent parameters, and the determination of the correspondence between these parameters and those corresponding to the synthesis models. Additive synthesis, nonlinear synthesis, and waveguide synthesis are discussed.},
author = {Kronland-Martinet, R and Guillemain, P and Ystad, S},
journal = {Organised Sound},
keywords = {TFR},
number = {3},
pages = {179--191},
title = {{Modelling of Natural Sounds by Time Frequency and Wavelet Representations}},
volume = {2},
year = {1997}
}
@inproceedings{Leveau2006,
address = {Florence, Italy},
author = {Leveau, P and Daudet, L},
booktitle = {Proc. European Signal Process. Conf.},
title = {{Multi-resolution Partial Tracking with Modified Matching Pursuit}},
year = {2006}
}
@article{Daudet2002,
author = {Daudet, L and Torr\'{e}sani, B},
journal = {Signal Processing},
number = {11},
pages = {1595--1617},
title = {{Hybrid representations for audiophonic signal encoding}},
volume = {82},
year = {2002}
}
@inproceedings{Rao1998,
author = {Rao, B D},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = may,
pages = {1861--1864},
title = {{Signal processing with the sparseness constraint}},
volume = {3},
year = {1998}
}
@inproceedings{McLeran2008,
address = {Berlin, Germany},
author = {McLeran, A and Roads, C and Sturm, B L and Shynk, J J},
booktitle = {Sound and Music Computing Conference},
month = jul,
title = {{Granular methods of sound spatialization using overcomplete representations}},
year = {2008}
}
@inproceedings{Hope1997,
abstract = {The objective of this paper is to investigate and compare the timbre representation potential of the STFT and the Wigner Distribution in the context of timbre morphing. Both Time-Frequency distributions can be interpreted as the energy in time and frequency of a signal. There are however, intrinsic differences between the distributions. The Wigner distribution of multi-component signals exhibits cross terms, while the STFT representation inherently involves smearing in both time and frequency directions. However, the Wigner distribution cross terms can be reduced through the use of an appropriate smoothing window, thereby providing the basis for improved timbre feature analysis and processing.},
author = {Hope, C J and Furlong, D J},
booktitle = {Proc. Symp. of Brasilian Computer Music},
keywords = {TFR},
title = {{Time Frequency Distributions for Timbre Morphing: The Wigner Distribution versus the STFT}},
url = {http://www.ciaranhope.com/paper1.html},
year = {1997}
}
@article{Jensen2009,
author = {Jensen, J H and Christensen, M G and Ellis, D P W and Jensen, S H},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
month = may,
number = {4},
pages = {693--703},
title = {{Quantitative Analysis of a Common Audio Similarity Measure}},
volume = {17},
year = {2009}
}
@phdthesis{Every2006,
author = {Every, M R},
school = {University of the Witwatersrand},
title = {{Separation of Musical Sources and Structure from Single-Channel Polyphonic Recordings}},
year = {2006}
}
@article{Casey2008a,
author = {Casey, M and Veltkamp, R and Goto, M and Leman, M and Rhodes, C and Slaney, M},
file = {::},
journal = {Proc. IEEE},
number = {4},
pages = {668--696},
title = {{Content-based Music Information Retrieval: Current Directions and Future Challenges}},
volume = {96},
year = {2008}
}
@article{Jaggi1998,
author = {Jaggi, S and Karl, W C and Mallat, S and Willsky, A S},
journal = {Applied and Computational Harmonic Analysis},
number = {4},
pages = {428--449},
title = {{High resolution pursuit for feature extraction}},
volume = {5},
year = {1998}
}
@article{Bergstra2006,
address = {Hingham, MA, USA},
author = {Bergstra, James and Casagrande, Norman and Erhan, Dumitru and Eck, Douglas and K\'{e}gl, Bal\'{a}zs},
journal = {Mach. Learn.},
number = {2-3},
pages = {473--484},
publisher = {Kluwer Academic Publishers},
title = {{Aggregate features and ADABOOST for music classification}},
volume = {65},
year = {2006}
}
@phdthesis{Tzanetakis2002b,
abstract = {Digital audio and especially music collections are becoming a major part of the average
computer user experience. Large digital audio collections of sound effects are also used by
the movie and animation industry. Research areas that utilize large audio collections include:
Auditory Display, Bioacoustics, Computer Music, Forensics, and Music Cognition.

In order to develop more sophisticated tools for interacting with large digital audio
collections, research in Computer Audition algorithms and user interfaces is required.
In this work a series of systems for manipulating, retrieving from, and analysing large
collections of audio signals will be described. The foundation of these systems is the design
of new and the application of existing algorithms for automatic audio content analysis. The
results of the analysis are used to build novel 2D and 3D graphical user interfaces for
browsing and interacting with audio signals and collections. The proposed systems are
based on techniques from the fields of Signal Processing, Pattern Recognition, Information
Retrieval, Visualization and Human Computer Interaction. All the proposed algorithms and
interfaces are integrated under MARSYAS, a free software framework designed for rapid
prototyping of computer audition research. In most cases the proposed algorithms have
been evaluated and informed by conducting user studies.

New contributions of this work to the area of Computer Audition include: a general
multifeature audio texture segmentation methodology, feature extraction from mp3
compressed data, automatic beat detection and analysis based on the Discrete Wavelet
Transform and musical genre classification combining timbral, rhythmic and harmonic
features. Novel graphical user interfaces developed in this work are various tools for
browsing and visualizing large audio collections such as the Timbregram, TimbreSpace,
GenreGram, and Enhanced Sound Editor.},
author = {Tzanetakis, G},
keywords = {MIR},
month = jun,
school = {Princeton University},
title = {{Manipulation, Analysis and Retrieval Systems for Audio Signals}},
year = {2002}
}
@article{Kahveci2004,
author = {Kahveci, T and Singh, A K},
journal = {IEEE Trans. Knowledge Data Eng.},
keywords = {DB},
number = {4},
pages = {418--433},
title = {{Optimizing Similarity Search for Arbitrary Length Time Series Queries}},
volume = {16},
year = {2004}
}
@inproceedings{Wang2001,
address = {Ottawa, Canada},
author = {Wang, Y and Vilermo, M},
booktitle = {Proc. ACM Int. Conf. Multimedia},
pages = {194--202},
title = {{A compressed domain beat detector using \{MP3\} audio bitstreams}},
year = {2001}
}
@article{Gray1998,
author = {Gray, R M and Neuhoff, D L},
journal = {IEEE Trans. Inf. Theory},
number = {6},
pages = {2325--2383},
title = {{Quantization}},
volume = {44},
year = {1998}
}
@book{Boyd2004,
address = {Cambridge, UK},
author = {Boyd, S and Vandenberghe, L},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
year = {2004}
}
@article{Christensen2006,
author = {Christensen, M G and Jensen, S H},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {1},
pages = {99--109},
title = {{On Perceptual Distortion Minimization and Nonlinear Least-Squares Frequency Estimation}},
volume = {14},
year = {2006}
}
@article{Lyon2010,
author = {Lyon, R F and Rehn, M and Bengio, S and Walters, T C and Chechik, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lyon et al/Lyon et al. - 2010 - Sound retrieval and ranking using sparse auditory representations - Neural Computation.pdf:pdf},
journal = {Neural Computation},
number = {9},
title = {{Sound retrieval and ranking using sparse auditory representations}},
volume = {22},
year = {2010}
}
@article{Blumensath2006a,
author = {Blumensath, T},
journal = {IEEE Trans. Audio, Speech, Lang. Proc.},
number = {1},
pages = {50--57},
title = {{Sparse and Shift-Invariant Representations of Music}},
volume = {14},
year = {2006}
}
@article{Keogh2000,
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
journal = {Journal of Knowledge and Information Systems},
keywords = {DB},
pages = {263--286},
title = {{Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases}},
volume = {3},
year = {2000}
}
@inproceedings{Tropp2006c,
author = {Tropp, J A},
booktitle = {submitted},
title = {{Random subdictionaries of general dictionaries}},
year = {2006}
}
@article{Davies2006,
author = {Davies, M E and Daudet, L},
journal = {Signal Processing},
number = {3},
pages = {457--470},
title = {{Sparse audio representations using the MCLT}},
volume = {86},
year = {2006}
}
@article{Elad2006,
author = {Elad, M and Aharon, M},
journal = {IEEE Trans. Image Process.},
number = {12},
pages = {3736--3745},
title = {{Image denoising via sparse and redundant representations over learned dictionaries}},
volume = {15},
year = {2006}
}
@inproceedings{Pohle2006,
author = {Pohle, T and Knees, P and Schedl, M and Widmer, G},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
pages = {228--233},
title = {{Independent component analysis for music similarity computation}},
year = {2006}
}
@article{Baraniuk2008,
author = {Baraniuk, R G and Cevher, V and Duarte, M and Hegde, C},
journal = {IEEE Trans. Info. Theory},
title = {{Model-based Compressive Sensing}}
}
@article{Tcheou2007,
author = {Tcheou, M P and Lovisolo, L and da Silva, E A B and Rodrigues, M A M and Diniz, P S R},
journal = {\{IEEE\} Signal Proc. Letters},
keywords = {MP},
number = {2},
pages = {81--84},
title = {{Optimum rate-distortion dictionary selection for compression of atomic decompositions of electric disturbance signals}},
volume = {14},
year = {2007}
}
@inproceedings{Chan1999,
address = {Sydney, Australia},
author = {Chan, K P and Fu, A W.-C.},
booktitle = {Proc. Int. Conf. Data Eng.},
keywords = {DB},
pages = {126--133},
title = {{Efficient Time Series Matching by Wavelets}},
year = {1999}
}
@article{Carabias-Orti2010,
author = {Carabias-Orti, J J and Vera-Candeas, P and Canadas-Quesada, F J and Ruiz-Reyes, N},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {473--486},
title = {{Music Scene-Adaptive Harmonic Dictionary for Unsupervised Note-Event Detection}},
volume = {18},
year = {2010}
}
@inproceedings{Daudet2001,
address = {Toulouse, France},
author = {Daudet, L and Molla, S and Torr\'{e}sani, B},
booktitle = {Proc. 18th Symp. GRETSI'01 Sig. Image Process.},
title = {{Transient detection and encoding using wavelet coefficient trees}},
year = {2001}
}
@article{Kreutz-Delgado2003,
author = {Kreutz-Delgado, K and Murray, J F and Rao, B D and Engan, K and Lee, T and Sejnowski, T J},
journal = {Neural Computation},
number = {2},
pages = {349--396},
title = {{Dictionary Learning Algorithms for Sparse Representation}},
volume = {15},
year = {2003}
}
@article{Durka2001,
author = {Durka, P J and Ircha, D and Blinowska, K J},
journal = {IEEE Trans. Signal Process.},
number = {3},
pages = {507--510},
title = {{Stochastic Time-Frequency Dictionaries for Matching Pursuit}},
volume = {49},
year = {2001}
}
@article{Leveau2008a,
author = {Leveau, Pierre and Vincent, Emmanuel and Richard, Ga\"{E}l and Daudet, Laurent},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
month = jan,
number = {1},
pages = {116--128},
title = {{Instrument-Specific Harmonic Atoms for Mid-Level Music Representation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4383077},
volume = {16},
year = {2008}
}
@article{Jost2006,
author = {Jost, P and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. on Signal Processing},
month = may,
title = {{Tree-Based Pursuit: Algorithm and Properties}},
year = {2006}
}
@inproceedings{Jost2005,
author = {Jost, P and Lesage, S and Vandergheynst, P and Gribonval, R},
booktitle = {???},
month = nov,
title = {{Learning redundant dictionaries with translation invariance property: the MoTIF algorithm}},
year = {2005}
}
@conference{Christensen2007,
address = {Pacific Grove, CA},
author = {Christensen, M G and Jensen, S H},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
title = {{The Cyclic Matching Pursuit and Its Application to Audio Modeling and Coding}},
year = {2007}
}
@article{Allen1977,
author = {Allen, J.},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
month = jun,
number = {3},
pages = {235--238},
title = {{Short term spectral analysis, synthesis, and modification by discrete Fourier transform}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1162950},
volume = {25},
year = {1977}
}
@inproceedings{Duarte2005,
author = {Duarte, M and Wakin, M B and Baraniuk, R G},
booktitle = {Proc. SPARS'05 Conf.},
title = {{Fast Reconstruction of Piecewise Smooth Signals from Incoherent Projections}},
year = {2005}
}
@inproceedings{Wang2000,
author = {Wang, C and Wang, X S},
booktitle = {Proc. Int. Conf. on Scientific and Statistical Database Management},
month = jul,
pages = {69--81},
title = {{Supporting Content-based Searches on Time Series via Approximation}},
year = {2000}
}
@article{Yin2008,
author = {Yin, W and Osher, S and Goldfarb, D and Darbon, J},
journal = {SIAM J. Imaging Sciences},
number = {1},
pages = {143--168},
publisher = {SIAM},
title = {{Bregman Iterative Algorithms for $\backslash$ell\_1-Minimization with Applications to Compressed Sensing}},
volume = {1},
year = {2008}
}
@article{Gardner2006,
author = {Gardner, T J and Magnasco, M O},
journal = {Proc. National Academy of the Sciences},
number = {16},
pages = {6094--6099},
title = {{Sparse time-frequency representations}},
volume = {103},
year = {2006}
}
@inproceedings{Pope2004,
abstract = {Persistent storage and access of sound/music meta-data is an
increasingly relevant topic to the developers of multimedia
software. This paper focuses on the design of music signal analysis
tools and database formats for modern applications. It is partly
tutorial in nature, and partly a discussion of design issues. We
begin with a high-level overview of the dimensions of music
database (MDB) software, and then walk through the common g
feature extraction techniques. A requirements analysis of several
application categories will allow us to carefully determine which
features might be most useful for them. This leads us to suggest
concrete architectural and design criteria, and to close by
introducing several of our recent implemented systems.
The authors believe that much current MDB software suffers due
to ad-hoc design of analysis systems and feature vectors, which
often incorporate only low-level features and are not tuned for the
application at hand. Our goal is to advance the state of the art of
music meta-data extraction and database design by fostering a
better engineering practice in the construction of high-level feature
vectors and analysis engines for music software.
},
address = {Miami, Florida},
author = {Pope, S T and Holm, F and Kouznetsov, A},
booktitle = {Proc. Int. Computer Music Conf.},
keywords = {MIR},
publisher = {ICMA},
title = {{Feature Extraction and Database Design for Music Software}},
year = {2004}
}
@inproceedings{Christensen2006a,
address = {Toulouse, France},
author = {Christensen, M G and Jensen, S H},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {61--64},
title = {{Computationally efficient amplitude modulated sinusoidal audio coding using frequency-domain linear prediction}},
volume = {5},
year = {2006}
}
@article{Tropp2006e,
author = {Tropp, J and Gilbert, a and Strauss, M},
journal = {Signal Processing},
keywords = {greedy algorithms,multiple measurement vectors,orthogonal matching pursuit,simultaneous sparse approximation},
month = mar,
number = {3},
pages = {572--588},
title = {{Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405002227},
volume = {86},
year = {2006}
}
@inproceedings{Sugden2004,
address = {Montreal, Quebec, Canada},
author = {Sugden, P and Canagarajah, N},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = may,
pages = {557--560},
title = {{Underdetermined noisy blind separation using dual matching pursuits}},
year = {2004}
}
@inproceedings{Foote1997,
address = {Dallas, TX},
author = {Foote, J T},
booktitle = {Proc. SPIE Multimedia Storage Archiving Syst.},
pages = {138--147},
title = {{Content-Based Retrieval of Music and Audio}},
year = {1997}
}
@inproceedings{Gemmeke2009,
address = {Glasgow, Scotland},
author = {Gemmeke, J and ten Bosch, L and L.Boves and Cranen, B},
booktitle = {Proc. EUSIPCO},
pages = {1755--1759},
title = {{Using sparse representations for exemplar based continuous digit recognition}},
year = {2009}
}
@inproceedings{Bingham2001,
address = {San Francisco, CA},
author = {Bingham, E and Mannila, H},
booktitle = {Proc. Int. Conf. Knowledge Discovery Data Mining},
pages = {245--250},
title = {{Random projection in dimensionality reduction: Application to image and text data}},
year = {2001}
}
@inproceedings{Weiss2010,
author = {Weiss, R J and Bello, J P},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Identifying Repeated Patterns in Music Using Sparse Convolutive Non-negative Matrix Factorization}},
year = {2010}
}
@article{Yin2008,
author = {Yin, W and Osher, S and Goldfarb, D and Darbon, J},
journal = {SIAM J. Imaging Sciences},
number = {1},
pages = {143--168},
publisher = {SIAM},
title = {{Bregman Iterative Algorithms for $\backslash$ell\_1-Minimization with Applications to Compressed Sensing}},
volume = {1},
year = {2008}
}
@inproceedings{Kawagoe2002,
address = {Washington, DC},
author = {Kawagoe, K and Ueda, T},
booktitle = {Proc. Int. Symp. Temporal Representation, Reasoning},
keywords = {DB},
pages = {86--92},
title = {{A Similarity Search Method of Time Series Data with Combination of Fourier and Wavelet Transforms}},
year = {2002}
}
@inproceedings{Cotton2009,
address = {Mohonk, NY},
author = {Cotton, C and Ellis, D P W},
booktitle = {Proc. IEEE Workshop App. Signal Process. Audio and Acoustics},
pages = {125--128},
title = {{Finding Similar Acoustic Events using Matching Pursuit and Locality-Sensitive Hashing}},
year = {2009}
}
@article{Ghias1995a,
address = {New York, New York, USA},
author = {Ghias, Asif and Logan, Jonathan and Chamberlin, David and Smith, Brian C.},
journal = {Proceedings of the third ACM international conference on Multimedia - MULTIMEDIA '95},
pages = {231--236},
publisher = {ACM Press},
title = {{Query by humming}},
url = {http://portal.acm.org/citation.cfm?doid=217279.215273},
year = {1995}
}
@article{Umapathy2005b,
author = {Umapathy, K and Krishnan, S and Jimaa, S},
journal = {IEEE Trans. Multimedia},
number = {2},
pages = {308--315},
title = {{Multigroup Classification of Audio Signals Using Time-Frequency Parameters}},
volume = {7},
year = {2005}
}
@inproceedings{Lazier2003,
abstract = {The process of creating an audio mosaic consists of the concatenation
of segments of sound. Segments are chosen to correspond
best with a description of a target sound specified by the desired
features of the final mosaic. Current audio mosaicing techniques
take advantage of the description of future target units in order
to make more intelligent decisions when choosing individual segments.
In this paper, we investigate ways to expand mosaicing
techniques in order to use the mosaicing process as an interactive
means of musical expression in real time.

In our system, the user can interactively choose the specification
of the target as well as the source signals from which the
mosaic is composed. These means of control are incorporated into
MoSievius, a framework intended for the rapid implementation of
different interactive mosaicing techniques. Its integral means of
control, the Sound Sieve, provides real-time control over the source
selection process when creating an audio mosaic. We discuss a
number of new real-time effects that can be achieved through use
of the Sound Sieve.},
address = {Queen Mary, University of London},
author = {Lazier, A and Cook, P},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
keywords = {CSS},
title = {{Mosievius: Feature Driven Interactive Audio Mosaicing}},
year = {2003}
}
@inproceedings{Amatriain2002,
abstract = {As audio and music applications tend to a higher level of abstraction and to fill in the gap between the signal processing
world and the end-user we are more and more interested on processing content and not (only) signal. This change in
point of view leads to the redefinition of several ``classical'' concepts, and a new conceptual framework needs to be set
to give support to these new trends. In [2], a model for the transmission of audio content was introduced. The model is
now extended to include the idea of Sound Objects. With these thoughts in mind, examples of design decisions that
have led to the implementation of the CLAM framework are also given.},
address = {Espoo, Finland},
author = {Amatriain, X and Herrera, P},
booktitle = {AES Int. Conf. on Virtual, Synthetic, and Entertainment Audio},
keywords = {MIR},
title = {{Transmitting Audio Content as Sound Objects}},
year = {2002}
}
@article{Aharon2006,
author = {Aharon, M and Elad, M and Bruckstein, A M},
journal = {IEEE Trans. Signal Process.},
keywords = {SA},
month = nov,
number = {11},
pages = {4311--4322},
title = {{K-\{SVD\}: An Algorithm for Designing of Overcomplete Dictionaries for Sparse Representation}},
volume = {54},
year = {2006}
}
@book{Kostelanetz1970,
address = {New York},
editor = {Kostelanetz, R},
publisher = {Praeger},
title = {{John Cage}},
year = {1970}
}
@inproceedings{Rauber2002,
address = {Paris, France},
author = {Rauber, A and Pampalk, E and Merkl, D},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Using Psycho-Acoustic Models and Self-Organizing Maps To Create Hierarchical Structuring of Music by Sound Similarity}},
year = {2002}
}
@article{Escoda2009,
author = {Escoda, O D and Monaci, G and {Figueras i Ventura}, R M and Vandergheynst, P and Bierlaire, M},
journal = {IEEE Trans. Image Process.},
number = {8},
pages = {1703--1716},
title = {{Geometric Video Approximation Using Weighted Matching Pursuit}},
volume = {18},
year = {2009}
}
@book{Davis1989,
author = {Davis, H F},
publisher = {Dover},
title = {{Fourier Series and Orthogonal Functions}},
year = {1989}
}
@inproceedings{Sturm2007,
address = {Pacific Grove, CA},
author = {Sturm, B L and Shynk, J J and Daudet, L},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
pages = {1126--1129},
title = {{A Short-Term Measure of Dark Energy in Sparse Atomic Estimations}},
year = {2007}
}
@inproceedings{Grosse2007,
author = {Grosse, R and Raina, R and Kwong, H and Ng, A Y},
booktitle = {Proc. UAI},
title = {{Shift-invariant Sparse Coding for Audio Classification}},
year = {2007}
}
@article{Childers1977,
author = {Childers, D.G. and Skinner, D.P. and Kemerait, R.C.},
journal = {Proceedings of the IEEE},
number = {10},
pages = {1428--1443},
title = {{The cepstrum: A guide to processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1455016},
volume = {65},
year = {1977}
}
@book{Roads2001,
address = {Cambridge, MA},
author = {Roads, C},
publisher = {MIT Press},
title = {{Microsound}},
year = {2001}
}
@inproceedings{Aharon2005a,
author = {Aharon, M and Elad, M and Bruckstein, A.\~{}M.},
booktitle = {Wavelets XI. Edited by Papadakis, Manos; Laine, Andrew F.; Unser, Michael A. Proceedings of the SPIE, Volume 5914, pp. 327-339 (2005).},
editor = {Bodmann, B.\~{}G. and Papadakis, M and Kouri, D.\~{}J. and Gertz, S.\~{}D. and Cherukuri, P and Vela, D and Gladish, G.\~{}W. and Cody, D.\~{}D. and Abodashy, I and Conyers, J.\~{}L. and Willerson, J.\~{}T. and Casscells, S.\~{}W.},
keywords = {SA},
pages = {327--339},
title = {{K-SVD and its non-negative variant for dictionary design}},
year = {2005}
}
@inproceedings{Sturm2008d,
address = {Belfast, Ireland},
author = {Sturm, B L and Roads, C and McLeran, A and Shynk, J J},
booktitle = {Proc. Int. Computer Music Conf.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm et al/Sturm et al. - 2009 - Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods - J. New Music Researc.pdf:pdf},
title = {{Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods}},
year = {2008}
}
@article{Sturm2010,
author = {Sturm, B L and Shynk, J J},
journal = {IEEE Trans. Acoustics, Speech, Lang. Process.},
number = {3},
pages = {461--472},
title = {{Sparse Approximation and the Pursuit of Meaningful Signal Models with Interference Adaptation}},
volume = {18},
year = {2010}
}
@article{Gray1998a,
author = {Gray, R.M. and Neuhoff, D.L.},
journal = {IEEE Transactions on Information Theory},
number = {6},
pages = {2325--2383},
title = {{Quantization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=720541},
volume = {44},
year = {1998}
}
@inproceedings{Pohle2006,
author = {Pohle, T and Knees, P and Schedl, M and Widmer, G},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
pages = {228--233},
title = {{Independent component analysis for music similarity computation}},
year = {2006}
}
@article{Plumbley2002,
abstract = {In this article, we give an overview of a range of approaches to the
analysis and separation of musical audio. In particular, we consider
the problems of automatic music transcription and audio source separation,
which are of particular interest to our group. Monophonic music transcription,
where a single note is present at one time, can be tackled using
an autocorrelation-based method. For polyphonic music transcription,
with several notes at any time, other approaches can be used, such
as a blackboard model or a multiple-cause/sparse coding method. The
latter is based on ideas and methods related to independent component
analysis (ICA), a method for sound source separation.},
author = {Plumbley, M D and Abdallah, S A and Bello, J P and Davies, M E and Monti, G and Sandler, M B},
journal = {Cybernetics and Systems},
number = {6},
pages = {603--627},
title = {{Automatic Music Transcription and Audio Source Separation}},
volume = {33},
year = {2002}
}
@article{Kimura2008,
author = {Kimura, A and Kashino, K and Kurozumi, T and Murase, H},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {2},
pages = {396--407},
title = {{A quick search method for audio signals based on piecewise linear representation of feature trajectories}},
volume = {16},
year = {2008}
}
@article{Atal2006,
author = {Atal, B S},
file = {::},
journal = {IEEE Signal Processing Mag.},
month = mar,
pages = {154--158},
title = {{The History of Linear Prediction}},
year = {2006}
}
@inproceedings{Tzanetakis2002c,
abstract = {The majority of existing work in music information retrieval
for audio signals has followed the content-based
query-by-example paradigm. In this paradigm a musical
piece is used as a query and the result is a list of
other musical pieces ranked by their content similarity.
In this paper we describe algorithms and graphical
user interfaces that enable novel alternative ways for
querying and browsing large audio collections. Computer
audition algorithms are used to extract content
information from audio signals. This automatically extracted
information is used to configure the graphical
user interfaces and to genereate new query audio signals
for browsing and retrieval.},
author = {Tzanetakis, G and Ermolinskyi, A and Cook, P},
booktitle = {Proc. Int. Computer Music Conf.},
keywords = {MIR},
title = {{Beyond the Query-By-Example Paradigm: New Query Interfaces for Music Information Retrieval}},
year = {2002}
}
@inproceedings{Typke2005,
address = {London, U.K.},
author = {Typke, R and Wiering, F and Veltkamp, R C},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{A Survey of Music Information Retrieval Systems}},
year = {2005}
}
@inproceedings{Struzik1999,
address = {London, UK},
author = {Struzik, Zbigniew R and Siebes, Arno},
booktitle = {PKDD '99: Proceedings of the Third European Conference on Principles of Data Mining and Knowledge Discovery},
pages = {12--22},
publisher = {Springer-Verlag},
title = {{The Haar Wavelet Transform in the Time Series Similarity Paradigm}},
year = {1999}
}
@article{Tzanetakis2002a,
author = {Tzanetakis, G. and Cook, P.},
journal = {IEEE Transactions on Speech and Audio Processing},
month = jul,
number = {5},
pages = {293--302},
title = {{Musical genre classification of audio signals}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1021072},
volume = {10},
year = {2002}
}
@inproceedings{Tran2009,
address = {Taipei, Taiwan},
author = {Tran, H D and Li, H},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {177--180},
title = {{Sound event classification based on feature integration, recursive feature elimination and structured classification}},
year = {2009}
}
@article{Vincent2007b,
author = {Vincent, E and Plumbley, M D},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
month = may,
number = {4},
pages = {1273--1282},
title = {{Low Bitrate Object Coding of Musical Audio Using \{B\}ayesian Harmonic Models}},
volume = {15},
year = {2007}
}
@inproceedings{Andrle2006,
address = {Toulouse, France},
author = {Andrle, M and Rebollo-Neira, L},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing},
pages = {313--316},
title = {{Improvement of Orthogonal Matching Pursuit Strategies by Backward and Forward Movements}},
volume = {3},
year = {2006}
}
@article{Lee2002,
author = {Lee, Jonghyun and Chun, Joohwan and Science, Computer and Korea, South},
journal = {Conference Record of the Thirty-Sixth Asilomar Conference on Signals, Systems and Computers, 2002.},
pages = {196--199},
publisher = {Ieee},
title = {{Musical instruments recognition using hidden Markov model}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1197175},
year = {2002}
}
@article{Yu1996,
author = {Yu, P.S. and Castelli, V.},
journal = {Proceedings of the Twelfth International Conference on Data Engineering},
pages = {546--553},
publisher = {IEEE Comput. Soc. Press},
title = {{HierarchyScan: a hierarchical similarity search algorithm for databases of long sequences}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=492205},
year = {1996}
}
@article{Yu2008,
author = {Yu, Jun and Chen, Xiaoou and Yang, Deshun},
journal = {2008 International Conference on Audio, Language and Image Processing},
month = jul,
pages = {1145--1152},
publisher = {Ieee},
title = {{Chinese folk musical instruments recognition in polyphonic music}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4590024},
year = {2008}
}
@incollection{Vera-Candeas2005,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Rosa-Zurera, M and Cuevas-Mart$\backslash$'inez, J C and L\'{o}pez-Ferreras, F},
booktitle = {IEE Proc. -- Visual Image Signal Processing},
pages = {571--578},
publisher = {Springer Berlin},
title = {{Adaptive Signal Models for Wide-Band Speech and Audio Compression}},
volume = {3523/2005},
year = {2005}
}
@inproceedings{Ke2005,
author = {Ke, Y and Hoiem, D and Sukthankar, R},
booktitle = {Proc. IEEE Conf. Computer Vision Pattern Recog.},
keywords = { TFR,MIR},
month = jun,
pages = {597--604},
title = {{Computer Vision for Music Identification}},
year = {2005}
}
@inproceedings{Pinquier2004,
address = {Sherbrooke, Canada},
author = {Pinquier, J and Arias, J and Andr\'{e}-Obrecht, R},
booktitle = {Proc. Multidisciplinary Image, Video, and Audio Retrieval and Mining},
title = {{Audio Classification by Search of Primary Components}},
year = {2004}
}
@article{Tcheou2007,
author = {Tcheou, M P and Lovisolo, L and da Silva, E A B and Rodrigues, M A M and Diniz, P S R},
journal = {\{IEEE\} Signal Proc. Letters},
keywords = {MP},
number = {2},
pages = {81--84},
title = {{Optimum rate-distortion dictionary selection for compression of atomic decompositions of electric disturbance signals}},
volume = {14},
year = {2007}
}
@article{Overholt2009,
author = {Overholt, D and Thompson, J and Putnam, L and Bell, B and Kleban, J and Sturm, B and Kuchera-Morin, J},
journal = {Computer Music J.},
number = {4},
pages = {69--82},
title = {{A Multimodal System for Gesture Recognition in Interactive Music Performance}},
volume = {33},
year = {2009}
}
@phdthesis{Dorfler2002,
author = {D$\backslash$:orfler, M},
school = {Universit$\backslash$:\{a\}t Wien},
title = {{Gabor Analysis for a Class of Signals called Music}},
year = {2002}
}
@inproceedings{Arias2005,
address = {Istanbul, Turkey},
author = {Arias, J A and Pinquier, J and Andr\'{e}-Obrecht, R},
booktitle = {Proc. European Signal Process. Conf.},
title = {{Evaluation of classification techniques for audio indexing}},
year = {2005}
}
@inproceedings{Ogle2007,
address = {Honolulu, Hawaii},
author = {Ogle, J and Ellis, D P W},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {233--236},
title = {{Fingerprinting to Identify Repeated Sound Events in Long-Duration Personal Audio Recordings}},
volume = {1},
year = {2007}
}
@inproceedings{Mailhe2009,
address = {St. Malo, France},
author = {Mailh\'{e}, B and Gribonval, R and Bimbot, F and Vandergheynst, P},
booktitle = {Proc. Signal Process. Adaptive Sparse Structured Representations},
title = {{Local orthogonal greedy pursuits for scalable sparse approximation of large signals with shift-invariant dictionaries}},
year = {2009}
}
@inproceedings{Lesage2006a,
address = {Charleston, South Carolina},
author = {Lesage, S and Krstulovic, S and Gribonval, R},
booktitle = {Proc. Int. Conf. Independent Component Analysis Blind Source Separation},
pages = {633--640},
title = {{Underdetermined source separation: Comparison of two approaches based on sparse decompositions}},
year = {2006}
}
@inproceedings{Mallat1993a,
author = {Mallat, S and Zhang, Z},
booktitle = {Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing},
pages = {241--244},
title = {{Adaptive Time-Frequency Transform}},
year = {1993}
}
@article{Potter1945,
author = {Potter, Ralph K},
journal = {Science},
number = {2654},
pages = {463--470},
title = {{Visible Patterns of Sound}},
volume = {102},
year = {1945}
}
@inproceedings{Sturm2004b,
address = {Miami, FL},
author = {Sturm, B L and Gibson, J},
booktitle = {Proc. Int. Computer Music Conf.},
title = {{SIGNALS AND SYSTEMS USING MATLAB: AN EFFECTIVE APPLICATION FOR EXPLORING AND TEACHING MEDIA SIGNAL PROCESSING}},
year = {2004}
}
@article{Hans2001,
author = {Hans, M and Schafer, R W},
journal = {IEEE Sig. Process. Mag.},
month = jul,
number = {4},
pages = {21--32},
title = {{Lossless compression of digital audio}},
volume = {18},
year = {2001}
}
@inproceedings{Wu2008,
address = {Chengdu, China},
author = {Wu, W and Hu, J},
booktitle = {Proc. IEEE Conf. Cybernetics and Intelligent Syst.},
pages = {388--393},
title = {{Similarity Search Based on Random Projection for High Frequency Time Series}},
year = {2008}
}
@article{Ebrahimi-Moghadam2007,
abstract = {Matching pursuit (MP) is a multiresolution signal analysis method and can be used to render a selected region of an image with a specific quality. A novel, scalable, and progressive MP-based region-of-interest image-coding scheme is presented. The method is capable of providing a trade off between rate, distortion, and complexity. The method also provides an interactive way of information refinement for regions of an image with higher receiver's priority. By selecting a proper subset of the huge initial MP dictionary, using the method described in this paper, the complexity burden of MP analysis can be adapted to the computational power of the image encoder.},
author = {Ebrahimi-Moghadam, Abbas and Shirani, Shahram},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Data Compression,Data Compression: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Numerical Analysis, Computer-Assisted,Signal Processing, Computer-Assisted},
month = feb,
number = {2},
pages = {406--15},
title = {{Matching pursuit-based region-of-interest image coding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17269634},
volume = {16},
year = {2007}
}
@inproceedings{Melih1997,
author = {Melih, K and Gonzalez, R and Ogubona, P},
booktitle = {Proc. IEEE Tencon},
title = {{An Audio Representation for Content Based Retrieval}},
year = {1997}
}
@book{Rabiner1993,
address = {Upper Saddle River, New Jersey},
author = {Rabiner, L R and Juang, B H},
publisher = {Prentice Hall},
title = {{Fundamentals of Speech Recognition}},
year = {1993}
}
@article{Erkucuk2003,
author = {Erkucuk, S. and Krishnan, S. and Zeytinoglu, M.},
journal = {2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)},
pages = {513--516},
publisher = {Ieee},
title = {{Robust audio watermarking using a chirp based technique}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1221666},
year = {2003}
}
@article{Bruckstein2008,
author = {Bruckstein, Alfred M. and Elad, Michael and Zibulevsky, Michael},
journal = {2008 IEEE International Conference on Acoustics, Speech and Signal Processing},
month = mar,
pages = {5145--5148},
publisher = {Ieee},
title = {{On the uniqueness of non-negative sparse \& redundant representations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4518817},
year = {2008}
}
@article{Gunasekaran2008a,
author = {Gunasekaran, S. and Revathy, K.},
journal = {2008 International Conference on Audio, Language and Image Processing},
month = jul,
pages = {257--261},
publisher = {Ieee},
title = {{Fractal dimension analysis of audio signals for Indian musical instrument recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4590238},
year = {2008}
}
@inproceedings{Arias2005,
address = {Istanbul, Turkey},
author = {Arias, J A and Pinquier, J and Andr\'{e}-Obrecht, R},
booktitle = {Proc. European Signal Process. Conf.},
title = {{Evaluation of classification techniques for audio indexing}},
year = {2005}
}
@article{Tibshirani1996,
author = {Tibshirani, R},
journal = {J. Royal Statist. Soc. B},
number = {1},
pages = {267--288},
title = {{Regression shrinkage and selection via the lasso}},
volume = {58},
year = {1996}
}
@article{Vera-Candeas2006,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Cuevas-Mart$\backslash$'inez, J C and Rosa-Zurera, M and L\'{o}pez-Ferreras, F},
journal = {IEE Proc.-Visual Image Signal Process.},
number = {4},
pages = {431--435},
title = {{Sinusoidal modeling using perceptual matching pursuits in the Bark scale for parametric audio coding}},
volume = {153},
year = {2006}
}
@inproceedings{Plumbley2007b,
author = {Plumbley, M D},
booktitle = {Proc. Int. Conf. Independent Component Analysis Signal Separation (ICA 2007)},
pages = {406--413},
title = {{Dictionary Learning for L1-Exact Sparse Coding}},
year = {2007}
}
@inproceedings{Tropp2006d,
author = {Tropp, J A and Wakin, M B and Duarte, M F and Baron, D and Baraniuk, R G},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing},
pages = {872--875},
title = {{Random Filters for Compressive Sampling and Reconstruction}},
volume = {3},
year = {2006}
}
@inproceedings{Gemmeke2010,
address = {Dallas, TX, USA},
author = {Gemmeke, J and Virtanen, T},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = mar,
title = {{Noise robust exemplar-based connected digit recognition}},
year = {2010}
}
@electronic{Bacry2006,
author = {Bacry, E},
title = {{LastWave Software and Documentation}},
url = {http://www.cmap.polytechnique.fr/~bacry/LastWave/}
}
@article{Amatriain2003,
abstract = {Content processing is a vast and growing field that integrates different approaches borrowed from the signal processing, 
information retrieval and machine learning disciplines. In this article we deal with a particular type of content pro- 
cessing: the so-called content-based transformations. We will not focus on any particular application but rather try to give 
an overview of different techniques and conceptual implications. We first describe the transformation process itself, 
including the main model schemes that are commonly used, which lead to the establishment of the formal basis for a 
definition of content-based transformations. Then we take a quick look at a general spectral based analysis/synthesis 
approach to process audio signals and how to extract features that can be used in the content-based transformation context. Using this analysis/synthesis approach we give some examples on how content-based transformations can be applied to modify the basic perceptual axis of a sound and how we can even combine different basic effects in order to perform more meaningful transformations. We finish by going a step further in the abstraction ladder and present transformations that are related to musical (and thus symbolic) properties rather than to those of the sound or the signal itself.},
author = {Amatriain, X and Bonada, J and Loscos, \`{A} and Arcos, J L and Verfaille, V},
journal = {J. New Music Research},
keywords = { synth,MIR},
number = {1},
pages = {95--114},
title = {{Content-Based Transformations}},
url = {http://www.iua.upf.es/mtg/publications/jnmr32-xamat.pdf},
volume = {32},
year = {2003}
}
@inproceedings{Goodwin1997b,
address = {New Paltz, New York},
author = {Goodwin, M M and Vetterli, M},
booktitle = {Proc. IEEE Workshop Appl. Signal Process. Audio Acoust.},
keywords = {MP},
pages = {4--8},
title = {{Atomic decompositions of audio signals}},
year = {1997}
}
@article{Casey2001,
author = {Casey, M},
journal = {IEEE Trans. Circuits Systems Video Tech.},
month = jun,
number = {6},
pages = {737--747},
title = {{\{MPEG\}-7 Sound-Recognition Tools}},
volume = {11},
year = {2001}
}
@inproceedings{Lesage2005,
address = {Philadelphia, PA},
author = {Lesage, S and Gribonval, R and Bimbot, F and Benaroya, L},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {293--296},
title = {{Learning Unions of Orthonormal Bases with Thresholded Singular Value Decomposition}},
volume = {5},
year = {2005}
}
@inproceedings{Zils2001,
abstract = {This work addresses the issue of retrieving efficiently sound 
samples in large databases, in the context of digital music 
composition. We propose a sequence generation mechanism called 
musical mosaicing, which enables to generate automatically 
sequences of sound samples by specifying only high-level 
properties of the sequence to generate. The properties of the 
sequence specified by the user are translated automatically into 
constraints holding on descriptors of the samples. The system we 
propose is able to scale up on databases containing more than 
100.000 samples, using a local search method based on constraint 
solving. In this paper, we describe the method for retrieving and 
sequencing audio samples, and illustrate it with rhythmic and 
melodic musical sequences. },
address = {Limerick, Ireland},
author = {Zils, A and Pachet, F},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zils, Pachet/Zils, Pachet - 2001 - Musical Mosaicing - Proc. COST G-6 Conf. Digital Audio Effects.pdf:pdf},
keywords = {CSS},
title = {{Musical Mosaicing}},
year = {2001}
}
@article{Essid2006,
author = {Essid, S. and Richard, G. and David, B.},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = jan,
number = {1},
pages = {68--80},
title = {{Instrument recognition in polyphonic music based on automatic taxonomies}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1561265},
volume = {14},
year = {2006}
}
@incollection{Ellis1998,
address = {Mahwah, NJ},
author = {Ellis, D P W and Rosenthal, D F},
booktitle = {Computational Auditory Scene Analysis},
editor = {Rosenthal, D F and Okuno, H G},
pages = {257--272},
publisher = {Lawrence Erlbaum Associates},
title = {{Mid-level representations for computational auditory scene analysis}},
year = {1998}
}
@article{Cohen1989a,
author = {Cohen, L.},
journal = {Proceedings of the IEEE},
month = jul,
number = {7},
pages = {941--981},
title = {{Time-frequency distributions-a review}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=30749},
volume = {77},
year = {1989}
}
@inproceedings{Mailhe2009b,
address = {Taipei, Taiwan},
author = {Mailh\'{e}, B and Gribonval, R and Bimbot, F and Vandergheynst, P},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {3445--3448},
title = {{A low complexity orthogonal matching pursuit for sparse signal approximation with shift-invariant dictionaries}},
year = {2009}
}
@article{Aucouturier2007,
author = {Aucouturier, J-.J. and Defreville, B and Pachet, F},
journal = {J. Acoust. Soc. America},
number = {2},
pages = {881--891},
title = {{The bag of frames approach to audio pattern recognition: A sufficient model for urban soundscapes but not for polyphonic music}},
volume = {122},
year = {2007}
}
@article{Hlawatsch1994,
author = {Hlawatsch, F and Kozek, W},
journal = {IEEE Trans. Signal Processing},
number = {12},
pages = {3321--3334},
title = {{Time-Frequency Projection Filters and Time-Frequency Signal Expansions}},
volume = {42},
year = {1994}
}
@article{Fanelli,
author = {a.M. Fanelli and Caponetti, L. and Castellano, G. and Buscicchio, C.a.},
journal = {Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, 2004.},
keywords = {audio features extraction,content-based audio classification,recurrent neural networks},
pages = {361--364},
publisher = {Ieee},
title = {{Content-based recognition of musical instruments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1433794},
volume = {2}
}
@techreport{Blumensath2007,
address = {Edinburgh, Scotland, U.K.},
author = {Blumensath, T and Davies, M E},
institution = {University of Edinburgh},
title = {{On the difference between orthogonal matching pursuit and orthogonal least squares}},
year = {2007}
}
@inproceedings{Sturm2004c,
address = {Naples, Italy},
author = {Sturm, B L},
booktitle = {Proc. 7th Int. Conf. Digital Audio Effects},
title = {{MATConcat: An Application for Exploring Concatenative Sound Synthesis Using MATLAB}},
year = {2004}
}
@article{Rao1999,
author = {Rao, B D and Kreutz-Delgado, K},
journal = {IEEE Trans. Signal Process.},
number = {1},
pages = {187--200},
title = {{An affine scaling methodology for best basis selection}},
volume = {47},
year = {1999}
}
@inproceedings{Pece2000,
address = {Spain},
author = {Pece, A and Petkov, N},
booktitle = {Proc. 15th Int. Conf. on Pattern Recognition},
pages = {215--218},
title = {{Fast atomic decomposition by the inhibition method}},
year = {2000}
}
@inproceedings{Daudet2004,
address = {Naples, Italy},
author = {Daudet, L},
booktitle = {Proc. Int. Conf. Digital Audio Effects},
keywords = {MP},
pages = {22--26},
title = {{Sparse and Structured Decompositions of Audio Signals in Overcomplete Spaces}},
volume = {14},
year = {2004}
}
@inproceedings{Monro2006,
address = {Kos, Greece},
author = {Monro, D M},
booktitle = {Proc. IEEE Int. Symp. Circuits Syst.},
month = may,
pages = {2985--2988},
title = {{Basis picking for matching pursuits audio compression}},
volume = {4},
year = {2006}
}
@article{Neff1997,
author = {Neff, R and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {1},
pages = {158--170},
title = {{Very low bit-rate video coding based on matching pursuits}},
volume = {7},
year = {1997}
}
@article{Kahveci2004,
author = {Kahveci, T and Singh, A K},
journal = {IEEE Trans. Knowledge Data Eng.},
keywords = {DB},
number = {4},
pages = {418--433},
title = {{Optimizing Similarity Search for Arbitrary Length Time Series Queries}},
volume = {16},
year = {2004}
}
@article{Schmid2004,
author = {Schmid-Saugeon, P and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
month = jun,
number = {6},
pages = {880--886},
title = {{Dictionary design for matching pursuit and application to motion-compensated video coding}},
volume = {14},
year = {2004}
}
@article{Joder2009,
author = {Joder, C and Essid, S and Richard, G},
journal = {IEEE Trans. Acoustics, Speech, Signal Process.},
keywords = {MIR},
number = {1},
pages = {174--184},
title = {{Temporal Integration for Audio Classification with Application to Musical Instrument Classification}},
volume = {17},
year = {2009}
}
@article{Brown1999,
abstract = {Cepstral coefficients based on a constant Q transform have been calculated for 28 short (1-2 s) oboe sounds and 52 short saxophone sounds. These were used as features in a pattern analysis to determine for each of these sounds comprising the test set whether it belongs to the oboe or to the sax class. The training set consisted of longer sounds of 1 min or more for each of the instruments. A k-means algorithm was used to calculate clusters for the training data, and Gaussian probability density functions were formed from the mean and variance of each of the clusters. Each member of the test set was then analyzed to determine the probability that it belonged to each of the two classes; and a Bayes decision rule was invoked to assign it to one of the classes. Results have been extremely good and are compared to a human perception experiment identifying a subset of these same sounds.},
author = {Brown, J C},
journal = {The Journal of the Acoustical Society of America},
keywords = {Algorithms,Auditory Perception,Auditory Perception: physiology,Automatic Data Processing,Computers,Databases as Topic,Humans,Models, Theoretical,Music,Normal Distribution,Sound},
month = mar,
number = {3},
pages = {1933--41},
title = {{Computer identification of musical instruments using pattern recognition with cepstral coefficients as features.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10089614},
volume = {105},
year = {1999}
}
@inproceedings{Gribonval2003a,
author = {Gribonval, R and Nielsen, M},
booktitle = {Proc. SPIE "Wavelets: Applications in Signal and Image Processing"},
pages = {216--227},
title = {{Approximation with Highly Redundant Dictionaries}},
volume = {5207},
year = {2003}
}
@incollection{Rodet1980,
address = {New York},
author = {Rodet, X},
booktitle = {Spoken Language Generation and Understanding},
editor = {Simon, J C},
pages = {429--441},
publisher = {D. Reidel},
title = {{Time-domain formant-wave function synthesis}},
year = {1980}
}
@inproceedings{Divekar2009,
author = {Divekar, A and Ersoy, O},
booktitle = {Proc. Asilomar Conf. Signals, Systems, and Computers},
title = {{Compact Storage of Correlated Data for Content Based Retrieval}},
year = {2009}
}
@techreport{Adiloglu2009,
address = {Berlin},
author = {Adiloglu, K and Anni\'{e}s, R and Purwins, H and Obermayer, K},
institution = {NI-BIT},
month = jul,
title = {{Visualisation and Measurement Assisted Design}},
year = {2009}
}
@article{Popovici2005,
author = {Popovici, V and Bengio, S and Thiran, J},
journal = {Pattern Recognition},
keywords = {kernel methods,matching pursuit,radial basis,sparse approximation,support vector machines},
month = dec,
number = {12},
pages = {2385--2390},
title = {{Kernel matching pursuit for large datasets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320305000932},
volume = {38},
year = {2005}
}
@incollection{Dodero1998,
address = {Amsterdam, The Netherlands},
author = {Dodero, G and Gianuzzi, V and Moscati, M and Corvi, M},
booktitle = {Proc. HPCN'98 Conference},
pages = {458--466},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A scalable parallel algorithm for matching pursuit signal decomposition}},
year = {1998}
}
@inproceedings{Kashino1999,
author = {Kashino, K and Smith, G and Murase, H},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = {DB},
pages = {2993--2996},
title = {{Time-series active search for quick retrieval of audio and video}},
volume = {6},
year = {1999}
}
@article{Davis1994a,
author = {Davis, G and Mallat, S and Zhang, Z},
journal = {Optical Engineering},
keywords = {MP},
month = jul,
number = {7},
pages = {2183--2191},
title = {{Adaptive time-frequency decompositions with Matching Pursuit}},
volume = {33},
year = {1994}
}
@inproceedings{Bergeaud1995,
address = {Detroit, MI},
author = {Bergeaud, F and Mallat, S},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = may,
pages = {53--56},
title = {{Matching pursuit of images}},
year = {1995}
}
@book{Cremer1982,
author = {Cremer, L and M\"{u}ller, H},
publisher = {Applied \{S\}cience \{P\}ublishers \{L\}td},
title = {{Principles and \{A\}pplications of \{R\}oom \{A\}coustics}},
volume = {1},
year = {1982}
}
@article{Plumbley03-algorithms,
author = {Plumbley, M D},
journal = {IEEE Transactions on Neural Networks},
month = may,
number = {3},
pages = {534--543},
title = {{Algorithms for Nonnegative Independent Component Analysis}},
volume = {14},
year = {2003}
}
@inproceedings{Jost2005,
author = {Jost, P and Lesage, S and Vandergheynst, P and Gribonval, R},
booktitle = {???},
month = nov,
title = {{Learning redundant dictionaries with translation invariance property: the MoTIF algorithm}},
year = {2005}
}
@inproceedings{Tropp2006c,
author = {Tropp, J A},
booktitle = {submitted},
title = {{Random subdictionaries of general dictionaries}},
year = {2006}
}
@article{Elad2006,
author = {Elad, M and Aharon, M},
journal = {IEEE Trans. Image Process.},
number = {12},
pages = {3736--3745},
title = {{Image denoising via sparse and redundant representations over learned dictionaries}},
volume = {15},
year = {2006}
}
@article{Yaghoobi2009a,
author = {Yaghoobi, Mehrdad and Blumensath, Thomas and Davies, Mike E.},
journal = {IEEE Transactions on Signal Processing},
month = jun,
number = {6},
pages = {2178--2191},
title = {{Dictionary Learning for Sparse Approximations With the Majorization Method}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4787130},
volume = {57},
year = {2009}
}
@article{Kuster2008,
author = {Kuster, M},
journal = {J. Acoust. Soc. of Am.},
number = {2},
pages = {982--993},
title = {{Reliability of estimating the room volume from a single room impulse response}},
volume = {124},
year = {2008}
}
@inproceedings{Foote1997,
address = {Dallas, TX},
author = {Foote, J T},
booktitle = {Proc. SPIE Multimedia Storage Archiving Syst.},
pages = {138--147},
title = {{Content-Based Retrieval of Music and Audio}},
year = {1997}
}
@inproceedings{Jost2006a,
address = {Toulouse, France},
author = {Jost, P and Vandergheynst, P and Lesage, S and Gribonval, R},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {857--860},
title = {{\{MoTIF\}: an Efficient Algorithm for Learning Translation Invariant Dictionaries}},
volume = {5},
year = {2006}
}
@book{Roads2001,
address = {Cambridge, MA},
author = {Roads, C},
publisher = {MIT Press},
title = {{Microsound}},
year = {2001}
}
@inproceedings{Maddage2006,
address = {Seattle, WA},
author = {Maddage, N C and Li, H and Kankanhalli, M S},
booktitle = {Proc. Int. ACM SIGIR Conf. Research and Development in Information Retrieval},
file = {::},
pages = {67--74},
title = {{Music Structure based Vector Space Retrieval}},
year = {2006}
}
@inproceedings{Jehan2005,
address = {New Paltz, New York},
author = {Jehan, T},
booktitle = {Proc. IEEE Workshop Appl. Signal Process. Audio Acoust.},
pages = {311--314},
title = {{Hierarchical Multi-class self similarities}},
year = {2005}
}
@inproceedings{Parker2007,
address = {Corvallis, OR},
author = {Parker, C and Fern, A and Tadepalli, P},
booktitle = {Proc. Int. Conf. Machine Learning},
title = {{Learning for efficient retrieval of structured data with noisy queries}},
year = {2007}
}
@inproceedings{FiVentura2008,
address = {Las Vegas, NV},
author = {{Figueras i Ventura}, R M and Rajashekar, U and Wang, Z and Simoncelli, E P},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {877--880},
title = {{Contextually Adaptive Signal Representation Using Conditional Principal Component Analysis}},
year = {2008}
}
@article{Wright2009,
author = {Wright, J and Ma, Y and Mairal, J and Sapiro, G and Huang, T and Yan, S},
journal = {Proc. IEEE},
title = {{Sparse Representation for Computer Vision and Pattern Recognition}},
year = {2009}
}
@article{Blumensath2006a,
author = {Blumensath, T},
journal = {IEEE Trans. Audio, Speech, Lang. Proc.},
number = {1},
pages = {50--57},
title = {{Sparse and Shift-Invariant Representations of Music}},
volume = {14},
year = {2006}
}
@article{Hlawatsch1994,
author = {Hlawatsch, F and Kozek, W},
journal = {IEEE Trans. Signal Processing},
number = {12},
pages = {3321--3334},
title = {{Time-Frequency Projection Filters and Time-Frequency Signal Expansions}},
volume = {42},
year = {1994}
}
@inproceedings{Sturm2008c,
address = {Paris, France},
author = {Sturm, B L and Shynk, J J and McLeran, A and Roads, C and Daudet, L},
booktitle = {Proc. Acoustics},
month = jun,
pages = {5775--5780},
title = {{A comparison of molecular approaches for generating sparse and structured multiresolution representations of audio and music signals}},
year = {2008}
}
@article{FiguerasiVentura2006,
abstract = {New breakthroughs in image coding possibly lie in signal decomposition through nonseparable basis functions that can efficiently capture edge characteristics, present in natural images. The work proposed in this paper provides an adaptive way of representing images as a sum of two-dimensional features. It presents a low bit-rate image coding method based on a matching pursuit (MP) expansion, over a dictionary built on anisotropic refinement and rotation of contour-like atoms. This method is shown to provide, at low bit rates, results comparable to the state of the art in image compression, represented here by JPEG2000 and SPIHT, with generally a better visual quality in the MP scheme. The coding artifacts are less annoying than the ringing introduced by wavelets at very low bit rate, due to the smoothing performed by the basis functions used in the MP algorithm. In addition to good compression performances at low bit rates, the new coder has the advantage of producing highly flexible streams. They can easily be decoded at any spatial resolution, different from the original image, and the bitstream can be truncated at any point to match diverse bandwidth requirements. The spatial adaptivity is shown to be more flexible and less complex than transcoding operations generally applied to state of the art codec bitstreams. Due to both its ability for capturing the most important parts of multidimensional signals, and a flexible stream structure, the image coder proposed in this paper represents an interesting solution for low to medium rate image coding in visual communication applications.},
author = {{Figueras i Ventura}, Rosa M and Vandergheynst, Pierre and Frossard, Pascal},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Computer Communication Networks,Computer Graphics,Data Compression,Data Compression: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Signal Processing, Computer-Assisted},
month = mar,
number = {3},
pages = {726--39},
title = {{Low-rate and flexible image coding with redundant representations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16519358},
volume = {15},
year = {2006}
}
@article{Mitra1971,
author = {Mitra, S K},
journal = {SIAM J. Applied Math.},
number = {2},
pages = {195--198},
title = {{On the Probability Distribution of the Sum of Uniformly Distributed Random Variables}},
volume = {20},
year = {1971}
}
@article{Lewicki2002,
author = {Lewicki, M S},
file = {:Users/pkmital/Documents/Mendeley Desktop/Lewicki/Lewicki - 2002 - Efficient Coding of Natural Sounds - Nature Neuroscience.pdf:pdf},
journal = {Nature Neuroscience},
number = {4},
pages = {356--363},
title = {{Efficient Coding of Natural Sounds}},
volume = {5},
year = {2002}
}
@inproceedings{Jost2008,
address = {Lausanne, Switzerland},
author = {Jost, P and Vandergheynst, P},
booktitle = {Proc. European Signal Process. Conf.},
keywords = { DB,SA},
pages = {1--5},
title = {{On finding approximate nearest neighbours in a set of compressible signals}},
year = {2008}
}
@misc{Tropp2003,
author = {Tropp, J and Gilbert, A C and Strauss, M J and Muthukrishnan, S},
howpublished = {presentation slides},
title = {{Improved Sparse Approximation over Quasi-Incoherent Dictionaries}},
year = {2003}
}
@book{Gray2008,
address = {New York},
author = {Gray, Robert M},
publisher = {Springer Verlag},
title = {{Probability, Random Processes, and Ergodic Properties}},
year = {2008}
}
@article{Daudet2006,
author = {Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
keywords = {MP},
number = {5},
pages = {1808--1816},
title = {{Sparse and Structured Decompositions of Signals with the Molecular Matching Pursuit}},
volume = {14},
year = {2006}
}
@article{Baraniuk2008,
author = {Baraniuk, R G and Cevher, V and Duarte, M and Hegde, C},
journal = {IEEE Trans. Info. Theory},
title = {{Model-based Compressive Sensing}}
}
@article{Eronen,
author = {Eronen, a.},
journal = {Seventh International Symposium on Signal Processing and Its Applications, 2003. Proceedings.},
pages = {133--136},
publisher = {Ieee},
title = {{Musical instrument recognition using ica-based transform of features and discriminatively trained HMMS}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1224833}
}
@article{Stowell2009b,
author = {Stowell, D and Plumbley, M D},
journal = {IEEE Signal Process. Lett.},
pages = {537--540},
title = {{Fast multidimensional entropy estimation by k-d partitioning}},
volume = {16},
year = {2009}
}
@article{Daudet2004a,
author = {Daudet, L. and Sandler, M.},
journal = {IEEE Transactions on Speech and Audio Processing},
month = may,
number = {3},
pages = {302--312},
title = {{MDCT Analysis of Sinusoids: Exact Results and Applications to Coding Artifacts Reduction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1288156},
volume = {12},
year = {2004}
}
@inproceedings{Jensen2002,
author = {Jensen, J and Heusdens, R},
booktitle = {Proc. European Signal Processing Conf.},
title = {{A Comparison of Sinusoidal Model Variants for Speech and Audio Representation}},
year = {2002}
}
@article{Gribonval2001b,
author = {Gribonval, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gribonval/Gribonval - 2001 - Fast matching pursuit with a multiscale dictionary of Gaussian chirps - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
month = may,
number = {5},
pages = {994--1001},
title = {{Fast matching pursuit with a multiscale dictionary of Gaussian chirps}},
volume = {49},
year = {2001}
}
@article{Green1984,
author = {Green, D N and Bass, S C},
journal = {IEEE Trans. Circuits and Systems},
number = {6},
pages = {518--534},
title = {{Representing Periodic Waveforms with Nonorthogonal Basis Functions}},
volume = {CAS-31},
year = {1984}
}
@article{Aucouturier2006,
author = {Aucouturier, J.-J. and Pachet, F},
journal = {J. New Music Research},
keywords = { CSS,synth},
number = {1},
title = {{Jamming With Plunderphonics: Interactive Contatenative Synthesis of Music}},
volume = {35},
year = {2006}
}
@inproceedings{Zils2001,
abstract = {This work addresses the issue of retrieving efficiently sound 
samples in large databases, in the context of digital music 
composition. We propose a sequence generation mechanism called 
musical mosaicing, which enables to generate automatically 
sequences of sound samples by specifying only high-level 
properties of the sequence to generate. The properties of the 
sequence specified by the user are translated automatically into 
constraints holding on descriptors of the samples. The system we 
propose is able to scale up on databases containing more than 
100.000 samples, using a local search method based on constraint 
solving. In this paper, we describe the method for retrieving and 
sequencing audio samples, and illustrate it with rhythmic and 
melodic musical sequences. },
address = {Limerick, Ireland},
author = {Zils, A and Pachet, F},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
file = {:Users/pkmital/Documents/Mendeley Desktop/Zils, Pachet/Zils, Pachet - 2001 - Musical Mosaicing - Proc. COST G-6 Conf. Digital Audio Effects.pdf:pdf},
keywords = {CSS},
title = {{Musical Mosaicing}},
year = {2001}
}
@article{Keogh2000,
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
journal = {Journal of Knowledge and Information Systems},
keywords = {DB},
pages = {263--286},
title = {{Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases}},
volume = {3},
year = {2000}
}
@article{Dunn2000,
author = {Dunn, Robert B. and Reynolds, Douglas a. and Quatieri, Thomas F.},
journal = {Digital Signal Processing},
keywords = {clustering,detection,gaus-,multispeaker,sian mixture model,speaker recognition,tracking},
month = jan,
number = {1-3},
pages = {93--112},
title = {{Approaches to Speaker Detection and Tracking in Conversational Speech☆☆☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1051200499903597},
volume = {10},
year = {2000}
}
@inproceedings{Agrawal1993,
address = {Chicago, IL},
author = {Agrawal, R and Faloutsos, C and Swami, A},
booktitle = {Proc. Int. Conf. Foundations Data Org. Algo.},
keywords = {DB},
pages = {69--84},
title = {{Efficient Similarity Search in Sequence Databases}},
year = {1993}
}
@inproceedings{Sturm2003,
address = {New London, CT},
author = {Sturm, B L},
booktitle = {Proc. 9th Biennial Arts Tech. Symp.},
title = {{'Music from the Ocean': A Cross-Discipline Multimedia CD}},
year = {2003}
}
@article{Atal2006,
author = {Atal, B S},
file = {::},
journal = {IEEE Signal Processing Mag.},
month = mar,
pages = {154--158},
title = {{The History of Linear Prediction}},
year = {2006}
}
@book{Roads2001,
address = {Cambridge, MA},
author = {Roads, C},
publisher = {MIT Press},
title = {{Microsound}},
year = {2001}
}
@article{Bimbot2004,
author = {Bimbot, F and Bonastre, J.-F. and Fredouille, C and Gravier, G and Magrin-Chagnolleau, I and Meignier, S and Merlin, T and Ortega-Garc$\backslash$'ia, J and Petrovska-Delacr\'{e}taz, D and Reynolds, D A},
journal = {EURASIP Journal on Applied Signal Processing},
number = {4},
pages = {430--451},
title = {{A Tutorial on Text-Independent Speaker Verification}},
volume = {2004},
year = {2004}
}
@phdthesis{Escoda2005,
address = {Lausanne, Switzerland},
author = {Escoda, \`{O} D},
month = jun,
school = {\'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne},
title = {{Toward Sparse and Geometry Adapted Video Approximations}},
year = {2005}
}
@inproceedings{Pati1993,
address = {Pacific Grove, CA},
author = {Pati, Y and Rezaiifar, R and Krishnaprasad, P},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pati, Rezaiifar, Krishnaprasad/Pati, Rezaiifar, Krishnaprasad - 1993 - Orthogonal Matching Pursuit Recursive Function Approximation with Applications to Wavelet Decomp.pdf:pdf},
keywords = {MP},
pages = {40--44},
title = {{Orthogonal Matching Pursuit: Recursive Function Approximation with Applications to Wavelet Decomposition}},
volume = {1},
year = {1993}
}
@inproceedings{Scholler2010,
address = {Firenze, Italy},
author = {Scholler, S and Purwins, H},
booktitle = {Proc. Int. Workshop Machine Learning Music ACM Multimedia},
title = {{Sparse Coding for Drum Sound Classification and its Use as a Similarity Measure}},
year = {2010}
}
@article{Neff1997,
author = {Neff, R and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {1},
pages = {158--170},
title = {{Very low bit-rate video coding based on matching pursuits}},
volume = {7},
year = {1997}
}
@article{Yu2008a,
author = {Yu, Y and Joe, K and Downie, J S},
journal = {IEICE Trans. Information and Systems},
month = jun,
number = {6},
pages = {1730--1739},
title = {{Efficient Query-by-Content Audio Retrieval by Locality Sensitive Hashing and Partial Sequence Comparison}},
volume = {E91-D},
year = {2008}
}
@article{Aucouturier2006,
author = {Aucouturier, Jean-Julien and Pachet, Fran\c{c}ois},
journal = {Journal of New Music Research},
month = mar,
number = {1},
pages = {35--50},
title = {{Jamming with Plunderphonics: Interactive concatenative synthesis of music}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09298210600696790\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {35},
year = {2006}
}
@inproceedings{Cancelli2006,
address = {San Jose, CA},
author = {Cancelli, G and Barni, M and Menegaz, G},
booktitle = {Proc. SPIE Int. Soc. Opt. Eng.},
pages = {1--4},
title = {{\{MP\}steg: Hiding a message in the Matching Pursuit domain}},
volume = {6072},
year = {2006}
}
@article{Ravelli2008,
author = {Ravelli, E and Richard, G and Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Proc.},
number = {8},
pages = {1361--1372},
title = {{Union of \{MDCT\} Bases for Audio Coding}},
volume = {16},
year = {2008}
}
@phdthesis{Abdallah2002,
address = {London, U.K.},
author = {Abdallah, S A},
month = jun,
school = {King's College London, Department of Electrical Engineering},
title = {{Towards Music Perception by Redundancy Reduction and Unsupervised Learning in Probabilistic Models}},
year = {2002}
}
@inproceedings{Young1997,
author = {Young, S J and Brown, M G and Foote, J T and Jones, G J F and {Sparck Jones}, K},
booktitle = {Acoustics, Speech, and Signal Processing, 1997. ICASSP-97., 1997 IEEE International Conference on},
month = apr,
pages = {199--202},
title = {{Acoustic indexing for multimedia retrieval and browsing}},
volume = {1},
year = {1997}
}
@article{Rahmoune2006,
author = {Rahmoune, A and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {2},
pages = {178--190},
title = {{Flexible Motion-Adaptive Video Coding With Redundant Expansions}},
volume = {16},
year = {2006}
}
@article{Gribonval2006b,
author = {Gribonval, R and i Ventura, R M Figueras and Vandergheynst, P},
journal = {Signal Process.},
number = {3},
pages = {496--510},
title = {{A simple test to check the optimality of a sparse signal approximation}},
volume = {86},
year = {2006}
}
@article{Vincent2008,
author = {Vincent, E and Plumbley, M D},
journal = {Neurocomputing},
pages = {79--87},
title = {{Efficient \{B\}ayesian inference for harmonic models via adaptive posterior factorization}},
volume = {72},
year = {2008}
}
@inproceedings{Muller2005b,
address = {New Paltz, NY},
author = {M\"{u}ller, M and Kurth, F and Clausen, M},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
pages = {275--278},
title = {{Chroma-based statistical audio features for audio matching}},
year = {2005}
}
@article{Christensen2006b,
author = {Christensen, M G and van de Par, S},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
month = jul,
number = {4},
pages = {1340--1351},
title = {{Efficient Parametric Coding of Transients}},
volume = {14},
year = {2006}
}
@inproceedings{Levine1999,
address = {Phoenix},
author = {Levine, S and {Smith III}, J O},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {985--988},
title = {{A switched parametric and transform audio coder}},
volume = {2},
year = {1999}
}
@inproceedings{Giacobello2008,
address = {Brisbane, Australia},
author = {Giacobello, D and Christensen, M G and Dahl, J and Jensen, S H and Moonen, M},
booktitle = {Proc. Interspeech},
pages = {1353--1356},
title = {{Sparse Linear Predictors for Speech Processing}},
year = {2008}
}
@article{Etemoglu2003,
author = {Etemo$\backslash$uglu, \c{C} \"{O} and Cuperman, V},
journal = {IEEE Trans. Speech Audio Process.},
number = {5},
pages = {413--424},
title = {{Matching pursuits sinusoidal speech coding}},
volume = {11},
year = {2003}
}
@article{Loughran2008,
author = {Loughran, Roisin and Walker, Jacqueline and O'Neill, Michael and O'Farrell, Marion},
journal = {2008 International Conference on Audio, Language and Image Processing},
month = jul,
pages = {643--648},
publisher = {Ieee},
title = {{Musical instrument identification using Principal Component Analysis and Multi-Layered Perceptrons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4590236},
year = {2008}
}
@techreport{Pfeiffer2001,
address = {Australia},
author = {Pfeiffer, S and Vincent, T},
institution = {CSIRO Mathematical and Information Sciences},
keywords = {MIR},
title = {{Formalisation of MPEG-1 compressed domain audio features}},
year = {2001}
}
@article{Plumbley2009,
author = {Plumbley, M D and Blumensath, T and Daudet, L and Gribonval, R and Davies., M E},
journal = {Proc. IEEE},
title = {{Sparse representations in audio and music: from coding to source separation.}},
year = {2009}
}
@inproceedings{Rath2008,
address = {Lausanne, Switzerland},
author = {Rath, G and Guillemot, C},
booktitle = {Proc. European Signal Process. Conf.},
title = {{A complementary matching pursuit algorithm for sparse approximation}},
year = {2008}
}
@article{Berger1994,
author = {Berger, J and Coifman, R and Goldberg, M},
journal = {J. Audio Eng. Soc.},
number = {10},
pages = {808--818},
title = {{Removing Noise from Music Using Local Trigonometric Bases and Wavelet Packets}},
volume = {42},
year = {1994}
}
@article{Durka2003,
author = {Durka, P J},
journal = {BioMedical Engineering OnLine},
number = {1},
title = {{From wavelets to adaptive approximations: \{T\}ime-frequency parameterization of \{EEG\}}},
volume = {2},
year = {2003}
}
@inproceedings{Vos1999,
address = {Florence, Italy},
author = {Vos, K and Vafin, R and Heusdens, R and Kleijn., W.\~{}B.},
booktitle = {Proc. Audio Eng. Soc. Int. Conf. High Quality Audio Coding},
pages = {244--250},
title = {{High-Quality consistent analysis-synthesis in sinusoidal coding}},
year = {1999}
}
@article{Umapathy2005a,
author = {Umapathy, K and Krishnan, S and Parsa, V and Jamieson, D G},
journal = {IEEE Trans. Biomedical Eng.},
number = {3},
pages = {421--430},
title = {{Discrimination of Pathological Voices Using a Time-Frequency Approach}},
volume = {52},
year = {2005}
}
@inproceedings{Plumbley2006b,
author = {Plumbley, M D},
booktitle = {Proc. Int. Conf. Independent Component Analysis Blind Source Separation \{(ICA\} 2006), Charleston, \{SC\}, \{USA\}},
pages = {206--213},
title = {{Recovery of Sparse Representations by Polytope Faces Pursuit}},
year = {2006}
}
@article{Durka2005a,
author = {Durka, P J and Matysiak, A and Montes, E M and Sosa, P V and Blinowska, K J},
journal = {Journal of Neuroscience Methods},
number = {1},
pages = {49--59},
title = {{Multichannel matching pursuit and EEG inverse solutions}},
volume = {148},
year = {2005}
}
@inproceedings{Mohimani2008,
address = {Las Vegas, NV},
author = {Mohimani, G H and Babaie-Zadeh, M and Jutten, C},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {3881--3884},
title = {{Complex-valued sparse representation based on smoothed $\backslash$ell\_0 norm}},
year = {2008}
}
@article{Chen1995b,
author = {Chen, S and Wigger, J},
journal = {IEEE Trans. Signal Process.},
month = jul,
number = {7},
pages = {1713--1715},
title = {{Fast orthogonal least-squares algorithm for efficient subset model selection}},
volume = {43},
year = {1995}
}
@article{Donoho2006,
author = {Donoho, D L and Tsaig, Y and Drori, I and Starck, J-L.},
journal = {IEEE Trans. on Info. Theory},
title = {{Sparse Solution of Underdetermined Linear Equations by Stagewise Orthogonal Matching Pursuit}}
}
@article{Pham2006,
author = {Pham, T V and Smeulders, A},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {4},
pages = {555--567},
title = {{Sparse Representation for Coarse and Fine Object Recognition}},
volume = {28},
year = {2006}
}
@inproceedings{Lobo2003,
address = {Hong Kong, China},
author = {Lobo, A P and Loizou, P C},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {820--823},
title = {{Voiced/unvoiced speech discrimination in noise using \{G\}abor atomic decomposition}},
year = {2003}
}
@article{Blumensath2008,
author = {Blumensath, T and Davies, M E},
journal = {IEEE Trans. Signal Process.},
month = jun,
number = {6},
pages = {2370--2382},
title = {{Gradient Pursuits}},
volume = {56},
year = {2008}
}
@inproceedings{Wang2006,
author = {Wang, B and Bangham, J A},
booktitle = {Proc. IEEE Int. Conf. Video Signal Based Surveillance (AVSS'06)},
keywords = {MP},
title = {{Shape Retrieval Using Matching Pursuit Decomposition}},
year = {2006}
}
@article{Escoda2006,
author = {Escoda, O D and Granai, L and Vandergheynst, P},
journal = {IEEE Trans. Signal Processing},
number = {9},
pages = {3468--3482},
title = {{On the use of a priori information for sparse signal approximations}},
volume = {54},
year = {2006}
}
@article{Mazhar2009a,
author = {Mazhar, R and Gader, P D and Wilson, J N},
journal = {IEEE Trans. Fuzzy Syst.},
number = {5},
pages = {1175--1188},
title = {{Matching Pursuits Dissimilarity Measure for Shape-based Comparison and Classification of High-dimensional Data}},
volume = {17},
year = {2009}
}
@inproceedings{Verma1999,
address = {Phoenix, Arizona},
author = {Verma, T S and Meng, T H Y},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {981--984},
title = {{Sinusoidal modeling using frame-based perceptually weighted matching pursuits}},
volume = {2},
year = {1999}
}
@conference{Cho2007,
address = {New Paltz, NY},
author = {Cho, N and Shiu, Y and Kuo, C.-C. J},
booktitle = {Proc. IEEE Workshop Appl. Signal Process. Audio Acoust.},
pages = {287--290},
title = {{Audio Source Separation with Matching Pursuit and Content-Adaptive Dictionaries (\{MP-CAD\})}},
year = {2007}
}
@article{Sturm2005a,
author = {Sturm, B L},
journal = {Leonardo J. Arts Sciences},
number = {2},
pages = {143--149},
title = {{Pulse of an Ocean: Sonification of Ocean Buoy Data}},
volume = {38},
year = {2005}
}
@article{Cancelli2006a,
author = {Cancelli, G.},
journal = {Proceedings of SPIE},
keywords = {MPSteg: hiding a message in the matching pursuit d},
pages = {60720P--60720P--9},
publisher = {Spie},
title = {{MPsteg: hiding a message in the Matching Pursuit domain}},
url = {http://link.aip.org/link/PSISDG/v6072/i1/p60720P/s1\&Agg=doi},
volume = {6072},
year = {2006}
}
@article{Vetterli2001,
author = {Vetterli, M},
journal = {IEEE Sig. Process. Mag.},
number = {9},
pages = {59--73},
title = {{Wavelets, approximation, and compression}},
year = {2001}
}
@book{Mallat2009,
address = {Amsterdam, The Netherlands},
author = {Mallat, S},
edition = {3rd},
keywords = { TFR, wavelets,MP},
publisher = {Academic Press, Elsevier},
title = {{A Wavelet Tour of Signal Processing: The Sparse Way}},
year = {2009}
}
@phdthesis{Pampalk2006,
abstract = {
This thesis aims at developing techniques which support users in accessing and discovering music. The main part consists of two chapters.

Chapter 2 gives an introduction to computational models of music similarity. The combination of different approaches is optimized and the largest evaluation of music similarity measures published to date is presented. The best combination performs significantly better than the baseline approach in most of the evaluation categories. A particular effort is made to avoid overfitting. To cross-check the results from the evaluation based on genre classification a listening test is conducted. The test confirms that genre-based evaluations are suitable to efficiently evaluate large parameter spaces. Chapter 2 ends with recommendations on the use of similarity measures.

Chapter 3 describes three applications of such similarity measures. The first application demonstrates how music collections can be organized and visualized so that users can control the aspect of similarity they are interested in. The second application demonstrates how music collections can be organized hierarchically into overlapping groups at the artist level. These groups are summarized using words from web pages associated with the respective artists. The third application demonstrates how playlists can be generated which require minimum user input.
},
address = {Vienna, Austria},
author = {Pampalk, Elias},
keywords = {MIR},
month = mar,
school = {Vienna University of Technology},
title = {{Computational Models of Music Similarity and their Application in Music Information Retrieval}},
year = {2006}
}
@inproceedings{Sturm2002,
address = {Kyoto, Japan},
author = {Sturm, B L},
booktitle = {Proc. Int. Conf. Auditory Display},
month = jul,
title = {{Surf Music: Sonification of Ocean Buoy Spectral Data}},
year = {2002}
}
@inproceedings{Weinstein2007,
address = {Honolulu, Hawaii},
author = {Weinstein, E and Moreno, P},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{Music Identification with Weighted Finite-State Transducers}},
year = {2007}
}
@inproceedings{Pece2000,
address = {Spain},
author = {Pece, A and Petkov, N},
booktitle = {Proc. 15th Int. Conf. on Pattern Recognition},
pages = {215--218},
title = {{Fast atomic decomposition by the inhibition method}},
year = {2000}
}
@inproceedings{Duarte2005,
author = {Duarte, M and Wakin, M B and Baraniuk, R G},
booktitle = {Proc. SPARS'05 Conf.},
title = {{Fast Reconstruction of Piecewise Smooth Signals from Incoherent Projections}},
year = {2005}
}
@inproceedings{Zayyani2009,
address = {Taipei, Taiwan},
author = {Zayyani, H and Babaie-Zadeh, M and Jutten, C},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {1549--1552},
title = {{Bayesian pursuit algorithm for sparse representation}},
year = {2009}
}
@article{Polack1992,
author = {Polack, J.-D.},
journal = {Acta Acustica},
pages = {257--272},
title = {{Modifying Chambers to play Billiards: the Foundations of Reverberation Theory}},
volume = {76},
year = {1992}
}
@inproceedings{Krishnan1997a,
address = {Chicago, IL},
author = {Krishnan, S and Rangayyan, R M and Bell, G D and Frank, C B},
booktitle = {Proc. Int. Conf. Eng. in Medicine and Biology},
pages = {1309--1312},
publisher = {IEEE},
title = {{Time-frequency signal feature extraction and screening of knee joint vibroarthrographic signals using the matching pursuit method}},
volume = {3},
year = {1997}
}
@article{Linde1986,
author = {Linde, Y and Buzo, A and Gray, R M},
journal = {IEEE Trans. on Communications},
number = {1},
pages = {84--95},
title = {{An Algorithm for Vector Quantizer Design}},
volume = {28},
year = {1980}
}
@incollection{Vera-Candeas2005,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Rosa-Zurera, M and Cuevas-Mart$\backslash$'inez, J C and L\'{o}pez-Ferreras, F},
booktitle = {IEE Proc. -- Visual Image Signal Processing},
pages = {571--578},
publisher = {Springer Berlin},
title = {{Adaptive Signal Models for Wide-Band Speech and Audio Compression}},
volume = {3523/2005},
year = {2005}
}
@article{Durka2003a,
abstract = {This paper presents a summary of time-frequency analysis of the electrical activity of the brain (EEG). It covers in details two major steps: introduction of wavelets and adaptive approximations. Presented studies include time-frequency solutions to several standard research and clinical problems, encountered in analysis of evoked potentials, sleep EEG, epileptic activities, ERD/ERS and pharmaco-EEG. Based upon these results we conclude that the matching pursuit algorithm provides a unified parametrization of EEG, applicable in a variety of experimental and clinical setups. This conclusion is followed by a brief discussion of the current state of the mathematical and algorithmical aspects of adaptive time-frequency approximations of signals.},
author = {Durka, Piotr J},
journal = {Biomedical engineering online},
keywords = {Algorithms,Electroencephalography,Electroencephalography: standards,Evoked Potentials,Humans,Image Interpretation, Computer-Assisted,Image Processing, Computer-Assisted,Midazolam,Midazolam: pharmacology,Models, Theoretical,Pyridines,Pyridines: pharmacology,Signal Processing, Computer-Assisted,Sleep,Sleep: drug effects,Sleep: physiology,Stochastic Processes,Time Factors},
month = jan,
pages = {1},
title = {{From wavelets to adaptive approximations: time-frequency parametrization of EEG.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=149437\&tool=pmcentrez\&rendertype=abstract},
volume = {2},
year = {2003}
}
@article{Jafari2008,
author = {Jafari, M G and Vincent, E and Abdallah, S A and Plumbley, M D and Davies, M E},
journal = {Neurocomputing},
pages = {2087--2097},
title = {{An adaptive stereo basis method for convolutive blind audio source separation}},
volume = {71},
year = {2008}
}
@article{Christensen2006b,
author = {Christensen, M G and van de Par, S},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
month = jul,
number = {4},
pages = {1340--1351},
title = {{Efficient Parametric Coding of Transients}},
volume = {14},
year = {2006}
}
@techreport{Peeters2004,
author = {Peeters, G},
institution = {IRCAM},
title = {{A large set of audio features for sound description (similarity and classification) in the CUIDADO project}},
year = {2004}
}
@article{Portnoff1976a,
author = {Portnoff, M.},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
month = jun,
number = {3},
pages = {243--248},
title = {{Implementation of the digital phase vocoder using the fast Fourier transform}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1162810},
volume = {24},
year = {1976}
}
@inproceedings{Virtanen2007,
author = {Virtanen, R and Hel\'{e}n, M},
booktitle = {Proc. WASPAA},
title = {{PROBABILISTIC MODEL BASED SIMILARITY MEASURES FOR AUDIO QUERY-BY-EXAMPLE}},
year = {2007}
}
@inproceedings{Schwarz2003,
abstract = {Concatenative data-driven synthesis methods are gaining more interest
for musical sound synthesis and effects. They are based on
a large database of sounds and a unit selection algorithm which
finds the units that match best a given sequence of target units.
We describe related work and our CATERPILLAR synthesis system,
focusing on recent new developments: the advantages of the
addition of a relational SQL database, work on segmentation by
alignment, the reformulation and extension of the unit selection
algorithm using a constraint resolution approach, and new applications
for musical and speech synthesis.},
address = {London, U.K.},
author = {Schwarz, D},
booktitle = {Proc. COST G-6 Conf. Digital Audio Effects},
keywords = {CSS},
title = {{The \{C\}aterpillar \{S\}ystem for Data-Driven Concatenative Sound Synthesis}},
year = {2003}
}
@phdthesis{Tropp2004a,
author = {Tropp, J},
month = aug,
school = {The University of Texas at Austin},
title = {{Topics in Sparse Approximation}},
year = {2004}
}
@inproceedings{Haitsma2002,
author = {Haitsma, J and Kalker, T},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
pages = {107--115},
title = {{A Highly Robust Audio Fingerprinting System}},
year = {2002}
}
@phdthesis{Blumensath2006,
author = {Blumensath, T},
school = {Queen Mary, University of London},
title = {{Bayesian Modelling of Music: Algorithmic Advances and Experimental Studies of Shift-Invariant Sparse Coding}},
year = {2006}
}
@inproceedings{Aharon2005a,
author = {Aharon, M and Elad, M and Bruckstein, A.\~{}M.},
booktitle = {Wavelets XI. Edited by Papadakis, Manos; Laine, Andrew F.; Unser, Michael A. Proceedings of the SPIE, Volume 5914, pp. 327-339 (2005).},
editor = {Bodmann, B.\~{}G. and Papadakis, M and Kouri, D.\~{}J. and Gertz, S.\~{}D. and Cherukuri, P and Vela, D and Gladish, G.\~{}W. and Cody, D.\~{}D. and Abodashy, I and Conyers, J.\~{}L. and Willerson, J.\~{}T. and Casscells, S.\~{}W.},
keywords = {SA},
pages = {327--339},
title = {{K-SVD and its non-negative variant for dictionary design}},
year = {2005}
}
@book{Tolstov1976,
author = {Tolstov, Georgi P},
publisher = {Dover},
title = {{Fourier Series}},
year = {1976}
}
@inproceedings{Firouzi2008,
address = {Las Vegas, NV},
author = {Firouzi, H and Babaie-Zadeh, M and Sahebi, A G and Jutten, C},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {1921--1924},
title = {{A first step to convolutive sparse representation}},
year = {2008}
}
@inproceedings{Aucouturier2002,
address = {Paris, France},
author = {Aucouturier, J-.J. and Pachet, F},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Music Similarity Measures: What's The Use?}},
year = {2002}
}
@inproceedings{Firouzi2008,
address = {Las Vegas, NV},
author = {Firouzi, H and Babaie-Zadeh, M and Sahebi, A G and Jutten, C},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {1921--1924},
title = {{A first step to convolutive sparse representation}},
year = {2008}
}
@article{Phillips1998,
author = {Phillips, P J},
journal = {IEEE Trans. Image Process.},
number = {8},
pages = {1150--1164},
title = {{Matching pursuit filters applied to face identification}},
volume = {7},
year = {1998}
}
@book{Mendel1995,
address = {Upper Saddle River, NJ},
author = {Mendel, J M},
publisher = {Prentice Hall},
series = {Signal Processing Series},
title = {{Lessons in Estimation Theory for Signal Processing, Communications, and Control}},
year = {1995}
}
@article{Davy2006,
author = {Davy, Manuel and Godsill, Simon and Idier, Jéro\^{}me},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2498},
title = {{Bayesian analysis of polyphonic western tonal music}},
url = {http://link.aip.org/link/JASMAN/v119/i4/p2498/s1\&Agg=doi},
volume = {119},
year = {2006}
}
@article{Fitz2002,
author = {Fitz, K and Haken, L},
journal = {J. Audio Eng. Soc.},
number = {11},
pages = {879--893},
title = {{On the use of time-frequency reassignment in additive sound modeling}},
volume = {50},
year = {2002}
}
@conference{Sturm2008b,
address = {Princeton, NJ},
author = {Sturm, B L and Shynk, J J and Daudet, L},
booktitle = {Proc. Conf. Info. Sciences Syst.},
pages = {961--966},
title = {{Measuring Interference in Overcomplete Signal Representations}},
year = {2008}
}
@article{Daudet2010,
author = {Daudet, L},
journal = {IEEE Sig. Process. Mag.},
number = {2},
pages = {90--96},
title = {{Audio sparse decompositions in parallel: let the greed be shared!}},
volume = {27},
year = {2010}
}
@article{Pfeiffer1996,
address = {New York, New York, USA},
author = {Pfeiffer, Silvia and Fischer, Stephan and Effelsberg, Wolfgang},
journal = {Proceedings of the fourth ACM international conference on Multimedia - MULTIMEDIA '96},
pages = {21--30},
publisher = {ACM Press},
title = {{Automatic audio content analysis}},
url = {http://portal.acm.org/citation.cfm?doid=244130.244139},
year = {1996}
}
@inproceedings{Yu2009,
address = {Taiwan, China},
author = {Yu, G and Slotine, J.-J.},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {1677--1680},
title = {{Audio Classification from Time-frequency Texture}},
year = {2009}
}
@article{Linde1986,
author = {Linde, Y and Buzo, A and Gray, R M},
journal = {IEEE Trans. on Communications},
number = {1},
pages = {84--95},
title = {{An Algorithm for Vector Quantizer Design}},
volume = {28},
year = {1980}
}
@techreport{Wu2000b,
address = {Santa Barbara, CA},
author = {Wu, Y.-L. and Agrawal, D and Abbadi, A E},
institution = {University of California, Santa Barbara},
keywords = {DB},
month = may,
number = {2000-08},
title = {{A Comparison of DFT and DWT Based Similarity Search in Time-series Databases}},
year = {2000}
}
@article{Karabulut2006,
author = {Karabulut, G Z and Moura, L and Panario, D and Yongaco$\backslash$\~{}glu, A},
journal = {IEE Proc.-Vis. Image Signal Processing},
number = {5},
pages = {538--548},
title = {{Integrating flexible tree searches to orthogonal matching pursuit algorithm}},
volume = {153},
year = {2006}
}
@article{Kaminskyj2005,
author = {Kaminskyj, Ian and Czaszejko, Tadeusz},
journal = {Journal of Intelligent Information Systems},
keywords = {automatic musical instrument identification,feature extraction,pattern recognition},
month = mar,
number = {2-3},
pages = {199--221},
title = {{Automatic Recognition of Isolated Monophonic Musical Instrument Sounds using kNNC}},
url = {http://www.springerlink.com/index/10.1007/s10844-005-0323-7},
volume = {24},
year = {2005}
}
@article{Makhoul1985,
author = {Makhoul, J and Roucos, S and Gish, H},
journal = {Proc. IEEE},
number = {11},
pages = {1551--1588},
title = {{Vector Quantization in Speech Coding}},
volume = {73},
year = {1985}
}
@article{Aucouturier2007,
author = {Aucouturier, J-.J. and Defreville, B and Pachet, F},
journal = {J. Acoust. Soc. America},
number = {2},
pages = {881--891},
title = {{The bag of frames approach to audio pattern recognition: A sufficient model for urban soundscapes but not for polyphonic music}},
volume = {122},
year = {2007}
}
@article{Gray1984,
abstract = {A vector quantizer is a system for mapping a sequence of continuous or discrete vectors into a digital sequence suitable for communication over or storage in a digital channel. The goal of such a system is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital storage memory requirements while maintaining the necessary fidelity of the data. The mapping for each vector may or may not have memory in the sense of depending on past actions of the coder, just as in well established scalar techniques such as PCM, which has no memory, and predictive quantization, which does. Even though information theory implies that one can always obtain better performance by coding vectors instead of scalars, scalar quantizers have remained by far the most common data compression system because of their simplicity and good performance when the communication rate is sufficiently large. In addition, relatively few design techniques have existed for vector quantizers. During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes. It is the purpose of this article to survey some of these design techniques and their applications.},
author = {Gray, R},
journal = {IEEE ASSP Mag.},
number = {2},
pages = {4--29},
title = {{Vector Quantization}},
volume = {1},
year = {1984}
}
@inproceedings{Sturm2008e,
address = {Pacific Grove, CA},
author = {Sturm, B L and Shynk, J J},
booktitle = {Proc. Asilomar Conf. Signals, Syst., Comput.},
title = {{Interference-Driven Adaptation in Sparse Approximations}},
year = {2008}
}
@article{Barrington2010,
author = {Barrington, L and Chan, A B and Lanckriet, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barrington, Chan, Lanckriet/Barrington, Chan, Lanckriet - 2010 - Modeling Music as a Dynamic Texture - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {602--612},
title = {{Modeling Music as a Dynamic Texture}},
volume = {18},
year = {2010}
}
@inproceedings{Valimaki2000,
address = {Istanbul, Turkey},
author = {V\"{a}lim\"{a}ki, V and Laakso, T I},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
month = jun,
pages = {3870--3873},
title = {{Principles of fractional delay filters}},
year = {2000}
}
@techreport{Jaggi1995,
address = {Cambridge, MA},
author = {Jaggi, S and Karl, W C and Mallat, S and Willsky, A S},
institution = {Laboratory for Information and Decision Systems, MIT},
title = {{High resolution pursuit for feature extraction}},
year = {1995}
}
@article{Aucouturier2004,
author = {Aucouturier, J-.J. and Pachet, F},
journal = {J. of Negative Results in Speech and Audio Sciences},
number = {1},
title = {{Improving Timbre Similarity: How high is the sky?}},
volume = {1},
year = {2004}
}
@article{Gardner2006,
author = {Gardner, T J and Magnasco, M O},
journal = {Proc. National Academy of the Sciences},
number = {16},
pages = {6094--6099},
title = {{Sparse time-frequency representations}},
volume = {103},
year = {2006}
}
@article{Fischer2006,
author = {Fischer, S and Crist\'{o}bal, G and Redondo, R},
journal = {IEEE Trans. Image Processing},
number = {2},
pages = {265--272},
title = {{Sparse Overcomplete Gabor Wavelet Representation Based on Local Competitions}},
volume = {15},
year = {2006}
}
@inproceedings{Panagakis2009,
address = {Glasgow, Scotland},
author = {Panagakis, Y and Kotopoulos, C and Arce, G R},
booktitle = {Proc. European Signal Process. Conf.},
pages = {1--5},
title = {{Music genre classification via sparse representations of auditory temporal modulations}},
year = {2009}
}
@article{Huber1985,
author = {Huber, P J},
journal = {The Annals of Statistics},
month = jun,
number = {2},
pages = {435--475},
title = {{Projection Pursuit}},
volume = {13},
year = {1985}
}
@article{Rebollo-Neira2002,
author = {Rebollo-Neira, L and Lowe, D},
journal = {\{IEEE\} Signal Process. Lett.},
number = {4},
pages = {137--140},
title = {{Optimized Orthogonal Matching Pursuit Approach}},
volume = {9},
year = {2002}
}
@inproceedings{Sturm2004a,
address = {Miami, FL},
author = {Sturm, B L and Pope, S T},
booktitle = {Proc. Int. Computer Music Conf.},
title = {{Spectral Characteristics of the Musical Iced Tea Can}},
year = {2004}
}
@inproceedings{Gribonval2005,
author = {Gribonval, R and i Ventura, R M Figueras and Vandergheynst, P},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{A simple test to check the optimality of sparse signal approximations}},
year = {2005}
}
@article{Campbell1997,
author = {Campbell, J.P.},
journal = {Proceedings of the IEEE},
keywords = {access control,authentication,bio-,biomedical measure-,biomedical signal processing,biomedical transducers,communication system security,computer network security,computer security,corpus,data bases,identification of persons,ments,metric},
number = {9},
pages = {1437--1462},
title = {{Speaker recognition: a tutorial}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=628714},
volume = {85},
year = {1997}
}
@inproceedings{Wang2006,
author = {Wang, B and Bangham, J A},
booktitle = {Proc. IEEE Int. Conf. Video Signal Based Surveillance (AVSS'06)},
keywords = {MP},
title = {{Shape Retrieval Using Matching Pursuit Decomposition}},
year = {2006}
}
@inproceedings{Wang2003,
address = {Baltimore, Maryland, USA},
author = {Wang, A},
booktitle = {Proc. Int. Conf. Music Info. Retrieval},
keywords = { MIR,DB},
pages = {1--4},
title = {{An industrial strength audio search algorithm}},
year = {2003}
}
@inproceedings{Duxbury2001,
address = {Limerick, Ireland},
author = {Duxbury, C and Davies, M and Sandler, M},
booktitle = {Proc. Conf. Digital Audio Effects},
title = {{Separation of transient information in musical audio using multiresolution analysis techniques}},
year = {2001}
}
@article{Plumbley2007,
author = {Plumbley, M D},
journal = {IEEE Trans. Info. Theory},
number = {9},
pages = {3188--3195},
title = {{On polar polytopes and the recovery of sparse representations}},
volume = {53},
year = {2007}
}
@article{Pye,
author = {Pye, D.},
file = {::},
journal = {2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)},
pages = {2437--2440},
publisher = {Ieee},
title = {{Content-based methods for the management of digital music}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=859334}
}
@article{Makhoul1975,
author = {Makhoul, J},
journal = {Proc. IEEE},
number = {4},
pages = {561--580},
title = {{Linear prediction: A tutorial review}},
volume = {63},
year = {1975}
}
@article{Woods1986,
author = {Woods, J. and O'Neil, S.},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
month = oct,
number = {5},
pages = {1278--1288},
title = {{Subband coding of images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1164962},
volume = {34},
year = {1986}
}
@article{Candes2010,
author = {Cand\`{e}s, E J and Eldar, Y C and Needell, D},
journal = {arXiv:1005.2613v1},
month = may,
title = {{Compressed sensing with coherent and redundant dictionaries}},
year = {2010}
}
@article{Al-Shaykh1999,
author = {Al-Shaykh, O K and Miloslavsky, E and Nomura, T and Neff, R and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {1},
pages = {123--143},
title = {{Video compression using matching pursuits}},
volume = {9},
year = {1999}
}
@article{Daudet2002,
author = {Daudet, L and Torr\'{e}sani, B},
journal = {Signal Processing},
number = {11},
pages = {1595--1617},
title = {{Hybrid representations for audiophonic signal encoding}},
volume = {82},
year = {2002}
}
@inproceedings{Giacobello2008,
address = {Brisbane, Australia},
author = {Giacobello, D and Christensen, M G and Dahl, J and Jensen, S H and Moonen, M},
booktitle = {Proc. Interspeech},
pages = {1353--1356},
title = {{Sparse Linear Predictors for Speech Processing}},
year = {2008}
}
@article{Jost2006,
author = {Jost, P and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. on Signal Processing},
month = may,
title = {{Tree-Based Pursuit: Algorithm and Properties}},
year = {2006}
}
@article{Fischer2006,
author = {Fischer, S and Crist\'{o}bal, G and Redondo, R},
journal = {IEEE Trans. Image Processing},
number = {2},
pages = {265--272},
title = {{Sparse Overcomplete Gabor Wavelet Representation Based on Local Competitions}},
volume = {15},
year = {2006}
}
@inproceedings{Popivanov2002,
address = {San Jose, CA},
author = {Popivanov, I and Miller, R J},
booktitle = {Proc. IEEE Int. Conf. Data Eng.},
keywords = {DB},
pages = {212--221},
title = {{Similarity Search Over Time-series Data Using Wavelets}},
year = {2002}
}
@inproceedings{Smith-III1991,
address = {Montreal, Canada},
author = {{Smith III}, J O},
booktitle = {Proc. Int. Computer Music Conf.},
organization = {International Computer Music Association},
title = {{Viewpoints on the History of Digital Synthesis}},
url = {http://www-ccrma.stanford.edu/~jos/kna/kna.html},
year = {1991}
}
@article{Gersho1994,
author = {Gersho, A},
journal = {Proc. IEEE},
number = {6},
pages = {900--918},
title = {{Advances in Speech and Audio Compression}},
volume = {82},
year = {1994}
}
@inproceedings{Beckmann1990,
author = {Beckmann, N and Kriegel, H.-P. and Schneider, R and Seeger, B},
booktitle = {Proc. ACM SIGMOD},
month = may,
pages = {322--331},
title = {{The r*-tree: an efficient and robust access method for points and rectangles}},
year = {1990}
}
@article{Ravelli2009,
author = {Ravelli, E and Richard, G and Daudet, L},
journal = {IEEE Trans. Acoustics, Speech, Lang. Process.},
keywords = { DB,MP},
number = {3},
pages = {434--446},
title = {{Audio signal representations for indexing in the transform domain}},
volume = {18},
year = {2010}
}
@article{Evangelista2001,
author = {Evangelista, G},
journal = {Journal of New Music Research},
keywords = { wavelets,TFR},
number = {1},
pages = {13--22},
title = {{Flexible Wavelets for Music Signal Processing}},
volume = {30},
year = {2001}
}
@article{Andrle2006a,
author = {Andrle, M and Rebollo-Neira, L},
journal = {Signal Process.},
number = {3},
pages = {480--495},
title = {{A swapping-based refinement of orthogonal matching pursuit strategies}},
volume = {86},
year = {2006}
}
@phdthesis{Schwarz2004,
author = {Schwarz, D},
school = {l'Universit\'{e} Paris 6 -- Pierre et Marie Curie},
title = {{Data-Driven Concatenative Sound Synthesis}},
year = {2004}
}
@article{Martin1998,
author = {Martin, Keith D.},
journal = {The Journal of the Acoustical Society of America},
month = sep,
number = {3},
pages = {1768},
title = {{Musical instrument identification: A pattern-recognition approach}},
url = {http://link.aip.org/link/?JAS/104/1768/3\&Agg=doi},
volume = {104},
year = {1998}
}
@article{Makhoul1975a,
author = {Makhoul, J.},
journal = {Proceedings of the IEEE},
number = {4},
pages = {561--580},
title = {{Linear prediction: A tutorial review}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1451722},
volume = {63},
year = {1975}
}
@article{Smith2005,
author = {Smith, E and Lewicki, M S},
journal = {Neural Computation},
number = {1},
pages = {19--45},
title = {{Efficient Coding of Time-relative Structure Using Spikes}},
volume = {17},
year = {2005}
}
@inproceedings{Gasser2010,
address = {Barcelona, Spain},
author = {Gasser, M and Flexer, A and Schnitzer, D},
booktitle = {Proc. Sound and Music Computing},
month = jul,
title = {{Hubs and Orphans --- An Explorative Approach}},
year = {2010}
}
@article{Heusdens2002,
author = {Heusdens, R and Vafin, R and Kleijn, W B},
journal = {\{IEEE\} Signal Process. Lett.},
number = {8},
pages = {262--265},
title = {{Sinusoidal Modeling Using Psychoacoustic-Adaptive Matching Pursuits}},
volume = {9},
year = {2002}
}
@article{Overholt2009,
author = {Overholt, D and Thompson, J and Putnam, L and Bell, B and Kleban, J and Sturm, B and Kuchera-Morin, J},
journal = {Computer Music J.},
number = {4},
pages = {69--82},
title = {{A Multimodal System for Gesture Recognition in Interactive Music Performance}},
volume = {33},
year = {2009}
}
@article{Blumensath2009,
author = {Blumensath, T and Davies, M E},
journal = {Signal Process. (submitted)},
title = {{Iterative Hard Thresholding for Compressed Sensing}},
year = {2009}
}
@article{Candes2008b,
author = {Cand\`{e}s, E J and Wakin, M B and Boyd, S P},
journal = {J. Fourier Analysis Applications},
number = {5-6},
pages = {877--905},
title = {{Enhancing Sparsity by Reweighted $\backslash$($\backslash$ell\_1$\backslash$) Minimization}},
volume = {14},
year = {2008}
}
@inproceedings{Ravelli2008a,
address = {Philadelphia, PA},
author = {Ravelli, E and Richard, G and Daudet, L},
booktitle = {Int. Conf. Music Info. Retrieval},
file = {:Users/pkmital/Documents/Mendeley Desktop/Ravelli, Richard, Daudet/Ravelli, Richard, Daudet - 2008 - Fast MIR in a Sparse Transform Domain - Int. Conf. Music Info. Retrieval.pdf:pdf},
title = {{Fast MIR in a Sparse Transform Domain}},
year = {2008}
}
@inproceedings{Ellis2008,
address = {Las Vegas, NV},
author = {Ellis, D P W and Cotton, C V and Mandel, M I},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {57--60},
title = {{Cross-Correlation of Beat-Synchronous Representations for Music Similarity}},
year = {2008}
}
@inproceedings{Goodwin1997a,
address = {Munich, Germany},
author = {Goodwin, M M and Vetterli, M},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = {MP},
pages = {2037--2040},
title = {{Matching pursuit with damped sinusoids}},
volume = {3},
year = {1997}
}
@article{Abdallah2006,
author = {Abdallah, S A and Plumbley, M D},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {179--196},
title = {{Unsupervised Analysis of Polyphonic Music by Sparse Coding}},
volume = {17},
year = {2006}
}
@article{Gray1998,
author = {Gray, R M and Neuhoff, D L},
journal = {IEEE Trans. Inf. Theory},
number = {6},
pages = {2325--2383},
title = {{Quantization}},
volume = {44},
year = {1998}
}
@inproceedings{Christensen2009,
address = {Pacific Grove, CA},
author = {Christensen, M and \O stergaard, J and Jensen, S H},
booktitle = {Proc. Asilomar Conf. Signals, Systems, and Computers},
title = {{On Compressed Sensing and Its Application to Speech and Audio Signals}},
year = {2009}
}
@article{Durka2001,
author = {Durka, P J and Ircha, D and Blinowska, K J},
journal = {IEEE Trans. Signal Process.},
number = {3},
pages = {507--510},
title = {{Stochastic Time-Frequency Dictionaries for Matching Pursuit}},
volume = {49},
year = {2001}
}
@inproceedings{Gasser2010,
address = {Barcelona, Spain},
author = {Gasser, M and Flexer, A and Schnitzer, D},
booktitle = {Proc. Sound and Music Computing},
month = jul,
title = {{Hubs and Orphans --- An Explorative Approach}},
year = {2010}
}
@article{Aucouturier2004,
author = {Aucouturier, J-.J. and Pachet, F},
journal = {J. of Negative Results in Speech and Audio Sciences},
number = {1},
title = {{Improving Timbre Similarity: How high is the sky?}},
volume = {1},
year = {2004}
}
@inproceedings{Wang2000,
author = {Wang, C and Wang, X S},
booktitle = {Proc. Int. Conf. on Scientific and Statistical Database Management},
month = jul,
pages = {69--81},
title = {{Supporting Content-based Searches on Time Series via Approximation}},
year = {2000}
}
@article{Schwarz2006,
author = {Schwarz, D},
file = {:Users/pkmital/Documents/Mendeley Desktop/Schwarz/Schwarz - 2006 - Concatenative Sound Synthesis The Early Years - J. New Music Research.pdf:pdf},
journal = {J. New Music Research},
keywords = {CSS},
number = {1},
title = {{Concatenative Sound Synthesis: The Early Years}},
volume = {35},
year = {2006}
}
@inproceedings{Kling2004,
address = {Naples, Italy},
author = {Kling, G and Roads, C},
booktitle = {Proc. Int. Conf. Digital Audio Effects},
file = {:Users/pkmital/Documents/Mendeley Desktop/Kling, Roads/Kling, Roads - 2004 - Audio Analysis, Visualization, and Transformation with the Matching Pursuit Algorithm - Proc. Int. Conf. Digital A.pdf:pdf},
keywords = {MP},
pages = {33--37},
title = {{Audio Analysis, Visualization, and Transformation with the Matching Pursuit Algorithm}},
year = {2004}
}
@article{Wichern2010,
author = {Wichern, G and Xue, J and Thornburg, H and Mechtley, B and Spanias, A},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {688--707},
title = {{Segmentation, Indexing, and Retrieval for Environmental and Natural Sounds}},
volume = {18},
year = {2010}
}
@article{Plumbley2006,
abstract = {We consider two approaches for sparse decomposition of polyphonic
music: a time-domain approach based on a shift-invariant model, and
a frequency-domain approach based on phase-invariant power spectra.
When trained on an example of a MIDI-controlled acoustic piano recording,
both methods produce dictionary vectors or sets of vectors which
represent underlying notes, and produce component activations related
to the original MIDI score. The time-domain method is more computationally
expensive, but produces sample-accurate spike-like activations and
can be used for a direct time-domain reconstruction. The spectral-domain
method discards phase information, but is faster than the time-domain
method and retains more higher-frequency harmonics. These results
suggest that these two methods would provide a powerful yet complementary
approach to automatic music transcription or object-based coding
of musical audio.},
author = {Plumbley, M D and Abdallah, S A and Blumensath, T and Davies, M E},
journal = {Signal Process.},
number = {3},
pages = {417--431},
title = {{Sparse Representations of Polyphonic Music}},
volume = {86},
year = {2006}
}
@inproceedings{Cho2009,
author = {Cho, Y and Saul, L K},
booktitle = {Proc. Int. Conf. Machine Learning},
title = {{Learning Dictionaries of Stable Autoregressive Models for Audio Scene Analysis}},
year = {2009}
}
@phdthesis{Davis1994,
address = {New York},
author = {Davis, G},
keywords = {MP},
school = {New York University, Department of Mathematics},
title = {{Adaptive Nonlinear Approximations}},
year = {1994}
}
@article{Srinivasan2005,
author = {Srinivasan, U and Pfeiffer, S and Nepal, S and Lee, M and Gu, L and Barrass, S},
journal = {Multimedia Tools and Applications},
number = {1},
pages = {105--141},
title = {{A Survey of MPEG-1 Audio, Video and Semantic Analysis Techniques}},
volume = {27},
year = {2005}
}
@inproceedings{Agrawal1995,
address = {San Francisco, CA, USA},
author = {Agrawal, Rakesh and Lin, King-Ip and Sawhney, Harpreet S and Shim, Kyuseok},
booktitle = {VLDB '95: Proceedings of the 21th International Conference on Very Large Data Bases},
keywords = {DB},
pages = {490--501},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases}},
year = {1995}
}
@article{Leveau2008,
author = {Leveau, P and Vincent, E and Richard, G and Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {1},
pages = {116--128},
title = {{Instrument-specific Harmonic Atoms for Mid-level Music Representation}},
volume = {16},
year = {2008}
}
@inproceedings{Meng2005,
address = {Philadelphia, PA},
author = {Meng, A and Ahrendt, P and Larsen, J},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {497--500},
title = {{Improving Music Genre Classification by Short-time Feature Integration}},
volume = {5},
year = {2005}
}
@phdthesis{Sturm2009,
address = {Santa Barbara, CA},
author = {Sturm, B L},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm/Sturm - 2009 - Sparse Approximation and Atomic Decomposition Considering Atom Interactions in Evaluating and Building Signal Representat.pdf:pdf},
school = {University of California},
title = {{Sparse Approximation and Atomic Decomposition: Considering Atom Interactions in Evaluating and Building Signal Representations}},
year = {2009}
}
@article{Castellanos2010,
abstract = {A method is presented that allows for retrieving 1D spectra of the individual components of a mixture from a sparsely acquired 2D-TOCSY spectrum. The decomposition of the 2D-TOCSY data into pure 1D traces is achieved using a non-negative matrix factorization algorithm, also known as multivariate curve resolution analysis. Here, we show that the algorithm can be applied to data processed in the direct dimension only. Thus, our method can be applied to non-linearly sampled experiments or data acquired with few indirect points. An example is shown for the spectra of a mixture of six amino acids, acquired in 15 min. Copyright (c) 2010 John Wiley \& Sons, Ltd.},
author = {Castellanos, Eddy Roc\'{\i}o Rey and Wist, Julien},
journal = {Magnetic resonance in chemistry : MRC},
month = jul,
number = {7},
pages = {2845--2862},
title = {{Decomposition of mixtures' spectra by multivariate curve resolution of rapidly acquired TOCSY experiments.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20688155},
volume = {47},
year = {2010}
}
@inproceedings{Mallat1992,
author = {Mallat, S and Zhang, Z},
booktitle = {Proc. IEEE-SP Int. Symp.},
keywords = {MP},
organization = {IEEE},
pages = {7--10},
title = {{Adaptive Time-Frequency Decomposition with Matching Pursuits}},
year = {1992}
}
@article{Burges2003,
abstract = {Mapping audio data to feature vectors for the classification, retrieval or identification tasks presents four principal challenges. The dimensionality of the input must be significantly reduced; the resulting features must be robust to likely distortions of the input; the features must be informative for the task at hand; and the feature extraction operation must be computationally efficient. We propose distortion discriminant analysis (DDA), which fulfills all four of these requirements. DDA constructs a linear, convolutional neural network out of layers, each of which performs an oriented PCA dimensional reduction. We demonstrate the effectiveness of DDA on two audio fingerprinting tasks: searching for 500 audio clips in 36 h of audio test data; and playing over 10 days of audio against a database with approximately 240 000 fingerprints. We show that the system is robust to kinds of noise that are not present in the training procedure. In the large test, the system gives a false positive rate of 1.5 ? 10-8 per audio clip, per fingerprint, at a false negative rate of 0.2\% per clip.},
author = {Burges, C J C and Platt, J C and Jana, S},
journal = {Speech and Audio Processing, IEEE Transactions on},
keywords = {MIR},
month = may,
number = {3},
pages = {165--174},
title = {{Distortion discriminant analysis for audio fingerprinting}},
volume = {11},
year = {2003}
}
@inproceedings{Bruckstein2008,
address = {Las Vegas, NV},
author = {Bruckstein, A M and Elad, M and Zibukevsky, M},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {5145--5148},
title = {{On the uniqueness of non-negative sparse and redundant representations}},
year = {2008}
}
@misc{Blumensath2004,
author = {Blumensath, T},
howpublished = {Web, powerpoint presentation},
title = {{Unsupervised learning of shift-invariant over-complete dictionaries for time-series analysis}}
}
@article{Keogh2001,
address = {Santa Barbara, CA},
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Mehrotra, Sharad and Pazzani, Michael},
journal = {ACM Trans. Database Syst.},
keywords = {DB},
number = {2},
pages = {188--228},
title = {{Locally adaptive dimensionality reduction for indexing large time series databases}},
volume = {27},
year = {2001}
}
@article{Guo2003,
abstract = {Support vector machines (SVMs) have been recently proposed as a new learning algorithm for pattern recognition. In this paper, the SVMs with a binary tree recognition strategy are used to tackle the audio classification problem. We illustrate the potential of SVMs on a common audio database, which consists of 409 sounds of 16 classes. We compare the SVMs based classification with other popular approaches. For audio retrieval, we propose a new metric, called distance-from-boundary (DFB). When a query audio is given, the system first finds a boundary inside which the query pattern is located. Then, all the audio patterns in the database are sorted by their distances to this boundary. All boundaries are learned by the SVMs and stored together with the audio database. Experimental comparisons for audio retrieval are presented to show the superiority of this novel metric to other similarity measures.},
author = {Guo, Guodong and Li, S Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo, Li/Guo, Li - 2003 - Content-Based Audio Classification and Retrieval by Support Vector Machines - IEEE Trans. Neural Networks.pdf:pdf},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
month = jan,
number = {1},
pages = {209--15},
title = {{Content-based audio classification and retrieval by support vector machines.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18238003},
volume = {14},
year = {2003}
}
@article{Sturm2006c,
author = {Sturm, B L},
journal = {Computer Music J.},
number = {4},
pages = {46--66},
title = {{Adaptive Concatenative Sound Synthesis and Its Application to Micromontage Composition}},
volume = {30},
year = {2006}
}
@phdthesis{Jost2007,
address = {Lausanne, Switzerland},
author = {Jost, P},
month = jun,
school = {Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne},
title = {{Algorithmic aspects of sparse approximations}},
year = {2007}
}
@article{Chen1998,
author = {Chen, S S and Donoho, D L and Saunders, M A},
journal = {SIAM J. Sci. Comput.},
number = {1},
pages = {33--61},
title = {{Atomic Decomposition by Basis Pursuit}},
volume = {20},
year = {1998}
}
@inproceedings{Ravelli2007,
address = {New Paltz, NY},
author = {Ravelli, E and Richard, G and Daudet, L},
booktitle = {IEEE Workshop Appl. Signal Process. Audio Acoustics},
title = {{Extending transform coding to very low bitrates using overcomplete dictionaries}},
year = {2007}
}
@misc{Gribonval2004,
author = {Gribonval, R and Bacry, E and Abadia, J},
howpublished = {http://www.cmap.polytechnique.fr/\~{}bacry/LastWave/$\backslash$$\backslash$packages/mp/mp.html},
month = jul,
title = {{Matching Pursuit Software and Documentation}},
url = {http://www.cmap.polytechnique.fr/~bacry/LastWave/packages/mp/mp.html},
year = {2004}
}
@inproceedings{Keogh2002,
address = {New York, NY, USA},
author = {Keogh, Eamonn and Kasetty, Shruti},
booktitle = {KDD '02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
pages = {102--111},
publisher = {ACM},
title = {{On the need for time series data mining benchmarks: a survey and empirical demonstration}},
year = {2002}
}
@article{Vincent2007,
abstract = {Source separation is a difficult problem for which many algorithms
have been proposed. In this article, we define oracle estimators
which compute the best performance achievable by different classes
of algorithms on a given mixture, in a theoretical evaluation framework
where the reference sources are available. We describe explicit oracle
estimators for three particular classes of algorithms: multichannel
time-invariant filtering, single-channel time-frequency masking and
multichannel time-frequency masking. We evaluate their performance
on various audio mixtures and study their robustness. We draw several
conclusions for their three typical applications, namely providing
performance bounds for existing and future blind algorithms, selecting
the best class of algorithms for a given mixture and assessing the
separation difficulty. In particular, we show that it is worth developing
blind time-frequency masking algorithms relaxing the common assumption
of a single active source per time-frequency point.},
author = {Vincent, E and Gribonval, R and Plumbley, M D},
journal = {Signal Process.},
number = {8},
pages = {1933--1950},
title = {{Oracle Estimators for the Benchmarking of Source Separation Algorithms}},
volume = {87},
year = {2007}
}
@article{FiVentura2006,
author = {{Figueras i Ventura}, R M and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. Image Process.},
number = {3},
pages = {726--739},
title = {{Low-rate and flexible image coding with redundant representations}},
volume = {15},
year = {2006}
}
@article{Vandewalle2009,
author = {Vandewalle, P and Kovacevic, J and Vetterli, M},
journal = {IEEE Signal Process. Mag.},
month = may,
number = {3},
pages = {37--47},
title = {{Reproducible Research in Signal Processing --- What, why, and how}},
volume = {26},
year = {2009}
}
@inproceedings{Pfeiffer1997,
address = {Boston, MA},
author = {Pfeiffer, S and Fischer, S and Effelsberg, W},
booktitle = {Proc. Int. Multimedia Conf.},
pages = {21--30},
title = {{Automatic Audio Content Analysis}},
year = {1997}
}
@article{Vera-Candeas2004b,
author = {Vera-Candeas, P and Ruiz-Reyes, N and Rosa-Zurera, M and Martinez-Mu$\backslash$tildenoz, D and Curpi\'{a}n-Alonso, J},
journal = {\{IEEE\} Proc. - Visual Image Signal Processing},
number = {1},
pages = {21--28},
title = {{New matching pursuit based sinusoidal modelling method for audio coding}},
volume = {151},
year = {2004}
}
@article{Gunasekaran2008,
author = {Gunasekaran, S. and Revathy, K.},
journal = {2008 International Conference on Computer and Electrical Engineering},
month = dec,
pages = {847--851},
publisher = {Ieee},
title = {{Recognition of Indian Musical Instruments with Multi-Classifier Fusion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4741103},
year = {2008}
}
@misc{Tropp2003b,
author = {Tropp, J and Gilbert, A C and Strauss, M J},
howpublished = {presentation slides},
title = {{An Algorithmic Approach to Sparse Time-frequency Analysis}},
year = {2002}
}
@article{Chang1987,
author = {Chang, P -C. and Gray, R M and May, J},
journal = {IEEE Trans. on Communications},
number = {10},
pages = {1059--1068},
title = {{Fourier Transform Vector Quantization for Speech Coding}},
volume = {35},
year = {1987}
}
@article{DeCheveigne2002,
author = {de Cheveigné, Alain and Kawahara, Hideki},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {1917},
title = {{YIN, a fundamental frequency estimator for speech and music}},
url = {http://link.aip.org/link/JASMAN/v111/i4/p1917/s1\&Agg=doi},
volume = {111},
year = {2002}
}
@article{Rath2010,
author = {Rath, G and Guillemot, C},
journal = {Signal Process.},
number = {2},
pages = {702--706},
title = {{On a simple derivation of the complementary matching pursuit}},
volume = {90},
year = {2010}
}
@inproceedings{Rafiei1998,
address = {Kobe, Japan},
author = {Rafiei, D and Mendelzon, A},
booktitle = {Proc. Int. Conf. Found. Data Org.},
keywords = {DB},
pages = {249--257},
title = {{Efficient Retrieval of Similar Time Sequences Using \{DFT\}}},
year = {1998}
}
@book{Roads2001,
address = {Cambridge, MA},
author = {Roads, C},
publisher = {MIT Press},
title = {{Microsound}},
year = {2001}
}
@inproceedings{Aharon2005a,
author = {Aharon, M and Elad, M and Bruckstein, A.\~{}M.},
booktitle = {Wavelets XI. Edited by Papadakis, Manos; Laine, Andrew F.; Unser, Michael A. Proceedings of the SPIE, Volume 5914, pp. 327-339 (2005).},
editor = {Bodmann, B.\~{}G. and Papadakis, M and Kouri, D.\~{}J. and Gertz, S.\~{}D. and Cherukuri, P and Vela, D and Gladish, G.\~{}W. and Cody, D.\~{}D. and Abodashy, I and Conyers, J.\~{}L. and Willerson, J.\~{}T. and Casscells, S.\~{}W.},
keywords = {SA},
pages = {327--339},
title = {{K-SVD and its non-negative variant for dictionary design}},
year = {2005}
}
@article{Turnbull2008,
author = {Turnbull, D and Barrington, L and Torres, D and Lanckriet, G},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
title = {{Semantic annotation and retrieval of music and sound effects}},
volume = {16},
year = {2008}
}
@book{Mitra2006,
author = {Mitra, S K},
edition = {3},
keywords = {DSP},
publisher = {McGraw Hill},
title = {{Digital Signal Processing: A Computer Based Approach}},
year = {2006}
}
@article{Gribonval2001b,
author = {Gribonval, R},
file = {:Users/pkmital/Documents/Mendeley Desktop/Gribonval/Gribonval - 2001 - Fast matching pursuit with a multiscale dictionary of Gaussian chirps - IEEE Trans. Signal Process.pdf:pdf},
journal = {IEEE Trans. Signal Process.},
month = may,
number = {5},
pages = {994--1001},
title = {{Fast matching pursuit with a multiscale dictionary of Gaussian chirps}},
volume = {49},
year = {2001}
}
@inproceedings{Vlachos2002,
address = {San Francisco, CA},
author = {Vlachos, M and Lin, J and Keogh, E and Gunopulos, D},
booktitle = {Proc. Workshop on Clustering High Dimensionality Data and Its Applications},
keywords = {DB},
month = may,
pages = {23--30},
title = {{A Wavelet-based Anytime Algorithm for K-means Clustering of Time Series}},
year = {2003}
}
@article{Plumbley05-geometrical,
abstract = {We explore the use of geometrical methods to tackle the non-negative
independent component analysis (non-negative ICA) problem, without
assuming the reader has an existing background in differential geometry.
We concentrate on methods that achieve this by minimizing a cost
function over the space of orthogonal matrices. We introduce the
idea of the manifold and Lie group SO(n) of special orthogonal matrices
that we wish to search over, and explain how this is related to the
Lie algebra of skew-symmetric matrices. We describe how familiar
optimization methods such as steepest descent and conjugate gradients
can be transformed into this Lie group setting, and how the Newton
update step has an alternative Fourier version in SO(n). Finally,
we introduce the concept of a toral subgroup generated by a particular
element of the Lie group or Lie algebra, and explore how this commutative
subgroup might be used to simplify searches on our constraint surface.
No proofs are presented in this article.},
author = {Plumbley, M D},
journal = {Neurocomputing},
month = aug,
pages = {161--197},
title = {{Geometrical Methods for Non-Negative \{ICA\}: Manifolds, \{L\}ie Groups and Toral Subalgebras}},
volume = {67},
year = {2005}
}
@article{Sturm2008a,
author = {Sturm, B L and Shynk, J J and Daudet, L and Roads, C},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {671--676},
title = {{Dark Energy in Sparse Atomic Estimations}},
volume = {16},
year = {2008}
}
@article{McAulay1986,
author = {McAulay, J and Quatieri, T},
journal = {IEEE Trans. Acoustics, Speech, Signal Process.},
number = {4},
pages = {744--754},
title = {{Speech Analysis/Synthesis Based on a Sinusoidal Representation}},
volume = {34},
year = {1986}
}
@article{Davis1997,
author = {Davis, G and Mallat, S and Avellaneda, M},
journal = {J. Constr. Approx.},
number = {1},
pages = {57--98},
title = {{Adaptive Greedy Approximations}},
volume = {13},
year = {1997}
}
@inproceedings{Manzagol2008,
address = {Philadelphia, PA},
author = {Manzagol, P.-A and Bertine-Mahieux, T and Eck, D},
booktitle = {Proc. Int. Soc. Music Information Retrieval},
title = {{On the use of sparse time-relative auditory codes for music}},
year = {2008}
}
@article{Joder2009,
author = {Joder, C and Essid, S and Richard, G},
journal = {IEEE Trans. Acoustics, Speech, Signal Process.},
keywords = {MIR},
number = {1},
pages = {174--184},
title = {{Temporal Integration for Audio Classification with Application to Musical Instrument Classification}},
volume = {17},
year = {2009}
}
@article{DeVore1996,
author = {DeVore, R A and Temlyakov, V N},
journal = {Adv. Comput. Math},
pages = {173--187},
title = {{Some remarks on greedy algorithms}},
volume = {5},
year = {1996}
}
@inproceedings{McLeran2009,
address = {Santa Barbara, CA},
author = {McLeran, A and Roads, C and Sturm, B L},
booktitle = {Proc. The Future of Interactive Media: Workshop on Media Arts, Science, and Technology},
title = {{Scatter: A Software Tool for Visualizing, Transforming, and Performing Atomic Decompositions of Sound}},
year = {2009}
}
@inproceedings{Chu2008,
address = {Las Vegas, NV},
author = {Chu, S and Narayanan, S and Kuo, C.-C. J},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {1--4},
title = {{Environmental Sound Recognition using \{MP\}-Based Features}},
year = {2008}
}
@article{Zhu2008,
author = {Zhu, J and Wang, Y},
journal = {Computer Music J},
number = {1},
pages = {71--87},
title = {{Complexity-scalable beat detection with mp3 audio bitstreams}},
volume = {32},
year = {2008}
}
@inproceedings{Kronland-Martinet2001,
author = {Kronland-Martinet, R and Guillemain, Ph. and Ystad, S},
booktitle = {Workshop on Proceedings of MOSART Current Research Directions in Computer Music Workshop},
title = {{From sound modeling to analysis-synthesis of sounds}},
year = {2001}
}
@inproceedings{Amatriain2001,
author = {Amatriain, X and Bonada, J and Loscos, A and Serra, X},
booktitle = {Proc. MOSART Workshop Current Research Directions Computer Music},
title = {{Spectral Modeling for Higher-level Sound Transformations}},
year = {2001}
}
@article{Rao1999,
author = {Rao, B D and Kreutz-Delgado, K},
journal = {IEEE Trans. Signal Process.},
number = {1},
pages = {187--200},
title = {{An affine scaling methodology for best basis selection}},
volume = {47},
year = {1999}
}
@article{Kostek2000,
author = {Kostek, Bozena},
journal = {The Journal of the Acoustical Society of America},
number = {5},
pages = {2818},
title = {{Automatic classification of musical instrument sounds}},
url = {http://link.aip.org/link/JASMAN/v107/i5/p2818/s4\&Agg=doi},
volume = {107},
year = {2000}
}
@inproceedings{Abdallah2003,
abstract = {We used Independent Component Analysis (ICA) with sparse coding to
analyze music spectral sequences. We modelled an audio spectrum as
an approximate mixture of the spectra of individual notes, using
our ICA approach to "unmix" this to nd the individual notes and note
spectra. Notes are assumed to be approximately independent, and sparse
(mostly off). Results on synthesized harpsichord music are encouraging,
producing an approximate piano-roll transcription, and a passable
rendition of the original music when resynthesized. We are currently
working to extend and improve this through the use of temporal information
of note activities and to handle more complex timbral behaviour.},
address = {Amsterdam, The Netherlands},
author = {Abdallah, S A and Plumbley, M D},
booktitle = {Proc. 114th Conv. Audio Eng. Soc.},
title = {{An Independent Component Analysis approach to Automatic Music Transcription}},
year = {2003}
}
@incollection{Dutilleux2002,
author = {Dutilleux, P and Poli, G De and Z\"{o}lzer, U},
booktitle = {\{DAFx\}: Digital Audio Effects},
editor = {Z\"{o}lzer, U},
publisher = {Wiley},
title = {{Time-segment Processing}},
year = {2002}
}
@book{Gray2008b,
address = {New York},
author = {Gray, Robert M},
publisher = {Springer Verlag},
title = {{Entropy and Information Theory}},
year = {2008}
}
@article{Zibulski1994,
author = {Zibulski, M and Zeevi, Y Y},
journal = {IEEE Trans. Signal Proc.},
month = apr,
number = {4},
pages = {942--945},
title = {{Frame analysis of the discrete Gabor-scheme}},
volume = {42},
year = {1994}
}
@article{Al-Shaykh1999,
author = {Al-Shaykh, O K and Miloslavsky, E and Nomura, T and Neff, R and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {1},
pages = {123--143},
title = {{Video compression using matching pursuits}},
volume = {9},
year = {1999}
}
@inproceedings{Erkucuk2003,
address = {Baltimore, MD},
author = {Erk\"{u}\c{c}\"{u}k, S and Krishnan, S and Zeytino$\backslash$uglu, M},
booktitle = {Proc. IEEE Int. Conf. Multimedia Expo},
month = jul,
pages = {513--516},
title = {{Robust Audio Watermarking using a chirp based technique}},
year = {2003}
}
@inproceedings{Martin2009,
author = {Martin, R and Nagathil, A},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
title = {{Cepstral Modulation Ratio Regression (CMRARE) Parameters for Audio Signal Analysis and Classification}},
year = {2009}
}
@article{Daudet2006,
author = {Daudet, L},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
keywords = {MP},
number = {5},
pages = {1808--1816},
title = {{Sparse and Structured Decompositions of Signals with the Molecular Matching Pursuit}},
volume = {14},
year = {2006}
}
@article{Durka2004a,
author = {Durka, Piotr},
journal = {Physical Review E},
month = may,
number = {5},
pages = {1--5},
title = {{Adaptive time-frequency parametrization of epileptic spikes}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.69.051914},
volume = {69},
year = {2004}
}
@article{Adler1997,
author = {Adler, J and Rao, B D},
journal = {Computer Engineering},
pages = {252--257},
title = {{Comparison of Basis Selection Methods}},
year = {1997}
}
@article{Wold1996,
abstract = {Many audio and multimedia applications would benefit from the ability to classify and search for audio based on its characteristics. The audio analysis, search, and classification engine described here reduces sounds to perceptual and acoustical features. This lets users search or retrieve sounds by any one feature or a combination of them, by specifying previously learned classes based on these features, or by selecting or entering reference sounds and asking the engine to retrieve similar or dissimilar sounds.},
author = {Wold, E and Blum, T and Keislar, D and Wheaton, J},
journal = {IEEE Multimedia},
keywords = {MIR},
number = {2},
pages = {27--36},
title = {{Content-Based Classification, Search and Retrieval of Audio}},
volume = {3},
year = {1996}
}
@article{Amatriain2003,
abstract = {Content processing is a vast and growing field that integrates different approaches borrowed from the signal processing, 
information retrieval and machine learning disciplines. In this article we deal with a particular type of content pro- 
cessing: the so-called content-based transformations. We will not focus on any particular application but rather try to give 
an overview of different techniques and conceptual implications. We first describe the transformation process itself, 
including the main model schemes that are commonly used, which lead to the establishment of the formal basis for a 
definition of content-based transformations. Then we take a quick look at a general spectral based analysis/synthesis 
approach to process audio signals and how to extract features that can be used in the content-based transformation context. Using this analysis/synthesis approach we give some examples on how content-based transformations can be applied to modify the basic perceptual axis of a sound and how we can even combine different basic effects in order to perform more meaningful transformations. We finish by going a step further in the abstraction ladder and present transformations that are related to musical (and thus symbolic) properties rather than to those of the sound or the signal itself.},
author = {Amatriain, X and Bonada, J and Loscos, \`{A} and Arcos, J L and Verfaille, V},
journal = {J. New Music Research},
keywords = { synth,MIR},
number = {1},
pages = {95--114},
title = {{Content-Based Transformations}},
url = {http://www.iua.upf.es/mtg/publications/jnmr32-xamat.pdf},
volume = {32},
year = {2003}
}
@article{Foote1999,
author = {Foote, Jonathan},
journal = {Multimedia Systems},
month = jan,
number = {1},
pages = {2--10},
title = {{An overview of audio information retrieval}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s005300050106},
volume = {7},
year = {1999}
}
@article{Liang2008,
abstract = {The estimation of the time of arrival (TOA) and/or time of flight of the ultrasonic echoes is essential in ultrasonic nondestructive evaluation. In this paper, matching pursuit method has been used to analyze noisy ultrasonic pulse-echo wavelet and decompose the noisy pulse-echo wavelet into unit-norm vectors. The error ratio of the mean square is used to monitor the acceptability of the unit-norm vector obtained by the matching pursuit performance. A matched filter can be designed by using the time reversal of the approximation pulse-echo wavelet obtained by the reconstruction result with several large coefficient decomposed unit-norm vectors. After performing the matched filter, the part of the signal related to the electrical noise will be removed leaving only the correlated portion of the ultrasonic echoes. Then no initial phase have been contained in the processed ultrasonic echoes. Therefore, the TOA can be estimated directly from the peaks of the representation of the processed signal. Numerical simulations and experimental results make evidence the good performance of the proposed approach which has good effect of noise suppression and results in much improved accuracy in the estimation of echo arrival time.},
author = {Liang, Wei and Que, Pei-wen and Lei, Hua-ming and Chen, Liang},
journal = {The Review of scientific instruments},
month = jul,
number = {7},
pages = {075105},
title = {{Matching pursuit for decomposition and approximation of ultrasonic pulse-echo wavelet and its application in ultrasonic nondestructive evaluation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20000927},
volume = {79},
year = {2008}
}
@phdthesis{Ravelli2008b,
address = {Paris, France},
author = {Ravelli, E},
keywords = { DSP, MIR,SA},
school = {Universit\'{e} Pierre et Marie Curie -- Paris 06},
title = {{Audio signal representations with overcomplete transforms for coding and indexing}},
year = {2008}
}
@article{Benetos2006a,
author = {Benetos, Emmanouil and Kotti, Margarita and Kotropoulos, Constantine},
journal = {2006 IEEE International Conference on Multimedia and Expo},
month = jul,
pages = {2105--2108},
publisher = {Ieee},
title = {{Applying Supervised Classifiers Based on Non-negative Matrix Factorization to Musical Instrument Classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4037047},
year = {2006}
}
@inproceedings{Sturm2009a,
address = {Baltimore, MD},
author = {Sturm, B L and Shynk, J J and Kim, D H},
booktitle = {Proc. Conf. Info. Sciences Syst.},
title = {{Pruning Sparse Signal Models Using Interference}},
year = {2009}
}
@inproceedings{Zhang2007a,
address = {Washington, DC},
author = {Zhang, X and Ras, Z W},
booktitle = {Proc. Int. Conf. Multimedia Ubiquitous Engineering},
pages = {3--8},
title = {{Analysis of Sound features for Music Timbre Recognition}},
year = {2007}
}
@article{Foote1999,
author = {Foote, J},
journal = {Multimedia Systems},
keywords = {MIR},
number = {1},
pages = {2--10},
title = {{An Overview of Audio Information Retrieval}},
volume = {7},
year = {1999}
}
@article{Kovacevic2007,
author = {Kova$\backslash$ucevi\'{c}, J and Chebira, A},
journal = {IEEE Sig. Process. Mag.},
month = jul,
pages = {86--104},
title = {{Life beyond bases: the advent of frames (part I)}},
year = {2007}
}
@inproceedings{Simon2005,
address = {Barcelona, Spain},
author = {Simon, I and Basu, S and Salesin, D and Agrawala, M},
booktitle = {Proc. Int. Computer Music Conf.},
month = jul,
pages = {65--72},
title = {{Audio analogies: creating new music from an existing performance by concatenative synthesi}},
year = {2005}
}
@inproceedings{Kashino1999,
author = {Kashino, K and Smith, G and Murase, H},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
keywords = {DB},
pages = {2993--2996},
title = {{Time-series active search for quick retrieval of audio and video}},
volume = {6},
year = {1999}
}
@book{Mallat1999,
address = {San Diego, CA},
author = {Mallat, S},
edition = {2nd},
keywords = { TFR, wavelets,MP},
publisher = {Academic Press},
title = {{A Wavelet Tour of Signal Processing}},
year = {1999}
}
@techreport{Adiloglu2008,
address = {Berlin},
author = {Adiloglu, K and Anni\'{e}s, R and Purwins, H and Obermayer, K},
institution = {NI-BIT},
month = jul,
title = {{Representations and Predictors for Everyday Sounds}},
year = {2008}
}
@incollection{Gribonval2001,
author = {Gribonval, R},
booktitle = {Trends in Approximation Theory},
editor = {Kopotun, K and Lyche, T and Neamtu, M},
month = may,
pages = {143--148},
publisher = {Vanderbilt University Press},
title = {{Partially Greedy Algorithms}},
year = {2001}
}
@article{Candes2008,
author = {Cand\`{e}s, E and Wakin, M B},
journal = {IEEE Signal Process. Mag.},
number = {2},
pages = {21--30},
title = {{An Introduction to Compressive Sampling}},
volume = {25},
year = {2008}
}
@article{Aharon2006,
author = {Aharon, M and Elad, M and Bruckstein, A M},
journal = {IEEE Trans. Signal Process.},
keywords = {SA},
month = nov,
number = {11},
pages = {4311--4322},
title = {{K-\{SVD\}: An Algorithm for Designing of Overcomplete Dictionaries for Sparse Representation}},
volume = {54},
year = {2006}
}
@article{Masri1997,
author = {Masri, Paul and Bateman, Andrew and Canagarajah, Nishan},
journal = {Organised Sound},
month = nov,
number = {3},
pages = {193--205},
title = {{A review of time–frequency representations, with application to sound/music analysis–resynthesis}},
url = {http://www.journals.cambridge.org/abstract\_S1355771898009042},
volume = {2},
year = {1997}
}
@incollection{Amatriain2008,
address = {Berlin, Germany},
author = {Amatriain, X and Castellanos, J and H\"{o}llerer, T and Kuchera-Morin, J and Pope, S T and Wakefield, G and Wolcott, W},
booktitle = {Lecture Notes in Computer Science: Sense to Sound},
editor = {Jensen, K K and Kronland-Martinet, R and Ystad, S},
publisher = {Springer Verlag},
title = {{Experiencing Audio and Music in a Fully Immersive Environment}},
year = {2008}
}
@techreport{Donoho2004,
author = {Donoho, D L},
institution = {Stanford University},
title = {{For Most Large Underdetermined Systems of Linear Equations, the minimal $\backslash$ell\_1-norm solution is also the sparsest solution}},
year = {2004}
}
@inproceedings{Kowalski2005,
address = {IRISA Rennes},
author = {Kowalski, M and Torr\'{e}sani, B},
booktitle = {Proc. SPARS'05 Conf.},
pages = {59--62},
title = {{A study of bernoulli and structured random waveform models for audio signals}},
year = {2005}
}
@article{Pati1993a,
author = {Pati, Y.C. and Rezaiifar, R. and Krishnaprasad, P.S.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Pati, Rezaiifar, Krishnaprasad/Pati, Rezaiifar, Krishnaprasad - 1993 - Orthogonal Matching Pursuit Recursive Function Approximation with Applications to Wavelet Decomp.pdf:pdf},
journal = {Proceedings of 27th Asilomar Conference on Signals, Systems and Computers},
pages = {40--44},
publisher = {IEEE Comput. Soc. Press},
title = {{Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=342465},
year = {1993}
}
@article{Hunt,
author = {a.J. Hunt and a.W. Black},
journal = {1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
pages = {373--376},
publisher = {Ieee},
title = {{Unit selection in a concatenative speech synthesis system using a large speech database}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=541110}
}
@inproceedings{Topper2002,
address = {Hamburg, Germany},
author = {Topper, D and Burtner, M and Serafin, S},
booktitle = {Proc. Conf. Digital Audio Effects},
pages = {1--5},
title = {{Spatio-operational Spectral (S.O.S.) Synthesis}},
year = {2002}
}
@inproceedings{Sturm2001a,
address = {New London, CT},
author = {Sturm, B L},
booktitle = {Proc. 8th Biennial Arts Tech. Symp.},
title = {{Synthesis and Algorithmic Composition Techniques Derived from Particle Physics}},
year = {2001}
}
@article{Morup2007,
author = {M$\backslash$orup, M and Schmidt, M N and Hansen, L K},
journal = {J. Machine Learning},
title = {{Shift Invariant Sparse Coding of Image and Music Data}},
year = {2007}
}
@inproceedings{Kawagoe2002,
address = {Washington, DC},
author = {Kawagoe, K and Ueda, T},
booktitle = {Proc. Int. Symp. Temporal Representation, Reasoning},
keywords = {DB},
pages = {86--92},
title = {{A Similarity Search Method of Time Series Data with Combination of Fourier and Wavelet Transforms}},
year = {2002}
}
@article{Schmid1997,
author = {Schmid, C and Mohr, R},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = may,
number = {5},
pages = {530--535},
title = {{Local grayvalue invariants for image retrieval}},
volume = {19},
year = {1997}
}
@article{Akcakaya2007b,
author = {Ak\c{c}akaya, M and Tarokh, V},
journal = {\{IEEE\} Signal Process. Lett.},
number = {11},
pages = {777--780},
title = {{Performance of Sparse Representation Algorithms using Randomly Generated Frames}},
volume = {14},
year = {2007}
}
@misc{Tropp2003,
author = {Tropp, J and Gilbert, A C and Strauss, M J and Muthukrishnan, S},
howpublished = {presentation slides},
title = {{Improved Sparse Approximation over Quasi-Incoherent Dictionaries}},
year = {2003}
}
@inproceedings{Struzik1999,
address = {London, UK},
author = {Struzik, Zbigniew R and Siebes, Arno},
booktitle = {PKDD '99: Proceedings of the Third European Conference on Principles of Data Mining and Knowledge Discovery},
pages = {12--22},
publisher = {Springer-Verlag},
title = {{The Haar Wavelet Transform in the Time Series Similarity Paradigm}},
year = {1999}
}
@inproceedings{Verfaille2001,
abstract = {Digital effects are most of the time non-adaptive: they are applied
with the same control values during the whole sound. Adaptive
digital audio effects are controlled by features extracted from the
sound itself. This means that both a time-frequency features extraction
and a mapping from these features to effects parameters
are needed. This way, the usual DAFx class is extended to a wider
class, the adaptive DAFx one. Four A-DAFx are proposed in this
paper, based on the phase vocoder technique: a selective timestretching,
an adaptive granular delay, an adaptive robotization and
an adaptive whisperization. They provide interesting sounds for
electroacoustic and electronic music, with a great coherence between
the effect and the original sound.},
address = {Limerick, Ireland},
author = {Verfaille, V and Arfib, D},
booktitle = {Proceedings of the COST G-6 Conference on Digital Audio Effects},
title = {{A-DAFx: Adaptive Digital Audio Effects}},
year = {2001}
}
@article{Gribonval2001a,
author = {Gribonval, R},
journal = {Journal of Approximation Theory},
pages = {128--138},
title = {{A counter-example to the general convergence of partially greedy algorithms}},
volume = {111},
year = {2001}
}
@article{Jincahitra2004,
author = {Jincahitra, P.},
journal = {2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)},
pages = {1211--1214},
publisher = {Ieee},
title = {{Polyphonic instrument identification using independent subspace analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1394439},
year = {2004}
}
@article{Andrle2006a,
author = {Andrle, M and Rebollo-Neira, L},
journal = {Signal Process.},
number = {3},
pages = {480--495},
title = {{A swapping-based refinement of orthogonal matching pursuit strategies}},
volume = {86},
year = {2006}
}
@article{Buzo1980a,
author = {Buzo, a. and Gray, a. and Gray, R. and Markel, J.},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
month = oct,
number = {5},
pages = {562--574},
title = {{Speech coding based upon vector quantization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1163445},
volume = {28},
year = {1980}
}
@article{Tropp2006b,
author = {Tropp, J},
journal = {Signal Process.},
number = {3},
pages = {589--602},
title = {{Algorithms for simultaneous sparse approximation. Part II: Convex relaxation}},
volume = {86},
year = {2006}
}
@article{Daubechies1996,
author = {Daubechies, I},
journal = {Proc. IEEE},
number = {4},
pages = {510--513},
title = {{Where do wavelets come from? A personal point of view}},
volume = {84},
year = {1991}
}
@article{Davies2007,
abstract = {We present a simple and efficient method for beat tracking of musical
audio. With the aim of replicating the human ability of tapping in
time to music, we formulate our approach using a two state model.
The first state performs tempo induction and tracks tempo changes,
while the second maintains contextual continuity within a single
tempo hypothesis. Beat times are recovered by passing the output
of an onset detection function through adaptively weighted comb filterbank
matrices to separately identify the beat period and alignment. We
evaluate our beat tracker both in terms of the accuracy of estimated
beat locations and computational complexity. In a direct comparison
with existing algorithms, we demonstrate equivalent performance at
significantly reduced computational cost.},
author = {Davies, M E P and Plumbley, M D},
file = {::},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {1009--1020},
title = {{Context-dependent beat tracking of musical audio}},
volume = {15},
year = {2007}
}
@article{Kronland-Martinet1997,
abstract = {Sound modelling is an important part of the analysis--synthesis process since it combines sound processing and algorithmic synthesis within the same formalism. Its aim is to make sound simulators by synthesis methods based on signal models or physical models, the parameters of which are directly extracted from the analysis of natural sounds. In this article the successive steps for making such systems are described. These are numerical synthesis and sound generation methods, analysis of natural sounds, particularly time--frequency and time--scale (wavelet) representations, extraction of pertinent parameters, and the determination of the correspondence between these parameters and those corresponding to the synthesis models. Additive synthesis, nonlinear synthesis, and waveguide synthesis are discussed.},
author = {Kronland-Martinet, R and Guillemain, P and Ystad, S},
journal = {Organised Sound},
keywords = {TFR},
number = {3},
pages = {179--191},
title = {{Modelling of Natural Sounds by Time Frequency and Wavelet Representations}},
volume = {2},
year = {1997}
}
@article{Abdallah2006,
author = {Abdallah, S A and Plumbley, M D},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {179--196},
title = {{Unsupervised Analysis of Polyphonic Music by Sparse Coding}},
volume = {17},
year = {2006}
}
@book{Xenakis1971,
address = {Bloomington, Indiana},
author = {Xenakis, I},
publisher = {Indiana University Press},
title = {{Formalized Music}},
year = {1971}
}
@book{Ledoux2006,
address = {Berlin},
author = {Ledoux, M and Talagrand, M},
publisher = {Springer},
title = {{Probability in Banach Spaces: Isoperimetry and Processes}},
year = {2006}
}
@article{Saastamoinen2005,
author = {Saastamoinen, Juhani and Karpov, Evgeny and Hautam\"{a}ki, Ville and Fr\"{a}nti, Pasi},
journal = {EURASIP Journal on Advances in Signal Processing},
keywords = {and phrases,fft,fixed point arithmetic,mfcc,round-off error,speaker identification,symbian},
number = {17},
pages = {2816--2827},
title = {{Accuracy of MFCC-Based Speaker Recognition in Series 60 Device}},
url = {http://www.hindawi.com/journals/asp/2005/878210.abs.html},
volume = {2005},
year = {2005}
}
@inproceedings{Sturm2001b,
address = {Leicester, UK},
author = {Sturm, B L},
booktitle = {Proc. Music Without Walls? Music Without Instruments? Conference},
month = jun,
title = {{Composing for an Ensemble of Atoms: The Metamorphosis of Scientific Experiment into Music."}},
year = {2001}
}
@inproceedings{Stober2010,
address = {Barcelona, Spain},
author = {Stober, S and N\"{u}rnberger, A},
booktitle = {Proc. Sound and Music Computing},
month = jul,
title = {{MusicGalaxy --- An Adaptive User-Interface for Exploratory Music Retrieval}},
year = {2010}
}
@article{Umapathy2005b,
author = {Umapathy, K and Krishnan, S and Jimaa, S},
journal = {IEEE Trans. Multimedia},
number = {2},
pages = {308--315},
title = {{Multigroup Classification of Audio Signals Using Time-Frequency Parameters}},
volume = {7},
year = {2005}
}
@article{Cowling2003,
author = {Cowling, M},
journal = {Pattern Recognition Letters},
keywords = {acoustic signal processing,audio signal processing,environmental sound recognition,joint time-frequency feature extraction,non-speech sound recognition},
month = nov,
number = {15},
pages = {2895--2907},
title = {{Comparison of techniques for environmental sound recognition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865503001478},
volume = {24},
year = {2003}
}
@article{Umapathy2007,
author = {Umapathy, K and Krishnan, S},
journal = {IEEE Trans. Signal Process.},
title = {{Time-width versus frequency band mapping of energy distributions}},
year = {2007}
}
@inproceedings{Sturm2008,
address = {Las Vegas, NV},
author = {Sturm, B L and Shynk, J J and Gauglitz, S},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {97--100},
title = {{Agglomerative clustering in sparse atomic decompositions of audio signals}},
year = {2008}
}
@inproceedings{Yi1998,
address = {Washington, DC, USA},
author = {Yi, Byoung-Kee and Jagadish, H V and Faloutsos, Christos},
booktitle = {ICDE '98: Proceedings of the Fourteenth International Conference on Data Engineering},
keywords = {DB},
pages = {201--208},
publisher = {IEEE Computer Society},
title = {{Efficient Retrieval of Similar Time Sequences Under Time Warping}},
year = {1998}
}
@inproceedings{Berger2008,
address = {Las Vegas, NV},
author = {Berger, C R and Areta, J and Pattipati, K and Willett, P},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {3857--3860},
title = {{COMPRESSED SENSING -- A LOOK BEYOND LINEAR PROGRAMMING}},
year = {2008}
}
@article{Elad2009,
author = {Elad, M and Yavneh, I},
journal = {IEEE Trans. Info. Theory},
number = {10},
pages = {4701--4714},
title = {{A Plurality of Sparse Representations is Better than the Sparsest One Alone}},
volume = {55},
year = {2009}
}
@inproceedings{Blumensath2005,
author = {Blumensath, T and Davies, M},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {213--216},
title = {{A fast importance sampling algorithm for unsupervised learning of over-complete dictionaries}},
volume = {5},
year = {2005}
}
@article{Andrle2006a,
author = {Andrle, M and Rebollo-Neira, L},
journal = {Signal Process.},
number = {3},
pages = {480--495},
title = {{A swapping-based refinement of orthogonal matching pursuit strategies}},
volume = {86},
year = {2006}
}
@article{Barrington2010,
author = {Barrington, L and Chan, A B and Lanckriet, G},
file = {:Users/pkmital/Documents/Mendeley Desktop/Barrington, Chan, Lanckriet/Barrington, Chan, Lanckriet - 2010 - Modeling Music as a Dynamic Texture - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {602--612},
title = {{Modeling Music as a Dynamic Texture}},
volume = {18},
year = {2010}
}
@article{Schroeder1962,
author = {Schroeder, M R and Atal, B S},
journal = {The Journal of the Acoustical Society of America},
number = {11},
pages = {1679--1683},
title = {{Generalized Short-Time Power Spectra and Autocorrelation Functions}},
volume = {34},
year = {1962}
}
@article{Wright2001,
author = {Wright, Matthew and Beauchamp, James and Fitz, Kelly and Rodet, Xavier and R\"{o}bel, Axel and Serra, Xavier and Wakefield, Gregory},
journal = {Organised Sound},
month = jul,
number = {03},
pages = {173--189},
title = {{Analysis/synthesis comparison}},
url = {http://www.journals.cambridge.org/abstract\_S1355771800005070},
volume = {5},
year = {2001}
}
@inproceedings{Lesage2006,
author = {Lesage, S and Mailh\'{e}, B and Gribonval, R},
booktitle = {Workshop on Transform Based on Independent Component Analysis for Audio, Video and Hyperspectral Images Data Reduction and Coding},
title = {{Apprentissage de motifs invariants par translation pour les d\'{e}compositions parcimonieuses}},
year = {2006}
}
@inproceedings{Amatriain2002,
abstract = {As audio and music applications tend to a higher level of abstraction and to fill in the gap between the signal processing
world and the end-user we are more and more interested on processing content and not (only) signal. This change in
point of view leads to the redefinition of several ``classical'' concepts, and a new conceptual framework needs to be set
to give support to these new trends. In [2], a model for the transmission of audio content was introduced. The model is
now extended to include the idea of Sound Objects. With these thoughts in mind, examples of design decisions that
have led to the implementation of the CLAM framework are also given.},
address = {Espoo, Finland},
author = {Amatriain, X and Herrera, P},
booktitle = {AES Int. Conf. on Virtual, Synthetic, and Entertainment Audio},
keywords = {MIR},
title = {{Transmitting Audio Content as Sound Objects}},
year = {2002}
}
@inproceedings{Shoa2006,
address = {Snowbird, Utah},
author = {Shoa, A and Shirani, S},
booktitle = {Proc. Data Compression Conf.},
pages = {466},
title = {{Distortion of Matching Pursuit: Modeling and Optimization}},
year = {2006}
}
@article{Buzo1980,
author = {Buzo, A and Gray, A H and Gray, R M and Markel, J D},
journal = {IEEE Trans. on Acoustics, Speech, and Signal Processing},
number = {5},
pages = {562--574},
title = {{Speech Coding Based Upon Vector Quantization}},
volume = {ASSP-28},
year = {1980}
}
@article{Allen1977c,
author = {Allen, J.B. and Rabiner, L.R.},
journal = {Proceedings of the IEEE},
number = {11},
pages = {1558--1564},
title = {{A unified approach to short-time Fourier analysis and synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1455039},
volume = {65},
year = {1977}
}
@article{Rabiner1989,
author = {Rabiner, L.R.},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=18626},
volume = {77},
year = {1989}
}
@inproceedings{Gribonval2002,
address = {Orlando, FL},
author = {Gribonval, R},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
month = may,
pages = {3057--3060},
title = {{Sparse decomposition of stereo signals with Matching Pursuit and application to blind separation of more than two sources from a stereo mixture}},
volume = {3},
year = {2002}
}
@article{Yaghoobi2009,
author = {Yaghoobi, M and Daudet, L and Davies, M},
journal = {IEEE Trans. Signal Process.},
title = {{Parametric Dictionary Design for Sparse Coding}}
}
@article{Elad2006b,
author = {Elad, M},
journal = {EURASIP J. Applied Signal Process.},
number = {1},
pages = {1--12},
title = {{Sparse Representations are most likely to be the sparsest possible}},
url = {http://www.hindawi.com/getarticle.aspx?doi=10.1155/asp/2006/96247},
volume = {2006},
year = {2006}
}
@article{Christensen2006,
author = {Christensen, M G and Jensen, S H},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {1},
pages = {99--109},
title = {{On Perceptual Distortion Minimization and Nonlinear Least-Squares Frequency Estimation}},
volume = {14},
year = {2006}
}
@inproceedings{Kang2008,
address = {Las Vegas, NV},
author = {Kang, T and Iltis, R},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {5296--5299},
title = {{MATCHING PURSUITS CHANNEL ESTIMATION FOR AN UNDERWATER ACOUSTIC OFDM MODEM}},
year = {2008}
}
@phdthesis{Blumensath2006,
author = {Blumensath, T},
school = {Queen Mary, University of London},
title = {{Bayesian Modelling of Music: Algorithmic Advances and Experimental Studies of Shift-Invariant Sparse Coding}},
year = {2006}
}
@article{Liu2006,
author = {Liu, C and Wechsler, H},
journal = {IEEE Trans. Pattern Analysis and Machine Intelligence},
month = jun,
number = {6},
pages = {570--582},
title = {{Evolutionary pursuit and its application to face recognition}},
volume = {22},
year = {2006}
}
@article{Panagakis2010,
author = {Panagakis, Y and Kotopoulos, C and Arce, G R},
journal = {IEEE Trans. Acoustics, Speech, Lang. Process.},
number = {3},
pages = {576--588},
title = {{Non-negative multilinear principal component analysis of auditory temporal modulations for music genre classification}},
volume = {18},
year = {2010}
}
@inproceedings{Elad2005,
author = {Elad, M},
booktitle = {Proc. SPARS'05 Conf.},
title = {{SHRINKAGE FOR REDUNDANT REPRESENTATIONS}},
year = {2005}
}
@article{Harris1978,
author = {Harris, F J},
journal = {Proc. IEEE},
number = {1},
pages = {51--83},
title = {{On the Use of Windows for Harmonic Analysis with the Discrete Fourier Transform}},
volume = {66},
year = {1978}
}
@inproceedings{Polack2006,
author = {Polack, J.-D.},
booktitle = {Proceedings of the Institute of Acoustics},
pages = {2},
title = {{Reverberation time and mean absorption in concert halls}},
volume = {28},
year = {2006}
}
@article{Donoho2006a,
author = {Donoho, D L and Elad, M and Temlyakov, V N},
journal = {IEEE Trans. Information Theory},
number = {1},
pages = {6--18},
title = {{Stable Recovery of Sparse Overcomplete Representations in the Presence of Noise}},
volume = {52},
year = {2006}
}
@article{Lobo,
author = {a.P. Lobo and Loizou, P.C.},
journal = {2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},
pages = {I--820--I--823},
publisher = {Ieee},
title = {{Voiced/unvoiced speech discrimination in noise using Gabor atomic decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1198907}
}
@book{Hamming1989,
author = {Hamming, R W},
edition = {3},
publisher = {Dover},
title = {{Digital Filters}},
year = {1989}
}
@article{Kurth2008a,
author = {Kurth, F and M\"{u}ller, M},
file = {::},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {2},
pages = {382--395},
title = {{Efficient index-based audio matching}},
volume = {16},
year = {2008}
}
@article{Chen1995b,
author = {Chen, S and Wigger, J},
journal = {IEEE Trans. Signal Process.},
month = jul,
number = {7},
pages = {1713--1715},
title = {{Fast orthogonal least-squares algorithm for efficient subset model selection}},
volume = {43},
year = {1995}
}
@article{Chang1987,
author = {Chang, P -C. and Gray, R M and May, J},
journal = {IEEE Trans. on Communications},
number = {10},
pages = {1059--1068},
title = {{Fourier Transform Vector Quantization for Speech Coding}},
volume = {35},
year = {1987}
}
@article{Kostek2004,
author = {Kostek, B.},
journal = {Proceedings of the IEEE},
keywords = {duet separation,mir,mpeg-7,music information,musical content processing,musical data manage-,retrieval},
month = apr,
number = {4},
pages = {712--729},
title = {{Musical Instrument Classification and Duet Analysis Employing Music Information Retrieval Techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1278693},
volume = {92},
year = {2004}
}
@inproceedings{Monro2006,
address = {Kos, Greece},
author = {Monro, D M},
booktitle = {Proc. IEEE Int. Symp. Circuits Syst.},
month = may,
pages = {2985--2988},
title = {{Basis picking for matching pursuits audio compression}},
volume = {4},
year = {2006}
}
@phdthesis{Gribonval1999,
address = {Paris, France},
author = {Gribonval, R},
school = {Universit\'{e} de Paris IX Daupine},
title = {{Approximations Non-lin\'{e}aires pour l'Analyse des Signaux Sonores}},
year = {1999}
}
@article{Rioul1991,
author = {Rioul, O and Vetterli, M},
journal = {IEEE Signal Processing Mag.},
number = {4},
pages = {14--38},
title = {{Wavelets and signal processing}},
volume = {8},
year = {1991}
}
@article{Sturm2005,
author = {Sturm, B.L. and Gibson, J.D.},
journal = {Proceedings Frontiers in Education 35th Annual Conference},
pages = {F2E--21--F2E--26},
publisher = {Ieee},
title = {{Signals and Systems Using MATLAB: An Integrated Suite of Applications for Exploring and Teaching Media Signal Processing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1612054},
year = {2005}
}
@article{Cohen1989,
author = {Cohen, L},
journal = {Proc. IEEE},
keywords = {TFR},
month = jul,
number = {7},
pages = {941--981},
title = {{Time-Frequency Distributions---\{A\} Review}},
volume = {77},
year = {1989}
}
@phdthesis{Essid2005,
address = {Paris, France},
author = {Essid, S},
school = {Universit\'{e} Pierre et Marie Curie, Paris 6},
title = {{Classification automatique des signaux audio-fr\'{e}quence: reconnaissance des instruments de musique}},
year = {2005}
}
@article{Rath2010a,
author = {Rath, Gagan and Guillemot, Christine},
journal = {Signal Processing},
keywords = {Complementary matching pursuit,Greedy algorithms,Matching pursuit,Orthogonal matching pursuit,sparse approximation},
month = feb,
number = {2},
pages = {702--706},
publisher = {Elsevier},
title = {{On a simple derivation of the complementary matching pursuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168409003442},
volume = {90},
year = {2010}
}
@article{Lawson2002,
author = {Lawson, S and Zhu, J},
journal = {Elec. Comm. Eng. J.},
month = jun,
number = {3},
pages = {112--121},
title = {{Image compression using wavelets and \{JPEG2000\}: a tutorial}},
volume = {14},
year = {2002}
}
@article{Lawson2002,
author = {Lawson, S and Zhu, J},
journal = {Elec. Comm. Eng. J.},
month = jun,
number = {3},
pages = {112--121},
title = {{Image compression using wavelets and \{JPEG2000\}: a tutorial}},
volume = {14},
year = {2002}
}
@inproceedings{Li2008a,
address = {Harbin, China},
author = {Li, Q and Wu, L and He, X},
booktitle = {Proc. Int. Conf. Intelligent Info. Hiding and Multimedia Signal Process.},
pages = {791--794},
title = {{Content-Based Audio Retrieval Using Perceptual Hash}},
year = {2008}
}
@incollection{Amatriain2002a,
address = {Chicester, England},
author = {Amatriain, X and Bonada, J and Loscos, A and Serra, X},
booktitle = {\{DAFx\}: Digital Audio Effects},
editor = {Z\"{o}lzer, U},
pages = {373--438},
publisher = {Wiley},
title = {{Spectral Processing}},
year = {2002}
}
@article{Atal2006,
author = {Atal, B S},
file = {::},
journal = {IEEE Signal Processing Mag.},
month = mar,
pages = {154--158},
title = {{The History of Linear Prediction}},
year = {2006}
}
@article{Allen1977a,
author = {Allen, J B and Rabiner, L},
journal = {Proc. IEEE},
keywords = {TFR},
number = {11},
pages = {1558--1564},
title = {{A Unified Approach to Short-Time \{F\}ourier Analysis and Synthesis}},
volume = {65},
year = {1977}
}
@inproceedings{Monaci2005,
address = {Genova, Italy},
author = {Monaci, G and Escoda, O D and Vandergheynst, P},
booktitle = {IEEE Int. Conf. Image Process.},
pages = {46--49},
title = {{Analysis of multimodal signals using redundant representations}},
volume = {3},
year = {2005}
}
@article{Durka2005,
author = {Durka, P J},
journal = {BioMedical Engineering OnLine},
number = {15},
title = {{On the methodological unification in electroencephalography}},
url = {http://www.biomedical-engineering-online.com/content/4/1/15},
volume = {4},
year = {2005}
}
@inproceedings{Aucouturier2002,
address = {Paris, France},
author = {Aucouturier, J-.J. and Pachet, F},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Music Similarity Measures: What's The Use?}},
year = {2002}
}
@article{Chen1998,
author = {Chen, S S and Donoho, D L and Saunders, M A},
journal = {SIAM J. Sci. Comput.},
number = {1},
pages = {33--61},
title = {{Atomic Decomposition by Basis Pursuit}},
volume = {20},
year = {1998}
}
@article{Mierswa2005,
author = {Mierswa, I and Morik, K},
journal = {Machine Learning J.},
pages = {127--149},
title = {{Automatic feature extraction for classifying audio data}},
volume = {58},
year = {2005}
}
@article{Aucouturier2007,
author = {Aucouturier, J-.J. and Defreville, B and Pachet, F},
journal = {J. Acoust. Soc. America},
number = {2},
pages = {881--891},
title = {{The bag of frames approach to audio pattern recognition: A sufficient model for urban soundscapes but not for polyphonic music}},
volume = {122},
year = {2007}
}
@article{Allen1977b,
author = {Allen, J B},
journal = {IEEE Trans. on Acoustics, Speech, and Signal Processing},
keywords = {TFR},
number = {3},
pages = {235--238},
title = {{Short Term Spectral Analysis, Synthesis, and Modification by Discrete Fourier Transform}},
volume = {25},
year = {1977}
}
@inproceedings{Li1996,
address = {New Orleans, LA},
author = {Li, C.-S. and Yu, P S and Castelli, V},
booktitle = {Proc. Int. Conf. Data Eng.},
pages = {546--553},
title = {{HierarchyScan: A Hierarchical Similarity Search Algorithm for Databases of Long Sequences}},
year = {1996}
}
@conference{Bertin2005,
address = {London, UK},
author = {Bertin, N and de Cheveign\'{e}, A},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
pages = {238--244},
title = {{Scalable Metadata and Quick Retrieval of Audio Signals}},
year = {2005}
}
@article{Nesbit2007,
abstract = {Audio source separation is a very challenging problem, and many different
approaches have been proposed in attempts to solve it. We consider
the problem of separating sources from two-channel instantaneous
audio mixtures. One approach to this is to transform the mixtures
into the time-frequency domain to obtain approximately disjoint representations
of the sources, and then separate the sources using time-frequency
masking. We focus on demixing the sources by binary masking, and
assume that the mixing parameters are known. In this paper, we investigate
the application of cosine packet (CP) trees as a foundation for the
transform. We determine an appropriate transform by applying a computationally
efficient best basis algorithm to a set of possible local cosine
bases organised in a tree structure. We develop a heuristically motivated
cost function which maximises the energy of the transform coefficients
associated with a particular source. Finally, we evaluate objectively
our proposed transform method by comparing it against fixed-basis
transforms such as the short-time Fourier transform (STFT) and modified
discrete cosine transform (MDCT). Evaluation results indicate that
our proposed transform method outperforms MDCT and is competitive
with the STFT, and informal listening tests suggest that the proposed
method exhibits less objectionable noise than the STFT.},
author = {Nesbit, A and Plumbley, M D and Davies, M E},
journal = {Signal Process.},
number = {8},
pages = {1848--1858},
title = {{Audio Source Separation with a Signal-Adaptive Local Cosine Transform}},
volume = {87},
year = {2007}
}
@article{Casey2008a,
author = {Casey, M and Veltkamp, R and Goto, M and Leman, M and Rhodes, C and Slaney, M},
file = {::},
journal = {Proc. IEEE},
number = {4},
pages = {668--696},
title = {{Content-based Music Information Retrieval: Current Directions and Future Challenges}},
volume = {96},
year = {2008}
}
@article{Pardalos2010,
author = {Pardalos, Panos},
journal = {Optimization Methods and Software},
month = jun,
number = {3},
pages = {487--487},
title = {{Convex optimization theory}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/10556781003625177\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {25},
year = {2010}
}
@article{Bergstra2006,
address = {Hingham, MA, USA},
author = {Bergstra, James and Casagrande, Norman and Erhan, Dumitru and Eck, Douglas and K\'{e}gl, Bal\'{a}zs},
journal = {Mach. Learn.},
number = {2-3},
pages = {473--484},
publisher = {Kluwer Academic Publishers},
title = {{Aggregate features and ADABOOST for music classification}},
volume = {65},
year = {2006}
}
@inproceedings{Sturm2000,
address = {Atlanta, GA},
author = {Sturm, B L},
booktitle = {Proc. Int. Conf. Auditory Display},
title = {{Sonification of Particle Systems via de Broglie's Hypothesis}},
year = {2000}
}
@article{Tropp2004,
author = {Tropp, J},
file = {:Users/pkmital/Documents/Mendeley Desktop/Tropp/Tropp - 2004 - Greed is good Algorithmic results for sparse approximation - IEEE Trans. Info. Theory.pdf:pdf},
journal = {IEEE Trans. Info. Theory},
number = {10},
pages = {2231--2242},
title = {{Greed is good: Algorithmic results for sparse approximation}},
volume = {50},
year = {2004}
}
@article{Al-Shaykh1999,
author = {Al-Shaykh, O K and Miloslavsky, E and Nomura, T and Neff, R and Zakhor, A},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {1},
pages = {123--143},
title = {{Video compression using matching pursuits}},
volume = {9},
year = {1999}
}
@inproceedings{Amatriain2002,
abstract = {As audio and music applications tend to a higher level of abstraction and to fill in the gap between the signal processing
world and the end-user we are more and more interested on processing content and not (only) signal. This change in
point of view leads to the redefinition of several ``classical'' concepts, and a new conceptual framework needs to be set
to give support to these new trends. In [2], a model for the transmission of audio content was introduced. The model is
now extended to include the idea of Sound Objects. With these thoughts in mind, examples of design decisions that
have led to the implementation of the CLAM framework are also given.},
address = {Espoo, Finland},
author = {Amatriain, X and Herrera, P},
booktitle = {AES Int. Conf. on Virtual, Synthetic, and Entertainment Audio},
keywords = {MIR},
title = {{Transmitting Audio Content as Sound Objects}},
year = {2002}
}
@article{Pei1997,
author = {Pei, S.-C. and Yeh, M.-H.},
journal = {IEEE Sig. Process. Mag.},
pages = {84--96},
title = {{An introduction to discrete finite frames}},
year = {1997}
}
@article{Jang2005,
author = {Jang, H K and Park, J S},
journal = {IEEE Trans. Speech and Audio Processing},
number = {2},
pages = {254--262},
title = {{Multiresolution sinusoidal model with dynamic segmentation for timescale modification of polyphonic audio signals}},
volume = {13},
year = {2005}
}
@inproceedings{Jensen2002,
author = {Jensen, J and Heusdens, R},
booktitle = {Proc. European Signal Processing Conf.},
title = {{A Comparison of Sinusoidal Model Variants for Speech and Audio Representation}},
year = {2002}
}
@article{Plumbley2007,
author = {Plumbley, M D},
journal = {IEEE Trans. Info. Theory},
number = {9},
pages = {3188--3195},
title = {{On polar polytopes and the recovery of sparse representations}},
volume = {53},
year = {2007}
}
@article{Evangelista2001,
author = {Evangelista, G},
journal = {Journal of New Music Research},
keywords = { wavelets,TFR},
number = {1},
pages = {13--22},
title = {{Flexible Wavelets for Music Signal Processing}},
volume = {30},
year = {2001}
}
@inproceedings{Sturm2001a,
address = {New London, CT},
author = {Sturm, B L},
booktitle = {Proc. 8th Biennial Arts Tech. Symp.},
title = {{Synthesis and Algorithmic Composition Techniques Derived from Particle Physics}},
year = {2001}
}
@article{Guo2003a,
author = {Guo, G and Li, S Z},
file = {:Users/pkmital/Documents/Mendeley Desktop/Guo, Li/Guo, Li - 2003 - Content-Based Audio Classification and Retrieval by Support Vector Machines - IEEE Trans. Neural Networks.pdf:pdf},
journal = {IEEE Trans. Neural Networks},
number = {1},
pages = {209--215},
title = {{Content-Based Audio Classification and Retrieval by Support Vector Machines}},
volume = {14},
year = {2003}
}
@inproceedings{Typke2005,
address = {London, U.K.},
author = {Typke, R and Wiering, F and Veltkamp, R C},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{A Survey of Music Information Retrieval Systems}},
year = {2005}
}
@unpublished{Wickerhauser1991,
author = {Wickerhauser, Mladen V},
pages = {75},
title = {{Lectures on wavelet packet algorithms}},
url = {citeseer.ist.psu.edu/124574.html}
}
@techreport{Hsu2003,
address = {Taiwan, China},
author = {Hsu, C W and Chang, C C and Lin, C J},
institution = {National Taiwan University},
month = may,
number = {http://www.csie.ntu.edu.tw/\~{}cjlin},
title = {{A Practical Guide to Support Vector Classification}},
year = {2009}
}
@phdthesis{Sun2004,
author = {Sun, X},
month = jun,
school = {University of California, Santa Barbara},
title = {{Motion Activity for Video Indexing}},
year = {2004}
}
@article{Daudet2006a,
author = {Daudet, L.},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = sep,
number = {5},
pages = {1808--1816},
title = {{Sparse and structured decompositions of signals with the molecular matching pursuit}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1677999},
volume = {14},
year = {2006}
}
@inproceedings{Divekar2009,
author = {Divekar, A and Ersoy, O},
booktitle = {Proc. Asilomar Conf. Signals, Systems, and Computers},
title = {{Compact Storage of Correlated Data for Content Based Retrieval}},
year = {2009}
}
@article{Moghadam2007,
author = {E.-Moghadam, A and Shahram, S},
journal = {IEEE Trans. Image Process.},
number = {2},
pages = {406--415},
title = {{Matching pursuit-based region-of-interest image coding}},
volume = {16},
year = {2007}
}
@article{Raphael1999,
author = {Raphael, C.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = apr,
number = {4},
pages = {360--370},
title = {{Automatic segmentation of acoustic musical signals using hidden Markov models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=761266},
volume = {21},
year = {1999}
}
@inproceedings{Hunt1996,
address = {Atlanta, Georgia},
author = {Hunt, A J and Black, A W},
booktitle = {Proc. Int. Conf. On Acoustics, Speech, and Signal Processing},
keywords = {CSS},
organization = {IEEE},
pages = {373--376},
title = {{Unit selection in a concatenative speech synthesis system using a large speech database}},
year = {1996}
}
@conference{Akcakaya2007,
address = {Princeton, NJ},
author = {Ak\c{c}akaya, M and Tarokh, V},
booktitle = {Proc. Conf. Info. Sciences Syst.},
pages = {726--729},
title = {{Performance Study of Various Sparse Representation Methods Using Redundant Frames}},
year = {2007}
}
@article{Kronland-Martinet1989,
author = {Kronland-Martinet, R},
journal = {Computer Music J.},
number = {4},
pages = {11--20},
title = {{The Wavelet Transform for Analysis, Synthesis, and Processing of Speech and Music Sounds}},
volume = {12},
year = {1989}
}
@article{Beller2005,
abstract = {In this paper, we describe a concatenative synthesis system
which was first designed for a realistic synthesis of
melodic phrases. It has since been augmented to become
an experimental TTS (Text-to-Speech) synthesizer. Today,
it is able to realize hybrid synthesis involving speech
segments and musical excerpts coming from any recording
imported in its database. The system can also synthesize
sentences with different voices, sentences with musical
sounds, melodic phrases with speech segments and
generate compositional material from specific intonation
patterns using a prosodic pattern extractor.},
author = {Beller, G and Schwarz, D and Hueber, T and Rodet, X},
journal = {Journ\{\'{e}\}es d'Informatique Musicale},
keywords = { CSS,synth},
title = {{A Hybrid Concatenative Synthesis System on the Intersection of Music and Speech}},
url = {http://jim2005.mshparisnord.net/download/6.hybridconcat.pdf},
year = {2005}
}
@article{Casey2001,
author = {Casey, M},
journal = {IEEE Trans. Circuits Systems Video Tech.},
month = jun,
number = {6},
pages = {737--747},
title = {{\{MPEG\}-7 Sound-Recognition Tools}},
volume = {11},
year = {2001}
}
@article{Gribonval,
author = {Gribonval, R.},
journal = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {III--3057--III--3060},
publisher = {Ieee},
title = {{Sparse decomposition of stereo signals with matching pursuit and application to blind separation of more than two sources from a stereo mixture}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1005332}
}
@article{Muller2010,
author = {M\"{u}ller, M and Ewert, S},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
number = {3},
pages = {649--662},
title = {{Towards Timbre-Invariant Audio Features for Harmony-Based Music}},
volume = {18},
year = {2010}
}
@article{Gribonval2005a,
author = {Gribonval, R},
journal = {IEEE Trans. Neural Networks},
number = {3},
pages = {522--532},
title = {{From Projection Pursuit and CART to Adaptive Discriminant Analysis?}},
volume = {16},
year = {2005}
}
@article{Masri1997a,
author = {Masri, P and Bateman, A and Canagarajah, N},
journal = {Organised Sound},
number = {3},
pages = {193--205},
title = {{A review of time-frequency representations with application to sound/music analysis-synthesis}},
volume = {2},
year = {1997}
}
@article{Etemoglu2003,
author = {Etemo$\backslash$uglu, \c{C} \"{O} and Cuperman, V},
journal = {IEEE Trans. Speech Audio Process.},
number = {5},
pages = {413--424},
title = {{Matching pursuits sinusoidal speech coding}},
volume = {11},
year = {2003}
}
@article{Haitsma2003,
author = {Haitsma, J and Kalker, T},
journal = {J. New Music Research},
month = jun,
number = {2},
pages = {211--221},
title = {{A Highly Robust Audio Fingerprinting System With an Efficient Search Strategy}},
volume = {32},
year = {2003}
}
@article{Andrle2004,
author = {Andrle, M and Rebollo-Neira, L and Sagianos, E},
journal = {\{IEEE\} Signal Process. Lett.},
number = {9},
pages = {705--708},
title = {{Backward-optimized Orthogonal Matching Pursuit Approach}},
volume = {11},
year = {2004}
}
@inproceedings{Ganchev2005,
address = {Patras, Greece},
author = {Ganchev, T and Fakotakis, N and Kokkinakis, G},
booktitle = {Proc. Int. Conf. Speech Computer},
pages = {191--194},
title = {{Comparative evaluation of various MFCC implementations on the speaker verification task}},
volume = {1},
year = {2005}
}
@phdthesis{Every2006,
author = {Every, M R},
school = {University of the Witwatersrand},
title = {{Separation of Musical Sources and Structure from Single-Channel Polyphonic Recordings}},
year = {2006}
}
@article{Akcakaya2007b,
author = {Ak\c{c}akaya, M and Tarokh, V},
journal = {\{IEEE\} Signal Process. Lett.},
number = {11},
pages = {777--780},
title = {{Performance of Sparse Representation Algorithms using Randomly Generated Frames}},
volume = {14},
year = {2007}
}
@article{Casey2008,
author = {Casey, M and Rhodes, C and Slaney, M},
file = {:Users/pkmital/Documents/Mendeley Desktop/Casey, Rhodes, Slaney/Casey, Rhodes, Slaney - 2008 - Analysis of Minimum Distances in High-Dimensional Musical Spaces - IEEE Trans. Audio, Speech, Lang. Process.pdf:pdf},
journal = {IEEE Trans. Audio, Speech, Lang. Process.},
keywords = { DB,MIR},
month = jul,
number = {5},
pages = {1015--1028},
title = {{Analysis of Minimum Distances in High-Dimensional Musical Spaces}},
volume = {16},
year = {2008}
}
@article{Donoho2006b,
author = {Donoho, D L},
journal = {IEEE Trans. Info. Theory},
number = {4},
pages = {1289--1306},
title = {{Compressed sensing}},
volume = {52},
year = {2006}
}
@article{Serra1990,
author = {Serra, X and {Smith III}, J O},
journal = {Computer Music J.},
pages = {12--24},
title = {{Spectral modeling synthesis: a sound analysis/synthesis system based on a deterministic plus stochastic decomposition}},
volume = {14},
year = {1990}
}
@inproceedings{Derrien2006,
address = {Toulouse, France},
author = {Derrien, O},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {57--60},
title = {{Multi-scale frame-based analysis of audio signals for musical transcription using a dictionary of chromatic waveforms}},
volume = {5},
year = {2006}
}
@article{Huggins2007,
author = {Huggins, P S and Zucker, S W},
journal = {IEEE Trans. Signal Process.},
month = jul,
number = {7},
pages = {3760--3772},
title = {{Greedy Basis Pursuit}},
volume = {55},
year = {2007}
}
@inproceedings{Krishnan1997a,
address = {Chicago, IL},
author = {Krishnan, S and Rangayyan, R M and Bell, G D and Frank, C B},
booktitle = {Proc. Int. Conf. Eng. in Medicine and Biology},
pages = {1309--1312},
publisher = {IEEE},
title = {{Time-frequency signal feature extraction and screening of knee joint vibroarthrographic signals using the matching pursuit method}},
volume = {3},
year = {1997}
}
@article{Heusdens2002,
author = {Heusdens, R and Vafin, R and Kleijn, W B},
journal = {\{IEEE\} Signal Process. Lett.},
number = {8},
pages = {262--265},
title = {{Sinusoidal Modeling Using Psychoacoustic-Adaptive Matching Pursuits}},
volume = {9},
year = {2002}
}
@techreport{Donoho2004,
author = {Donoho, D L},
institution = {Stanford University},
title = {{For Most Large Underdetermined Systems of Linear Equations, the minimal $\backslash$ell\_1-norm solution is also the sparsest solution}},
year = {2004}
}
@article{Masri1997b,
author = {Masri, P and Bateman, A and Canagarajah, N},
journal = {Organised Sound},
number = {3},
pages = {207--214},
title = {{The importance of the time-frequency representation for sound/music analysis-resynthesis}},
volume = {2},
year = {1997}
}
@article{Nuttall1981,
author = {Nuttall, A},
journal = {IEEE Trans. Acoustics, Speech, and Sig. Process.},
number = {1},
pages = {84--91},
title = {{Some Windows with Very Good Sidelobe Behavior}},
volume = {29},
year = {1981}
}
@inproceedings{Leveau2005,
address = {Rennes, France},
author = {Leveau, P and Daudet, L},
booktitle = {Signal Processing with Adaptative Sparse Structured Representations},
title = {{Model-based Matching Pursuit: Estimation of Chirp Factors and Scale of Gabor Atoms with Iterative Extension}},
year = {2005}
}
@article{Harris1978,
author = {Harris, F J},
journal = {Proc. IEEE},
number = {1},
pages = {51--83},
title = {{On the Use of Windows for Harmonic Analysis with the Discrete Fourier Transform}},
volume = {66},
year = {1978}
}
@inproceedings{Sturm2008d,
address = {Belfast, Ireland},
author = {Sturm, B L and Roads, C and McLeran, A and Shynk, J J},
booktitle = {Proc. Int. Computer Music Conf.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Sturm et al/Sturm et al. - 2009 - Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods - J. New Music Researc.pdf:pdf},
title = {{Analysis, Visualization, and Transformation of Audio Signals Using Dictionary-based Methods}},
year = {2008}
}
@inproceedings{Wipf2005,
author = {Wipf, D P and Rao, B D},
booktitle = {Proc. SPARS'05 Conf.},
title = {{FINDING SPARSE REPRESENTATIONS IN MULTIPLE RESPONSE MODELS VIA BAYESIAN LEARNING}},
year = {2005}
}
@article{Krishnan,
author = {Krishnan, S. and Rangayyan, R.M.},
journal = {1997 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, PACRIM. 10 Years Networking the Pacific Rim, 1987-1997},
pages = {138--141},
publisher = {Ieee},
title = {{Detection of chirp and other components in the time-frequency plane using the Hough and Radon transforms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=619920}
}
@article{Masri1997b,
author = {Masri, P and Bateman, A and Canagarajah, N},
journal = {Organised Sound},
number = {3},
pages = {207--214},
title = {{The importance of the time-frequency representation for sound/music analysis-resynthesis}},
volume = {2},
year = {1997}
}
@inproceedings{Wu2000,
address = {McLean, Virginia, United States},
author = {Wu, Y.-L. and Agrawal, D and {El Abbadi}, A},
booktitle = {Proc. Ninth Int. Conf. on Information and Knowledge Management},
keywords = {DB},
pages = {488--495},
title = {{A comparison of DFT and DWT based similarity search in time-series databases}},
year = {2000}
}
@article{Gribonval2006b,
author = {Gribonval, R and i Ventura, R M Figueras and Vandergheynst, P},
journal = {Signal Process.},
number = {3},
pages = {496--510},
title = {{A simple test to check the optimality of a sparse signal approximation}},
volume = {86},
year = {2006}
}
@inproceedings{Holzapfel2009,
address = {Taipei, Taiwan},
author = {Holzapfel, A and Stylianou, Y},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {317--320},
title = {{A Scale Based Method for Rhythmic Similarity of Music}},
year = {2009}
}
@article{Sturm2006a,
author = {Sturm, B L},
journal = {J. New Music Research},
number = {1},
pages = {23--33},
title = {{Concatenative Sound Synthesis and Intellectual Property: An Analysis of the Legal Issues Surrounding the Synthesis of Novel Sounds from Copyright-Protected Work}},
volume = {35},
year = {2006}
}
@inproceedings{Tzanetakis2002c,
abstract = {The majority of existing work in music information retrieval
for audio signals has followed the content-based
query-by-example paradigm. In this paradigm a musical
piece is used as a query and the result is a list of
other musical pieces ranked by their content similarity.
In this paper we describe algorithms and graphical
user interfaces that enable novel alternative ways for
querying and browsing large audio collections. Computer
audition algorithms are used to extract content
information from audio signals. This automatically extracted
information is used to configure the graphical
user interfaces and to genereate new query audio signals
for browsing and retrieval.},
author = {Tzanetakis, G and Ermolinskyi, A and Cook, P},
booktitle = {Proc. Int. Computer Music Conf.},
keywords = {MIR},
title = {{Beyond the Query-By-Example Paradigm: New Query Interfaces for Music Information Retrieval}},
year = {2002}
}
@inproceedings{Parvaix2008,
address = {Las Vegas, NV},
author = {Parvaix, M and Krishnan, S and Ioana, C},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {1721--1724},
title = {{An Audio Watermarking Method Based on Molecular Matching Pursuit}},
year = {2008}
}
@inproceedings{Mandel2005,
address = {London, U.K.},
author = {Mandel, M and Ellis, D P W},
booktitle = {Proc. Int. Symp. Music Info. Retrieval},
title = {{Song-Level Features And Support Vector Machines For Music Classification}},
year = {2005}
}
@article{Giacobello2010,
author = {Giacobello, D and Christensen, M and Murthi, M N and Jensen, S H and Moonen, M},
journal = {IEEE Sig. Proc. Letts.},
number = {1},
pages = {103--106},
title = {{Retrieving Sparse Patterns Using a Compressed Sensing Framework: Applications to Speech Coding Based on Sparse Linear Prediction}},
volume = {17},
year = {2010}
}
@article{Plumbley2006a,
author = {Plumbley, M and Abdallah, S and Blumensath, T and Davies, M},
journal = {Signal Processing},
keywords = {automatic music transcription,ica,independent component analysis,music signal processing,sparse coding},
month = mar,
number = {3},
pages = {417--431},
title = {{Sparse representations of polyphonic music}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405002124},
volume = {86},
year = {2006}
}
@inproceedings{Gowreesunker2008,
address = {Las Vegas, NV},
author = {Gowreesunker, B V and Tewfik, A H},
booktitle = {Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.},
pages = {33--36},
title = {{BLIND SOURCE SEPARATION USING MONOCHANNEL OVERCOMPLETE DICTIONARIES}},
year = {2008}
}
@article{Rahmoune2006,
author = {Rahmoune, A and Vandergheynst, P and Frossard, P},
journal = {IEEE Trans. Circuits Syst. Video Technol.},
number = {2},
pages = {178--190},
title = {{Flexible Motion-Adaptive Video Coding With Redundant Expansions}},
volume = {16},
year = {2006}
}
@article{Umapathy2005a,
author = {Umapathy, K and Krishnan, S and Parsa, V and Jamieson, D G},
journal = {IEEE Trans. Biomedical Eng.},
number = {3},
pages = {421--430},
title = {{Discrimination of Pathological Voices Using a Time-Frequency Approach}},
volume = {52},
year = {2005}
}
@article{Lewicki2000,
author = {Lewicki, M S and Sejnowski, T J},
journal = {Neural Computation},
pages = {337--365},
title = {{Learning Overcomplete Representations}},
volume = {12},
year = {2000}
}
@article{Zhang2001,
author = {Zhang, T and Kuo, C.-C. J},
journal = {IEEE Trans. Speech Audio Process.},
month = may,
number = {4},
pages = {441--457},
title = {{Audio content analysis for online audiovisual data segmentation and classification}},
volume = {9},
year = {2001}
}
@techreport{Gribonval2004a,
address = {Rennes, France},
author = {Gribonval, R and i Ventura, R M Figueras and Vandergheynst, P},
institution = {Institut de Recherche en Informatique et Syste\`{e}mes Al\'{e}atoires},
number = {1161},
title = {{A simple test to check the optimality of sparse signal approximations}},
year = {2004}
}
@inproceedings{Gribonval2003b,
address = {San Diego, CA, USA},
author = {Gribonval, R},
booktitle = {Proc. Soc. Photographic Instrumentation Eng.},
pages = {297--310},
title = {{Piecewise linear source separation}},
volume = {5207},
year = {2003}
}
@article{Malinowska2006,
author = {Malinowska, U and Durka, P J and Blinowska, K J and Szelenberger, W and Wakarow, A},
journal = {IEEE Eng. Med. Biol. Mag.},
number = {4},
pages = {26--31},
title = {{Micro- and Macrostructure of Sleep \{EEG\}: \{A\} Universal Adaptive Time-Frequency Parameterization}},
volume = {25},
year = {2006}
}
@inproceedings{Nakajima1999,
address = {Phoenix, AZ},
author = {Nakajima, Y and Lu, Y and Sugano, M and Yoneyama, A and Yamagihara, H and Kurematsu, A},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, Signal Process.},
pages = {3005--3008},
title = {{A fast audio classification from MPEG coded data}},
volume = {6},
year = {1999}
}
@inproceedings{Tropp2005,
author = {Tropp, J A and Gilbert, A C and Strauss, M J},
booktitle = {Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing},
title = {{Simultaneous Sparse Approximation via Greedy Pursuit}},
year = {2005}
}
@inproceedings{Hansen2005,
address = {Espoo, Finland},
author = {Hansen, L K and Ahrendt, P and Larsen, J},
booktitle = {Proc. Int. Interdisciplinary Conf. Adaptive Knowledge Representation Reasoning},
month = jun,
pages = {148--153},
title = {{Towards Cognitive Component Analysis}},
year = {2005}
}
@article{Holleis2007,
abstract = {The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.},
author = {Holleis, Paul and Otto, Friederike and Hussmann, Heinrich and Schmidt, Albrecht},
journal = {Conference on Human Factors in Computing Systems},
keywords = {design decisions,keystroke-level model (KLM),mobile phone interaction,real world interaction,user performance},
pages = {1505},
title = {{Keystroke-level model for advanced mobile phone interaction}},
url = {http://portal.acm.org/citation.cfm?id=1240851},
year = {2007}
}
@article{Bay2005,
author = {Bay, Herbert and Fasel, Beat and Gool, Luc Van},
file = {::},
journal = {Analysis},
keywords = {bluetooth,image-based museum guide that,in lighting,interactive museum guide,is invariant to changes,object recognition,scale,viewpoint,we present an interactive,zoom},
pages = {1--4},
title = {{Interactive Museum Guide}},
year = {2005}
}
@misc{Rukzio,
abstract = {This paper presents an analysis, implementation and evaluation of the physical mobile interaction techniques touching, pointing and scanning. Based on this we have formulated guidelines that show in which context which interaction technique is preferred by the user. Our main goal was to identify typical situations and scenarios in which the different techniques might be useful or not. In support of these aims we have developed and evaluated, within a user study, a low-fidelity and a high-fidelity prototype to assess scanning, pointing and touching interaction techniques within different contexts. Other work has shown that mobile devices can act as universal remote controls for interaction with smart objects but, to date, there has been no research which has analyzed when a given mobile interaction technique should be used. In this research we analyze the appropriateness of three interaction techniques as selection techniques in smart environments.},
author = {Rukzio, Enrico and Leichtenstern, Karin and Callaghan, Vic and Holleis, Paul and Schmidt, Albrecht and Chin, Jeannette},
file = {::},
pages = {1--18},
title = {{An Experimental Comparison of Physical Mobile Interaction Techniques : Touching , Pointing and Scanning}}
}
@article{Olwal2006,
abstract = {The vision of spatially aware handheld interaction devices has been hard to realize. The difficulties in solving the general track- ing problem for small devices have been addressed by several research groups and examples of issues are performance, hard- ware availability and platform independency. We present Light- Sense, an approach that employs commercially available compo- nents to achieve robust tracking of cell phone LEDs, without any modifications to the device. Cell phones can thus be promoted to interaction and display devices in ubiquitous installations of sys- tems such as the ones we present here. This could enable a new generation of spatially aware handheld interaction devices that would unobtrusively empower and assist us in our everyday tasks.},
author = {Olwal, Alex},
doi = {10.1109/ISMAR.2006.297802},
file = {::},
isbn = {1-4244-0650-1},
journal = {2006 IEEE/ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality,cell phone,handheld,led,mixed reality,mobile,portable,spa-,tially aware,ubiquitous},
month = oct,
pages = {119--122},
publisher = {Ieee},
title = {{LightSense: enabling spatially aware handheld interaction devices}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4079264},
volume = {2006},
year = {2006}
}
@inproceedings{Wagner2008,
author = {Wagner, Daniel and Reitmayr, Gerhard and Mulloni, Alessandro and Drummond, Tom and Schmalstieg, Dieter},
booktitle = {Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
pages = {125--134},
title = {{Pose Tracking from Natural Features on Mobile Phones}},
year = {2008}
}
@article{Schmalstieg2007,
abstract = {In this paper, we present Studierstube ES, a framework for the development of handheld Augmented Reality. The applications run self-contained on handheld computers and smartphones with Windows CE. A detailed description of the performance critical tracking and rendering components are given. We also report on the implementation of a client-server architecture for multi-user applications, and a game engine for location based museum games that has been built on top of this infrastructure. Details on two games that were created, permanently deployed and evaluated in two Austrian museums illustrate the practical value of the framework and lessons learned from using it.},
author = {Schmalstieg, Dieter and Wagner, Daniel},
doi = {10.1109/ISMAR.2007.4538819},
file = {::},
isbn = {978-1-4244-1749-0},
journal = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
keywords = {augmented reality games,cultural heritage,mobile augmented reality,wearable computing},
month = nov,
pages = {1--13},
publisher = {Ieee},
title = {{Experiences with Handheld Augmented Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538819},
year = {2007}
}
@article{Bruns2007,
abstract = {We present a museum guidance system called PhoneGuide that uses widespread camera-equipped mobile phones for on-device object recognition in combination with pervasive tracking. It also provides location- and object- aware multimedia content to museum visitors, and is scalable to cover a large number of museum objects.},
author = {Bruns, E and Brombach, B and Zeidler, T and Bimber, O},
doi = {10.1109/MMUL.2007.33},
file = {::},
issn = {1070986X},
journal = {Ieee Multimedia},
number = {2},
pages = {16},
publisher = {IEEE COMPUTER SOCIETY},
title = {{Enabling mobile phones to support large-scale museum guidance}},
url = {http://webuser.uni-weimar.de/~bruns/Pub/PhoneGuide\_2007\_MM.pdf},
volume = {14},
year = {2007}
}
@inproceedings{Mohring2004,
abstract = {We present a first running video see-through augmented reality system on a consumer cell-phone. It supports the detection and differentiation of different markers, and correct integration of rendered 3D graphics into the live video stream via a weak perspective projection camera model and an OpenGL rendering pipeline.},
author = {M\"{o}hring, Mathias and Lessig, Christian and Bimber, Oliver},
booktitle = {Workshop on Virtual and Augmented Reality of the GI-Fachgruppe AR/VR},
file = {::},
pages = {193--204},
title = {{Optical Tracking and Video See-Through AR on Consumer Cell-Phones}},
year = {2004}
}
@inproceedings{Mohring2004,
abstract = {We present a first running video see-through augmented reality system on a consumer cell-phone. It supports the detection and differentiation of different markers, and correct integration of rendered 3D graphics into the live video stream via a weak perspective projection camera model and an OpenGL rendering pipeline.},
author = {M\"{o}hring, Mathias and Lessig, Christian and Bimber, Oliver},
booktitle = {International Symposium on Augmented and Mixed Reality (ISMAR2004)},
doi = {10.1109/ISMAR.2004.63},
file = {::},
isbn = {0-7695-2191-6},
pages = {252--253},
publisher = {Ieee},
title = {{Video see-through AR on consumer cell-phones}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1383062},
year = {2004}
}
@inproceedings{Kurz2011a,
author = {Kurz, Daniel and BenHimane, Selim},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR2011)},
keywords = {Inertial sensor-aligned visual feature descriptors},
pages = {161--166},
title = {{Inertial sensor-aligned visual feature descriptors}},
year = {2011}
}
@inproceedings{Wagner2003,
author = {Wagner, Daniel and Schmalstieg, Dieter},
booktitle = {Proceedings of the 7th IEEE International Symposium on Wearable Computers},
isbn = {0-7695-2034-0},
keywords = {Augmented Reality,Mobile Computing,PDA,Tracking},
month = oct,
pages = {127},
title = {{First Steps Towards Handheld Augmented Reality}},
url = {http://dl.acm.org/citation.cfm?id=946249.946910},
year = {2003}
}
@inproceedings{Kurz2011,
author = {Kurz, Daniel and Benhimane, Selim},
booktitle = {IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR2011)},
keywords = {Handheld Augmented Reality Inertial Sensors Gravit},
pages = {111--120},
title = {{Gravity-Aware Handheld Augmented Reality}},
year = {2011}
}
@article{Bruns2008a,
author = {Bruns, Erich and Brombach, Benjamin and Bimber, Oliver},
file = {::},
title = {{Mobile Phone-Enabled Museum Guidance with Adaptive Classification}},
year = {2008}
}
@inproceedings{Wagner2008a,
author = {Wagner, Daniel and Langlotz, Tobias and Schmalstieg, Dieter},
booktitle = {Proceedings of the 2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality 2008},
pages = {121--124},
publisher = {IEEE Computer Society},
title = {{Robust and unobtrusive marker tracking on mobile phones}},
url = {http://portal.acm.org/citation.cfm?id=1605358},
year = {2008}
}
@inproceedings{Brombach2008,
author = {Brombach, Benjamin and Bruns, Erich and Bimber, Oliver},
booktitle = {Proceedingsc of the 13th international conference on Intelligent user interfaces IUI 09},
doi = {10.1145/1502650.1502688},
file = {::},
isbn = {9781605581682},
organization = {ACM},
pages = {267},
publisher = {ACM Press},
title = {{Subobject detection through spatial relationships on mobile phones}},
url = {http://portal.acm.org/citation.cfm?doid=1502650.1502688},
year = {2008}
}
@book{Lee2007,
abstract = {Our paper presents a system for efficient recognition of landmarks taken from camera phones. Information such as tutorial rooms within the captured landmarks is returned to user within seconds. The system uses a database of multiple viewpoint's images for matching. Various navigational aids and sensors are used to optimize accuracy and retrieval time by providing complementary information about relative position and viewpoint of each query image. This makes our system less sensitive to orientation, scale and perspective distortion. Multi-scale approach and a reliability score model are proposed in this application. Our system is validated by several experiments in the campus, with images taken from different resolution's camera phones, positions and times of day.},
author = {Lee, Jimmy Addison and Yow, Kin Choong},
booktitle = {2007 IEEE International Conference on Image Processing},
doi = {10.1109/ICIP.2007.4379550},
isbn = {978-1-4244-1436-9},
pages = {VI -- 177--VI -- 180},
publisher = {IEEE},
title = {{Image Recognition for Mobile Applications}},
url = {http://www.ieeexplore.ieee.org/xpl/freeabs\_all.jsp?tp=\&arnumber=4379550\&isnumber=4379494},
year = {2007}
}
@inproceedings{Schmalstieg2008,
author = {Schmalstieg, Dieter and Wagner, Daniel},
booktitle = {Proceedings of the IEEE VR 2008 Workshop on Software Engineering and Architectures for Realtime Interactive Systems},
pages = {43--44},
title = {{Mobile Phones as a Platform for Augmented Reality}},
year = {2008}
}
@inproceedings{Wagner2010,
author = {Wagner, Daniel and Mulloni, Alessandro and Langlotz, Tobias and Schmalstieg, Dieter},
booktitle = {2010 IEEE Virtual Reality Conference (VR)},
doi = {10.1109/VR.2010.5444786},
file = {::},
isbn = {978-1-4244-6237-7},
month = mar,
pages = {211--218},
publisher = {Ieee},
title = {{Real-time panoramic mapping and tracking on mobile phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5444786},
year = {2010}
}
@inproceedings{Foeckler2005b,
abstract = {We present PhoneGuide - an enhanced museum guidance system that uses camera-equipped mobile phones and on-device object recognition.Our main technical achievement is a simple and light-weight object recognition approach that is realized with single-layer perceptron neuronal networks. In contrast to related systems which perform computationally intensive image processing tasks on remote servers, our intention is to carry out all computations directly on the phone. This ensures little or even no network traffic and consequently decreases cost for online times. Our laboratory experiments and field surveys have shown that photographed museum exhibits can be recognized with a probability of over 90\%.We have evaluated different feature sets to optimize the recognition rate and performance. Our experiments revealed that normalized color features are most effective for our method. Choosing such a feature set allows recognizing an object below one second on up-to-date phones. The amount of data that is required for differentiating 50 objects from multiple perspectives is less than 6KBytes.},
author = {Foeckler, Paul and Zeidler, Thomas and Brombach, Benjamin and Bruns, Erich and Bimber, Oliver},
booktitle = {Proceedings of the 4th international conference on Mobile and ubiquitous multimedia},
doi = {10.1145/1149488.1149490},
file = {::},
isbn = {0473106582},
number = {1},
organization = {MUM '05},
pages = {3--10},
publisher = {ACM},
series = {December 08-10},
title = {{PhoneGuide: museum guidance supported by on-device object recognition on mobile phones}},
url = {http://portal.acm.org/citation.cfm?id=1149488.1149490},
volume = {6},
year = {2005}
}
@article{Jung2007,
abstract = {We present a mobile augmented reality (AR) system for indoor guidance where we apply vision technique without using markers. There are two main problems: First, to augment suitable information according to users situation, it has to be identified which place the user belongs to. Second, to put information into the scene and to make it aligned with the target scene element, the basic structure of the augmenting space should be grasped. For place recognition in real time mobile system, we employ simple feature detection method combined with graph based spatial connectivity representation. Also, Image-based analysis method is applied to interpret the basic scene structure from the video.},
author = {Jung, Eunsoo and Oh, Sujin and Nam, Yanghee},
journal = {Virtual Reality Software and Technology},
keywords = {augmented reality,computer vision,mobile guidance},
pages = {47},
title = {{Handheld AR indoor guidance system using vision technique}},
url = {http://portal.acm.org/citation.cfm?id=1315190},
year = {2007}
}
@article{Langlotz2010,
author = {Langlotz, Tobias and Wagner, Daniel and Mulloni, Alessandro and Schmalstieg, Dieter},
doi = {10.1109/MPRV.2010.69},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
month = aug,
publisher = {IEEE Computer Society},
title = {{Online Creation of Panoramic Augmented Reality Annotations on Mobile Phones}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/MPRV.2010.69},
year = {2010}
}
@article{Bruns2008b,
abstract = {We present an enhancement towards adap- tive video training for PhoneGuide, a digital museum guidance system for ordinary camera–equipped mobile phones. It enables museum visitors to identify exhibits by capturing photos of them. In this article, a com- bined solution of object recognition and pervasive track- ing is extended to a client–server–system for improving data acquisition and for supporting scale–invariant ob- ject recognition. A static as well as a dynamic training technique are presented that preprocess the collected ob- ject data differently and apply two types of neural net- works for classification. Furthermore, the system enables a temporal adaptation for ensuring a continuous data acquisition to improve the recognition rate over time. A formal field experiment reveals current recognition rates and indicates the practicability of both methods under realistic conditions in a museum. Fig.},
author = {Bruns, Erich and Bimber, Oliver},
doi = {10.1007/s00779-008-0194-3},
file = {::},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
month = mar,
number = {2},
pages = {165--178},
title = {{Adaptive training of video sets for image recognition on mobile phones}},
url = {http://www.springerlink.com/index/10.1007/s00779-008-0194-3},
volume = {13},
year = {2008}
}
@inproceedings{Bruns2008,
abstract = {In this paper, we present a novel technique for adapting local image classifiers that are applied for object recognition on mobile phones through ad-hoc network communication between the devices. By continuously accumulating and exchanging collected user feedback among mobile phones that are located within signal range, we show that our approach improves the overall classification rate and adapts to dynamic changes quickly. This technique is applied in the context of PhoneGuide – an adaptive museum guidance system.},
author = {Bruns, Erich and Bimber, Oliver},
booktitle = {MoMM},
file = {::},
keywords = {Mobile Computing,Museum Guidance Application,Phone- to-Phone Communication,Real-Time Adaptation},
title = {{Phone-to-phone communication for adaptive image classification}},
url = {http://www.mendeley.com/profiles/erich-bruns/},
year = {2008}
}
@misc{Rukzio2007,
abstract = {So far, mobile devices have mainly been used for interactions between the user, the device and the used service without considering the context of use. However, during the last years we have seen a huge interest in industry and academia in using mobile devices for interactions with things, places and people in the real world, termed physical mobile interactions in this thesis. Until now there has been no comprehensive analysis of these interaction techniques and no user studies have been conducted to analyze when which interaction technique is preferred by which users. Furthermore there is no comprehensive framework available which can be reused by application developers to integrate such interactions into their applications, and no specific methods and best practices have been reported that can be of use when developing physical mobile interactions and applications. This dissertation presents the first comprehensive analysis and classification of physical mobile interactions. Furthermore a mature framework was developed that provides various implementations of four different interaction techniques. These four physical mobile interaction techniques were then used in five different prototypes and analysed in five different user studies. The results concern the advantages and disadvantages of these interaction techniques as seen by potential users. This work also reports experiences, guidelines, methods and best practices that simplify the process of developing physical mobile interactions and applications. Furthermore this dissertation provides an analysis of privacy aspects in mobile interactions with public displays, presents the novel interaction technique rotating compass and the first concept of using the mobile device for direct touch-based interaction with dynamic displays.},
author = {Rukzio, Enrico},
file = {::},
pages = {180},
title = {{Physical Mobile Interactions : Mobile Devices as Pervasive Mediators for Interactions with the Real World}},
year = {2007}
}
@article{Burraston2005a,
abstract = {This paper will review electronic music and sonic art applications of Cellular Automata (CA) in a historical and technical context. Algorithmic and computational processes have been of interest to artists for many years, creating an emerging culture of generative electronic art. Creating patterns and sequences is necessary for the creative artist working spatially and temporally within a chosen medium. CA are capable of a wide variety of emergent behaviours and represent an important generative tool for the artist. The sonic artist and musician must be prepared to investigate the theoretical background of CA in order to successfully employ their vast behaviour space within compositional strategy. There is an extensive amount of mathematical and scientific literature relating to CA, however much of this is esoteric or difficult to understand. Important and accessible CA concepts are presented concisely in a non mathematical context to give sufficient background for the review. There have been several approaches at applying CA in the production of electronic music and sonic art. Examples exist in the fields of overall structural composition, MIDI sequencing and sound synthesis/modification techniques. Applications from academic, independent and commercial sectors will be critically reviewed in an artistic, historical and technical context. This will provide the artist and scientist with a balanced view of this emerging field.},
author = {Burraston, Dave and Edmonds, Ernest},
file = {::},
journal = {Digital Creativity},
keywords = {algorithmic composition,cellular automata,electronic music,generative music,sound synthesis},
number = {3},
pages = {165},
title = {{Cellular Automata in Generative Electronic Music and Sonic Art: Historical and Technical Review}},
volume = {16},
year = {2005}
}
@inproceedings{Collins2009c,
abstract = {Recently, “smart” table-top touchscreen comput- ers, in which users position themselves around a horizontal computer screen, have been introduced. Although the use of touchscreen computers is still not widespread, given the growing popularity of multi-touch mobility devices (e.g., iPods, smart- phones), the move to multi-user touchscreens and a horizontal surface is a likely trajectory of the technology. However, before table-top touch- screen computing becomes widely accepted, there are many questions, particularly with respect to sound production and reception, and multi-modal interaction for these devices that need to be ex- plored. In this paper we provide an overview of a table-top touchscreen computer setup and de- scribe a simple amplitude panning method for the output of sound amongst four loudspeakers. The paper begins with a background on sound interac- tion design.},
author = {Collins, Karen and Kapralos, Bill and Kanev, Kamen},
booktitle = {Proceedings of the 12th International Conference on Humans and Computers},
file = {::},
keywords = {audio-video interaction,computer,human-computer interaction,smart table computer,sound interac-,table-top,tion design},
title = {{Sound Interface Design for Smart Table Computer Interaction}},
year = {2009}
}
@article{Knott2003a,
author = {Knott, Dave and Pai, D.K.},
file = {::},
journal = {Computer Graphics Forum},
keywords = {agespace computations,collision detection,geometric modeling,graphics hardware,im-},
publisher = {Citeseer},
title = {{CInDeR: Collision and interference detection in real-time using graphics hardware}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.316},
year = {2003}
}
@inproceedings{Smyth2001a,
author = {Smyth, T. and Smith, J.O.},
booktitle = {Proc. of ISMA 2001, Int. Symposium on Musical Acoustics},
file = {::},
publisher = {Citeseer},
title = {{Applications of Bioacoustics in Physical Modeling and the Creation of New Musical Instruments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.8934\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@inproceedings{Paul2010a,
author = {Paul, Leonard J},
booktitle = {Game Sound Conference 2010},
file = {::},
title = {{Procedural Sound Design}},
year = {2010}
}
@inproceedings{Raghuvanshi2006a,
abstract = {We present an interactive approach for generating realistic physically-based sounds from rigid-body dynamic simulations. We use spring-mass systems to model each object’s local deformation and vibration, which we demonstrate to be an adequate approxi- mation for capturing physical effects such as magnitude of impact forces, location of impact, and rolling sounds. No assumption is made about the mesh connectivity or topology. Surface meshes used for rigid-body dynamic simulation are utilized for sound simu- lation without any modifications. We use results in auditory percep- tion and a novel priority-based quality scaling scheme to enable the system to meet variable, stringent time constraints in a real-time ap- plication, while ensuring minimal reduction in the perceived sound quality. With this approach, we have observed up to an order of magnitude speed-up compared to an implementation without the acceleration. As a result, we are able to simulate moderately com- plex simulations with upto hundreds of sounding objects at over 100 frames per second (FPS), making this technique well suited for interactive applications like games and virtual environments. Furthermore, we utilize OpenAL and EAXTM on Creative Sound Blaster Audigy 2TM cards for fast hardware-accelerated propaga- tion modeling of the synthesized sound.},
address = {New York, New York, USA},
author = {Raghuvanshi, Nikunj and Lin, Ming C.},
booktitle = {Proceedings of the 2006 symposium on Interactive 3D graphics and games - SI3D '06},
doi = {10.1145/1111411.1111429},
file = {::},
isbn = {159593295X},
keywords = {a three-octave xylophone in,close,figure 1,musical tones,numerous dice fall on,openal,our algorithm is able,playing out the song,rigid-body simulation,see the video,sound synthesis,succession,the entertainer,to produce the corresponding},
pages = {101},
publisher = {ACM Press},
title = {{Interactive sound synthesis for large scale environments}},
url = {http://portal.acm.org/citation.cfm?doid=1111411.1111429},
year = {2006}
}
@article{Thalla,
abstract = {A new granular sound signal generator, processor, and control system is presented, developed, and discussed. The unifying principles that exist among past implementations are first examined. The result of this investigation is a systematic design that, through reclassification and generalization, combines and extends these early models. Sets of signal processing sub-routines are then identified, collected and combined into a general-purpose grain generator. A novel user interface is also presented along with various high-level control regimes. This assists the user in navigating the multi-dimensional parameter space inherent in granular transformations. The combination of fast and efficient processing with scalable and customized controllers results in a system designed exclusively for advanced granular synthesis and processing. This system could be used in real, virtual, and mixed immersive environments, providing a real- time synchronized stream of complex spatial ambient and environmental tones and noises alongside synthesized visual and/or tactile streams.},
author = {Thall, David},
file = {::},
journal = {Interactive Digital Multimedia IGERT Annual Research Review},
pages = {4--6},
title = {{Experiments in Sound Granulation and Spatialization for Immersive Environments}}
}
@article{Tagg2001a,
author = {Tagg, Philip and Collins, Karen E},
file = {::},
journal = {Sound Practice},
pages = {1--11},
title = {{The Sonic Aesthetics of the Industrial: Re-Constructing Yesterday's Soundscape for Today's Alienation and Tomorrow's Dystopia}},
year = {2001}
}
@article{Menzies2006b,
abstract = {Ambisonic encodings can be rendered binaurally, as well as for speaker arrays. We first consider how binaural signals can be calculated from high-order Ambisonic encodings of general soundfields containing near and far sources. For sufficently near sources we identify an error resulting fromthe limited field of validity of the freefield harmonic expansion. A modified expansion is derived that can render such sources without error.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--17},
title = {{Nearfield Binaural Synthesis and Ambisonics}},
year = {2006}
}
@inproceedings{Kahrs2001a,
author = {Kahrs, M. and Avanzini, F.},
booktitle = {Proc. COST G6 Conf. on Digital Audio Effects (Limerick, Ireland, December 2001},
file = {::},
pages = {23--7},
publisher = {Citeseer},
title = {{Computer Synthesis of Bird Songs and Calls}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.3169\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@inproceedings{James2006a,
author = {James, D.L. and Barbi\v{c}, J. and Pai, D.K.},
booktitle = {ACM Transactions on Graphics (TOG)},
file = {::},
isbn = {1595933646},
issn = {0730-0301},
keywords = {acoustic radiation,boundary element method,equiva-,helmholtz,lent sources,modal vibration,multipole,sound synthesis,source simulation,trefftz},
number = {3},
pages = {987--995},
publisher = {ACM},
title = {{Precomputed Acoustic Transfer : Output-sensitive , accurate sound generation for geometrically complex vibration sources}},
url = {http://portal.acm.org/citation.cfm?id=1141983},
volume = {25},
year = {2006}
}
@article{Grandvaleta,
author = {Grandvalet, Yves and Eck, Douglas and Paiement, Jean-Francois and Bengio, Samy},
file = {::},
pages = {1--8},
title = {{A Generative Model for Rhythms}}
}
@inproceedings{Rath2003a,
abstract = {As part of the SOb European project several cartoon models of contact sounds of solid bodies, “hitting”, “bouncing”, “dropping”, “breaking”, “rolling”, have been developed and implemented as modules (and sub-patches) for free real-time sound software pd 1. The models are accessed through perceptually meaningful parameters and run with low computational load on standard PC hardware. The underlying idea of cartoonification, its motivation and background in psychoacoustic research are sketched first. The main common sound-core of most models, a physics-based algorithm of impact-interaction with interacting resonators in modal description, is shortly presented. The impact module is embedded in patches of higher-level control to model more complex contact scenarios. The structure, use and potential of the resulting sound objects is described. While the results are a possible basis for reactive sonic interfaces in Human-Computer-Interaction, they can as well be exploited for musical purposes.},
address = {Firenze, Italy},
author = {Rath, M. and Avanzini, F. and Bernardini, N. and Borin, G. and Fontana, F. and Ottaviani, L. and Rocchesso, D.},
booktitle = {Proceedings of the XIV Colloquium on Musical Informatics (XIV CIM 2003)},
file = {::},
pages = {6},
title = {{An Introductory Catalog of Computer-Synthesized Contact Sounds, in Real-Time}},
year = {2003}
}
@article{Amatriain2003b,
author = {Amatriain, Xavier and Bonada, Jordi and Loscos, �Lex and Arcos, Josep Llu�s and Verfaille, Vincent},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = mar,
number = {1},
pages = {95--114},
title = {{Content-based Transformations}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1076/jnmr.32.1.95.16800\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {32},
year = {2003}
}
@phdthesis{Gwee2002a,
abstract = {Successful algorithmic music composition requires the efficient creation of works that reflect human preferences. In examining this key issue, we make two main contributions in this dissertation: analysis of the computational complexity of algorithmic music composition, and methods to produce music that approximates a commendable human effort. We use species counterpoint as our compositional model, wherein a set of stylistic and grammatical rules governs the search for suitable countermelodies to match a given melody. Our analysis of the complexity of rule-based music composition considers four different types of computational problems: decision, enumeration, number, and optimization. For restricted versions of the decision problem, we devise a polynomial algorithm by constructing a non-deterministic finite state transducer. This transducer can also solve corresponding restricted versions of the enumeration and number problems. The general forms of the four types of problems, however, are respectively NP- complete, \#P-complete, NP-complete in the strong sense, and NP-equivalent. We prove this by first reducing from the well known Three-Dimensional Matching problem to the music composition decision problem, and then by reducing among the music problems themselves. In order to compose music both correct and human-like, we formulate new “artistry” rules to supplement traditional rules of musical style and grammar. We also propose the fuzzy application of these artistry rules, to complement the crisp application of the traditional rules. We then suggest two methods to model human preferences: (1) distinguish an expert’s compositions from alternative compositions by determining rule weights; (2) train an artificial neural network to reflect an expert’s musical preferences through the latter’s evaluations of a set of compositions. We were able to approximate that elusive factor of human preference with better than 75\% accuracy. To solve the optimization problem, we adapt two different search algorithms: best-first search with branch-and-bound pruning (for m ≥ 1 optimal solutions), and a genetic algorithm (for m ≥ 1 near- optimal solutions). Through these algorithms, we test the techniques of rule weightings and of trained neural networks as evaluation functions. Our adaptation of the genetic algorithm produced optimal countermelodies in execution time favorably comparable to that taken by the best-first algorithm.},
author = {Gwee, N.},
booktitle = {Memory},
file = {::},
number = {December},
publisher = {Citeseer},
school = {Louisiana State University},
title = {{Complexity and Heuristics in Rule-based Algorithmic Music Composition}},
type = {Doctor of Philosophy},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.828\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Bonneel2008a,
author = {Bonneel, Nicolas and Drettakis, George and Tsingos, Nicolas and Viaud-Delmon, Isabelle and James, Doug},
doi = {10.1145/1360612.1360623},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {dering,modal synthesis,physically based animation,real-time audio ren-,sound synthesis,time-domain modal synthesis},
month = aug,
number = {3},
pages = {1},
title = {{Fast modal sounds with scalable frequency-domain synthesis}},
url = {http://portal.acm.org/citation.cfm?doid=1360612.1360623},
volume = {27},
year = {2008}
}
@article{Casey1994a,
abstract = {This research report describes an approach to parameter estimation for physical models of sound-generating systems using distal teachers and forward models (Jordan \& Rumelhart, 1992; Jordan, 1990). The general problem is to find an inverse model of a sound-generating system that transforms sounds to action parameters; these parameters constitute a model-based description of the sound. We first show that a two-layer feedforward model is capable of performing inverse mappings for a simple physical model of a violin string. We refer to this learning strategy as direct inverse modeling; it requires an explicit teacher and it is only suitable for convex regions of the parameter space. A model of two strings was implemented that had non-convex regions in its parameter space. We show how the direct modeling strategy failed at the task of learning the inverse model in this case and that forward models can be used, in conjunction with distal teachers, to bias the learning of an inverse model so that non-convex regions are mapped to single-point solutions in the parameter space. Our results show that forward models are appropriate for learning to map sounds to parametric representations.},
author = {Casey, Michael},
doi = {10.1080/09540099408915730},
file = {::},
isbn = {0262071819},
issn = {0954-0091},
journal = {Connection Science},
number = {2},
pages = {355--371},
publisher = {The MIT Press},
title = {{Understanding Musical Sound with Forward Models and Physical Models}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09540099408915730\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {6},
year = {1994}
}
@inproceedings{Veneri2008a,
address = {Paris},
author = {Veneri, Olivier and Planqueel, Yann},
booktitle = {Game Developers Conference},
file = {::},
title = {{Create a scalable and creative audio environment: middleware project PLAY ALL}},
year = {2008}
}
@article{Abdallah2006b,
author = {Abdallah, Samer and Sandler, Mark and Rhodes, Christophe and Casey, Michael},
doi = {10.1007/s10994-006-0586-4},
file = {::},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {duration prior,gibbs sampling,mcmc,segmentation,wolff},
month = nov,
number = {2-3},
pages = {485--515},
title = {{Using duration models to reduce fragmentation in audio segmentation}},
url = {http://www.springerlink.com/index/10.1007/s10994-006-0586-4},
volume = {65},
year = {2006}
}
@article{Picard-Limpens2009a,
author = {Picard-Limpens, C\'{e}cile},
journal = {Environments},
title = {{Expressive Sound Synthesis for Animation}},
url = {http://www-sop.inria.fr/members/Cecile.Picard/index.html},
year = {2009}
}
@article{Goble2008a,
author = {Goble, Brian and Price, Garrett and Hipsoft},
file = {::},
journal = {Casual Games Quarterly},
number = {1},
pages = {16},
title = {{Build-A-Lot Post Mortem}},
volume = {3},
year = {2008}
}
@article{Raghuvanshia,
abstract = {Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design. Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the Wave Equation in rectangular domains, and utilizes an efficient implementation of the Discrete Cosine Transform on Graphics Processors (GPU) to achieve at least a 100-fold performance gain compared to a standard Finite-Difference Time-Domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.},
author = {Raghuvanshi, Nikunj and Narain, Rahul and Lin, Ming C},
doi = {10.1109/TVCG.2009.27},
file = {::},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
number = {5},
pages = {789--801},
pmid = {19590105},
title = {{Efficient and accurate sound propagation using adaptive rectangular decomposition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19590105},
volume = {15}
}
@phdthesis{Martino2000a,
abstract = {A compelling area of exploration in the domain of physical modeling and vocal synthesis is the production of non-human, expressive, animal-like vocalizations. Animal sounds can convey a wide variety of emotional states, and synthesizing life-like vocalizations would allow for interesting applications in the world of video games, film, music, and artificial intelligence systems. This paper describes Synthasaurus, a synthesis engine prototype developed in Opcode MAX/MSP, which enables one to create emotive animal-like calls, and provides enough flexibility to synthesize a variety of organisms that can resemble different mammals, birds, reptiles and amphibians. Alien, robotic, and other imaginary creatures can also be conceived. Synthasaurus builds on research and technology developed for human speech synthesis, with special kinds of control added for creating more animal-like sounds.},
author = {Martino, Robert},
booktitle = {Synthesis},
file = {::},
title = {{Synthasaurus : An ANimal Vocalization Synthesizer}},
year = {2000}
}
@incollection{Collins2007a,
address = {New York, New York, USA},
author = {Collins, Karen},
booktitle = {Essays on Sound and Vision},
doi = {10.1145/281388.281880},
editor = {Hawkins, Stan and Richardson, John},
file = {::},
isbn = {1581130457},
pages = {263--298},
publisher = {ACM Press},
title = {{An Introduction to the Participatory and Non-Linear Aspects of Video Games Audio}},
url = {http://portal.acm.org/citation.cfm?doid=281388.281880},
year = {2007}
}
@inproceedings{Farnell2010a,
abstract = {This work presents an overview of real-time client-side synthetic sound for use in games and interactive applications. Creating and managing native sound synthesis code for immediate client-side execution is large scale programming and design task. We need a good understanding of sound design practice to optimally solve the problem, but this is not sound design, nor is it music. We wish to sketch out a systematic way of attacking the general programming problems of procedural sound, for the general case of sound effects. There are two commonly used sources of sound, digital samples made by recording, and synthesised sounds created from first principles. While the former is the currently preferred method for most games, our focus is the second kind of sound generation. This approach has many benefits and tradeoffs. We can demonstrate that as complexity increases it eventually becomes more effective and efficient to synthesise many sounds on the client machine. We will remain aware of the most complicated and difficult application, multi-player network games, where a proper solution must allow for object replication across multiple clients and deal with issues like consistency, latency and client CPU usage.},
author = {Farnell, Andy James},
booktitle = {Sounding Out 3},
file = {::},
pages = {1--9},
title = {{Sound synthesis for games}},
year = {2010}
}
@techreport{Veneria,
abstract = {Constantly increasing power of gaming platforms now makes it possible for game developers to consider using procedural techniques in making games. These techniques are actually used to create part of graphical assets such as object’s textures [9] or to generate character motion [26]. However, sound is still a challenging domain for procedural content creation. This article presents a new software framework designed to support the use of procedural audio for games. This framework is named GAF (Game Audio Framework) and is currently developped by CNAM/CEDRIC laboratory in Paris as part of the PLAY ALL platform. In a first part, we will give a quick overview of current framework architectures. In a second part, we will discuss Procedural Audio. In a third and forth part, we will introduce the new framework proposition we make. We end this article with a demonstration of procedural musical capabilities that this framework enables},
author = {Veneri, Olivier and Cedric, Cnam and Natkin, Stephane},
file = {::},
number = {figure 1},
title = {{Procedural Audio for Game using GAF}}
}
@article{Farnella,
author = {Farnell, Andy James},
file = {::},
keywords = {audio,biomechanics,bipedal motion,computer games,footsteps,procedural,puredata,sound design,synthesis},
title = {{Marching onwards Procedural synthetic footsteps for video games and animation .}}
}
@article{Farnell2007c,
abstract = {This document looks generally at the application of synthetic audio to video games and presents some experimental results and analysis from research in generating efficient synthetic sound for vir- tual worlds. Dynamic sound effects for real-time use in game worlds require far more careful thought to de- sign than brute force methods employed where sound is computed prior to delivery, not just in terms of static computational cost, but in how they are structured and behave when parametrised by world events. To make synthetic audio a possibility for the next generation of game audio compromises must be found that satisfy several conflicting variables. Examples are presented that demonstrate cost effective approximations based on key physical parameters and psychoacoustic cues, what can be called ”Practical synthetic sound design”.},
author = {Farnell, Andy},
file = {::},
title = {{Synthetic game audio with Puredata}},
year = {2007}
}
@inproceedings{Smyth2002a,
abstract = {This research presents a model of the avian vocal tract, imple- mented using classical waveguide synthesis and numerical meth- ods. The vocal organ of the songbird, the syrinx, has a unique topography of acoustic tubes (a trachea with a bifurcation at its base) making it a rather unique subject for waveguide synthesis. In the upper region of the two bifid bronchi lies a nonlinear vi- brating membrane – the primary resonator in sound production. Unlike most reed musical instruments, the more significant dis- placement of the membrane is perpendicular to the directions of airflow, due to the Bernoulli effect. The model of the membrane displacement, and the resulting pressure through the constriction created by the membrane motion, is therefore derived beginning with the Bernoulli equation.},
author = {Smyth, T. and Smith, J.O.},
booktitle = {DAFX 2002 Proceedings},
file = {::},
pages = {26--29},
publisher = {Citeseer},
title = {{The Sounds of the Avian Syrinx - Are They Really Flute Like?}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.6948\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@inproceedings{Jacob1995a,
author = {Jacob, B.L.},
booktitle = {Proceedings of the 1995 International Computer Music Conference},
file = {::},
number = {September},
pages = {452--455},
publisher = {Citeseer},
title = {{Composing with genetic algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.4011\&amp;rep=rep1\&amp;type=pdf},
year = {1995}
}
@article{Dobashi2003b,
author = {Dobashi, Yoshinori and Yamamoto, Tsuyoshi and Nishita, Tomoyuki},
doi = {10.1145/882262.882339},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {--------------------------------------------------,aerodynamic sound,animation,computational fluid dynamics,simulation,sound synthesis},
month = jul,
number = {3},
pages = {732},
title = {{Real-time rendering of aerodynamic sound using sound textures based on computational fluid dynamics}},
url = {http://portal.acm.org/citation.cfm?doid=882262.882339},
volume = {22},
year = {2003}
}
@article{Visell2009,
author = {Visell, Y. and Fontana, F. and Giordano, B.L. and Nordahl, R. and Serafin, S. and Bresin, R.},
doi = {10.1016/j.ijhcs.2009.07.007},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {auditory display,interaction design,vibrotactile display,walking interfaces},
month = nov,
number = {11},
pages = {947--959},
title = {{Sound design and perception in walking interactions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581909000895},
volume = {67},
year = {2009}
}
@article{Verfaille2006a,
author = {Verfaille, V. and Zolzer, U. and Arfib, D.},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = sep,
number = {5},
pages = {1817--1831},
title = {{Adaptive digital audio effects (a-DAFx): a new class of sound transformations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1678000},
volume = {14},
year = {2006}
}
@inproceedings{Raghuvanshi2009a,
abstract = {We present a method for real-time sound propagation that captures all wave effects, including diffraction and reverberation, for multiple moving sources and a moving listener in a complex, static 3D scene. It performs an offline numerical simulation over the scene and then applies a novel technique to extract and compactly en- code the perceptually salient information in the resulting acoustic responses. Each response is automatically broken into two phases: early reflections (ER) and late reverberation (LR), via a threshold on the temporal density of arriving wavefronts. The LR is simulated and stored in the frequency domain, once per room in the scene. The ER accounts for more detailed spatial variation, by recording a set of peak delays/amplitudes in the time domain and a residual frequency response sampled in octave frequency bands, at each source/receiver point pair in a 5D grid. An efficient run-time uses this precomputed representation to perform binaural sound rendering based on frequency-domain convolution. Our system demonstrates realistic, wave-based acoustic effects in real time, including diffraction low-passing behind obstructions, sound focusing, hollow reverberation in empty rooms, sound diffusion in fully-furnished rooms, and realistic late reverberation.},
address = {Los Angeles},
author = {Raghuvanshi, Nikunj and Snyder, John and Mehra, Ravish and Lin, Ming and Govindaraju, Naga},
booktitle = {SIGGRAPH 2010: The 37th International Conference and Exhibition on Computer Graphics and Interactive Techniques.},
file = {::},
title = {{Precomputed Wave Simulation for Real-Time Sound Propagation of Dynamic Sources in Complex Scenes}},
year = {2009}
}
@misc{Kastbauer2010a,
author = {Kastbauer, Damian},
booktitle = {Gamasutra.com},
file = {::},
pages = {1--6},
publisher = {Gamasutra},
title = {{The Next Big Steps in Game Sound Design}},
year = {2010}
}
@inproceedings{Jarvelainen2000a,
abstract = {This paper surveys some of the methods of algorithmic composition. Western classical music has been formalized in many ways throughout centuries, but the development of computers and the exponential growth of computing power have made it possible to generate music automatically. Common composing algorithms include state machines, rule-based grammars, stochastic processes, genetic algorithms, and so on. But who or what is the composer: the user or the maker of the algorithm?},
author = {Jarvelainen, H.},
booktitle = {Seminar on content creation, Telecommunications software and multimedia laboratory, Helsinki University of Technology},
file = {::},
pages = {11},
title = {{Algorithmic musical composition}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Algorithmic+Musical+Composition\#0},
year = {2000}
}
@inproceedings{Nordahl2004a,
abstract = {In this paper we describe the results of experiments whose goal is to investigate the effect of enhancing a virtual reality experience with the sound of synthetic footsteps.},
author = {Nordahl, Rolf},
booktitle = {Proceedings of the Eight Annual International Workshop Presence, London, UK},
file = {::},
pages = {5--6},
publisher = {Citeseer},
title = {{Self-induced footsteps sounds in virtual reality: Latency, recognition, quality and presence}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.8636\&amp;rep=rep1\&amp;type=pdf},
volume = {5},
year = {2004}
}
@inproceedings{VandenDoel2004,
abstract = {A physically based liquid sound synthesis methodology is developed. The fundamental mechanism for the produc- tion of liquid sounds is identified as the acoustic emission of bubbles. After reviewing the physics of vibrating bubbles as it is relevant to audio synthesis, a sound model for iso- lated single bubbles is developed and validated with a small user study. A stochastic model for the real-time interac- tive synthesis of complex liquid sounds such as produced by streams, pouring water, rivers, rain, and breaking waves is based on the synthesis of single bubble sounds. It is shown how realistic complex high dimensional sound spaces can be synthesized in this manner.},
author = {van den Doel, Kees},
booktitle = {Proceedings of ICAD 04 - Tenth Meeting of the International Conference on Auditory Display.},
file = {::},
pages = {1--8},
title = {{Physically-based Models for Liquid Sounds}},
year = {2004}
}
@article{Fagerlund2003a,
abstract = {For humans bird song is as natural phenomena as speech or human singing. However organization and generation of bird song is not so well-known as one for speech. In this paper we take short review to the basic stuctures of sounds birds can produce and also to principles of sound producing mech- anism in birds. Birds have unique organ for sound production among all animals in the world. Both organ itself and also sounds it can produce have large diversity between different species. We also introduce how popular speech and audio modelling methods can be used to model sound production in birds.},
author = {Fagerlund, Seppo},
file = {::},
journal = {Laboratory of Acoustics and Signal Processing, HUT, Finland},
publisher = {Citeseer},
title = {{Acoustics and physical models of bird sounds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.6303\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@unpublished{Menziesd,
abstract = {A system is described for simulating environmental sound in interactive virtual worlds, using the physical state of objects as control parameters. It contains a unified framework for integration with physics simulation engines, and synthesis algorithms that are tailored to work within the framework. A range of behaviours can be simulated, including diffuse and non-linear resonators, and loose surfaces. The overall aim has been to produce a flexible and practical system with intuitive controls that will appeal to sound design professionals. This could be valuable for computer game design, and in other areas where realistic environmental audio is required. A review of previous work is included, and discussion of the issues which influence the overall design of the system.},
author = {Menzies, Dylan},
booktitle = {Technology},
file = {::},
keywords = {environmental sound,sound synthesis,virtual reality,virtual world},
mendeley-tags = {environmental sound,sound synthesis,virtual reality,virtual world},
pages = {1--23},
title = {{Physically Motivated Environmental Sound Synthesis for Virtual Worlds}}
}
@inproceedings{Menzies2002c,
author = {Menzies, Dylan},
booktitle = {Proceedings of the 2002 International Conference on Auditory Display},
file = {::},
pages = {1--7},
publisher = {Citeseer},
title = {{Scene management for modelled audio objects in interactive worlds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.9249\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Tschuch1999a,
author = {Tschuch, Gunther and Brothers, Denis J.},
doi = {10.1121/1.428227},
file = {::},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {3706},
title = {{Modeling vibration and sound production in insects with nonresonant stridulatory organs}},
url = {http://link.aip.org/link/JASMAN/v106/i6/p3706/s1\&Agg=doi},
volume = {106},
year = {1999}
}
@article{Birchfield2003a,
address = {New York, New York, USA},
author = {Birchfield, David},
doi = {10.1145/982484.982504},
file = {::},
isbn = {1581137753},
journal = {Proceedings of the 2003 ACM SIGMM workshop on Experiential telepresence - ETP '03},
keywords = {arts,composition,digital audio,generative,generative model,generative system,genetic algorithm,multimedia,music,music cognition,music theory,perception},
pages = {99},
publisher = {ACM Press},
title = {{Generative model for the creation of musical emotion, meaning, and form}},
url = {http://portal.acm.org/citation.cfm?doid=982484.982504},
year = {2003}
}
@article{VandenDoel,
author = {van den Doel, Kees and Pai, Dinesh K.},
file = {::},
journal = {Audio anecdotes},
pages = {1--8},
title = {{Modal Synthesis for Vibrating Objects}}
}
@inproceedings{Menzies2009a,
abstract = {Phya is an open source C++ library that facilitates physically motivated audio in virtual environments. A review is presented and recent developments in the context of game audio, including the launch of VFoley, a project using Phya as the basis for a fully fledged virtual sound design environment. This will enable sound designers to rapidly produce rich Foley content from within a virtual environment, and author enhanced objects for use by Phya enabled applications.},
address = {London, UK.},
author = {Menzies, Dylan},
booktitle = {AES 35th International Conference},
file = {::},
pages = {1--8},
title = {{Phya and VFoley , Physically Motivated Audio for Virtual Environments}},
year = {2009}
}
@incollection{Farnell2010b,
abstract = {This chapter expands some key concepts and problems in the emerging field of procedural audio. In ad- dition to historical, philosophical, commercial, and technological themes, it examines why procedural audio differs from earlier “computer music” and “computer sound”. In particular, the extension of sound synthesis to the general case of ordinary, everyday objects in a virtual world, and the requirements for interactivity and real-time computation are examined.},
author = {Farnell, Andy},
booktitle = {Game Sound Technology and Player Interaction: Concepts and Developments},
doi = {10.4018/978-1-61692-828-5.ch015},
editor = {Grimshaw, Mark},
file = {::},
pages = {29},
publisher = {Information Science Reference},
title = {{Behaviour, Structure and Causality in Procedural Audio}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=sWPeR9nMVCcC\&amp;oi=fnd\&amp;pg=PR1\&amp;dq=Game+Sound+Technology+and+Player+Interaction:+Concepts+and+Developments\&amp;ots=rFHh93JxeU\&amp;sig=rlOSkaZsQ7vaKX-pHPmC6ey5lZ8},
year = {2010}
}
@inproceedings{O'Brien2001a,
address = {New York, New York, USA},
author = {O'Brien, James F. and Cook, Perry R. and Essl, Georg},
booktitle = {SIGGRAPH 2001: Proceedings of the 28th annual conference on Computer graphics and interactive techniques.},
doi = {10.1145/383259.383321},
file = {::},
isbn = {158113374X},
keywords = {animation techniques,dynamics,finite,physically based modeling,sim-,sound modeling,surface vibrations,ulation},
pages = {529--536},
publisher = {ACM Press},
title = {{Synthesizing sounds from physically based motion}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383321},
year = {2001}
}
@inproceedings{Menzies2010a,
abstract = {While it may be many years before high resolution active acoustic boundaries will be widely available, accurate soundfield control presents an interesting theoretical problem. We investigate and compare several different methods, including existing methods and two new ones, that aim to find the driving functions for sources on a general boundary, such that any given soundfield is reproduced as accurately as possible everywhere within. The methods considered include High Order Ambisonics, Wavefields, boundary element modeling, a modal boundary decomposition approach, and pressure control points. Finally a method is presented, referred to here as Distributed Modal Constraints, in which multiple regions are constrained by modal expansions simultaneously.},
author = {Menzies, Dylan},
booktitle = {Proceedings of the 2nd International Symposium on Ambisonics and Spherical Acoustics},
file = {::},
title = {{Soundfield Synthesis for General Enclosures}},
year = {2010}
}
@book{Cook2002b,
abstract = {Virtual environments such as games and animated and "real" movies require realistic sound effects that can be integrated by computer synthesis. The book emphasizes physical modeling of sound and focuses on real-world interactive sound effects. It is intended for game developers, graphics programmers, developers of virtual reality systems and training simulators, and others who want to learn about computational sound. It is written at an introductory level with mathematical foundations provided in appendices. An enclosed CD contains code examples and sound files.},
author = {Cook, Perry},
isbn = {1568811683},
pages = {xvii, 263 p.},
publisher = {AK Peters, Ltd.},
title = {{Real Sound Synthesis for Interactive Applications}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1568811683},
year = {2002}
}
@article{Verron2010a,
author = {Verron, Charles},
title = {{Synth\`{e}se immersive de sons d ’ environnement}},
year = {2010}
}
@misc{Paul2003a,
author = {Paul, By Leonard J},
booktitle = {Gamasutra.com},
file = {::},
title = {{Audio Prototyping with Pure Data}},
url = {http://www.gamasutra.com/resource\_guide/200 0!2"/pau\#\_0\$.shtm\#},
year = {2003}
}
@article{Dobashi2004a,
author = {Dobashi, Yoshinori and Yamamoto, Tsuyoshi and Nishita, Tomoyuki},
doi = {10.1111/j.1467-8659.2004.00785.x},
file = {::},
issn = {0167-7055},
journal = {Computer Graphics Forum},
month = sep,
number = {3},
pages = {539--545},
title = {{Synthesizing Sound from Turbulent Field using Sound Textures for Interactive Fluid Simulation}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2004.00785.x},
volume = {23},
year = {2004}
}
@phdthesis{Perry1991a,
author = {Perry, Ramond Cook},
file = {::},
pages = {171},
school = {Stanford University},
title = {{Identification of Control Parameters in an Articulatory Vocal Tract Model, with Applications to the Synthesis of Singing}},
type = {Doctor of Philosophy},
year = {1991}
}
@inproceedings{Bottcher2009,
abstract = {A simple audio only game was designed in order to test the possibilities of different interactive sound synthesis techniques simulating aerodynamic sword-like sounds. The Wii remote was used as the controller for generating the sound and this device was connected to the Max/MSP sound synthesis engine. In order to gain a user centered perspective on the potential of the diverse synthesis techniques, in terms of sound quality, interactivity and entertainment value, several techniques to synthesize real time interactive sword-like sounds were implemented. In this test a sample based model was compared to physically inspired modal synthesis, purely perceptually modeled subtractive synthesis and granular synthesis.},
author = {B\"{o}ttcher, Niels and Serafin, Stefania},
booktitle = {Proc. of the Audio Engineering Society 35th International Conference, London},
file = {::},
pages = {1--6},
title = {{Design and Evaluation of Physically Inspired Models of Sound Effects in Computer Games}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=15167},
year = {2009}
}
@inproceedings{Smyth2003a,
abstract = {In this research, a method is presented for extracting the control parameters of an avian syrinx synthesis model from recorded bird- song. A look-up table pairs combinations of pressure and tension parameters with the model’s corresponding output power spectra. At each time frame, a generalized likelihood ratio fills a pressure- tension matrix indicating similarity between the birdsong power spectrum and the tabulated spectra. Successive pressure-tension matrices are stacked and points exhibiting a good fit to the data align to form trajectories corresponding to changes in pressure and tension over time which can then be used to control the model. In the event a range of trajectories matches the data well, the selected trajectory is that of least action.},
author = {Smyth, Tamara and Abel, Jonathan S and Iii, Julius O Smith},
booktitle = {Proceedings of the Stockholm Music Acoustics Conference.},
file = {::},
number = {Smac 03},
pages = {3--6},
title = {{The Estimation of Birdsong Control Parameters Using Maximum Likelihood and Minimum Action}},
volume = {2003},
year = {2003}
}
@inproceedings{Fels2001b,
abstract = {We describe a system that maps the interaction between two people to control a genetic process for generating music. We start with a population of melodies encoded genetically. This population is allowed to breed every biological cycle creating new members of the population based upon the semantics of the spatial relationship between two people moving in a large, physical space. A pre-specified hidden melody is used to select a melody from the population to play every musical cycle. The overlapping of selected melodies provides an intriguing textured musical space.},
address = {Manchester, UK.},
author = {Fels, Sidney and Manzolli, Jonatas},
booktitle = {Multimedia 2001: proceedings of the Eurographics Workshop.},
file = {::},
isbn = {3211837698},
pages = {153},
publisher = {Springer Verlag Wien},
title = {{Interactive, evolutionary textured sound composition}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=2ueyZAG32KUC\&amp;oi=fnd\&amp;pg=PA153\&amp;dq=Interactive,+Evolutionary+Textured+Sound+Composition\&amp;ots=0A7Y-im7Tw\&amp;sig=k174uajYy6boHONbFp4asuISI10},
year = {2001}
}
@inproceedings{Dorin1999a,
author = {Dorin, Alan},
booktitle = {Proceedings, First Iteration, Dorin \& McCormack (eds), CEMA, Monash University, Australia},
file = {::},
keywords = {algorithmic composition,kinetic art,physically-based modelling,procedural animation},
pages = {68--79},
publisher = {Citeseer},
title = {{Classification of physical processes for virtual-kinetic art}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.4853\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@book{Bilbao2009a,
abstract = {Digital sound synthesis has long been approached using standard digital filtering techniques. Newer synthesis strategies, however, make use of physical descriptions of musical instruments, and allow for much more realistic and complex sound production and thereby synthesis becomes a problem of simulation. This book has a special focus on time domain finite difference methods presented within an audio framework. It covers time series and difference operators, and basic tools for the construction and analysis of finite difference schemes, including frequency-domain and energy-based methods, with special attention paid to problems inherent to sound synthesis. Various basic lumped systems and excitation mechanisms are covered, followed by a look at the 1D wave equation, linear bar and string vibration, acoustic tube modelling, and linear membrane and plate vibration. Various advanced topics, such as the nonlinear vibration of strings and plates, are given an elaborate treatment. Key features: Includes a historical overview of digital sound synthesis techniques, highlighting the links between the various physical modelling methodologies. A pedagogical presentation containing over 150 problems and programming exercises, and numerous figures and diagrams, and code fragments in the MATLAB programming language helps the reader with limited experience of numerical methods reach an understanding of this subject. Offers a complete treatment of all of the major families of musical instruments, including certain audio effects. Numerical Sound Synthesis is suitable for audio and software engineers, and researchers in digital audio, sound synthesis and more general musical acoustics. Graduate students in electrical engineering, mechanical engineering or computer science, working on the more technical side of digital audio and sound synthesis, will also find this book of interest.},
author = {Bilbao, Stefan},
isbn = {0470510463},
pages = {456},
publisher = {John Wiley and Sons},
title = {{Numerical Sound Synthesis}},
url = {http://catalogo.unipd.it/F?func=find-c\&ccl\_term=IDN=PUV1187104\&local\_base=SBP01},
year = {2009}
}
@inproceedings{Farnell2007b,
author = {Farnell, Andy},
booktitle = {Audio Mostly Conference},
file = {::},
number = {September},
pages = {1--31},
title = {{An introduction to procedural audio and its application in computer games}},
url = {http://obiwannabe.co.uk/html/papers/proc-audio/proc-audio.pdf},
year = {2007}
}
@inproceedings{Cook2002c,
abstract = {This paper presents algorithms and systems for automatic analysis and parametric synthesis of walking and other (gesture-rate) periodically modulated noisy sounds. A recording of walking is analyzed, extracting the gait (tempo and left/right asymmetries), heel-toe events, etc. Linear prediction is used to extract the basic resonances. Wavelet decomposition is performed, and a high frequency-subband is used to calculate statistics for a particle resynthesis model. Control envelopes are extracted from the original sound. A real-time synthesis program allows flexible resynthesis of walking sounds, controlled by a score extracted from a sound file, a graphical user interface, or parameters from game/animation/VR data. Results for the analysis algorithm are presented for synthesisized data, and for hand-crafted real experimental sounds of gravel.},
author = {Cook, P.},
booktitle = {Proceedings of the AES 22nd International Conference on Virtual, Synthetic, and Entertainment Audio},
file = {::},
pages = {73--78},
publisher = {Citeseer},
title = {{Modeling Bill's Gait: Analysis and Parametric Synthesis of Walking Sounds}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.1820\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@article{Mullan2009a,
author = {Mullan, Eoin},
journal = {2009 International IEEE Consumer Electronics Society's Games Innovations Conference},
month = aug,
pages = {1--9},
publisher = {Ieee},
title = {{Driving sound synthesis from a physics engine}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5293591},
year = {2009}
}
@article{Zheng2009a,
author = {Zheng, Changxi and James, Doug L.},
doi = {10.1145/1531326.1531343},
file = {::},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {acoustic bubbles,acoustic transfer,and kinetic energy as,as compressed air and,basically,scale air bubbles,see figure 1,sound synthesis,surface tension,surrounding fluid vibrations,the bubble oscilla-,the impor-,tor stores potential energy},
month = jul,
number = {3},
pages = {1},
title = {{Harmonic fluids}},
url = {http://portal.acm.org/citation.cfm?doid=1531326.1531343},
volume = {28},
year = {2009}
}
@misc{Paula,
author = {Paul, Leonard J},
booktitle = {Event (London)},
file = {::},
keywords = {1,adaptive audio,fig,game coding,game prototyping,interactive audio,open sound control,osc,pd,prototyping using,pure data,screenshot of software used,to demonstrate game audio,video game,video game audio},
pages = {3--8},
title = {{Video Game Audio Prototyping with Pure Data}}
}
@inproceedings{Taylor2009b,
abstract = {We present an algorithm for fast computation of diffraction paths for geometric-acoustics in complex environments based on theUTD formulation. Our method extends ray-frustum tracing to efficiently compute paths in the shadow region caused by long diffracting edges. Our approach can handle general scenes withmoving sources, receivers, and dynamic objects. We evaluate the accuracy through comparisons with physically validated geometric simulations. In practice, our edge diffraction algorithm can perform sound propa- gation at nearly interactive rates in dynamic scenarios on a multi- core PC.},
author = {Taylor, Micah and Chandak, Anish and Zhimin, Ren and Lauterbach, Christian and Manocha, Dinesh},
booktitle = {Proceedings of the EAA Symposium on Auralization.},
file = {::},
number = {June},
pages = {15--17},
title = {{Fast Edge-Diffraction for Sound Propagation in Complex Virtual Environments}},
year = {2009}
}
@techreport{Savioja2010a,
abstract = {An efficient algorithm for time-domain solution of the wave equation for the purpose of room acous- tics is presented. Numerical dispersion is controlled by computing an adaptive rectangular decompo- sition of the environment and using analytical solutions within the partitions that rely on spatially invariant speed of sound. Due to the near absence of dispersion, this technique is suitable for au- ralizations and sound field visualizations, even on coarse meshes approaching the Nyquist limit. It is demonstrated that by carefully mapping all components of the algorithm to match the paral- lel processing capabilities of graphics processors, significant improvement in performance is gained compared to the corresponding CPU-based solver, while producing numerically identical results. Substantial performance gain over a high-order finite-difference time-domain (FDTD) method is observed. Using this technique, a 1 second long simulation can be performed on scenes of air vol- ume 7500 m3 till 1650 Hz within 18 minutes compared to the corresponding CPU-based solver that takes five hours and the high-order FDTD solver up to three weeks on a desktop computer. To the best of the authors’ knowledge, this is the fastest time-domain solver for modeling the room acoustics of large, complex-shaped 3D scenes that generates broad-band results for both auralization and visualization.},
address = {Chapel Hill},
author = {Savioja, Lauri and Mehra, Ravish and Raghuvanshi, Nikunj and Lin, Ming C. and Manocha, Dinesh},
booktitle = {Processing},
file = {::},
institution = {University of North Carolina},
title = {{An efficient time-domain solver for the acoustic wave equation on graphics processors}},
year = {2010}
}
@inproceedings{Grigoriou2010a,
abstract = {In this work a novel audio binaural mixing platform is presented which employs advanced gestural-based interaction techniques for controlling the mixing parameters. State-of-the-art binaural technology algorithms are used for producing the final two- channel binaural signal. These algorithms are optimized for real- time operation, able to manipulate high-quality audio (typically 24bit / 96kHz) for an arbitrary number of fixed-position or moving sound sources in closed acoustic enclosures. Simple gestural rules are employed, which aim to provide the complete functionality required for the mixing process, using low cost equipment. It is shown that the proposed platform can be efficiently used for general audio mixing / mastering purposes, providing an attractive alternative to legacy hardware control designs and software-based mixing user interfaces.},
author = {Grigoriou, Nikolas and Floros, Andreas and Drossos, K.},
booktitle = {Proceedings of the 5th Audio Mostly Conference: A Conference on Interaction with Sound},
file = {::},
pages = {1--6},
publisher = {ACM},
title = {{Binaural mixing using gestural control interaction}},
url = {http://portal.acm.org/citation.cfm?id=1859803},
year = {2010}
}
@inproceedings{Schwarz2011a,
author = {Schwarz, Diemo},
booktitle = {DAFx},
file = {::},
pages = {1--10},
title = {{State of the Art in Sound Texture Synthesis}},
year = {2011}
}
@inproceedings{Menziesc,
address = {Graz},
author = {Menzies, Dylan},
booktitle = {Ambisonics Symposium 2009},
file = {::},
title = {{HRTFs from Point Source Representations}}
}
@article{Roma2010a,
author = {Roma, Gerard and Janer, Jordi and Kersten, Stefan and Schirosa, Mattia and Herrera, Perfecto and Serra, Xavier},
issn = {1687-4714},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
pages = {1--11},
title = {{Ecological Acoustics Perspective for Content-Based Retrieval of Environmental Sounds}},
url = {http://www.hindawi.com/journals/asmp/2010/960863.html},
volume = {2010},
year = {2010}
}
@inproceedings{Eladhari2006a,
author = {Eladhari, Mirjam and Nieuwdorp, Rik and Fridenfalk, Mikael},
booktitle = {Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology},
file = {::},
isbn = {1595933808},
keywords = {adaptive audio,believable agents,game,music,role playing},
pages = {54--es},
publisher = {ACM},
title = {{The Soundtrack of Your Mind: Mind Music - Adaptive Audio for Game Characters}},
url = {http://portal.acm.org/citation.cfm?id=1178887},
year = {2006}
}
@phdthesis{Misra2009,
author = {Misra, Ananya},
pages = {1--186},
school = {Princeton University},
title = {{TAPESTREA: Techniques and Paradigms for Expressive Synthesis, Transformation, and Re-composition of Environmental Audio}},
year = {2009}
}
@inproceedings{Menzies2002b,
address = {Espoo, Finland},
author = {Menzies, Dylan},
booktitle = {Proceedings of the 22nd International Conference of the AES on Virtual Synthetic and Entertainment Audio, Espoo, Finland},
file = {::},
publisher = {Citeseer},
title = {{W-panning and O-format, tools for object spatialization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.2792\&amp;rep=rep1\&amp;type=pdf},
year = {2002}
}
@inproceedings{VandenDoel2001,
abstract = {We describe algorithms for real-time synthesis of realistic sound effects for interactive simulations (e.g., games) and animation. These sound effects are produced automatically, from 3D models using dynamic simulation and user interac- tion. We develop algorithms that are efficient, physically- based, and can be controlled by users in natural ways. We develop effective techniques for producing high quality con- tinuous contact sounds from dynamic simulations running at video rates which are slow relative to audio synthesis. We ac- complish this using modal models driven by contact forces modeled at audio rates, which are much higher than the graphics frame rate. The contact forces can be computed from simulations or can be custom designed. We demon- strate the effectiveness with complex realistic simulations.},
address = {New York, New York, USA},
author = {van den Doel, Kees and Kry, Paul G. and Pai, Dinesh K.},
booktitle = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques - SIGGRAPH '01},
doi = {10.1145/383259.383322},
file = {::},
isbn = {158113374X},
keywords = {Animation Systems,Computer Games,Head Mounted Displays.,Multimedia,Physically Based Animation,Physically BasedModeling,Sound Visualization,Virtual Reality},
mendeley-tags = {Animation Systems,Computer Games,Head Mounted Displays.,Multimedia,Physically Based Animation,Physically BasedModeling,Sound Visualization,Virtual Reality},
pages = {537--544},
publisher = {ACM Press},
title = {{FoleyAutomatic: Physically-based Sound Effects for Interactive Simulation and Animation}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383322},
year = {2001}
}
@inproceedings{Livingstone2005a,
author = {Livingstone, S. and Brown, A.},
booktitle = {Australasian Conference On Interactive Entertainment},
file = {::},
keywords = {and film scoring having,computer games,computer music,emotion,matured into the essential,plays,role that it now,story-telling,the current generation of},
pages = {105--111},
title = {{Dynamic response: real-time adaptation for music emotion}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=rhKGK\_c7T70C\&amp;oi=fnd\&amp;pg=PA105\&amp;dq=Dynamic+Response+:+Real-Time+Adaptation+for+Music+Emotion\&amp;ots=kyH58b-ddK\&amp;sig=OoEHYuihKRMeRPDFZA17gHnScd4},
volume = {2},
year = {2005}
}
@inproceedings{Bresin2001a,
abstract = {The control of sound synthesis is a well-known problem. This is particularly true if the modeling techniques that sounds are generated with physical typically need specification of numerous control parameters. In the present work outcomes from studies on automatic music performance are used for tackling this problem.},
address = {Limerick, Ireland},
author = {Bresin, R. and Friberg, A. and Dahl, S.},
booktitle = {Proc. COST-G6 Conf. Digital Audio Effects (DAFX-01)},
file = {::},
pages = {45--49},
title = {{Toward a New Model For Sound Control}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Toward+a+New+Model+For+Sound+Control\#0},
year = {2001}
}
@inproceedings{Fontana2003a,
abstract = {Three types of ecological events (crushing, walking and running) have been considered. Their acoustic properties have been mod- eled following the physics-based approach. Starting from an ex- isting physically-based impact model, we superimposed to it the dynamic and temporal stochastic characteristics governing crush- ing events. The resulting model was triggered by control rules realizing typical walking and running time patterns. This bottom-up design strategywas made possible because the sound synthesis and sound control models could be directly con- nected each other via a common switchboard of driving and con- trol parameters. The existence of a common interface specification for all the models follows from the application of physics-based modeling, and translates in major advantages when those models are implemented as independent, self-contained blocks and proce- dures connected together in real-time inside a sw architecture like pd.},
address = {Firenze, Italy},
author = {Fontana, F. and Bresin, R.},
booktitle = {Proceedings of the XIV Colloquium on Musical Informatics (XIV CIM 2003)},
file = {::},
pages = {109--114},
title = {{Physics-based Sound Synthesis and Control: Crushing, Walking and Running by Crumpling Sounds}},
url = {http://www.speech.kth.se/prod/publications/files/981.pdf},
year = {2003}
}
@article{Lloyd2011a,
author = {Lloyd, D Brandon and Raghuvanshi, Nikunj and Govindaraju, Naga K.},
journal = {ACM},
keywords = {interactive audio,sound synthesis},
pages = {55--62},
title = {{Sound Synthesis for Impact Sounds in Video Games}},
year = {2011}
}
@article{Raghuvanshi2007a,
abstract = {Simulating the complete process of sound synthesis and propagation by exploiting aural perception makes the experience of playing games much more realistic and immersive.},
author = {Raghuvanshi, Nikunj and Lauterbach, Christian and Chandak, Anish and Manocha, Dinesh and Lin, Ming C},
doi = {10.1145/1272516.1272541},
issn = {00010782},
journal = {Communications of the ACM},
number = {7},
pages = {66--73},
publisher = {ACM},
title = {{Real-time sound synthesis and propagation for games}},
url = {http://portal.acm.org/citation.cfm?id=1272516.1272541},
volume = {50},
year = {2007}
}
@article{Menzies2007b,
abstract = {Exterior expansions of complex sound sources are presented as flexible objects for producing Ambisonic soundfield encodings. The sources can be synthesized or recorded directly, rotated and positioned in space. Related techniques can also be used to efficiently add high quality reverberation depending on the orientation and location of the source and listener.},
author = {Menzies, Dylan and Al-Akaidi, Marwan},
file = {::},
pages = {1--28},
title = {{Ambisonic Synthesis of Complex Sources}},
year = {2007}
}
@article{Collins2009b,
author = {Collins, Karen},
doi = {10.1080/07494460802663983},
file = {::},
issn = {0749-4467},
journal = {Contemporary Music Review},
month = feb,
number = {1},
pages = {5--15},
title = {{An Introduction to Procedural Music in Video Games}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/07494460802663983\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {28},
year = {2009}
}
@article{Schneider2012,
author = {Schneider, Frank E. and Wildermuth, Dennis},
doi = {10.1016/j.robot.2012.05.001},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = nov,
number = {11},
pages = {1421--1428},
publisher = {Elsevier B.V.},
title = {{Influences of the robot group size on cooperative multi-robot localisation—Analysis and experimental validation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889012000577},
volume = {60},
year = {2012}
}
@article{Liebe2006,
author = {Liebe, C.C. and Padgett, C. and Chapsky, J. and Wilson, D. and Brown, K. and Jerebets, S. and Goldberg, H. and Schroeder, J.},
doi = {10.1109/AERO.2006.1655898},
file = {::},
isbn = {0-7803-9545-X},
journal = {2006 IEEE Aerospace Conference},
pages = {1--10},
publisher = {Ieee},
title = {{Spacecraft Hazard Avoidance Utilizing Structured Light}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1655898},
year = {2006}
}
@unpublished{Vezien,
abstract = {Ce cours est l’aboutissement d’un travail de r\'{e}daction coll\'{e}gial initi\'{e} par le professeur A. Gagalowicz au d\'{e}but des ann\'{e}es 1990 dans le cadre de cours dispens\'{e}s \`{a} l’ESIEA. Il a depuis fait l’objet de constants remaniements et additions, notamment au regard de l’explosion de la manipulation d’images et de contenus multim\'{e}dias dans le domaine grand public, et reste en \'{e}volution constante. 2},
author = {V\'{e}zien, Jean-Marc},
title = {{TRAITEMENT DES IMAGES et VISION PAR MACHINE}},
url = {http://www.limsi.fr/~vezien/pdf\_cours\_ima\_jmv.pdf}
}
@article{Potyrailo2012,
abstract = {New sensor technologies for homeland security applications must meet the key requirements of sensitivity to detect agents below risk levels, selectivity to provide minimal false-alarm rates, and response speed to operate in high throughput environments, such as airports, sea ports, and other public places. Chemical detection using existing sensor systems is facing a major challenge of selectivity. In this review, we provide a brief summary of chemical threats of homeland security importance; focus in detail on modern concepts in chemical sensing; examine the origins of the most significant unmet needs in existing chemical sensors; and, analyze opportunities, specific requirements, and challenges for wireless chemical sensors and wireless sensor networks (WSNs). We further review a new approach for selective chemical sensing that involves the combination of a sensing material that has different response mechanisms to different species of interest, with a transducer that has a multi-variable signal-transduction ability. This new selective chemical-sensing approach was realized using an attractive ubiquitous platform of battery-free passive radio-frequency identification (RFID) tags adapted for chemical sensing. We illustrate the performance of RFID sensors developed in measurements of toxic industrial materials, humidity-independent detection of toxic vapors, and detection of chemical-agent simulants, explosives, and strong oxidizers.},
author = {Potyrailo, Radislav a and Nagraj, Nandini and Surman, Cheryl and Boudries, Hacene and Lai, Hanh and Slocik, Joseph M and Kelley-Loughnane, Nancy and Naik, Rajesh R},
doi = {10.1016/j.trac.2012.07.013},
issn = {0165-9936},
journal = {Trends in analytical chemistry : TRAC},
keywords = {Radio-frequency identification (RFID),Response speed,Toxic industrial material (TIM),Wireless sensor network (WSN),chemical agent,chemical sensing,homeland security,multivariate statistical analysis,radio-frequency identification,response,rfid,selectivity,sensitivity,speed,tim,toxic industrial material,wireless sensor network,wsn},
month = nov,
number = {4},
pages = {133--145},
pmid = {23175590},
publisher = {Elsevier Ltd},
title = {{Wireless sensors and sensor networks for homeland security applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23175590},
volume = {40},
year = {2012}
}
@article{Gerla2011,
author = {Gerla, Mario and Kleinrock, Leonard},
doi = {10.1016/j.comnet.2010.10.015},
issn = {13891286},
journal = {Computer Networks},
month = feb,
number = {2},
pages = {457--469},
publisher = {Elsevier B.V.},
title = {{Vehicular networks and the future of the mobile internet}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389128610003324},
volume = {55},
year = {2011}
}
@article{Koong2012,
author = {Koong, Chorng-Shiuh and Shih, Chihhsiong and Hsiung, Pao-Ann and Lai, Hung-Jui and Chang, Chih-Hung and Chu, William C. and Hsueh, Nien-Lin and Yang, Chao-Tung},
doi = {10.1016/j.jss.2011.08.030},
issn = {01641212},
journal = {Journal of Systems and Software},
month = jan,
number = {1},
pages = {43--60},
publisher = {Elsevier Inc.},
title = {{Automatic testing environment for multi-core embedded software—ATEMES}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121211002305},
volume = {85},
year = {2012}
}
@article{Bakar2012,
author = {Bakar, Mohd Nazri Abu and Saad, Abdul Rahman Mohd.},
doi = {10.1016/j.proeng.2012.07.138},
file = {::},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {autonomous robot,detection and tracking,doctor following robot,monocular vision,range finding},
month = jan,
number = {Iris},
pages = {22--31},
title = {{A Monocular Vision-based Specific Person Detection System for Mobile Robot Applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812025246},
volume = {41},
year = {2012}
}
@article{Xue2012,
author = {Xue, Junpeng and Su, Xianyu},
doi = {10.1016/j.ijleo.2011.09.025},
file = {::},
issn = {00304026},
journal = {Optik - International Journal for Light and Electron Optics},
month = nov,
number = {21},
pages = {1923--1927},
publisher = {Elsevier GmbH.},
title = {{A new approach for the bundle adjustment problem with fixed constraints in stereo vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0030402611005390},
volume = {123},
year = {2012}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
chapter = {Graphical},
doi = {10.1117/1.2819119},
editor = {Jordan, M and Kleinberg, J and Sch\"{o}lkopf, B},
eprint = {0-387-31073-8},
file = {::},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
publisher = {Springer},
series = {Information science and statistics},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@article{Glette2006,
author = {Glette, K. and Torresen, J. and Yasunaga, M. and Yamaguchi, Y.},
doi = {10.1109/AHS.2006.55},
isbn = {0-7695-2614-4},
journal = {First NASA/ESA Conference on Adaptive Hardware and Systems (AHS'06)},
pages = {373--380},
publisher = {Ieee},
title = {{On-Chip Evolution Using a Soft Processor Core Applied to Image Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1638187},
year = {2006}
}
@article{Blas2011,
author = {Blas, Morten Rufus and Blanke, Mogens},
doi = {10.1016/j.compag.2010.10.012},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {texture classification},
month = jan,
number = {1},
pages = {159--168},
publisher = {Elsevier B.V.},
title = {{Stereo vision with texture learning for fault-tolerant automatic baling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016816991000222X},
volume = {75},
year = {2011}
}
@article{Nundy2013,
abstract = {Behavioral models for mobile phone-based diabetes interventions are lacking. This study explores the potential mechanisms by which a text message-based diabetes program affected self-management among African-Americans.},
author = {Nundy, Shantanu and Dick, Jonathan J and Solomon, Marla C and Peek, Monica E},
doi = {10.1016/j.pec.2012.09.008},
issn = {1873-5134},
journal = {Patient education and counseling},
month = jan,
number = {1},
pages = {125--32},
pmid = {23063349},
publisher = {Elsevier Ireland Ltd},
title = {{Developing a behavioral model for mobile phone-based diabetes interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23063349},
volume = {90},
year = {2013}
}
@article{Esmaeilabadi2012,
author = {Esmaeilabadi, Mir Ebad Ahmadzadeh},
doi = {10.1016/j.protcy.2012.03.013},
file = {::},
issn = {22120173},
journal = {Procedia Technology},
keywords = {face detection,head tracking,lighting,skin color,thresholding,virtual reality},
month = jan,
pages = {121--131},
title = {{3D Virtual Reality Navigation by Human's Head Movements Using a Generic Webcam}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212017312002423},
volume = {3},
year = {2012}
}
@article{Mustafah2012,
author = {Mustafah, Yasir Mohd and Azman, Amelia Wong and Akbar, Fajril},
doi = {10.1016/j.proeng.2012.07.214},
isbn = {6012604270},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {indoor localization,stereo vision,uav},
month = jan,
number = {Iris},
pages = {575--579},
title = {{Indoor UAV Positioning Using Stereo Vision Sensor}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812026148},
volume = {41},
year = {2012}
}
@article{Kim2012a,
author = {Kim, Jeongdae and Do, Yongtae},
doi = {10.1016/j.proeng.2012.07.262},
isbn = {8253850662},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {block-based motion estimation,mobile robot,obstacle avoidance,robot vision},
month = jan,
number = {Iris},
pages = {911--916},
title = {{Moving Obstacle Avoidance of a Mobile Robot Using a Single Camera}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812026628},
volume = {41},
year = {2012}
}
@article{Chatterjee2011,
author = {Chatterjee, Avishek and Ray, Olive and Chatterjee, Amitava and Rakshit, Anjan},
doi = {10.1016/j.eswa.2011.01.007},
file = {::},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {extended kalman filter},
month = jul,
number = {7},
pages = {8266--8274},
publisher = {Elsevier Ltd},
title = {{Development of a real-life EKF based SLAM system for mobile robots employing vision sensing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417411000273},
volume = {38},
year = {2011}
}
@article{Shabeer2012,
author = {Shabeer, H. Abdul and Wahidabanu, R.S.D.},
doi = {10.1016/j.proeng.2012.01.907},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {cell phone while driving,locate the vehicle using,mobile jammer,mobile phone,vehicle number plate},
month = jan,
number = {2011},
pages = {623--630},
title = {{Averting mobile phone use while driving and technique to locate the mobile phone used vehicle}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705812009174},
volume = {30},
year = {2012}
}
@article{Barnes2012,
author = {Barnes, Nick},
doi = {10.1016/j.imavis.2012.05.007},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Bionic eye,Computer vision,Face recognition,Orientation and mobility,Prosthetic vision,Retinal implants},
month = aug,
number = {8},
pages = {478--479},
publisher = {Elsevier B.V.},
title = {{The role of computer vision in prosthetic vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885612000832},
volume = {30},
year = {2012}
}
@article{Wu2012,
author = {Wu, Di and Sun, Da-Wen},
doi = {10.1016/j.tifs.2012.08.004},
file = {::},
issn = {09242244},
journal = {Trends in Food Science \& Technology},
month = sep,
title = {{Colour measurements by computer vision for food quality control – A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0924224412001835},
year = {2012}
}
@article{Chapitre,
author = {Chapitre, Cours},
pages = {1--11},
title = {{1. Qu'est-ce que la vision ? 1.1.}}
}
@article{Doctorants2003,
author = {Doctorants, Guilde Des},
file = {::},
keywords = {doctorat,guide,recherche,th\`{e}se},
mendeley-tags = {doctorat,guide,recherche,th\`{e}se},
pages = {1--107},
title = {{Guide du Doctorant}},
url = {http://guilde.jeunes-chercheurs.org/Alire/guide/},
year = {2003}
}
@article{Losada2012,
author = {Losada, Cristina and Mazo, Manuel and Palazuelos, Sira E. and Pizarro, Daniel and Marr\'{o}n, Marta and Velasco, Jos\'{e} F.},
doi = {10.1016/j.robot.2012.11.007},
file = {::},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
month = dec,
title = {{Identification and tracking of robots in an intelligent space using static cameras and an XPFCP}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889012002187},
year = {2012}
}
@article{Michalos2012,
author = {Michalos, G. and Makris, S. and Eytan, a. and Matthaiakis, S. and Chryssolouris, G.},
doi = {10.1016/j.procir.2012.07.061},
issn = {22128271},
journal = {Procedia CIRP},
keywords = {assembly,robotic welding,vision system},
month = jan,
pages = {352--357},
title = {{Robot Path Correction Using Stereo Vision System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212827112002338},
volume = {3},
year = {2012}
}
@article{Bardsley,
author = {Bardsley, Daniel},
file = {::},
pages = {1--11},
title = {{3D Reconstruction Using the Direct Linear Transform}}
}
@article{Wanga2012,
author = {Wanga, Jijing},
doi = {10.1016/j.proeng.2012.01.259},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {data fusion,map-matching,mixed navigation,mobile phone net},
month = jan,
pages = {2045--2049},
title = {{Design of Mobile Phone Networks and Map-matching Navigation System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S187770581200269X},
volume = {29},
year = {2012}
}
@article{Menezes2011,
author = {Menezes, Paulo and Lerasle, Fr\'{e}d\'{e}ric and Dias, Jorge},
doi = {10.1016/j.imavis.2011.01.003},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Assistant robot,Computer vision,Data fusion,Human motion capture,Particle filtering},
month = may,
number = {6},
pages = {382--393},
publisher = {Elsevier B.V.},
title = {{Towards human motion capture from a camera mounted on a mobile robot}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885611000102},
volume = {29},
year = {2011}
}
@inproceedings{Sokratis2011a,
author = {Vavilis, Sokratis and Kavallieratou, Ergina},
booktitle = {2011 International Conference on Document Analysis and Recognition},
file = {::},
keywords = {- document,algorithms,binarization,tool,training,user-feedback},
month = sep,
pages = {1--5},
publisher = {Ieee},
title = {{A Tool for Tuning Binarization Techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065265},
year = {2011}
}
@article{Garcia2011,
author = {Garc\'{\i}a, Antonio and Erenas, M.M. and Marinetto, Eugenio D. and Abad, Carlos a. and de Orbe-Paya, Ignacio and Palma, Alberto J. and Capit\'{a}n-Vallvey, Luis F.},
doi = {10.1016/j.snb.2011.04.045},
issn = {09254005},
journal = {Sensors and Actuators B: Chemical},
month = aug,
number = {1},
pages = {350--359},
title = {{Mobile phone platform as portable chemical analyzer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S092540051100342X},
volume = {156},
year = {2011}
}
@article{Milanes2012,
author = {Milan\'{e}s, Vicente and Llorca, David F. and Villagr\'{a}, Jorge and P\'{e}rez, Joshu\'{e} and Fern\'{a}ndez, Carlos and Parra, Ignacio and Gonz\'{a}lez, Carlos and Sotelo, Miguel a.},
doi = {10.1016/j.eswa.2011.09.024},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {advanced vehicle control and,safety},
month = feb,
number = {3},
pages = {3362--3373},
title = {{Intelligent automatic overtaking system using vision for vehicle detection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417411013339},
volume = {39},
year = {2012}
}
@article{Bayro-Corrochano2011,
author = {Bayro-Corrochano, Eduardo and Eklundh, Jan-Olof},
doi = {10.1016/j.patrec.2011.10.008},
file = {::},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = dec,
number = {16},
pages = {2143--2144},
publisher = {Elsevier B.V.},
title = {{Advances in theory and applications of pattern recognition, image processing and computer vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865511003527},
volume = {32},
year = {2011}
}
@misc{TheMendeleySupportTeam2011a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {::},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{NirmalSingh2011,
author = {{Nirmal Singh}, N. and Chatterjee, Avishek and Chatterjee, Amitava and Rakshit, Anjan},
doi = {10.1016/j.measurement.2010.12.002},
file = {::},
issn = {02632241},
journal = {Measurement},
month = may,
number = {4},
pages = {620--641},
publisher = {Elsevier Ltd},
title = {{A two-layered subgoal based mobile robot navigation algorithm with vision system and IR sensors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0263224110003271},
volume = {44},
year = {2011}
}
@article{Zhou2012,
author = {Zhou, Fuqiang and Wang, Yexin and Peng, Bin and Cui, Yi},
doi = {10.1016/j.measurement.2012.10.031},
file = {::},
issn = {02632241},
journal = {Measurement},
month = nov,
publisher = {Elsevier Ltd},
title = {{A Novel Way of Understanding for Calibrating Stereo Vision Sensor Constructed by a Single Camera and Mirrors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0263224112004034},
year = {2012}
}
@article{Arroqui2012,
author = {Arroqui, Mauricio and Mateos, Cristian and Machado, Claudio and Zunino, Alejandro},
doi = {10.1016/j.compag.2012.05.016},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {agricultural information systems},
month = sep,
pages = {14--18},
publisher = {Elsevier B.V.},
title = {{RESTful Web Services improve the efficiency of data transfer of a whole-farm simulator accessed by Android smartphones}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169912001305},
volume = {87},
year = {2012}
}
@article{Chapitrea,
author = {Chapitre, Cours},
pages = {1--5},
title = {{1. Probl\`{e}me g\'{e}n\'{e}ral de la vision du relief. 1.1.}}
}
@article{Chen2012,
author = {Chen, Gang and Guo, Yubo and Wang, Hanping and Ye, Dong and Gu, Yanfeng},
doi = {10.1016/j.ijleo.2011.05.030},
issn = {00304026},
journal = {Optik - International Journal for Light and Electron Optics},
month = apr,
number = {8},
pages = {731--734},
publisher = {Elsevier GmbH.},
title = {{Stereo vision sensor calibration based on random spatial points given by CMM}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0030402611003081},
volume = {123},
year = {2012}
}
@incollection{Sokratis2011,
author = {Vavilis, Sokratis and Kavallieratou, Ergina and Paredes, Roberto and Sotiropoulos, Kostas},
booktitle = {LEARNING STRUCTURE AND SCHEMAS FROM DOCUMENTS},
file = {::},
keywords = {binarization algorithm,document image processing,historical document images,hybrid algorithm},
pages = {165--179},
publisher = {Springer},
title = {{A Hybrid Binarization Technique for Document Images}},
year = {2011}
}
@article{Ambrosch2011,
author = {Ambrosch, Kristian and Kubinger, Wilfried},
doi = {10.1016/j.cviu.2010.11.008},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = feb,
number = {2},
pages = {287},
title = {{Corrigendum to “Accurate hardware-based stereo vision” [Comput. Vis. Image Understanding 114 (2010) 1303–1316}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314210002444},
volume = {115},
year = {2011}
}
@article{Niu2012,
author = {Niu, Yan and Xia, Heng and Huan, Lele},
doi = {10.1016/j.phpro.2012.03.105},
issn = {18753892},
journal = {Physics Procedia},
month = jan,
pages = {415--420},
publisher = {Elsevier Srl},
title = {{MIDP-based Realization of a Simple Phone Contact Book}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1875389212005214},
volume = {25},
year = {2012}
}
@article{Deepa2012,
author = {Deepa, P. and Vasanthanayaki, C.},
doi = {10.1016/j.mejo.2012.05.001},
file = {::},
issn = {00262692},
journal = {Microelectronics Journal},
keywords = {Field programmable gate arrays,Image processing,Low power,Scan order,Single port SRAM,True dual port SRAM},
month = nov,
number = {11},
pages = {916--928},
publisher = {Elsevier},
title = {{FPGA based efficient on-chip memory for image processing algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0026269212000985},
volume = {43},
year = {2012}
}
@inproceedings{Blum1998,
address = {New York, New York, USA},
author = {Blum, Avrim and Mitchell, Tom},
booktitle = {Proceedings of the eleventh annual conference on Computational learning theory - COLT' 98},
file = {::},
number = {4},
pages = {92--100},
publisher = {ACM Press},
title = {{Combining labeled and unlabeled data with co-training}},
url = {http://www.mendeley.com/catalog/combining-labeled-unlabeled-data-co-training/},
volume = {98},
year = {1998}
}
@article{Xue2012a,
author = {Xue, Ting and Qu, Liqun and Cao, Zhaofeng and Zhang, Tao},
doi = {10.1016/j.flowmeasinst.2012.07.007},
issn = {09555986},
journal = {Flow Measurement and Instrumentation},
keywords = {gas,liquid two-phase flow},
month = oct,
pages = {29--36},
publisher = {Elsevier Ltd},
title = {{Three-dimensional feature parameters measurement of bubbles in gas–liquid two-phase flow based on virtual stereo vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0955598612000799},
volume = {27},
year = {2012}
}
@article{Kolter2009,
author = {Kolter, J. Zico and Ng, Andrew Y.},
doi = {10.1109/ROBOT.2009.5152795},
isbn = {978-1-4244-2788-8},
journal = {2009 IEEE International Conference on Robotics and Automation},
month = may,
pages = {1557--1564},
publisher = {Ieee},
title = {{Stereo vision and terrain modeling for quadruped robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152795},
year = {2009}
}
@article{Tang2011a,
author = {Tang, Xinxing and Yamada, Hironao},
doi = {10.1016/j.proeng.2011.08.198},
issn = {18777058},
journal = {Procedia Engineering},
keywords = {computer graphics,hydraulic servo system,tele-operation construction robot,virtual reality},
month = jan,
pages = {1071--1076},
title = {{Tele-operation Construction Robot Control System with Virtual Reality Technology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877705811016997},
volume = {15},
year = {2011}
}
@article{Simoes2013,
author = {Sim\~{o}es, Jorge and Redondo, Rebeca D\'{\i}az and Vilas, Ana Fern\'{a}ndez},
doi = {10.1016/j.chb.2012.06.007},
issn = {07475632},
journal = {Computers in Human Behavior},
month = mar,
number = {2},
pages = {345--353},
title = {{A social gamification framework for a K-6 learning platform}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563212001574},
volume = {29},
year = {2013}
}
@article{Moreda2012,
author = {Moreda, G.P. and Mu\~{n}oz, M.a. and Ruiz-Altisent, M. and Perdigones, a.},
doi = {10.1016/j.jfoodeng.2011.08.011},
issn = {02608774},
journal = {Journal of Food Engineering},
month = jan,
number = {2},
pages = {245--261},
publisher = {Elsevier Ltd},
title = {{Shape determination of horticultural produce using two-dimensional computer vision – A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0260877411004511},
volume = {108},
year = {2012}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {Lowe, David G},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {::},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
number = {2},
pages = {91--110},
pmid = {20064111},
publisher = {Springer},
series = {Int. J. Comput. Vis. (Netherlands)},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Vidal-Calleja2011,
author = {Vidal-Calleja, Teresa a. and Berger, Cyrille and Sol\`{a}, Joan and Lacroix, Simon},
doi = {10.1016/j.robot.2011.05.008},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {multi-robots cooperation},
month = sep,
number = {9},
pages = {654--674},
publisher = {Elsevier B.V.},
title = {{Large scale multiple robot visual mapping with heterogeneous landmarks in semi-structured terrain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889011000923},
volume = {59},
year = {2011}
}
@article{Tsai2012,
abstract = {During nuclear accidents, when radioactive materials spread into the environment, the people in the affected areas should evacuate immediately. However, few information systems are available regarding escape guidelines for nuclear accidents. Therefore, this study constructs escape guidelines on mobile phones. This application is called Mobile Escape Guidelines (MEG) and adopts two techniques. One technique is the geographical information that offers multiple representations; the other is the augmented reality that provides semi-realistic information services. When this study tested the mobile escape guidelines, the results showed that this application was capable of identifying the correct locations of users, showing the escape routes, filtering geographical layers, and rapidly generating the relief reports. Users could evacuate from nuclear accident sites easily, even without relief personnel, since using slim devices to access the mobile escape guidelines is convenient. Overall, this study is a useful reference for a nuclear accident emergency response.},
author = {Tsai, Ming-Kuan and Lee, Yung-Ching and Lu, Chung-Hsin and Chen, Mei-Hsin and Chou, Tien-Yin and Yau, Nie-Jia},
doi = {10.1016/j.jenvrad.2011.12.025},
issn = {1879-1700},
journal = {Journal of environmental radioactivity},
keywords = {Geographic Information Systems,Guidelines as Topic,Nuclear Power Plants,Radioactive Hazard Release},
month = jul,
pages = {36--44},
pmid = {22260929},
publisher = {Elsevier Ltd},
title = {{Integrating geographical information and augmented reality techniques for mobile escape guidelines on nuclear accident sites.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22260929},
volume = {109},
year = {2012}
}
@article{REN2011,
abstract = {This paper proposes a simple and discriminative framework, using graphical model and 3D geometry to understand the diversity of urban scenes with varying viewpoints. Our algorithm constructs a conditional random field (CRF) network using over-segmented superpixels and learns the appearance model from different set of features for specific classes of our interest. Also, we introduce a training algorithm to learn a model for edge potential among these superpixel areas based on their feature difference. The proposed algorithm gives competitive and visually pleasing results for urban scene segmentation. We show the inference from our trained network improves the class labeling performance compared to the result when using the appearance model solely.},
author = {REN, Ke-yan and SUN, Han-xu and JIA, Qing-xuan and WU, Yao-hong and ZHANG, Wei-yu and GAO, Xin and YE, Ping and SONG, Jing-zhou},
doi = {10.1016/S1005-8885(10)60072-6},
issn = {10058885},
journal = {The Journal of China Universities of Posts and Telecommunications},
keywords = {3d geometry,crf,graphical model,scene recognition},
month = jun,
number = {3},
pages = {110--119},
publisher = {The Journal of China Universities of Posts and Telecommunications},
title = {{Urban scene recognition by graphical model and 3D geometry}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1005888510600726},
volume = {18},
year = {2011}
}
@article{Nordin2010,
author = {Nordin, Norazah and Embi, Mohamed Amin and Yunus, Melor Md.},
doi = {10.1016/j.sbspro.2010.10.019},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {conceptual framework,design system,learning applications,lifelong learning,mobile learning},
month = jan,
number = {C},
pages = {130--138},
title = {{Mobile Learning Framework for Lifelong Learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042810020239},
volume = {7},
year = {2010}
}
@article{Han2001,
author = {Han, Kyu-phil and Song, Kun-woen and Chung, Eui-yoon and Cho, Seok-je and Ha, Yeong-ho},
file = {::},
keywords = {crossover,disparity,fitness function,genetic algorithm,informed generation,intensity similarity,mutation,natural selection,smoothness,stereo matching},
pages = {1729--1740},
title = {{Stereo matching using genetic algorithm with adaptive chromosomes}},
volume = {34},
year = {2001}
}
@article{Costa2012,
annote = {		L’article d\'{e}crit l’utilisation de une method de d\'{e}tection des objets mobile ( ie : obstacle mobile /humain)  en se basant sur la technique block based motion estimation , \c{c}a consiste \`{a} comparer deux bloc de deux images , prise par une cam\'{e}ra fix\'{e} sur un robot mobile , la comparaison des deux bloc d’images suit le m\^{e}me principe du block matching d’un objet pris par deux cameras , sauf que dans notre cas , l’image est prise par la m\^{e}me camera , mais en deux moment diff\`{e}rent  , 
Le technique block based motion estimation nous permet ainsi de construire  un vecteur de mouvement indiquant le sens mouvement de l’objet.           
Supposition : Surface simple / le robot dispose d’une carte pour \'{e}viter les objets fixe (i e murs.).           
R\'{e}sultats        
-          D\'{e}tecter des objets 
-          Eviter les objets mobiles.           
Limitations : 
-           Effet des couleurs sur la d\'{e}tection des objets et le block matching ! 
-          Relativit\'{e}  mouvement du robot/ mouvement de l’objet   (un objet se d\'{e}pla\c{c}ant de la m\^{e}me vitesse et sens du robot parait fixe .) },
author = {Costa, Paulo and Fernandes, Hugo and Martins, Paulo and Barroso, Jo\~{a}o and Hadjileontiadis, Leontios J.},
doi = {10.1016/j.procs.2012.10.010},
issn = {18770509},
journal = {Procedia Computer Science},
month = jan,
number = {Dsai},
pages = {83--93},
title = {{Obstacle Detection using Stereo Imaging to Assist the Navigation of Visually Impaired People}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050912007727},
volume = {14},
year = {2012}
}
@article{Boyer2012,
author = {Boyer, Kim and Cetin, Mujdat and Jain, Anil and Lee, Seong-Whan},
doi = {10.1016/j.patrec.2012.02.010},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = may,
number = {7},
pages = {808--810},
publisher = {Elsevier B.V.},
title = {{Special Issue on Awards from ICPR 2010}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865512000517},
volume = {33},
year = {2012}
}
@article{Sabto2012,
author = {Sabto, Nosaiba a. and {Al Mutib}, Khalid},
doi = {10.1016/j.jksuci.2012.10.001},
file = {::},
issn = {13191578},
journal = {Journal of King Saud University - Computer and Information Sciences},
month = oct,
number = {October},
publisher = {King Saud University},
title = {{Autonomous mobile robot localization based on RSSI measurements using an RFID sensor and neural network BPANN}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1319157812000377},
year = {2012}
}
@article{Owens2013,
author = {Owens, Gary M},
issn = {1944-706X},
journal = {Journal of managed care pharmacy : JMCP},
month = jan,
number = {1 Suppl A},
pages = {S3},
pmid = {23383727},
title = {{Introduction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23404255},
volume = {19},
year = {2013}
}
@article{Hoseinnezhad2011,
author = {Hoseinnezhad, Reza and Bab-Hadiashar, Alireza},
doi = {10.1016/j.cviu.2011.03.007},
file = {::},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
month = aug,
number = {8},
pages = {1145--1156},
publisher = {Elsevier Inc.},
title = {{An M-estimator for high breakdown robust estimation in computer vision}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1077314211000956},
volume = {115},
year = {2011}
}
@article{Wasfy2012,
author = {Wasfy, Wael and Zheng, Hong},
doi = {10.1016/j.phpro.2012.05.122},
file = {::},
issn = {18753892},
journal = {Physics Procedia},
month = jan,
pages = {690--697},
title = {{General Structure Design for Fast Image Processing Algorithms Based upon FPGA DSP Slice}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1875389212014356},
volume = {33},
year = {2012}
}
@article{Sun2012,
author = {Sun, Wei and Chen, Long and Liu, Kai},
doi = {10.7321/jscse.v2.n5.1},
issn = {22517545},
journal = {International Journal of Soft Computing and Software Engineering},
keywords = {autonomous navigation,binocular,object recognition,optical measurement,rvd},
month = may,
number = {5},
pages = {1--12},
title = {{Research on Vision-based Autonomous Navigation Algorithm for RVD between Spacecrafts}},
url = {http://www.jscse.com/papers/?vol=2\&no=5\&n=1},
volume = {2},
year = {2012}
}
@article{Kim2012,
author = {Kim, Jung-Rack and Lin, Shih-Yuan and Hong, Jeong-Woo and Kim, Young-Hwi and Park, Chin-Kang},
doi = {10.1016/j.cageo.2011.09.018},
issn = {00983004},
journal = {Computers \& Geosciences},
keywords = {Geomorphology,High resolution DTM,Mars,Ortho-image,Stereo analysis,Virtual reality},
month = jul,
pages = {184--195},
publisher = {Elsevier},
title = {{Implementation of Martian virtual reality environment using very high-resolution stereo topographic data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0098300411003475},
volume = {44},
year = {2012}
}
@misc{Yee-King,
author = {Yee-King, Matthew},
file = {::},
title = {{Music Technology Lecture 9: Algorithmic Composition and State of the Art}}
}
@misc{Cope,
author = {Cope, David},
file = {::},
publisher = {Schirmer},
title = {{Techniques of the Contemporary Composer}}
}
@inproceedings{Milne2011b,
abstract = {In this paper, we describe a playable musical interface for tablets and multi-touch tables. The interface is a generalized keyboard, inspired by the Thummer, and consists of an array of virtual buttons. On a generalized keyboard, any given interval always has the same shape (and therefore fingering); furthermore, the fingering is consistent over a broad range of tunings. Compared to a physical generalized keyboard, a virtual version has some advantages—notably, that the spatial location of the buttons can be transformed by shears and rotations, and their colouring can be changed to reflect their musical function in different scales.

We exploit these flexibilities to facilitate the playing not just of conventional Western scales but also a wide variety of microtonal generalized diatonic scales known as moment of symmetry, or well-formed, scales. A user can choose such a scale, and the buttons are automatically arranged so their spatial height corresponds to their pitch, and buttons an octave apart are always vertically above each other. Furthermore, the most numerous scale steps run along rows, while buttons within the scale are light-coloured, and those outside are dark or removed.

These features can aid beginners; for example, the chosen scale might be the diatonic, in which case the piano’s familiar white and black colouring of the seven diatonic and five chromatic notes is used, but only one scale fingering need ever be learned (unlike a piano where every key needs a different fingering). Alternatively, it can assist advanced composers and musicians seeking to explore the universe of unfamiliar microtonal scales.},
address = {Oslo},
author = {Milne,  Andrew J. and Xamb\'{o},  Anna and Laney,  Robin and Sharp,  David B. and Prechtl,  Anthony and Holland,  Simon},
booktitle = {Proceedings of the 2011 International Conference on New Interfaces for Musical Expression (NIME11)},
editor = {Jensenius, A. R. and Tveit, A. and God\o y, R. and Overholt, D.},
file = {::},
keywords = {generalized keyboard,iPad,isomorphic layout,microtonality,multi-touch surface,musical interface design,tablet},
pages = {244 -- 247},
title = {{Hex Player—a virtual musical controller}},
url = {http://open.academia.edu/AndrewMilne/Papers/547611/Hex\_Player--a\_virtual\_musical\_controller},
year = {2011}
}
@article{Dannenberg2003,
author = {Dannenberg, Roger B. and Hu, Ning},
doi = {10.1076/jnmr.32.2.153.16738},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = jun,
number = {2},
pages = {153--163},
title = {{Pattern Discovery Techniques for Music Audio}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1076/jnmr.32.2.153.16738\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {32},
year = {2003}
}
@phdthesis{Bambrick,
abstract = {This paper details the implementation of a computer program which employs Genetic Algorithms (GAs) in the quest for an optimal lecture timetable generator. GA theory is covered with emphasis on less fully encoded systems employing non-genetic operators. The field of Automated Timetabling is also explored. A timetable is explained as, essentially, a schedule with constraints placed upon it. The program, written in C, incorporates a repair strategy for faster evolution. In a simplified university timetable problem it consistently evolves constraint violation free timetables. The effects of altered mutation rate and population size are tested. It is seen that the GA could be improved by the further incorporation of repair strategies, and is readily scalable to the complete timetabling problem. Appendices include the entire source code.},
author = {Bambrick, Leon},
booktitle = {Strategies},
file = {::},
school = {The University of Queensland},
title = {{Lecture Timetabling Using Genetic Algorithms}}
}
@misc{Milne2009b,
address = {The Open University, Milton Keynes, UK},
author = {Milne, Andrew J.},
institution = {The Open University, Milton Keynes, UK},
month = nov,
title = {{Metrics and Gaussian smoothing models}},
year = {2009}
}
@inproceedings{Fels2001,
abstract = {We describe a system that maps the interaction between two people to control a genetic process for generating music. We start with a population of melodies encoded genetically. This population is allowed to breed every biological cycle creating new members of the population based upon the semantics of the spatial relationship between two people moving in a large, physical space. A pre-specified hidden melody is used to select a melody from the population to play every musical cycle. The overlapping of selected melodies provides an intriguing textured musical space.},
author = {Fels, Sidney and Manzolli, Jonatas},
booktitle = {Proceedings of the 6th Eurographics Workshop on Multimedia},
file = {::},
title = {{Interactive, Evolutionary Textured Sound Composition}},
year = {2001}
}
@inproceedings{Milne2009a,
abstract = {This report presents a psychoacoustically derived computational model of the perceived distance between any two major or minor triads, the degree of activity created by any given pair of triads, and the cadential effectiveness of three-triad progressions. It also provides statistical analyses of the ratings given by thirty-five participants for the "similarity" and "fit" of triads in a pair, and the "cadential effectiveness" of three-triad progressions. Multiple regressions show that the model provides highly significant predictions of the experimentally obtained ratings. Finally, it is argued that because the model is based upon psychoacoustic axioms, it is likely the regression equations represent true causal models. As such, the computational model and its associated theory question the plausibility of theoretical approaches to tonality that use only long-term memory and statistical features, as well as those approaches based upon symmetrical geometrical structures like the torus. It is hoped that the psychoacoustic approach proposed here may herald not only the return of psychoacoustic approaches to tonal music theory, but also the exploration of the tonal possibilities offered by non-standard tunings and non-harmonic timbres.},
address = {Jyv\"{a}skyl\"{a}, Finland},
author = {Milne, Andrew J.},
booktitle = {ESCOM 2009 Proceedings},
editor = {Louhivuori, Jukka and Eerola, Tuomas and Saarikallio, Suvi and Himberg, Tommi and Eerola, P\"{a}ivi-Sisko},
month = aug,
pages = {328--337},
title = {{A psychoacoustic model of harmonic cadences: A preliminary report}},
url = {http://oro.open.ac.uk/21507/1/2009c\%2C\_conference\_(ESCOM)\%2C\_Milne\_\%2D\_A\_Psychoacoustic\_Model\_of\_Harmonic\_Cadences\_\%2D\_A\_Preliminary\_Report.pdf},
year = {2009}
}
@misc{Andreatta,
author = {Andreatta, Moreno},
booktitle = {Analysis},
file = {::},
title = {{Modern Algebra and the Object / Operation Duality in Music}}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {::},
keywords = {Mendeley,how-to,user manual},
pages = {1--14},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@incollection{Benson2004,
author = {Benson, Dave},
file = {::},
title = {{Mathematics and Music}},
year = {2004}
}
@article{Milne2011a,
abstract = {Models of the perceived distance between pairs of pitch collections are a core component of broader models of music cognition. Numerous distance measures have been proposed, including voice-leading, psychoacoustic, and pitch and interval class distances; but, so far, there has been no attempt to bind these different measures into a single mathematical or conceptual framework, nor to incorporate the uncertain or probabilistic nature of pitch perception.

This paper embeds pitch collections in expectation tensors and shows how metrics between such tensors can model their perceived dissimilarity. Expectation tensors indicate the expected number of tones, ordered pairs of tones, ordered triples of tones, etc., that are heard as having any given pitch, dyad of pitches, triad of pitches, etc.. The pitches can be either absolute or relative (in which case the tensors are invariant with respect to transposition). Examples are given to show how the metrics accord with musical intuition.},
author = {Milne, Andrew J. and Sethares, William A. and Laney, Robin and Sharp, David B.},
journal = {Journal of Mathematics and Music},
keywords = {expectation,expectation tensor,metric,microtonality,music cognition,pitch,salience,tonality,tone},
number = {1},
pages = {1--20},
title = {{Modelling the similarity of pitch collections with expectation tensors}},
url = {http://oro.open.ac.uk/28353/1/Modelling\_the\_Similarity\_of\_Pitch\_Collections\_with\_Expectation\_Tensors.pdf},
volume = {5},
year = {2011}
}
@article{Hirata2003,
author = {Hirata, Keiji; and Aoyagi, Tatsuya;},
file = {::},
journal = {Computer Music Journal},
number = {3},
pages = {73--89},
title = {{Computational Music Representation Based Generative of Tonal Music Deductive Object-Oriented Database}},
volume = {27},
year = {2003}
}
@inproceedings{Bernardes2010,
abstract = {In this paper we present an application using an evolu- tionary algorithm for real-time generation of polyphonic drum loops in a particular style. The population of rhythms is derived from analysis of MIDI drum loops, which profile each style for subsequent automatic genera- tion of rhythmic patterns that evolve over time through genetic algorithm operators and user input data.},
author = {Bernardes, Gilberto and Guedes, Carlos and Pennycook, Bruce},
booktitle = {Methods},
file = {::},
keywords = {Generative Music,Genetic Algorithm,Style Emulation},
mendeley-tags = {Generative Music,Genetic Algorithm,Style Emulation},
pages = {1--4},
title = {{STYLE EMULATION OF DRUM PATTERNS BY MEANS OF EVOLUTIONARY METHODS AND STA- TISTICAL ANALYSIS}},
year = {2010}
}
@inproceedings{Conklin2003,
abstract = {This paper discusses the use of statisticalmodels for the problemofmusical style imitation. Statisticalmodels are created from extant pieces in a stylistic corpus, and have an objective goal which is to accurately classify new pieces. The process of music generation is equated with the problem of sampling from a statistical model. In principle there is no need to make the classical distinction between analytic and synthetic models of music. This paper presents several methods for sampling from an analytic statistical model, and proposes a new approach that maintains the intra opus pattern repetition within an extant piece. A major component of creativity is the adaptation of extant art works, and this is also an efficient way to sample pieces from complex statistical models.},
address = {Aberystwyth, Wales},
author = {Conklin, Darrell},
booktitle = {Proceedings of the AISB 2003 Symposium on Artificial Intelli- gence and Creativity in the Arts and Sciences},
file = {::},
title = {{Music Generation from Statistical Models}},
year = {2003}
}
@techreport{Milne2006,
author = {Milne, Andrew J. and Sethares, William A. and Plamondon, James},
institution = {Thumtronics, Inc.},
month = nov,
title = {{X\_System}},
url = {http://oro.open.ac.uk/21510/1/X\_System.pdf},
year = {2006}
}
@inproceedings{Dannenberg1987b,
abstract = {Although computer systems have found widespread application in music production, there remains a gap between the characteristicly precise and mechanical information processing of the computer and the more subtle and expressive processing performed by humans. In order for computer systems to become more useful to musicians, the human-computer interface must be raised from the mechanical and syntactic level of present systems toward a high-level concept-based dialog. The term ‘‘music understanding’’ is introduced to describe the recognition of pattern and structure in musical information. Applications of music understanding include music transcription and music performance systems. The general state of the art in music understanding and two specific interactive real-time performance systems are described.},
author = {Dannenberg, Roger B.},
booktitle = {Computer Sscience Research Review},
file = {::},
pages = {19--28},
title = {{Music Understanding}},
year = {1987}
}
@book{SivanandamS.N.;Deepa2008,
author = {{Sivanandam, S. N.; Deepa}, S. N.;},
booktitle = {Electronics},
file = {::},
publisher = {Springer-Verlag},
title = {{Introduction to Genetic Algorithms}},
year = {2008}
}
@misc{Milne2010b,
abstract = {Microtonality is a huge and diverse area: I will be focussing on the use of microtonal well-formed scales that embed numerous major and minor triads. Such scales cannot be played in any conventional Western tuning (so they really are novel and different), but they also generalise many of the most important properties of the standard Western diatonic (major) scale (so they may provide a fertile resource for musical experimentation).

I'll also demonstrate a Thummer—a button-lattice MIDI controller that makes the playing of microtonal well-formed scales as straightforward as playing standard Western scales.},
address = {The Open University, Milton Keynes, UK},
author = {Milne, Andrew J.},
month = feb,
title = {{Microtonal music theory}},
year = {2010}
}
@incollection{Marsella1992,
author = {Marsella, S C and Schmidt, C F},
editor = {Balaban, M and Ebcioglu, K and Laske, O},
pages = {239--256},
publisher = {AAAI Press},
title = {{On the use of problem reduction search for algorithmic music composition}},
year = {1992}
}
@misc{Milne2008,
abstract = {The corpus of Western music theory has a hole in its heart: while there are effective psychoacoustic explanations of “vertical” (harmonic) consonance and dissonance, there are no effective psychoacoustic explanations of the “horizontal” tension, release, and expectations, evoked by successions of chords. This is most clearly exemplified by the harmonic cadences that characterise tonal harmonic music. For example, consider the familiar I→IV→V→I cadence (e.g., C major→F major→G major→C major)—in this succession, all the chords are simple major triads, but the G chord sounds particularly tense, while the C chord seems to resolve this tension (thereby providing a sense of release and closure of expectation). Existing theories either fail to accurately predict precisely which successions function cadentially, or rely on metaphysical or schematic explanations that have dubious scientific validity.

This paper presents a computational model built upon simple psychoacoustic axioms, and a theory of how this model relates to our perception of the tension, release and expectations evoked by successions of chords. Preliminary builds of the model already suggest that the proposed approach provides a highly effective explanation for many of the regularities found in Western music, including the common practice cadences that Lowinsky considered to be “the cradle of tonality”.},
author = {Milne, Andrew J.},
institution = {Centre for Music and Science, University of Cambridge, UK},
month = oct,
title = {{A psychoacoustic model of harmonic cadences}},
year = {2008}
}
@book{Temperley2007,
author = {Temperley, David},
file = {::},
publisher = {The MIT Press},
title = {{Music and Probability}},
year = {2007}
}
@book{FauvelJohn;FloodRaymond;Wilson2003,
editor = {{Fauvel, John; Flood, Raymond; Wilson}, Robin;},
file = {::},
publisher = {Oxford University Press},
title = {{Music and Mathematics}},
year = {2003}
}
@inproceedings{Blackwell2002,
abstract = {This paper describes SWARMUSIC, an interactive music improviser. A particle swarm algorithm is used to generate musical material by a mapping of particle positions onto events in MIDI space. Interaction with an external musical source arises through the attraction of the particle swarm to a target. SWARMUSIC is the first application of swarm intelligence to music. I},
author = {Blackwell, T.M. and Bentley, P.},
booktitle = {Proceedings of the 2002 Congress on Evolutionary Computation},
doi = {10.1109/CEC.2002.1004458},
file = {::},
isbn = {0-7803-7282-4},
pages = {1462--1467},
publisher = {Ieee},
title = {{Improvised music with swarms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1004458},
year = {2002}
}
@inproceedings{Izmirli2009,
abstract = {In this paper we look at the problem of classifying music audio as tonal or atonal by learning a low-dimensional structure representing tonal relationships among keys. We use a training set composed of tonal pieces which in- cludes all major and minor keys. A kernel eigenmap based method is used for structure learning and discov- ery. Specifically, a Diffusion Maps (DM) framework is used and its parameter tuning is discussed. Since these methods do not scale well with increasing data size, it becomes infeasible to use these methods in online appli- cations. In order to facilitate on-line classification an out- of-sample extension to the DM framework is given. The learned structure of tonal relationships is presented and a simple scheme for classification of tonal-atonal pieces is proposed. Evaluation results show that the method is able to perform at an accuracy above 90\% with the current data set.},
author = {Izmirli, \"{O}ozg\"{u}r},
booktitle = {10th International Society for Music Information Retrieval Conference},
file = {::},
number = {Ismir},
pages = {687--691},
title = {{TONAL-ATONAL CLASSIFICATION OF MUSIC AUDIO}},
year = {2009}
}
@article{Milne2008b,
abstract = {Previous work has demonstrated the existence of keyboard layouts capable of maintaining consistent fingerings across a parametrized family of tunings. This paper describes the general principles underlying layouts that are invariant in both transposition and tuning. Straightforward computational methods for determining appropriate bases for a regular temperament are given in terms of a row-reduced matrix for the temperament-mapping. A concrete description of the range over which consistent fingering can be maintained is described by the valid tuning range. Measures of the resulting keyboard layouts allow direct comparison of the ease with which various chordal and scalic patterns can be fingered as a function of the keyboard geometry. A number of concrete examples illustrate the generality of the methods and their applicability to a wide variety of commas and temperaments, tuning continua and keyboard layouts.},
author = {Milne, Andrew J. and Sethares, William A. and Plamondon, James},
issn = {1745-9737},
journal = {Journal of Mathematics and Music},
month = mar,
number = {1},
pages = {1--19},
title = {{Tuning continua and keyboard layouts}},
url = {http://www.informaworld.com/10.1080/17459730701828677},
volume = {2},
year = {2008}
}
@article{Jones2001,
author = {Jones, Evan},
file = {::},
journal = {Perspectives of New Music},
number = {2},
pages = {229--261},
title = {{RESIDUE-CLASS SETS IN THE MUSIC OF IANNIS XENAKIS : AND A ALGORITHM EXPRESSION}},
volume = {39},
year = {2001}
}
@article{UhleChristian;Herre2003,
author = {{Uhle, Christian; Herre}, Juergen;},
file = {::},
journal = {Proceedings of the 6th International Conference on Digital Audio Effects},
pages = {1--6},
title = {{ESTIMATION OF TEMPO , MICRO TIME AND TIME SIGNATURE FROM PERCUSSIVE MUSIC}},
year = {2003}
}
@article{Burton1999,
author = {Burton, Anthony R. and Vladimirova, Tanya},
doi = {10.1162/014892699560001},
file = {::},
issn = {0148-9267},
journal = {Computer Music Journal},
month = dec,
number = {4},
pages = {59--73},
title = {{Generation of Musical Sequences with Genetic Techniques}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/014892699560001},
volume = {23},
year = {1999}
}
@article{Friberg1991,
author = {Friberg, Anders},
file = {::},
journal = {Computer Music Journal},
number = {2},
pages = {56--71},
title = {{Generative Rules for Performance: Formal Description of a Rule System}},
volume = {15},
year = {1991}
}
@article{StammenDale;PennycookBruce;Parncutt,
author = {{Stammen, Dale; Pennycook, Bruce; Parncutt}, Richard},
file = {::},
title = {{A Revision of Parncutt's Psychoacoustical Model of the Root of a Musical Chord}}
}
@article{Lu2003,
address = {New York, New York, USA},
author = {Lu, Lie and Zhang, Hong-Jiang},
doi = {10.1145/957013.957043},
file = {::},
isbn = {1581137222},
journal = {Proceedings of the eleventh ACM international conference on Multimedia - MULTIMEDIA '03},
pages = {140},
publisher = {ACM Press},
title = {{Automated extraction of music snippets}},
url = {http://portal.acm.org/citation.cfm?doid=957013.957043},
year = {2003}
}
@phdthesis{Gomez2006,
author = {G\'{o}mez, Emilia},
file = {::},
title = {{Tonal Description of Music Audio SIgnals}},
year = {2006}
}
@misc{Eigenfeldt,
abstract = {This paper presents an evolutionary music software system that generates complex rhythmic polyphony in performance. A population of rhythms is derived from analysis of source material, using a first order Markov chain derived from subdivision transitions. The population evolves in performance, and each generation is analysed to provide rules for subsequent generations.},
author = {Eigenfeldt, Arne},
file = {::},
keywords = {genetic algorithms,realtime systems,recombinance,rhythm generation},
title = {{The Evolution of Evolutionary Software : Intelligent Rhythm Generation in Kinetic Engine}}
}
@misc{Sethares2007,
address = {New Orleans, LA, US},
author = {Sethares, William A. and Milne, Andrew J. and Plamondon, James},
month = jan,
title = {{Consistent fingerings for a continuum of syntonic commas}},
year = {2007}
}
@misc{Hamamci2010,
abstract = {In this paper, we re-examine the cellular automata (CA) algorithm to show that the result of its state evolution converges to that of the shortest path algorithm. We proposed a complete tumor segmentation method on post contrast T1 MR images, which standardizes the VOI and seed selection, uses CA transition rules adapted to the problem and evolves a level set surface on CA states to impose spatial smoothness. Validation studies on 13 clinical and 5 synthetic brain tumors demonstrated the proposed algorithm outperforms graph cut and grow cut algorithms in all cases with a lower sensitivity to initialization and tumor type.},
author = {Hamamci, Andac and Unal, Gozde and Kucuk, Nadir and Engin, Kayihan},
booktitle = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
file = {::},
month = jan,
number = {Pt 3},
pages = {137--46},
pmid = {20879393},
title = {{Cellular automata segmentation of brain tumors on post contrast MR images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20887052},
volume = {13},
year = {2010}
}
@book{Laurson2009,
author = {Laurson, Mikael and Kuuskankare, Mika},
booktitle = {October},
file = {::},
title = {{PWGL Book}},
year = {2009}
}
@article{Moroni2000,
author = {Moroni, Artemis and Manzolli, Jonatas and Zuben, Fernando Von and Gudwin, Ricardo},
doi = {10.1162/096112100570602},
file = {::},
issn = {09611215},
journal = {Leonardo Music Journal},
pages = {49--54},
title = {{Vox Populi: An Interactive Evolutionary System for Algorithmic Music Composition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/096112100570602},
volume = {10},
year = {2000}
}
@article{Capuzzo2006,
abstract = {This paper studies a set of instructional materials by the renowned jazz guitarist and pedagogue Pat Martino, winner of Downbeat Magazine's 2004 reader's poll for jazz guitarist of the year. The materials, titled The Nature of the Guitar, represent an ongoing project of Martino's begun in 1972. The Nature of Guitar is remarkable in its degree of overlap with Neo- Riemannian ideas. After discussing excerpts from The Nature of Guitar that engage parsimonious voice-leading, I compare Martino's analysis of John Coltrane's "Giant Steps" to that of Matthew Santa.},
author = {Capuzzo, Guy},
file = {::},
journal = {Music Theory Online},
keywords = {abstract,and pedagogue pat martino,by the renowned jazz,giant steps,guitar,guitarist,jazz theory,john coltrane,leading,neo-riemannian theory,parsimonious voice-,pat martino,s 2004 reader,s poll for jazz,set of instructional materials,this paper studies a,winner of downbeat magazine},
number = {1},
title = {{An Intersection of Jazz and Neo-Riemannian Theory}},
volume = {12},
year = {2006}
}
@misc{Milne2010,
abstract = {From the seventeenth century to the present day, tonal harmonic music has had a number of invariant properties: specific chord progressions (cadences) that induce a sense of closure; the asymmetrical privileging of certain progressions; the degree of fit between pairs of successively played tones or chords; the privileging of tertial harmony and the major and minor scales.

The most widely accepted explanation (e.g., Bharucha (1987), Krumhansl (1990), Lerdahl (2001)) has been that this is due to a process of enculturation: frequently occurring musical patterns are learned by listeners, some of whom become composers and replicate the same patterns, which go on to influence the next "generation" of composers, and so on. Some contemporary researchers (e.g., Parncutt, Milne (2009), Large (in press)) have argued that these are circular arguments, and have proposed various psychoacoustic, or neural, processes and constraints that shape tonal harmonic music into the form it has actually taken.

In this presentation, I discuss some of the broader music theoretical implications of my recently developed psychoacoustic model of harmonic cadences (which has had encouraging experimental support (Milne, 2009)). The core of the model is two different psychoacoustically-derived measures of pitch-based distance between chords (one modelling "fit", the other "voice-leading distance"), and the interaction of these two distances to model the feelings of activity, expectation, and resolution induced by certain chord progressions (notably cadences). When a played pair of chords have a poorer fit than an un-played comparison pair, that is also voice-leading-close, it is reasonable to assume the played pair is heard as an alteration of the comparison pair. This is similar to how a harmonically dissonant interval (e.g., the tritone B-F) is likely to be heard as an alteration of a voice-leading-close consonant interval (e.g., the perfect fourth B-E, or the major third C-E).

I explore the extent to which the model can predict the familiar tonal cadences described in music theory (including those containing tritone substitutions), and the asymmetries that are so characteristic of tonal harmony. I also compare and contrast the model with Riemann's functional theory, and show how it may be able to shed light upon the privileged status of the major and minor scales (over the modes), and the dependence of tonality upon triadic harmony.},
address = {Centre for Music and Science, University of Cambridge, Cambridge, UK},
author = {Milne, Andrew J.},
month = feb,
title = {{Tonal music theory: A psychoacoustical explanation?}},
year = {2010}
}
@article{Bernardes2001,
address = {Amsterdam},
author = {Bernardes, Gilberto},
file = {::},
journal = {Composer's Notebook Quartely},
title = {{Overriding Actuality: Some Thoughts about Improvisations}},
year = {2001}
}
@misc{Pachet2000,
abstract = {The recent progress of Electronic Music Distribution creates a natural pressure for fine-grained musical metadata. This metadata is needed to provide music distribution services which are able to cope with the mere size of music catalogues, and the desire of users to access music titles by similarity. In this context, we describe a project of a global music title metadatabase, and focus in the particular “genre” descriptor. We analyze existing taxonomies of musical genre as found in the music industry and on the Internet, and stress on their inconsistencies. We describe a novel music genre taxonomy based on a few guiding principles, and report on the process of building this taxonomy.},
author = {Pachet, Fran\c{c}ois and Cazaly, Daniel},
booktitle = {Proceedings of the Content-Based Multimedia Information Access Conference (RIAO)},
file = {::},
number = {April},
title = {{A Taxonomy of Musical Genres}},
year = {2000}
}
@inproceedings{Milne2008a,
abstract = {In this paper we explain the theoretical background of Dynamic Tonality using the Thummer, a new musical interface, and The Viking, a software synthesizer written especially for it. Dynamic Tonality is a musical audio routine that allows for novel tunings and enables the user to relate – to an arbitrary degree – these tunings with the partials of their notes. The Viking features Dynamic Tonality and works with any MIDI instrument, but when paired with the Thummer (or another two-dimensional interface) it creates a system of fingering invariance across chords and tunings. Thus, the Thummer and The Viking render non-standard tunings more physically, pedagogically, and aesthetically accessible.},
address = {Jyv\"{a}skyl\"{a}, Finland},
author = {Milne, Andrew J. and Prechtl, A.},
booktitle = {Proceedings of the 3rd International Haptic and Auditory Interaction Design Workshop (Vol. 2, pp. 20–22)},
editor = {Crossan, Andrew and Kaaresoja, Topi},
pages = {20--22},
title = {{New tonalities with the Thummer and The Viking}},
url = {http://www.auditorysigns.com/haid2008/haid2008vol2.pdf\#page=20},
volume = {2},
year = {2008}
}
@misc{Ariza2006,
abstract = {While Markov chain generators have been employed throughout the history of computer music as a tool for the creation of musical parameter values, input notations for Markov transition values are often cumbersome and opaque. Rejecting the transition matrix as an input notation, this paper offers a new language-independent, string-based input notation for incomplete, multiple-order, static Markov transition values. Transition values are given greater generality by accommodating multiple orders simultaneously, as well as the specification of transitions with the use of limited single-operator regular expressions. A complete Python implementation of this model is introduced, and high-level utilities and object interfaces are demonstrated in athenaCL.},
author = {Ariza, Christopher},
booktitle = {Pulse},
file = {::},
pages = {1--13},
title = {{Beyond the Transition Matrix: A Language-Independent, String-Based Input Notation for Incomplete, Multiple-Order, Static Markov Transition Values}},
year = {2006}
}
@article{Supper2001,
author = {Supper, Martin},
doi = {10.1162/014892601300126106},
file = {::},
issn = {0148-9267},
journal = {Computer Music Journal},
month = mar,
number = {1},
pages = {48--53},
title = {{A Few Remarks on Algorithmic Composition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/014892601300126106},
volume = {25},
year = {2001}
}
@article{Qian2004,
address = {New York, New York, USA},
author = {Qian, Gang and Sural, Shamik and Gu, Yuelong and Pramanik, Sakti},
doi = {10.1145/967900.968151},
file = {::},
isbn = {1581138121},
journal = {Proceedings of the 2004 ACM symposium on Applied computing - SAC '04},
keywords = {content based image retrieval,cosine angle distance,euclidean distance,inter-feature normalization,vector model},
pages = {1232},
publisher = {ACM Press},
title = {{Similarity between Euclidean and cosine angle distance for nearest neighbor queries}},
url = {http://portal.acm.org/citation.cfm?doid=967900.968151},
year = {2004}
}
@article{Ariza2005,
author = {Ariza, Christopher},
doi = {10.1162/0148926054094396},
file = {::},
issn = {0148-9267},
journal = {Computer Music Journal},
month = jun,
number = {2},
pages = {40--60},
title = {{The Xenakis Sieve as Object: A New Model and a Complete Implementation}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/0148926054094396},
volume = {29},
year = {2005}
}
@book{Rowe2001,
author = {Rowe, Robert},
publisher = {The MIT Press},
title = {{Machine Musicianship}},
year = {2001}
}
@article{Bartlett1988,
abstract = {Four experiments explored an asymmetry in the perceived similarity of melodies: If a first-presented melody is "scalar" (conforms to a diatonic major scale), and is followed by a second melody slightly altered to be "nonscalar" (deviating from a diatonic major scale), subjects judge simi- larity to be lower than if the nonscalar melody comes first. Experiment 1 produced evidence that asymmetric similarity is not due simply to more strongly scalar melodies having greater memorability. Experiment 2 ruled out the hypothesis that asymmetric similarity depends on a task- specific strategy reflecting demand characteristics. Experiments 3 and 4 replicated asymmetric similarity while controlling the number of one- semitone intervals in scalar versus nonscalar melodies. The data are con- sistent with Garner's principles that stimuli are perceived with reference to sets of alternatives and that good stimuli have few alternatives. Speci- fically, when m\'{e}lodie* are presented in scalar- nonscalar order, but not when presented in nonscalar-scalar order, the first melody evokes a small set of alternatives which the second melody often violates.},
author = {Bartlett, James C and Dowling, W J A Y},
file = {::},
journal = {Music Perception},
number = {3},
pages = {285--314},
title = {{Scale Structure and Similarity of Melodies}},
volume = {5},
year = {1988}
}
@book{MirandaEduardo;AlBiles2007,
booktitle = {Computer},
editor = {{Miranda, Eduardo; Al Biles}, John;},
file = {::},
publisher = {Springer-Verlag London},
title = {{Evolutionary Computer Music}},
year = {2007}
}
@article{Hirata2003a,
author = {Hirata, Keiji and Matsuda, Shu},
doi = {10.1076/jnmr.32.2.165.16744},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = jun,
number = {2},
pages = {165--177},
title = {{Interactive Music Summarization Based on Generative Theory of Tonal Music}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1076/jnmr.32.2.165.16744\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {32},
year = {2003}
}
@article{Thomassen1982,
author = {Thomassen, Joseph M.},
doi = {10.1121/1.387814},
file = {::},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {1596},
title = {{Melodic accent: Experiments and a tentative model}},
url = {http://link.aip.org/link/JASMAN/v71/i6/p1596/s1\&Agg=doi},
volume = {71},
year = {1982}
}
@misc{Temperley,
author = {Temperley, David},
file = {::},
title = {{Studying Music Performance: A Probabilistic Approach}}
}
@phdthesis{Andreatta2003,
author = {Andreatta, Moreno},
booktitle = {Musicales},
file = {::},
title = {{M\'{e}thodes alg\'{e}briques en musique et musicologie du XX e si\`{e}cle : aspects th\'{e}oriques , analytiques et compositionnels}},
year = {2003}
}
@misc{Bernardes2010a,
author = {Bernardes, Gilberto and Guedes, Carlos and Pennycook, Bruce},
file = {::},
title = {{Style Emulation of Drum Patterns by Means of Evolutionary Methods and Statistical Analysis Kinetic Controller Driven Music Systems}},
year = {2010}
}
@book{Chadade,
author = {Chadade, Joel},
file = {::},
isbn = {0-13-303231-0},
publisher = {Prentice Hall},
title = {{Electric Sound}}
}
@article{Gjerdingen2008,
author = {Gjerdingen, Robert and Perrott, David},
doi = {10.1080/09298210802479268},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = jun,
number = {2},
pages = {93--100},
title = {{Scanning the Dial: The Rapid Recognition of Music Genres}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09298210802479268\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2008}
}
@book{Nierhaus2009,
author = {Nierhaus, Gerhard},
file = {::},
publisher = {Springer-Verlag/Wien},
title = {{Algorithmic Composition}},
year = {2009}
}
@misc{Hammer1988,
author = {Hammer, Ernest Lee},
booktitle = {Computer Music Journal},
doi = {10.2307/3679942},
number = {2},
pages = {54},
title = {{Electronic and Computer Music}},
volume = {12},
year = {1988}
}
@misc{Plamondon2009,
abstract = {This paper describes Dynamic Tonality, a system of real-time alterations to tuning and timbre that extends the framework of tonality to include new structural resources such as polyphonic tuning bends, tuning progressions, and temperament modulations. These new resources could prepare art music for the 21st Century.},
address = {University of Oklahoma School of Music, Norman, OK, US},
author = {Plamondon, James and Milne, Andrew J. and Sethares, William A.},
month = mar,
shorttitle = {Dynamic Tonality},
title = {{Dynamic Tonality: Extending the framework of tonality into the 21st Century}},
year = {2009}
}
@inproceedings{WallisIsaac;IngallsTodd;Campana2008,
abstract = {This paper explores one way to use music in the context of affec- tive design. We've made a real-time music generator that is de- signed around the concepts of valence and arousal, which are two components of certain models of emotion. When set to a desired valence and arousal, the algorithm plays music corresponding to the intersection of these two parameters. We designed our algo- rithm using psychological theory of emotion and parametrized features of music which have been tested for affect. The results are a modular algorithm design, in which our parameters can be implemented in other affective music algorithms. We describe our implementation of these parameters, and our strategy for ma- nipulating the parameters to generate musical emotion. Finally we discuss possible applications for these techniques in the fields of the arts, medical systems, and research applications. We be- lieve that further work will result in a music generator which can produce music in any of a wide variety of commonly-perceived emotional connotations on command.},
author = {{Wallis, Isaac; Ingalls, Todd; Campana}, Ellen;},
booktitle = {Proceedings of the 11th International Conference on Digital Audio Effects},
file = {::},
pages = {1--6},
title = {{COMPUTER-GENERATING EMOTIONAL MUSIC : THE DESIGN OF AN AFFECTIVE MUSIC ALGORITHM}},
year = {2008}
}
@book{Gresser2005,
author = {Gresser, Clemens},
booktitle = {Tempo},
doi = {10.1017/S0040298205220314},
file = {::},
issn = {0040-2982},
month = sep,
number = {234},
title = {{Audio Culture – Readings in Modern Music edited by Christoph Cox and Daniel Warner. Continuum, £12.99.}},
url = {http://www.journals.cambridge.org/abstract\_S0040298205220314},
volume = {59},
year = {2005}
}
@misc{Biles2005,
author = {Biles, Al},
booktitle = {GECCO},
file = {::},
title = {{Evolutionary Music}},
year = {2005}
}
@article{Morris1979,
author = {Morris, Robert},
file = {::},
journal = {Perspectives of New Music},
number = {1/2},
pages = {445-- 460},
title = {{A Similarity Index for Pitch-Class Sets}},
volume = {18},
year = {1979}
}
@book{Miranda2002,
author = {Miranda, Eduardo},
booktitle = {Genesis},
edition = {2nd},
file = {::},
publisher = {Focal Press},
title = {{Computer Sound Design}},
year = {2002}
}
@incollection{Milne2011,
abstract = {In this paper, we introduce a new approach to computer-aided microtonal improvisation by combining methods for (1) interactive scale navigation, (2) real-time manipulation of musical patterns and (3) dynamical timbre adaption in solidarity with the respective scales. On the basis of the theory of well-formed scales we offer a visualization of the underlying combinatorial ramifications in terms of a scale labyrinth. This involves the selection of generic well-formed scales on a binary tree (based on the Stern-Brocot tree) as well as the choice of specific tunings through the specification of the sizes of a period (pseudo-octave) and a generator (pseudo-fifth), whose limits are constrained by the actual position on the tree. We also introduce a method to enable transformations among the modes of a chosen scale (generalized and refined “diatonic” and “chromatic” transpositions). To actually explore the scales and modes through the shaping and transformation of rhythmically and melodically interesting tone patterns, we propose a playing technique called Fourier Scratching. It is based on the manipulation of the “spectra” (DFT) of playing gestures on a sphere. The coordinates of these gestures affect score and performance parameters such as scale degree, loudness, and timbre. Finally, we discuss a technique to dynamically match the timbre to the selected scale tuning.},
address = {Berlin},
author = {Milne,  Andrew J. and Carl\'{e},  Martin and Sethares,  William A. and Noll,  Thomas and Holland,  Simon},
booktitle = {Mathematics and Computation in Music: Third International Conference, MCM 2011, Paris, France, June 2011},
editor = {Agon, C. and Amiot, E. and Andreatta, M. and Assayag, G. and Bresson, J. and Mandereau, J.},
keywords = {Farey sequence,Fourier scratching,MOS scales,Stern-Brocot tree,Well-formedScales,chromatic,diatonic},
pages = {180--195},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Scratching the scale labyrinth}},
url = {http://oro.open.ac.uk/28690/1/ScaleLabyrinth\%2DFinal.pdf},
volume = {6726},
year = {2011}
}
@misc{TheMendeleySupportTeam2011a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {::},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{GouyonFabien;Dixon2005,
author = {{Gouyon, Fabien; Dixon}, Simon;},
file = {::},
journal = {Computer Music Journal},
number = {1},
title = {{A review of automatic rhythm description systems}},
volume = {29},
year = {2005}
}
@article{Temperley2004,
author = {Temperley, David},
file = {::},
journal = {Computer Music Journal},
number = {3},
pages = {28--44},
title = {{An Evaluation System for Metrical Models}},
volume = {28},
year = {2004}
}
@article{Francois;2001,
abstract = {We survey works on the musical problem of automatic harmonization. This problem, which consists in creating musical scores which satisfy given rules of harmony, has been the object of numerous studies, most of them using constraint techniques in one way or another. We outline the main results obtained and the current status of this category of problems.},
author = {Fran\c{c}ois;, Pachet and Roy, Pierre;},
file = {::},
journal = {Constraints Journal},
keywords = {computer music,harmony,temporal constrains},
number = {1},
title = {{Musical Harmonization with Constraints : A Survey}},
volume = {6},
year = {2001}
}
@article{Strle,
author = {Strle, Blaz and Mozina, Martin and Bratko, Ivan},
file = {::},
journal = {Time},
title = {{Qualitative approximation to Dynamic Time Warping similarity between time series data}}
}
@phdthesis{Aschauer2008,
author = {Aschauer, Daniel},
booktitle = {Computer Music Journal},
doi = {10.2307/3681175},
number = {3},
title = {{Algorithmic Composition}},
volume = {18},
year = {2008}
}
@article{Wu,
author = {Wu, Ho-hsiang and Bello, Juan P},
file = {::},
journal = {Advances},
title = {{AUDIO-BASED MUSIC VISUALIZATION FOR MUSIC STRUCTURE ANALYSIS}}
}
@article{Squibbs2002,
author = {Squibbs, Ronald},
doi = {10.1080/07494460216653},
file = {::},
issn = {0749-4467},
journal = {Contemporary Music Review},
keywords = {analysis,form,in twentieth-century music,sieve theory,stochastic music,twentieth-century piano music,xenakis},
month = jun,
number = {2},
pages = {91--108},
title = {{Some observations on pitch, texture, and from in Xenakis' Mists}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/07494460216653\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {21},
year = {2002}
}
@book{Polotti2008,
booktitle = {Framework},
editor = {Polotti, Pietro and Rocchesso, Davide},
file = {::},
isbn = {978-8-8325-1600-0},
publisher = {Logos Verlag Berlin},
title = {{Sound to Sense , Sense to Sound A State of the Art in Sound and Music Computing}},
year = {2008}
}
@inproceedings{Maxwell2009,
abstract = {We propose a new machine-learning framework called the Hierarchical Sequential Memory for Music, or HSMM. The HSMM is an adaptation of the Hierarchical Temporal Memory (HTM) framework, designed to make it better suited to musical applications. The HSMM is an online learner, capable of recognition, generation, con- tinuation, and completion of musical structures.},
author = {Maxwell, James B and Pasquier, Philippe and Eigenfeldt, Arne},
booktitle = {Proceedings of the 10th International Society for Music Information Retrieval Conference},
file = {::},
number = {Ismir},
pages = {429--434},
title = {{Hierarchical Sequential Memory for Music : A Cognitive Model}},
year = {2009}
}
@article{Sethares2009,
author = {Sethares, William A. and Milne, Andrew J. and Tiedje, Stefan and Prechtl, Anthony and Plamondon, James},
file = {::},
journal = {Computer Music Journal},
month = jun,
number = {2},
pages = {71--84},
title = {{Spectral tools for Dynamic Tonality and audio morphing}},
url = {http://oro.open.ac.uk/21505/2/33.2.sethares.pdf},
volume = {33},
year = {2009}
}
@article{Bigand1996,
author = {Bigand, Emmanuel; and Pineau, Marion;},
file = {::},
journal = {CPC},
number = {1},
pages = {121--134},
title = {{Context effects on melody recognition: A dynamic interpretation}},
volume = {15},
year = {1996}
}
@inproceedings{Milnea,
address = {Seattle},
author = {Milne, Andrew J. and Sethares, William A. and Laney, Robin and Sharp, David B.},
booktitle = {Proceedings of the 11th International Conference on Music Perception and Cognition},
editor = {Demorest, S. M. and Morrison, S. J. and Campbell, P. S.},
pages = {77--80},
title = {{Metrics for pitch collections}},
url = {http://open.academia.edu/documents/0096/8502/Metrics\_for\_Pitch\_Collections\_-\_Full\_Paper.pdf},
year = {2010}
}
@article{Milne2007,
author = {Milne, Andrew J. and Sethares, William A. and Plamondon, James},
journal = {Computer Music Journal},
month = dec,
number = {4},
pages = {15--32},
shorttitle = {Isomorphic Controllers and Dynamic Tuning},
title = {{Isomorphic controllers and Dynamic Tuning: Invariant fingering over a tuning continuum}},
url = {http://dx.doi.org/10.1162/comj.2007.31.4.15},
volume = {31},
year = {2007}
}
@article{Johnson2003,
abstract = {In recent years, the personal computer has become an integral component in the typesetting and management of various types of music. However, the computer is capable of serving as more than just a typesetting and data management tool. This paper explores the ability of a computer to generate and arrange four part vocal harmony in the style of church hymnody. The research presented here involves the use of an evolutionary algorithm to generate a melody. The resulting melody is then arranged into four parts using a decision tree for assigning chords. The result is an application that produces unique and pleasing music suitably arranged for Soprano, Alto, Tenor, and Bass.},
author = {Johnson, Matt D},
file = {::},
journal = {Work},
title = {{Evolutionary Computation Applied to Melody Generation}},
year = {2003}
}
@inproceedings{Avenue2001a,
abstract = {An important application for use with multimedia databases is a browsing aid, which allows a user to quickly and efficiently pre- view selections from either a database or from the results of a database query. Methods for facilitating browsing, though, are necessarily media dependent. We present one such method that produces short, representative samples (or “audio thumbnails”) of selections of popular music. This method attempts to identify the chorus or refrain of a song by identifying repeated sections of the audiowaveform. Areduced spectral representation of the selection based on a chroma transformation of the spectrum is used to find repeating patterns. This representation encodes harmonic relation- ships in a signal and thus is ideal for popular music, which is often characterized by prominent harmonic progressions. The method is evaluated over a sizable database of popular music and found to perform well, with most of the errors resulting from songs that do not meet our structural assumptions.},
author = {Avenue, Beal and Wakefield, Gregory H},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
file = {:Users/pkmital/Documents/Mendeley Desktop/Avenue, Wakefield/Avenue, Wakefield - 2001 - TO CATCH A CHORUS USING CHROMA-BASED REPRESENTATIONS FOR AUDIO THUMBNAILING - IEEE Workshop on Applications.pdf:pdf},
title = {{TO CATCH A CHORUS : USING CHROMA-BASED REPRESENTATIONS FOR AUDIO THUMBNAILING}},
year = {2001}
}
@misc{Milne2010a,
abstract = {From the seventeenth century to the present day, tonal harmonic music has had a number of invariant properties: specific chord progressions (cadences) that induce a sense of closure; the asymmetrical privileging of certain progressions; the degree of fit between pairs of successively played tones or chords; the privileging of tertial harmony and the major and minor scales.

The most widely accepted explanation (e.g., Bharucha (1987), Krumhansl (1990), Lerdahl (2001)) has been that this is due to a process of enculturation: frequently occurring musical patterns are learned by listeners, some of whom become composers and replicate the same patterns, which go on to influence the next "generation" of composers, and so on. Some contemporary researchers (e.g., Parncutt, Milne (2009), Large (in press)) have argued that these are circular arguments, and have proposed various psychoacoustic, or neural, processes and constraints that shape tonal harmonic music into the form it has actually taken.

In this presentation, I discuss some of the broader music theoretical implications of my recently developed psychoacoustic model of harmonic cadences (which has had encouraging experimental support (Milne, 2009)). The core of the model is two different psychoacoustically-derived measures of pitch-based distance between chords (one modelling "fit", the other "voice-leading distance"), and the interaction of these two distances to model the feelings of activity, expectation, and resolution induced by certain chord progressions (notably cadences). When a played pair of chords have a poorer fit than an un-played comparison pair, that is also voice-leading-close, it is reasonable to assume the played pair is heard as an alteration of the comparison pair. This is similar to how a harmonically dissonant interval (e.g., the tritone B-F) is likely to be heard as an alteration of a voice-leading-close consonant interval (e.g., the perfect fourth B-E, or the major third C-E).

I explore the extent to which the model can predict the familiar tonal cadences described in music theory (including those containing tritone substitutions), and the asymmetries that are so characteristic of tonal harmony. I also compare and contrast the model with Riemann's functional theory, and show how it may be able to shed light upon the privileged status of the major and minor scales (over the modes), and the dependence of tonality upon triadic harmony.},
address = {Music Research Studio, The Open University, Milton Keynes, UK},
author = {Milne, Andrew J.},
month = feb,
title = {{Tonal music theory: A psychoacoustical explanation?}},
year = {2010}
}
@inproceedings{Solomos2006,
abstract = {This paper is an analytical approach to Xenakis’s 1990 string quartet Tetora. The analysis reflects the second phase of the application of sieve theory. Xenakis began developing his theory in 1963, when he was named artist in residence in West-Berlin. His studies, at that time, led him to the quest of an axiomatics of musical structures which can be built through highly formalised procedures. This is the case of Nomos Alpha (1966), but not with works from his later period. This paper touches upon the relation that the composer had developed with his own theory in its relocation (mid 1980s – mid 1990s). Although it is the period of musical scales and sonorities, Tetora exhibits evidence of a time- point structure whose compositional design and its application relate to transformations parallel to his ‘metabolae’. His theory would generate a way of thinking about pitch structures and sonorities, that – as the analysis of Tetora shows – was also to be extended to the temporal structure of (certain parts of) compositions.},
author = {Solomos, In Makis and Georgaki, Anastasia and Zervos, Giorgos and Proceedings, Definitive},
booktitle = {Proceedings of the International Symposium Iannis Xenakis},
file = {::},
title = {{INSIDE / OUTSIDE-TIME : METABOLAE IN IANNIS XENAKIS ’ S TETORA}},
year = {2006}
}
@article{Abdallah2005a,
author = {Abdallah, Samer and Noland, Katy and Sandler, Mark and Casey, Michael and Rhodes, Christophe},
file = {::},
journal = {Evaluation},
keywords = {audio,music,segmentation,structure},
title = {{THEORY AND EVALUATION OF A BAYESIAN MUSIC STRUCTURE EXTRACTOR}},
year = {2005}
}
@phdthesis{Milne2009,
abstract = {This thesis presents a psychoacoustically derived computational model of the perceived distance between any
two major or minor triads, the degree of activity created by any given pair of triads, and the cadential
effectiveness of three‐triad progressions. The model is tested against conventional music theory, and ratings
given by thirty‐five participants for the “similarity” and “fit” of triads in a pair, and the “cadential effectiveness”
of three‐triad progressions. Multiple regressions show that the model provides highly significant predictions of
the experimentally obtained ratings. Finally, it is argued that because the model is based upon psychoacoustic
axioms, it is likely the regression equations represent true causal models. As such, the computational model
and its associated theory question the plausibility of theoretical approaches to tonality that use only long‐term
memory and statistical features, as well as those approaches based upon symmetrical geometrical structures
like the torus. It is hoped that the approach proposed here may herald not only the return of psychoacoustics to tonal music theory, but also the exploration of the tonal possibilities offered by non‐standard tunings and nonharmonic timbres.},
address = {Jyv\"{a}skyl\"{a}, Finland},
author = {Milne, Andrew J.},
language = {English},
month = sep,
school = {University of Jyv\"{a}skyl\"{a}},
title = {{A psychoacoustic model of harmonic cadences}},
type = {Master's},
url = {https://jyx.jyu.fi/dspace/bitstream/handle/123456789/21724/URN\_NBN\_fi\_jyu-200908173596.pdf?sequence=1},
year = {2009}
}
@inproceedings{Milne,
address = {Seattle},
author = {Milne, Andrew J.},
booktitle = {Proceedings of the 11th International Conference on Music Perception and Cognition},
editor = {Demorest, S. M. and Morrison, S. J. and Campbell, P. S.},
pages = {597--600},
title = {{Tonal music theory: A psychoacoustic explanation?}},
url = {http://oro.open.ac.uk/21509/1/Tonal\_Music\_Theory\_-\_Full\_Paper.pdf},
year = {2010}
}
@article{Ellis2007,
author = {Ellis, Daniel},
doi = {10.1080/09298210701653344},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
keywords = {autocorrela-,beat tracking,culated for 8 khz,downsampled mono versions of,dynamic programming,is cal-,log-magnitude 40-channel mel-frequency spectrogram,tempo extraction,the orig-,tion},
month = mar,
number = {1},
pages = {51--60},
title = {{Beat Tracking by Dynamic Programming}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09298210701653344\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {36},
year = {2007}
}
@phdthesis{Diaz-Jerez2000,
author = {Diaz-Jerez, Gustavo},
file = {::},
number = {August},
title = {{Algorithmic Music: Using Mathematical Models in Music Composition}},
year = {2000}
}
@article{Serra2008,
author = {Serra, Joan and Gomez, Emilia and Herrera, Perfecto and Serra, Xavier},
doi = {10.1080/09298210902894085},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = dec,
number = {4},
pages = {299--309},
title = {{Statistical Analysis of Chroma Features in Western Music Predicts Human Judgments of Tonality}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/09298210902894085\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2008}
}
@phdthesis{Dubois2003,
abstract = {The purpose of this dissertation is to create and explore potential taxonomies for using algorithmic string-substitution systems in the generation of music. The focus of the author’s research is on using a specific category of string rewriting systems (called Lindenmayer, or L-systems) to generate musical material based on a musical primer provided by a live musician or musicians. The author explores and describes a variety of possible composing methodologies whereby a computer can generate, in real time, appropriate accompanying music and signal processing to a live performer. By experimenting with different taxonomies of mapping source material (live musical input) to accompanying processes (provided by the computer), an extensive system for generating a varied, yet systematically cohesive, corpus of musical work can be achieved. A series of short compositions based on this string-substitution process are included as applications of this system.},
author = {Dubois, Roger Luke},
file = {::},
title = {{Application of Generative String-Substitution Systems in Computer Music}},
year = {2003}
}
@article{Rolland1999,
author = {Rolland, Pierre-Yves and Ganascia, Jean-Gabriel and Ramalho, Geber L.},
doi = {10.1076/jnmr.28.2.105.3120},
file = {::},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = jun,
number = {2},
pages = {105--129},
title = {{An Artificially Intelligent Jazz Performer}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1076/jnmr.28.2.105.3120\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {28},
year = {1999}
}
@article{Bharucha1989,
author = {Bharucha, Jamshed and Olney, Katherine},
doi = {10.1080/07494468900640401},
file = {::},
issn = {0749-4467},
journal = {Contemporary Music Review},
number = {1},
pages = {341--356},
title = {{Tonal cognition, artificial intelligence and neural nets}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/07494468900640401\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {4},
year = {1989}
}
@inproceedings{Fornari2009,
abstract = {This work describes the implementation of RePartitura, a processual multi-modal artwork that uses principles of Evolutionary Computation (EC) in the creation of a Pd patch that resembles the biological evolution of individuals within a population. This project was initiated with a collection of handmade drawings that share the common characteristic of being similar but never identical. This resemblance with a biological population of individuals, led us to its usage with the Evolutionary Sound Synthesis methodology. From each drawing we retrieved sonic features that were represented by a subpatch into the Pd system implementation. As Pd allows the development of patch generating other patches, this system acts as if they are individuals artificially living inside a population, were they grow, reproduced and eventually dye. This paper describes the technical aspects of RePartitura implementation; the mapping of drawings into sonic features, the design and breeding of individuals and the final sonic result of all individuals coexisting within the population, thus leading to the self-organization of dynamically evolving soundscapes.},
author = {Fornari, Jose and Shellard, Mariana},
booktitle = {3rd PureData International Convention},
file = {::},
keywords = {evolutionary algorithm,multimodal art,processual artwork,sound synthesis,soundscapes},
title = {{Breeding Patches , Evolving Soundscapes}},
year = {2009}
}
@inproceedings{Horvitz1998a,
author = {Horvitz, E and Breese, J and Heckerman, David and Hovel, D and Rommelse, K},
booktitle = {Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence},
organization = {Citeseer},
pages = {256--265},
publisher = {Citeseer},
title = {{The Lumiere Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users}},
url = {http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed\&cmd=Retrieve\&dopt=AbstractPlus\&list\_uids=5872275123514932582related:Zn14uByDflEJ},
year = {1998}
}
@inproceedings{Baldwina,
abstract = {We describe the application of a predictive Kalman filter to the display of panoramic images. We discuss integrating a panoramic imaging system with prediction of viewing direction to create an effective telepresence system over low bandwidth links. Panoramic imaging using a reflective mirror surface offers an alternative to pan-tilt systems for obtaining a 360 degree field of view. Selecting a small window within a panoramic image allows a meaningful part of an image from a remote site to be seen at a higher refresh rate. Because of the delay in transmitting an image from a remote site, it is necessary to have additional image information available locally. This information can be used to simulate continuously flowing pictures with reduced apparent delay. Continuity in image viewing is achieved by predicting the next viewpoint of an operator and preemptively transmitting parts of an image. Experimental results are given to evaluate the proposed telepresence system},
author = {Baldwin, J. and Basu, A. and Zhang, H.},
booktitle = {Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)},
pages = {1922--1927},
publisher = {IEEE},
title = {{Panoramic video with predictive windows for telepresence applications}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=770389},
volume = {3}
}
@inproceedings{Duchamp1999a,
address = {Boulder, Colorado, USA},
author = {Duchamp, Dan},
booktitle = {Proceedings of USITS' 99: The 2nd USENIX Symposium on Internet Technologies \& Systems},
month = oct,
pages = {12},
title = {{Prefetching hyperlinks}},
url = {http://portal.acm.org/citation.cfm?id=1251480.1251492},
year = {1999}
}
@article{zhang2003personalized,
author = {Zhang, W and Lewanda, D B and Janneck, C D and Davison, B D},
journal = {Dept. of Computer Science and Engineering, Lehigh University, Bethlehem, USA, Tech. Rep. LU-CSE-03-006},
publisher = {Citeseer},
title = {{Personalized web prefetching in mozilla}},
year = {2003}
}
@article{Chan2005a,
author = {Chan, Addison and Lau, Rynson W. H. and Ng, Beatrice},
issn = {15335399},
journal = {ACM Transactions on Internet Technology},
keywords = {Mouse motion prediction,caching and prefetching,distributed virtual environments,virtual navigation},
month = feb,
number = {1},
pages = {70--91},
title = {{Motion prediction for caching and prefetching in mouse-driven DVE navigation}},
url = {http://portal.acm.org/citation.cfm?id=1052934.1052937},
volume = {5},
year = {2005}
}
@inproceedings{Kapoor:2010:IOS:1753326.1753529,
address = {New York, NY, USA},
author = {Kapoor, Ashish and Lee, Bongshin and Tan, Desney and Horvitz, Eric},
booktitle = {Proceedings of the 28th international conference on Human factors in computing systems},
doi = {http://doi.acm.org/10.1145/1753326.1753529},
isbn = {978-1-60558-929-9},
keywords = { interactive machine learning, interactive optimization, visualization,decision theory},
pages = {1343--1352},
publisher = {ACM},
series = {CHI '10},
title = {{Interactive optimization for steering machine classification}},
url = {http://doi.acm.org/10.1145/1753326.1753529},
year = {2010}
}
@inproceedings{Palpanas1999,
address = {San Diego, California, USA},
author = {Palpanas, Themistoklis and Mendelzon, Alberto},
booktitle = {4th International Web Caching Workshop},
title = {{Web Prefetching Using Partial Match Prediction}},
url = {http://workshop99.ircache.net/Papers/palpanas-0.ps.gz},
year = {1999}
}
@book{Hoffmann2009b,
address = {New York, New York, USA},
author = {Hoffmann, Alexander and Spelmezan, Daniel and Borchers, Jan},
booktitle = {Proceedings of the 27th international conference on Human factors in computing systems - CHI '09},
keywords = {adopting input device,error prevention,haptic,tactile feedback,text entry},
month = apr,
pages = {2265},
publisher = {ACM Press},
title = {{TypeRight}},
url = {http://portal.acm.org/citation.cfm?id=1518701.1519048},
year = {2009}
}
@book{Horvitz1999a,
address = {New York, New York, USA},
author = {Horvitz, Eric},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems the CHI is the limit - CHI '99},
keywords = {UI design,decision theory,direct manipulaton,intelligent agents,probability,user modeling},
month = may,
pages = {159--166},
publisher = {ACM Press},
title = {{Principles of mixed-initiative user interfaces}},
url = {http://portal.acm.org/citation.cfm?id=302979.303030},
year = {1999}
}
@article{DelaOssa,
author = {de la Ossa, B. and Gill, J. A. and Sahuquillo, J. and Pont, A.},
journal = {JORNADAS DE PARALELISMO},
pages = {1--6},
title = {{Prefetching next web user's accesses in a real environment}},
volume = {17},
year = {2006}
}
@inproceedings{Asano2005,
address = {New York, New York, USA},
author = {Asano, Takeshi and Sharlin, Ehud and Kitamura, Yoshifumi and Takashima, Kazuki and Kishino, Fumio},
booktitle = {Proceedings of the 18th annual ACM symposium on User interface software and technology - UIST '05},
file = {::},
keywords = {Windows icons menus pointer (WIMP),cursor,desktop,graphics user interfaces (GUI),mouse,prediction},
month = oct,
pages = {133},
publisher = {ACM Press},
title = {{Predictive interaction using the delphian desktop}},
url = {http://dl.acm.org/citation.cfm?id=1095034.1095058},
year = {2005}
}
@article{Yaeger1998a,
author = {Yaeger, Larry and Webb, Brandyn and Lyon, Richard},
journal = {AI Magazine},
number = {1},
pages = {73--90},
title = {{Combining Neural Networks and Context-Driven Search for On-Line, Printed Handwriting Recognition in the Newton}},
url = {http://www.aaai.org/ojs/index.php/aimagazine/article/view/1355/1255},
volume = {19},
year = {1998}
}
@book{Oirschot2001a,
abstract = {To create non-disturbing tactual feedback in human-computer interaction we want to predict the user’s goal, so that the user is helped toward the target and away from non-targets. In this paper we describe an exploration of cursor movements with an amplitude of 250 pixels, in eight different directions and with three different control devices (a mechanical mouse, an optical mouse and an optical trackball) to find characteristics of the cursor path which could be used to create a prediction algorithm on direction. The focus was on the mean curvature of and the variability between the paths in each direction. It can be concluded that on average cursor paths are rather straight in all eight directions and with all three devices. The variability of the paths depends on (1) direction; (2) friction of the control device; (3) user.},
address = {Berlin, Heidelberg},
author = {Oirschot, Hilde and Houtsma, Adrian and Brewster, Stephen and Murray-Smith, Roderick},
editor = {Brewster, Stephen and Murray-Smith, Roderick},
month = jul,
pages = {127--134},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Haptic Human-Computer Interaction}},
url = {http://www.springerlink.com/content/w6pphdfdgj35x8bh/},
volume = {2058},
year = {2001}
}
@article{murata1998improvement,
author = {Murata, A},
issn = {1044-7318},
journal = {International Journal of Human-Computer Interaction},
keywords = {input,prediction},
mendeley-tags = {input,prediction},
number = {1},
pages = {23--32},
publisher = {Taylor \& Francis},
title = {{Improvement of pointing time by predicting targets in pointing with a PC mouse}},
volume = {10},
year = {1998}
}
@inproceedings{Sahami1998a,
abstract = {In addressing the growing problem of junk E-mail on the Internet, we examine methods for the automated construction of filters to eliminate such unwanted messages from a user's mail stream. By casting this problem in a decision theoretic framework, we are able to make use of probabilistic learning methods in conjunction with a notion of differential misclassification cost to produce filters which are especially appropriate for the nuances of this task. While this may appear, at first, to be a straight-forward text classification problem, we show that by considering domain-specific features of this problem in addition to the raw text of E-mail messages, we can produce much more accurate filters. Finally, we show the efficacy of such filters in a real world usage scenario, arguing that this technology is mature enough for deployment. Introduction As the number of users connected to the Internet continues to skyrocket, electronic mail (E-mail) is quickly becoming one of the fastest and m...},
author = {Sahami, Mehran and Dumais, Susan and Heckerman, David and Horvitz, Eric},
booktitle = {Learning for Text Categorization Papers from the 1998 workshop},
doi = {10.1.1.48.1254},
file = {::},
number = {Cohen},
organization = {AAAI'98 Workshop on Learning for Text Categorization},
pages = {98--05},
publisher = {Madison, Wisconsin: AAAI Technical Report WS-98-05},
title = {{A Bayesian Approach to Filtering Junk E-Mail}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.1254},
volume = {62},
year = {1998}
}
@article{Bendor2010,
abstract = {Pitch, our perception of how high or low a sound is on a musical scale, crucially depends on a sound's periodicity. If an acoustic signal is temporally jittered so that it becomes aperiodic, the pitch will no longer be perceivable even though other acoustical features that normally covary with pitch are unchanged. Previous electrophysiological studies investigating pitch have typically used only periodic acoustic stimuli and as such these studies cannot distinguish between a neural representation of pitch and an acoustical feature that only correlates with pitch. In this report we examine in the auditory cortex of awake marmoset monkeys (Callithrix jacchus) the neural coding of a periodicity's repetition rate, an acoustic feature that covaries with pitch. We first examine if individual neurons show similar repetition rate tuning for different periodic acoustic signals. We next measure how sensitive these neural representations are to the temporal regularity of the acoustic signal. We find that neurons throughout auditory cortex covary their firing rate with the repetition rate of an acoustic signal. However, similar repetition rate tuning across acoustic stimuli and sensitivity to temporal regularity were generally only observed in a small group of neurons found near the anterolateral border of AI, the location of a previously identified putative pitch processing center. These results suggest that although the encoding of repetition rate is a general component of auditory cortical processing, the neural correlate of periodicity is confined to a special class of pitch-selective neurons within the putative pitch processing center of auditory cortex.},
author = {Bendor, Daniel and Wang, Xiaoqin},
doi = {10.1152/jn.00281.2009},
file = {::},
issn = {1522-1598},
journal = {Journal of neurophysiology},
month = feb,
pages = {1809--1822},
pmid = {20147419},
title = {{Neural coding of periodicity in marmoset auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20147419},
year = {2010}
}
@article{Teki2011,
author = {Teki, S. and Grube, M. and Kumar, S. and Griffiths, T. D.},
doi = {10.1523/JNEUROSCI.5561-10.2011},
file = {::},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = mar,
number = {10},
pages = {3805--3812},
title = {{Distinct Neural Substrates of Duration-Based and Beat-Based Auditory Timing}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5561-10.2011},
volume = {31},
year = {2011}
}
@article{Winkler2009,
abstract = {Predictive processing of information is essential for goal-directed behavior. We offer an account of auditory perception suggesting that representations of predictable patterns, or 'regularities', extracted from the incoming sounds serve as auditory perceptual objects. The auditory system continuously searches for regularities within the acoustic signal. Primitive regularities may be encoded by neurons adapting their response to specific sounds. Such neurons have been observed in many parts of the auditory system. Representations of the detected regularities produce predictions of upcoming sounds as well as alternative solutions for parsing the composite input into coherent sequences potentially emitted by putative sound sources. Accuracy of the predictions can be utilized for selecting the most likely interpretation of the auditory input. Thus in our view, perception generates hypotheses about the causal structure of the world.},
author = {Winkler, Istv\'{a}n and Denham, Susan L and Nelken, Israel},
doi = {10.1016/j.tics.2009.09.003},
file = {:Users/pkmital/Documents/Mendeley Desktop/Winkler, Denham, Nelken/Winkler, Denham, Nelken - 2009 - Modeling the auditory scene predictive regularity representations and perceptual objects. - Trends in c.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adaptation, Physiological,Adaptation, Physiological: physiology,Animal Communication,Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Hearing,Hearing: physiology,Humans,Models, Neurological,Predictive Value of Tests},
month = dec,
number = {12},
pages = {532--40},
pmid = {19828357},
title = {{Modeling the auditory scene: predictive regularity representations and perceptual objects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19828357},
volume = {13},
year = {2009}
}
@article{Janata2003a,
abstract = {Music consists of precisely patterned sequences of both movement and sound that engage the mind in a multitude of experiences. We move in response to music and we move in order to make music. Because of the intimate coupling between perception and action, music provides a panoramic window through which we can examine the neural organization of complex behaviors that are at the core of human nature. Although the cognitive neuroscience of music is still in its infancy, a considerable behavioral and neuroimaging literature has amassed that pertains to neural mechanisms that underlie musical experience. Here we review neuroimaging studies of explicit sequence learning and temporal production--findings that ultimately lay the groundwork for understanding how more complex musical sequences are represented and produced by the brain. These studies are also brought into an existing framework concerning the interaction of attention and time-keeping mechanisms in perceiving complex patterns of information that are distributed in time, such as those that occur in music.},
author = {Janata, Petr and Grafton, Scott T},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Brain,Brain Mapping,Brain: anatomy \& histology,Brain: physiology,Cluster Analysis,Cognitive Science,Cognitive Science: methods,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Mental Processes,Mental Processes: physiology,Music,Time Factors},
month = jul,
number = {7},
pages = {682--7},
shorttitle = {Nat Neurosci},
title = {{Swinging in the brain: shared neural substrates for behaviors related to sequencing and music.}},
url = {http://dx.doi.org/10.1038/nn1081},
volume = {6},
year = {2003}
}
@article{Chartrand2007a,
abstract = {Auditory expertise has mostly been studied in relation to musical processing, but expert auditory processing can also involve nonmusical auditory stimuli, such as birdsongs in bird experts. In this study, the neural correlates of bird expertise were investigated by using electroencephalography to measure auditory-evoked potentials in bird experts and novices. Auditory stimuli in three categories (birdsongs, environmental sounds and voices) were presented in a pseudo-random order while participants performed a simple target detection task (pure tone). We observed similar amplitudes and distributions of the N100-component in bird experts and novices. In contrast, the amplitude of the P200 component was significantly smaller in bird experts at the Pz and Cz electrodes, reflecting a more frontal topography of this positivity. Notably, this group difference was observed not only for birdsongs, but also for voices and environmental sounds, suggesting a general processing difference in bird experts, not restricted to the category of expertise.},
author = {Chartrand, Jean-Pierre and Filion-Bilodeau, Sarah and Belin, Pascal},
doi = {10.1097/WNR.0b013e328013cea9},
file = {::},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Analysis of Variance,Animals,Birds,Brain,Brain Mapping,Brain: physiology,Electroencephalography,Electroencephalography: methods,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Humans,Male,Middle Aged,Professional Competence,Reaction Time,Sound},
month = mar,
number = {4},
pages = {335--40},
pmid = {17435598},
title = {{Brain response to birdsongs in bird experts.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17435598},
volume = {18},
year = {2007}
}
@unpublished{Bachorik2012,
address = {Manila},
author = {Bachorik, Douglas},
file = {::},
institution = {Bob Jones Memorial Bible College},
keywords = {cross-cultural,emotion,emotion detection},
mendeley-tags = {emotion},
number = {July},
pages = {1--27},
title = {{A Feasibility Study on Cross-culturally Perceived Emotion in Music}},
year = {2012}
}
@article{Grahn2009a,
abstract = {Perception of musical rhythms is culturally universal. Despite this special status, relatively little is known about the neurobiology of rhythm perception, particularly with respect to beat processing. Findings are presented here from a series of studies that have specifically examined the neural basis of beat perception, using functional magnetic resonance imaging (fMRI) and studying patients with Parkinson's disease. fMRI data indicate that novel beat-based sequences robustly activate the basal ganglia when compared to irregular, nonbeat sequences. Furthermore, although most healthy participants find it much easier to discriminate changes in beat-based sequences compared to irregular sequences, Parkinson's disease patients fail to show the same degree of benefit. Taken together, these data suggest that the basal ganglia are performing a crucial function in beat processing. The results of an additional fMRI study indicate that the role of the basal ganglia is strongly linked to internal generation of the beat. Basal ganglia activity is greater when participants listen to rhythms in which internal generation of the beat is required, as opposed to rhythms with strongly externally cued beats. Functional connectivity between part of the basal ganglia (the putamen) and cortical motor areas (premotor and supplementary motor areas) is also higher during perception of beat rhythms compared to nonbeat rhythms. Increased connectivity between cortical motor and auditory areas is found in those with musical training. The findings from these converging methods strongly implicate the basal ganglia in processing a regular beat, particularly when internal generation of the beat is required.},
author = {Grahn, Jessica a},
doi = {10.1111/j.1749-6632.2009.04553.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Auditory Perception,Auditory Perception: physiology,Basal Ganglia,Basal Ganglia: physiology,Humans,Magnetic Resonance Imaging,Music,Neuropsychology,Neuropsychology: methods,Periodicity},
month = jul,
pages = {35--45},
pmid = {19673753},
title = {{The role of the basal ganglia in beat perception: neuroimaging and neuropsychological investigations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673753},
volume = {1169},
year = {2009}
}
@article{Peretz2005,
abstract = {Research on how the brain processes music is emerging as a rich and stimulating area of investigation of perception, memory, emotion, and performance. Results emanating from both lesion studies and neuroimaging techniques are reviewed and integrated for each of these musical functions. We focus our attention on the common core of musical abilities shared by musicians and nonmusicians alike. Hence, the effect of musical training on brain plasticity is examined in a separate section, after a review of the available data regarding music playing and reading skills that are typically cultivated by musicians. Finally, we address a currently debated issue regarding the putative existence of music-specific neural networks. Unfortunately, due to scarcity of research on the macrostructure of music organization and on cultural differences, the musical material under focus is at the level of the musical phrase, as typically used in Western popular music.},
author = {Peretz, Isabelle and Zatorre, Robert J},
doi = {10.1146/annurev.psych.56.091103.070225},
file = {::},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Affect,Affect: physiology,Auditory Perception,Auditory Perception: physiology,Basal Ganglia,Basal Ganglia: physiology,Brain,Brain: anatomy \& histology,Brain: physiology,Cerebellum,Cerebellum: physiology,Cognition,Cognition: physiology,Humans,Memory,Memory: physiology,Music,Nerve Net,Nerve Net: physiology,Pitch Perception,Pitch Perception: physiology,Recognition (Psychology),Time Perception,Time Perception: physiology},
month = jan,
pages = {89--114},
pmid = {15709930},
title = {{Brain organization for music processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15709930},
volume = {56},
year = {2005}
}
@article{Bendor,
abstract = {Pitch perception is crucial for vocal communication, music perception, and auditory object processing in a complex acoustic environment. How pitch is represented in the cerebral cortex has for a long time remained an unanswered question in auditory neuroscience. Several lines of evidence now point to a distinct non-primary region of auditory cortex in primates that contains a cortical representation of pitch.},
author = {Bendor, Daniel and Wang, Xiaoqin},
doi = {10.1016/j.conb.2006.07.001},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animals,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: anatomy \& histology,Auditory Pathways: physiology,Geniculate Bodies,Geniculate Bodies: anatomy \& histology,Geniculate Bodies: physiology,Haplorhini,Haplorhini: anatomy \& histology,Haplorhini: physiology,Humans,Neurons,Neurons: physiology,Pitch Perception,Pitch Perception: physiology,Primates,Primates: anatomy \& histology,Primates: physiology,Species Specificity},
number = {4},
pages = {391--9},
pmid = {16842992},
title = {{Cortical representations of pitch in monkeys and humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16842992},
volume = {16},
year = {2006}
}
@article{Janata2002a,
abstract = {Western tonal music relies on a formal geometric structure that determines distance relationships within a harmonic or tonal space. In functional magnetic resonance imaging experiments, we identified an area in the rostromedial prefrontal cortex that tracks activation in tonal space. Different voxels in this area exhibited selectivity for different keys. Within the same set of consistently activated voxels, the topography of tonality selectivity rearranged itself across scanning sessions. The tonality structure was thus maintained as a dynamic topography in cortical areas known to be at a nexus of cognitive, affective, and mnemonic processing.},
author = {Janata, Petr and Birk, Jeffrey L and {Van Horn}, John D and Leman, Marc and Tillmann, Barbara and Bharucha, Jamshed J},
doi = {10.1126/science.1076262},
file = {::},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Adult,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Auditory Perception,Brain,Brain Mapping,Brain: anatomy \& histology,Brain: physiology,Female,Functional Laterality,Humans,Magnetic Resonance Imaging,Male,Memory,Mental Processes,Middle Aged,Models, Neurological,Music,Nerve Net,Nerve Net: anatomy \& histology,Nerve Net: physiology,Neural Networks (Computer),Pitch Perception,Prefrontal Cortex,Prefrontal Cortex: anatomy \& histology,Prefrontal Cortex: physiology},
month = dec,
number = {5601},
pages = {2167--70},
pmid = {12481131},
title = {{The cortical topography of tonal structures underlying Western music.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12481131},
volume = {298},
year = {2002}
}
@article{Bendor2010,
abstract = {Pitch, our perception of how high or low a sound is on a musical scale, crucially depends on a sound's periodicity. If an acoustic signal is temporally jittered so that it becomes aperiodic, the pitch will no longer be perceivable even though other acoustical features that normally covary with pitch are unchanged. Previous electrophysiological studies investigating pitch have typically used only periodic acoustic stimuli and as such these studies cannot distinguish between a neural representation of pitch and an acoustical feature that only correlates with pitch. In this report we examine in the auditory cortex of awake marmoset monkeys (Callithrix jacchus) the neural coding of a periodicity's repetition rate, an acoustic feature that covaries with pitch. We first examine if individual neurons show similar repetition rate tuning for different periodic acoustic signals. We next measure how sensitive these neural representations are to the temporal regularity of the acoustic signal. We find that neurons throughout auditory cortex covary their firing rate with the repetition rate of an acoustic signal. However, similar repetition rate tuning across acoustic stimuli and sensitivity to temporal regularity were generally only observed in a small group of neurons found near the anterolateral border of AI, the location of a previously identified putative pitch processing center. These results suggest that although the encoding of repetition rate is a general component of auditory cortical processing, the neural correlate of periodicity is confined to a special class of pitch-selective neurons within the putative pitch processing center of auditory cortex.},
author = {Bendor, Daniel and Wang, Xiaoqin},
doi = {10.1152/jn.00281.2009},
issn = {1522-1598},
journal = {Journal of neurophysiology},
month = feb,
pages = {1809--1822},
pmid = {20147419},
title = {{Neural coding of periodicity in marmoset auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20147419},
year = {2010}
}
@article{Iversen2009a,
abstract = {Our perceptions are shaped by both extrinsic stimuli and intrinsic interpretation. The perceptual experience of a simple rhythm, for example, depends upon its metrical interpretation (where one hears the beat). Such interpretation can be altered at will, providing a model to study the interaction of endogenous and exogenous influences in the cognitive organization of perception. Using magnetoencephalography (MEG), we measured brain responses evoked by a repeating, rhythmically ambiguous phrase (two tones followed by a rest). In separate trials listeners were instructed to impose different metrical organizations on the rhythm by mentally placing the downbeat on either the first or the second tone. Since the stimulus was invariant, differences in brain activity between the two conditions should relate to endogenous metrical interpretation. Metrical interpretation influenced early evoked neural responses to tones, specifically in the upper beta range (20-30 Hz). Beta response was stronger (by 64\% on average) when a tone was imagined to be the beat, compared to when it was not. A second experiment established that the beta increase closely resembles that due to physical accents, and thus may represent the genesis of a subjective accent. The results demonstrate endogenous modulation of early auditory responses, and suggest a unique role for the beta band in linking of endogenous and exogenous processing. Given the suggested role of beta in motor processing and long-range intracortical coordination, it is hypothesized that the motor system influences metrical interpretation of sound, even in the absence of overt movement.},
author = {Iversen, John R and Repp, Bruno H and Patel, Aniruddh D},
doi = {10.1111/j.1749-6632.2009.04579.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adolescent,Adult,Auditory Perception,Auditory Perception: physiology,Child,Child, Preschool,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Infant,Magnetoencephalography,Periodicity,Young Adult},
month = jul,
pages = {58--73},
pmid = {19673755},
title = {{Top-down control of rhythm perception modulates early auditory responses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673755},
volume = {1169},
year = {2009}
}
@article{Hyde2009,
abstract = {The human brain has the remarkable capacity to alter in response to environmental demands. Training-induced structural brain changes have been demonstrated in the healthy adult human brain. However, no study has yet directly related structural brain changes to behavioral changes in the developing brain, addressing the question of whether structural brain differences seen in adults (comparing experts with matched controls) are a product of "nature" (via biological brain predispositions) or "nurture" (via early training). Long-term instrumental music training is an intense, multisensory, and motor experience and offers an ideal opportunity to study structural brain plasticity in the developing brain in correlation with behavioral changes induced by training. Here we demonstrate structural brain changes after only 15 months of musical training in early childhood, which were correlated with improvements in musically relevant motor and auditory skills. These findings shed light on brain plasticity and suggest that structural brain differences in adult experts (whether musicians or experts in other areas) are likely due to training-induced brain plasticity.},
author = {Hyde, Krista L and Lerch, Jason and Norton, Andrea and Forgeard, Marie and Winner, Ellen and Evans, Alan C and Schlaug, Gottfried},
doi = {10.1523/JNEUROSCI.5118-08.2009},
file = {::},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Age Factors,Brain,Brain: growth \& development,Child,Child, Preschool,Female,Humans,Learning,Learning: physiology,Longitudinal Studies,Male,Music,Neurogenesis,Neurogenesis: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Time Factors},
number = {10},
pages = {3019--25},
pmid = {19279238},
title = {{Musical training shapes structural brain development.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19279238},
volume = {29},
year = {2009}
}
@article{Large1999,
author = {Large, Edward W and Jones, Mari Riess},
file = {::},
journal = {Psychological Review},
number = {1},
pages = {119--59},
title = {{The Dynamics of Attending: How People Track Time-Varying Events}},
url = {http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ589141},
volume = {106},
year = {1999}
}
@article{Perani2010,
abstract = {In adults, specific neural systems with right-hemispheric weighting are necessary to process pitch, melody, and harmony as well as structure and meaning emerging from musical sequences. It is not known to what extent the specialization of these systems results from long-term exposure to music or from neurobiological constraints. One way to address this question is to examine how these systems function at birth, when auditory experience is minimal. We used functional MRI to measure brain activity in 1- to 3-day-old newborns while they heard excerpts of Western tonal music and altered versions of the same excerpts. Altered versions either included changes of the tonal key or were permanently dissonant. Music evoked predominantly right-hemispheric activations in primary and higher order auditory cortex. During presentation of the altered excerpts, hemodynamic responses were significantly reduced in the right auditory cortex, and activations emerged in the left inferior frontal cortex and limbic structures. These results demonstrate that the infant brain shows a hemispheric specialization in processing music as early as the first postnatal hours. Results also indicate that the neural architecture underlying music processing in newborns is sensitive to changes in tonal key as well as to differences in consonance and dissonance.},
author = {Perani, Daniela and Saccuman, Maria Cristina and Scifo, Paola and Spada, Danilo and Andreolli, Guido and Rovelli, Rosanna and Baldoli, Cristina and Koelsch, Stefan},
doi = {10.1073/pnas.0909074107},
file = {::},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
pages = {1--6},
pmid = {20176953},
title = {{Functional specializations for music processing in the human newborn brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20176953},
year = {2010}
}
@article{Magnani2012,
abstract = {The aim of the present study was to explore the spatial organization of auditory time and the effects of the manipulation of spatial attention on such a representation. In two experiments, we asked 28 adults to classify the duration of auditory stimuli as "short" or "long". Stimuli were tones of high or low pitch, delivered left or right of the participant. The time bisection task was performed either on right or left stimuli regardless of their pitch (Spatial experiment), or on high or low tones regardless of their location (Tonal experiment). Duration of left stimuli was underestimated relative to that of right stimuli, in the Spatial but not in the Tonal experiment, suggesting that a spatial representation of auditory time emerges selectively when spatial-encoding is enforced. Further, when we introduced spatial-attention shifts using the prismatic adaptation procedure, we found modulations of auditory time processing as a function of prismatic deviation, which correlated with the interparticipant adaptation effect. These novel findings reveal a spatial representation of auditory time, modulated by spatial attention.},
author = {Magnani, Barbara and Pavani, Francesco and Frassinetti, Francesca},
file = {::},
issn = {1873-7838},
journal = {Cognition},
keywords = {Kognition,Raum,Wahrnehmung,Zeit,auditiv,visuell},
month = aug,
number = {2},
pages = {243--233},
title = {{Changing auditory time with prismatic goggles.}},
url = {http://dx.doi.org/10.1016/j.cognition.2012.07.001},
volume = {125},
year = {2012}
}
@article{McDermott2008a,
author = {McDermott, Josh H and Lehr, Andriana J and Oxenham, Andrew J},
doi = {10.1111/j.1467-9280.2008.02235.x},
file = {::},
issn = {1467-9280},
journal = {Psychological science : a journal of the American Psychological Society / APS},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Female,Humans,Intuition,Intuition: physiology,Male,Pitch Discrimination,Pitch Discrimination: physiology,Pitch Perception,Pitch Perception: physiology,ROC Curve,Recognition (Psychology),Recognition (Psychology): physiology,Task Performance and Analysis,Young Adult},
month = dec,
number = {12},
pages = {1263--71},
pmid = {19121136},
title = {{Is Relative Pitch Specific to Pitch?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19712445},
volume = {19},
year = {2008}
}
@article{Loui2010,
author = {Loui, Psyche and Li, HCC and Hohmann, Anja and Schlaug, Gottfried},
file = {::},
journal = {Journal of Cognitive Neuroscience},
pages = {1--12},
title = {{Enhanced cortical connectivity in absolute pitch musicians: A model for local hyperconnectivity}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn.2010.21500?ai=t1\&amp;mi=0\&amp;af=R},
year = {2010}
}
@article{Sayles2008,
abstract = {Accurate neural coding of the pitch of complex sounds is an essential part of auditory scene analysis; differences in pitch help segregate concurrent sounds, while similarities in pitch can help group sounds from a common source. In quiet, nonreverberant backgrounds, pitch can be derived from timing information in broadband high-frequency auditory channels and/or from frequency and timing information carried in narrowband low-frequency auditory channels. Recording from single neurons in the cochlear nucleus of anesthetized guinea pigs, we show that the neural representation of pitch based on timing information is severely degraded in the presence of reverberation. This degradation increases with both increasing reverberation strength and channel bandwidth. In a parallel human psychophysical pitch-discrimination task, reverberation impaired the ability to distinguish a high-pass harmonic sound from noise. Together, these findings explain the origin of perceptual difficulties experienced by both normal-hearing and hearing-impaired listeners in reverberant spaces.},
author = {Sayles, Mark and Winter, Ian M},
doi = {10.1016/j.neuron.2008.03.029},
file = {::},
issn = {1097-4199},
journal = {Neuron},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Action Potentials,Action Potentials: physiology,Animals,Cochlear Nucleus,Cochlear Nucleus: cytology,Dose-Response Relationship, Radiation,Feedback,Feedback: physiology,Guinea Pigs,Neurons,Neurons: physiology,Pitch Discrimination,Pitch Discrimination: physiology,Psychoacoustics,Sound,Sound Spectrography,Sound Spectrography: methods,Spectrum Analysis,Time Factors},
month = jun,
number = {5},
pages = {789--801},
pmid = {18549789},
title = {{Reverberation challenges the temporal representation of the pitch of complex sounds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18549789},
volume = {58},
year = {2008}
}
@article{Shepard1982,
author = {Shepard, R.N.},
file = {::},
issn = {1939-1471},
journal = {Psychological Review},
number = {4},
pages = {305},
publisher = {American Psychological Association},
title = {{Geometrical approximations to the structure of musical pitch.}},
url = {http://psycnet.apa.org/journals/rev/89/4/305/},
volume = {89},
year = {1982}
}
@phdthesis{Gayler1988,
abstract = {The ability to discriminate two melodies as differing or identical is arguably the most basic musical task, yet modern research on melody discrimination has stagnated without reaching psychologically important conclusions. I reviewed previous research and identified the barriers to progress as the lack of a sophisticated theoretical framework, and inadequate experimental and data-analytic methodologies. My work addresses these barriers. The theoretical framework proposed distinguishes between the attributes describing a melody and the units in which those attributes are organised. This makes clear the need to ensure that corresponding units are compared in the comparison of melodies. The characteristics of the melodic domain make traditional experimental designs and analyses particularly inappropriate. Discriminability measures could only be calculated, analysed, and interpreted in terms of the summary properties of groups of melody pairs rather than the properties of the individual melodies. I developed an extension to signal detection analysis that allows the discriminability of individual melody pairs to be calculated and analysed in terms of the individual melodies involved. The first experiment was designed as an exploratory study to find previously unreported effects. It demonstrated effects related to contour reversal, overall contour shape, particular pitch transitions, pitch range, and cadence. The second and third experiments further investigated the contour reversal effect. This effect was convincingly demonstrated in these experiments while I developed my methods of data analysis. The third experiment also demonstrated effects associated with the repetition of a note across a contour reversal and with rhythmic stress. In the fourth experiment I used the new methodology to attack directly the question of the relative importance of interval-based and note-based attributes. This experiment demonstrated that simple measures of the number of notes and intervals changed are inadequate to account for melody discrimination performance. I found effects related to: repetition across a contour reversal, the tonic, the major triad, the commonness of particular pitch transitions, and the process of matching corresponding units. These effects were more naturally described in terms of note-based attributes than interval-based attributes.},
author = {Gayler, Ross W},
booktitle = {Psychology},
file = {::},
pages = {243},
school = {University of Queensland},
title = {{Development of a methodology and theoretical framework for melodic discrimination}},
url = {http://proquest.umi.com/pqdlink?did=745800051\&Fmt=7\&clientId},
year = {1988}
}
@article{Bendor,
abstract = {Pitch perception is crucial for vocal communication, music perception, and auditory object processing in a complex acoustic environment. How pitch is represented in the cerebral cortex has for a long time remained an unanswered question in auditory neuroscience. Several lines of evidence now point to a distinct non-primary region of auditory cortex in primates that contains a cortical representation of pitch.},
author = {Bendor, Daniel and Wang, Xiaoqin},
doi = {10.1016/j.conb.2006.07.001},
file = {::},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animals,Auditory Cortex,Auditory Cortex: anatomy \& histology,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: anatomy \& histology,Auditory Pathways: physiology,Geniculate Bodies,Geniculate Bodies: anatomy \& histology,Geniculate Bodies: physiology,Haplorhini,Haplorhini: anatomy \& histology,Haplorhini: physiology,Humans,Neurons,Neurons: physiology,Pitch Perception,Pitch Perception: physiology,Primates,Primates: anatomy \& histology,Primates: physiology,Species Specificity},
number = {4},
pages = {391--9},
pmid = {16842992},
title = {{Cortical representations of pitch in monkeys and humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16842992},
volume = {16},
year = {2006}
}
@article{Iversen2008,
abstract = {Many aspects of perception are known to be shaped by experience, but others are thought to be innate universal properties of the brain. A specific example comes from rhythm perception, where one of the fundamental perceptual operations is the grouping of successive events into higher-level patterns, an operation critical to the perception of language and music. Grouping has long been thought to be governed by innate perceptual principles established a century ago. The current work demonstrates instead that grouping can be strongly dependent on culture. Native English and Japanese speakers were tested for their perception of grouping of simple rhythmic sequences of tones. Members of the two cultures showed different patterns of perceptual grouping, demonstrating that these basic auditory processes are not universal but are shaped by experience. It is suggested that the observed perceptual differences reflect the rhythms of the two languages, and that native language can exert an influence on general auditory perception at a basic level.},
author = {Iversen, John R and Patel, Aniruddh D and Ohgushi, Kengo},
doi = {10.1121/1.2973189},
file = {::},
issn = {1520-8524},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Adolescent,Adult,California,Cross-Cultural Comparison,Cues,Humans,Japan,Language,Multilingualism,Periodicity,Pitch Discrimination,Signal Detection, Psychological,Young Adult},
month = oct,
number = {4},
pages = {2263--71},
pmid = {19062864},
title = {{Perception of rhythmic grouping depends on auditory experience.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19062864},
volume = {124},
year = {2008}
}
@article{Munte2002,
abstract = {Studies of experience-driven neuroplasticity at the behavioural, ensemble, cellular and molecular levels have shown that the structure and significance of the eliciting stimulus can determine the neural changes that result. Studying such effects in humans is difficult, but professional musicians represent an ideal model in which to investigate plastic changes in the human brain. There are two advantages to studying plasticity in musicians: the complexity of the eliciting stimulus music and the extent of their exposure to this stimulus. Here, we focus on the functional and anatomical differences that have been detected in musicians by modern neuroimaging methods.},
author = {M\"{u}nte, Thomas F and Altenm\"{u}ller, Eckart and J\"{a}ncke, Lutz},
doi = {10.1038/nrn843},
file = {::},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Cerebral Cortex,Cerebral Cortex: anatomy \& histology,Cerebral Cortex: physiology,Corpus Callosum,Corpus Callosum: anatomy \& histology,Corpus Callosum: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Models, Neurological,Motor Skills,Motor Skills: physiology,Music,Neuronal Plasticity,Neuronal Plasticity: physiology,Pitch Perception,Pitch Perception: physiology},
month = jun,
number = {6},
pages = {473--8},
pmid = {12042882},
title = {{The musician's brain as a model of neuroplasticity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21566538},
volume = {3},
year = {2002}
}
@article{Barrett2010,
abstract = {Participants listened to randomly selected excerpts of popular music and rated how nostalgic each song made them feel. Nostalgia was stronger to the extent that a song was autobiographically salient, arousing, familiar, and elicited a greater number of positive, negative, and mixed emotions. These effects were moderated by individual differences (nostalgia proneness, mood state, dimensions of the Affective Neurosciences Personality Scale, and factors of the Big Five Inventory). Nostalgia proneness predicted stronger nostalgic experiences, even after controlling for other individual difference measures. Nostalgia proneness was predicted by the Sadness dimension of the Affective Neurosciences Personality Scale and Neuroticism of the Big Five Inventory. Nostalgia was associated with both joy and sadness, whereas nonnostalgic and nonautobiographical experiences were associated with irritation.},
author = {Barrett, Frederick S and Grimm, Kevin J and Robins, Richard W and Wildschut, Tim and Sedikides, Constantine and Janata, Petr},
doi = {10.1037/a0019006},
file = {::},
issn = {1931-1516},
journal = {Emotion (Washington, D.C.)},
keywords = {2006,2007,affective neurosciences personality scale,ansons,autobio-,autobiograph-,batcho,big five inventory,graphical memories,ical memory,leboe,mixed emotions,nostalgia is an affective,popular music,process that can accompany},
month = jun,
number = {3},
pages = {390--403},
pmid = {20515227},
title = {{Music-evoked nostalgia: affect, memory, and personality.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20515227},
volume = {10},
year = {2010}
}
@article{Patel2009,
abstract = {The recent discovery of spontaneous synchronization to music in a nonhuman animal (the sulphur-crested cockatoo Cacatua galerita eleonora) raises several questions. How does this behavior differ from nonmusical synchronization abilities in other species, such as synchronized frog calls or firefly flashes? What significance does the behavior have for debates over the evolution of human music? What kinds of animals can synchronize to musical rhythms, and what are the key methodological issues for research in this area? This paper addresses these questions and proposes some refinements to the "vocal learning and rhythmic synchronization hypothesis."},
author = {Patel, Aniruddh D and Iversen, John R and Bregman, Micah R and Schulz, Irena},
doi = {10.1111/j.1749-6632.2009.04581.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Animals,Auditory Perception,Auditory Perception: physiology,Birds,Music,Periodicity,Primates},
month = jul,
pages = {459--69},
pmid = {19673824},
title = {{Studying synchronization to a musical beat in nonhuman animals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673824},
volume = {1169},
year = {2009}
}
@article{Koelsch2005,
abstract = {Music perception involves complex brain functions underlying acoustic analysis, auditory memory, auditory scene analysis, and processing of musical syntax and semantics. Moreover, music perception potentially affects emotion, influences the autonomic nervous system, the hormonal and immune systems, and activates (pre)motor representations. During the past few years, research activities on different aspects of music processing and their neural correlates have rapidly progressed. This article provides an overview of recent developments and a framework for the perceptual side of music processing. This framework lays out a model of the cognitive modules involved in music perception, and incorporates information about the time course of activity of some of these modules, as well as research findings about where in the brain these modules might be located.},
author = {Koelsch, Stefan and Siebel, Walter a},
doi = {10.1016/j.tics.2005.10.001},
file = {::},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Arousal,Arousal: physiology,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Autonomic Nervous System,Autonomic Nervous System: physiology,Brain,Brain Mapping,Brain: physiology,Emotions,Emotions: physiology,Evoked Potentials,Evoked Potentials: physiology,Gestalt Theory,Humans,Intelligence,Intelligence: physiology,Memory,Memory: physiology,Music,Psychoacoustics,Sound Spectrography},
month = dec,
number = {12},
pages = {578--84},
pmid = {16271503},
title = {{Towards a neural basis of music perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16271503},
volume = {9},
year = {2005}
}
@article{Krumhansl1982,
author = {Krumhansl, C L and Kessler, E J},
file = {::},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Humans,Music,Pitch Discrimination,Psychoacoustics},
month = jul,
number = {4},
pages = {334--68},
pmid = {7134332},
title = {{Tracing the dynamic changes in perceived tonal organization in a spatial representation of musical keys.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7134332},
volume = {89},
year = {1982}
}
@article{Peretz2006a,
abstract = {Music, as language, is a universal human trait. Throughout human history and across all cultures, people have produced and enjoyed music. Despite its ubiquity, the musical capacity is rarely studied as a biological function. Music is typically viewed as a cultural invention. In this paper, the evidence bearing on the biological perspective of the musical capacity is reviewed. Related issues, such as domain-specificity, innateness, and brain localization, are addressed in an attempt to offer a unified conceptual basis for the study of music processing. This scheme should facilitate the study of the biological foundations of music by bringing together the fields of genetics, developmental and comparative research, neurosciences, and musicology.},
author = {Peretz, Isabelle},
doi = {10.1016/j.cognition.2005.11.004},
file = {::},
issn = {0010-0277},
journal = {Cognition},
keywords = {Auditory Perception,Auditory Perception: physiology,Behavior,Behavior: physiology,Emotions,Genetics, Behavioral,Humans,Instinct,Language Development,Music,Music: psychology,Pitch Perception,Pitch Perception: physiology,Psychophysiology},
number = {1},
pages = {1--32},
pmid = {16487953},
title = {{The nature of music from a biological perspective.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16487953},
volume = {100},
year = {2006}
}
@article{Janata2003,
abstract = {Music consists of precisely patterned sequences of both movement and sound that engage the mind in a multitude of experiences. We move in response to music and we move in order to make music. Because of the intimate coupling between perception and action, music provides a panoramic window through which we can examine the neural organization of complex behaviors that are at the core of human nature. Although the cognitive neuroscience of music is still in its infancy, a considerable behavioral and neuroimaging literature has amassed that pertains to neural mechanisms that underlie musical experience. Here we review neuroimaging studies of explicit sequence learning and temporal production--findings that ultimately lay the groundwork for understanding how more complex musical sequences are represented and produced by the brain. These studies are also brought into an existing framework concerning the interaction of attention and time-keeping mechanisms in perceiving complex patterns of information that are distributed in time, such as those that occur in music.},
author = {Janata, Petr and Grafton, Scott T},
doi = {10.1038/nn1081},
file = {::},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Brain,Brain Mapping,Brain: anatomy \& histology,Brain: physiology,Cluster Analysis,Cognitive Science,Cognitive Science: methods,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Mental Processes,Mental Processes: physiology,Music,Time Factors},
month = jul,
number = {7},
pages = {682--7},
pmid = {12830159},
title = {{Swinging in the brain: shared neural substrates for behaviors related to sequencing and music.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12830159},
volume = {6},
year = {2003}
}
@article{Iversen2008a,
abstract = {Many aspects of perception are known to be shaped by experience, but others are thought to be innate universal properties of the brain. A specific example comes from rhythm perception, where one of the fundamental perceptual operations is the grouping of successive events into higher-level patterns, an operation critical to the perception of language and music. Grouping has long been thought to be governed by innate perceptual principles established a century ago. The current work demonstrates instead that grouping can be strongly dependent on culture. Native English and Japanese speakers were tested for their perception of grouping of simple rhythmic sequences of tones. Members of the two cultures showed different patterns of perceptual grouping, demonstrating that these basic auditory processes are not universal but are shaped by experience. It is suggested that the observed perceptual differences reflect the rhythms of the two languages, and that native language can exert an influence on general auditory perception at a basic level.},
author = {Iversen, John R and Patel, Aniruddh D and Ohgushi, Kengo},
doi = {10.1121/1.2973189},
issn = {1520-8524},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Adolescent,Adult,California,Cross-Cultural Comparison,Cues,Humans,Japan,Language,Multilingualism,Periodicity,Pitch Discrimination,Psychological,Signal Detection,Young Adult,rhythm},
mendeley-tags = {rhythm},
month = oct,
number = {4},
pages = {2263--71},
pmid = {19062864},
title = {{Perception of rhythmic grouping depends on auditory experience.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19062864},
volume = {124},
year = {2008}
}
@article{Nozaradan2011,
abstract = {Feeling the beat and meter is fundamental to the experience of music. However, how these periodicities are represented in the brain remains largely unknown. Here, we test whether this function emerges from the entrainment of neurons resonating to the beat and meter. We recorded the electroencephalogram while participants listened to a musical beat and imagined a binary or a ternary meter on this beat (i.e., a march or a waltz). We found that the beat elicits a sustained periodic EEG response tuned to the beat frequency. Most importantly, we found that meter imagery elicits an additional frequency tuned to the corresponding metric interpretation of this beat. These results provide compelling evidence that neural entrainment to beat and meter can be captured directly in the electroencephalogram. More generally, our results suggest that music constitutes a unique context to explore entrainment phenomena in dynamic cognitive processing at the level of neural networks.},
author = {Nozaradan, Sylvie and Peretz, Isabelle and Missal, Marcus and Mouraux, Andr\'{e}},
doi = {10.1523/JNEUROSCI.0411-11.2011},
file = {::},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
month = jul,
number = {28},
pages = {10234--40},
pmid = {21753000},
title = {{Tagging the neuronal entrainment to beat and meter.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21753000},
volume = {31},
year = {2011}
}
@article{Koelsch1999,
abstract = {The present study focuses on influences of long-term experience on auditory processing, providing the first evidence for pre-attentively superior auditory processing in musicians. This was revealed by the brain's automatic change-detection response, which is reflected electrically as the mismatch negativity (MMN) and generated by the operation of sensoric (echoic) memory, the earliest cognitive memory system. Major chords and single tones were presented to both professional violinists and non-musicians under ignore and attend conditions. Slightly impure chords, presented among perfect major chords elicited a distinct MMN in professional musicians, but not in non-musicians. This demonstrates that compared to non-musicians, musicians are superior in pre-attentively extracting more information out of musically relevant stimuli. Since effects of long-term experience on pre-attentive auditory processing have so far been reported for language-specific phonemes only, results indicate that sensory memory mechanisms can be modulated by training on a more general level.},
author = {Koelsch, S and Schr\"{o}ger, E and Tervaniemi, M},
file = {::},
issn = {0959-4965},
journal = {Neuroreport},
keywords = {Acoustic Stimulation,Adult,Analysis of Variance,Attention,Attention: physiology,Auditory Perception,Auditory Perception: physiology,Cognition,Cognition: physiology,Evoked Potentials, Auditory,Female,Hearing,Humans,Male,Memory,Music,Occupations},
month = apr,
number = {6},
pages = {1309--13},
pmid = {10363945},
title = {{Superior pre-attentive auditory processing in musicians.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10363945},
volume = {10},
year = {1999}
}
@article{Patil2012,
author = {Patil, Kailash and Pressnitzer, Daniel and Shamma, Shihab and Elhilali, Mounya},
editor = {Theunissen, Frederic E.},
file = {::},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = nov,
number = {11},
pages = {e1002759},
title = {{Music in Our Ears: The Biological Bases of Musical Timbre Perception}},
url = {http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1002759?imageURI=info:doi/10.1371/journal.pcbi.1002759.g003},
volume = {8},
year = {2012}
}
@article{Peretz2003,
annote = {References 5, 7,
        
sensitivity to disturbing rhythmic regularity (9)
-wrong note "pop out" effect?
      },
author = {Peretz, Isabelle},
doi = {10.1016/S1364-6613(03)00150-5},
file = {::},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = aug,
number = {8},
pages = {362--367},
title = {{What is specific to music processing? Insights from congenital amusia}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661303001505},
volume = {7},
year = {2003}
}
@article{Davies2007a,
abstract = {This study tested the assumption of sensory integration theory that states that a relationship exists between brain function and the behavioral manifestations of sensory integrative dysfunction.},
author = {Davies, Patricia L and Gavin, William J},
file = {::},
issn = {0272-9490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
keywords = {Brain,Brain: physiopathology,Child,Child Behavior,Child Behavior: psychology,Child, Preschool,Colorado,Electroencephalography,Electroencephalography: instrumentation,Female,Humans,Male,Somatosensory Disorders,Somatosensory Disorders: diagnosis,Somatosensory Disorders: physiopathology},
number = {2},
pages = {176--89},
pmid = {17436840},
title = {{Validating the diagnosis of sensory processing disorders using EEG technology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17436840},
volume = {61},
year = {2007}
}
@article{Hall2006,
abstract = {This study investigated the effects of a sensory diet and therapeutic listening intervention program, directed by an occupational therapist and implemented by parents, on children with sensory processing disorders (SPD) and visual-motor delays. A convenience sample was used of 10 participants, ages 5 to 11 years, with SPD and visual-motor delays. In the first phase, each participant completed a 4-week sensory diet program, then an 8-week therapeutic-listening and sensory diet program. The Sensory Profile was completed by the participants' parents before and after both study phases. The Draw-A-Person test, Developmental Test of Visual Motor Integration (VMI), and Evaluation Tool of Children's Handwriting (ETCH) were administered before and after each phase. Over 12 weeks, the participants exhibited significant improvement on the Sensory Profile, increasing a mean of 71 points. Parents reported improvements in their children's behaviors related to sensory processing. Scores on the VMI visual and ETCH legibility scales also improved more during the therapeutic listening phase. Therapeutic listening combined with a sensory diet appears effective in improving behaviors related to sensory processing in children with SPD and visual-motor impairments.},
author = {Hall, Leah and Case-Smith, Jane},
file = {::},
issn = {0272-9490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
keywords = {Adolescent,Child,Child Behavior,Child, Preschool,Comorbidity,Female,Humans,Male,Occupational Therapy,Occupational Therapy: methods,Psychomotor Performance,Questionnaires,Somatosensory Disorders,Somatosensory Disorders: physiopathology,Somatosensory Disorders: therapy,Sound,Treatment Outcome,United States},
number = {2},
pages = {209--15},
pmid = {17436843},
title = {{The effect of sound-based intervention on children with sensory processing disorders and visual-motor delays.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17436843},
volume = {61},
year = {2006}
}
@article{Keane2010a,
author = {Keane, Brian P. and Rosenthal, Orna and Chun, Nicole H. and Shams, Ladan},
doi = {10.1016/j.rasd.2009.09.015},
file = {:Users/pkmital/Documents/Mendeley Desktop/Keane et al/Keane et al. - 2010 - Audiovisual integration in high functioning adults with autism - Research in Autism Spectrum Disorders.pdf:pdf},
issn = {17509467},
journal = {Research in Autism Spectrum Disorders},
keywords = {audiovisual integration,high-functioning autism,multisensory integration},
month = apr,
number = {2},
pages = {276--289},
title = {{Audiovisual integration in high functioning adults with autism}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1750946709001019},
volume = {4},
year = {2010}
}
@article{Smitha,
abstract = {The embodiment hypothesis is the idea that intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity. We offer six lessons for developing embodied intelligent agents suggested by research in developmental psychology. We argue that starting as a baby grounded in a physical, social, and linguistic world is crucial to the development of the flexible and inventive intelligence that characterizes humankind.},
author = {Smith, Linda and Gasser, Michael},
doi = {10.1162/1064546053278973},
file = {:Users/pkmital/Documents/Mendeley Desktop/Smith, Gasser/Smith, Gasser - Unknown - The development of embodied cognition six lessons from babies. - Artificial life.pdf:pdf},
issn = {1064-5462},
journal = {Artificial life},
keywords = {Artificial Intelligence,Cognition,Cognition: physiology,Humans,Infant,Infant Behavior,Infant Behavior: physiology},
number = {1-2},
pages = {13--29},
pmid = {15811218},
title = {{The development of embodied cognition: six lessons from babies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15811218},
volume = {11}
}
@article{Shams2010a,
abstract = {Vision is generally considered the dominant sensory modality; self-contained and independent of other senses. In this article, we will present recent results that contradict this view, and show that visual perception can be strongly altered by sound and touch, and such alterations can occur even at early stages of processing, as early as primary visual cortex. We will first review the behavioral evidence demonstrating modulation of visual perception by other modalities. As extreme examples of such modulations, we will describe two visual illusions induced by sound, and a visual illusion induced by touch. Next, we will discuss studies demonstrating modulation of activity in visual areas by stimulation of other modalities, and discuss possible pathways that could underpin such interactions. This will be followed by a discussion of how crossmodal interactions can affect visual learning and adaptation. We will review several studies showing crossmodal effects on visual learning. We will conclude with a discussion of computational principles governing these crossmodal interactions, and review several recent studies that demonstrate that these interactions are statistically optimal.},
author = {Shams, Ladan and Kim, Robyn},
doi = {10.1016/j.plrev.2010.04.006},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shams, Kim/Shams, Kim - 2010 - Crossmodal influences on visual perception. - Physics of life reviews.pdf:pdf},
issn = {1873-1457},
journal = {Physics of life reviews},
keywords = {multisensory integration,multisensory perception,visual learning,visual perception},
month = apr,
pages = {1--16},
pmid = {20447880},
publisher = {Elsevier B.V.},
title = {{Crossmodal influences on visual perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20447880},
volume = {1},
year = {2010}
}
@article{May-Benson2007,
abstract = {This study developed an observational assessment of gravitational insecurity (GI), the GI Assessment, and examined its preliminary reliability and validity evidence.},
author = {May-Benson, Teresa a and Koomar, Jane a},
file = {::},
issn = {0272-9490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
keywords = {Anxiety,Child,Child, Preschool,Diagnostic Tests, Routine,Diagnostic Tests, Routine: instrumentation,Fear,Female,Gravitation,Humans,Male,Pilot Projects,Somatosensory Disorders,Somatosensory Disorders: classification,Somatosensory Disorders: diagnosis,United States},
number = {2},
pages = {142--7},
pmid = {17436835},
title = {{Identifying gravitational insecurity in children: a pilot study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17436835},
volume = {61},
year = {2007}
}
@article{Gerloff2002,
abstract = {Bimanual coordination of skilled finger movements requires intense functional coupling of the motor areas of both cerebral hemispheres. This coupling can be measured non-invasively in humans with task-related coherence analysis of multi-channel surface electroencephalography. Since bimanual coordination is a high-level capability that virtually always requires training, this review is focused on changes of interhemispheric coupling associated with different stages of bimanual learning. Evidence is provided that the interaction between hemispheres is of particular importance in the early phase of command integration during acquisition of a novel bimanual task. It is proposed that the dynamic changes in interhemispheric interaction reflect the establishment of efficient bimanual 'motor routines'. The effects of callosal damage on bimanual coordination and learning are reviewed as well as functional imaging studies related to bimanual movement. There is evidence for an extended cortical network involved in bimanual motor activities which comprises the bilateral primary sensorimotor cortex (SM1), supplementary motor area, cingulate motor area, dorsal premotor cortex and posterior parietal cortex. Current concepts about the functions of these structures in bimanual motor behavior are reviewed.},
author = {Gerloff, Christian and Andres, Frank G},
issn = {00016918},
journal = {Acta Psychologica},
keywords = {adult,corpus callosum,corpus callosum physiology,electroencephalography,female,fingers,fingers physiology,functional laterality,functional laterality physiology,humans,learning,learning physiology,magnetic resonance imaging,male,motor cortex,motor cortex physiology,motor cortex ultrasonography,motor skills,motor skills physiology,parietal lobe,parietal lobe physiology,psychomotor performance,psychomotor performance physiology},
number = {2-3},
pages = {161--186},
title = {{Bimanual coordination and interhemispheric interaction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12102104},
volume = {110},
year = {2002}
}
@article{Shimojo2001a,
author = {Shimojo, S. and Shams, L.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Shimojo, Shams/Shimojo, Shams - 2001 - Sensory modalities are not separate modalities plasticity and interactions - Current opinion in neurobiology.pdf:pdf},
journal = {Current opinion in neurobiology},
number = {4},
pages = {505--509},
publisher = {Elsevier},
title = {{Sensory modalities are not separate modalities: plasticity and interactions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438800002415},
volume = {11},
year = {2001}
}
@article{Yamadori2002,
abstract = {Based on the analysis of four types of basic praxis disorders, i.e. disturbance of single tool use (ideational apraxia), impairment of pantomiming ability to use a tool (ideomotor apraxia), inability to copy a non-meaningful finger pattern (limbkinetic apraxia), and inability to reproduce a series of hand movements (dynamic apraxia), a hypothesis on the neural organization of higher order motor production was proposed. It was stressed that these four types of praxis disorder should not be considered as different kinds of movement disorders at the same level. Rather they are examples of the motor realization disorder each representing a different level of neural substrate in a hierarchically organized motor structure.},
author = {Yamadori, Atsushi},
institution = {Division of Neuropsychology, Department of Disability Medicine, Tohoku University Graduate School of Medicine.},
journal = {Rinsho shinkeigaku Clinical neurology},
number = {11},
pages = {1082--1084},
title = {{Neurology of praxis disorder}},
volume = {42},
year = {2002}
}
@article{Debaere2004,
abstract = {Motor skill acquisition is associated with the development of automaticity and induces neuroplastic changes in the brain. Using functional magnetic resonance imaging (fMRI), the present study traced learning-related activation changes during the acquisition of a new complex bimanual skill, requiring a difficult spatio-temporal relationship between the limbs, i.e., cyclical flexion-extension movements of both hands with a phase offset of 90. Subjects were scanned during initial learning and after the coordination pattern was established. Kinematics of the movements were accurately registered and showed that the new skill was acquired well. Learning-related decreases in activation were found in right dorsolateral prefrontal cortex (DLPFC), right premotor, bilateral superior parietal cortex, and left cerebellar lobule VI. Conversely, learning-related increases in activation were observed in bilateral primary motor cortex, bilateral superior temporal gyrus, bilateral cingulate motor cortex (CMC), left premotor cortex, cerebellar dentate nuclei/lobule III/IV/Crus I, putamen/globus pallidus and thalamus. Accordingly, bimanual skill learning was associated with a shift in activation among cortico-subcortical regions, providing further evidence for the existence of differential cortico-subcortical circuits preferentially involved during the early and advanced stages of learning. The observed activation changes account for the transition from highly attention-demanding task performance, involving processing of sensory information and corrective action planning, to automatic performance based on memory representations and forward control.},
author = {Debaere, F and Wenderoth, N and Sunaert, S and {Van Hecke}, P and Swinnen, S P},
journal = {Neuropsychologia},
keywords = {basal ganglia,bimanual,cerebellum,cortical motor areas,cortico subcortical circuits,fmri,motor skill learning},
number = {7},
pages = {855--867},
title = {{Changes in brain activation during the acquisition of a new bimanual coordination task}},
url = {http://www.sciencedirect.com/science/article/B6T0D-4BMTCXC-6/1/db98a6a862bf4a22c15b366341a705d4},
volume = {42},
year = {2004}
}
@article{Schneider1972,
abstract = {Evaluation of sensory processing function serves as a critical component of treatment planning and implementation of intervention in pediatric occupational therapy practice. We developed a Sensory Processing Scale for Monkeys (SPS-M), based on human tests, that measures behavioral responses to a series of tactile stimuli. This assessment has been used to assess sensory processing in adult rhesus monkeys exposed to prenatal alcohol, stress, or postnatal lead. Control monkeys from undisturbed pregnancies showed a habituation pattern, prenatally stressed monkeys showed sensitization, and prenatal alcohol-exposed monkeys showed relatively high responsiveness without habituation across trials. Lead-exposed monkeys showed sensitization compared to nonlead-exposed controls, and chelation reduced the sensitization in lead-exposed animals. Aversive responsiveness was associated with up-regulated striatal dopamine receptor binding measured with positron emission tomography.},
author = {Schneider, Mary L and Moore, Colleen F and Gajewski, Lisa L and Laughlin, Nellie K and Larson, Julie a and Gay, Cynthia L and Roberts, Andrew D and Converse, Alexander K and DeJesus, Onofre T},
file = {::},
issn = {0272-9490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
keywords = {Animals,Behavior, Animal,Behavior, Animal: drug effects,Ethanol,Ethanol: toxicity,Evidence-Based Medicine,Female,Lead,Lead: blood,Lead: toxicity,Macaca mulatta,Macaca mulatta: physiology,Maternal Exposure,Models, Animal,Noise,Noise: adverse effects,Occupational Therapy,Physical Stimulation,Pregnancy,Random Allocation,Somatosensory Disorders,Somatosensory Disorders: chemically induced,Somatosensory Disorders: etiology,Stress, Psychological,Stress, Psychological: complications,United States},
number = {2},
pages = {247--53},
pmid = {17436847},
title = {{Sensory processing disorders in a nonhuman primate model: evidence for occupational therapy practice.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17436847},
volume = {61},
year = {1972}
}
@article{Klin2003a,
abstract = {Normative-IQ individuals with autism are capable of solving explicit social cognitive problems at a level that is not matched by their ability to meet the demands of everyday social situations. The magnitude of this discrepancy is now being documented through newer techniques such as eye tracking, which allows us to see and measure how individuals with autism search for meaning when presented with naturalistic social scenes. This paper offers an approach to social cognitive development intended to address the above discrepancy, which is considered a key element for any understanding of the pathophysiology of autism. This approach, called the enactive mind (EM), originates from the emerging work on 'embodied cognitive science', a neuroscience framework that views cognition as bodily experiences accrued as a result of an organism's adaptive actions upon salient aspects of the surrounding environment. The EM approach offers a developmental hypothesis of autism in which the process of acquisition of embodied social cognition is derailed early on, as a result of reduced salience of social stimuli and concomitant enactment of socially irrelevant aspects of the environment.},
author = {Klin, Ami and Jones, Warren and Schultz, Robert and Volkmar, Fred},
doi = {10.1098/rstb.2002.1202},
file = {:Users/pkmital/Documents/Mendeley Desktop/Klin et al/Klin et al. - 2003 - The enactive mind, or from actions to cognition lessons from autism. - Philosophical transactions of the Royal Society of London. Series B, Biological sciences.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Autistic Disorder,Autistic Disorder: psychology,Cognition,Humans,Psychological Theory,Psychophysiology,Visual Perception},
month = mar,
number = {1430},
pages = {345--60},
pmid = {12639332},
title = {{The enactive mind, or from actions to cognition: lessons from autism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12639332},
volume = {358},
year = {2003}
}
@article{Gibbs2007,
abstract = {Dyspraxia is an enigma to many people, both professional and lay alikewhat is it, how does it relate to developmental coordination disorder and associated conditions, how common is it, how is it recognised and diagnosed and how should it be managed? This article attempts to unravel this enigma by: dealing with the terminology of coordination difficulties from the clumsy child syndrome through dyspraxia to developmental coordination disorder (DCD); briefly examining the debate as to whether dyspraxia or DCD should be regarded as a medical or social disorder; discussing the differential diagnosis of dyspraxia or DCD; considering the assessment of children with dyspraxia or DCD; reviewing the range of current treatment approaches in the UK.},
author = {Gibbs, John and Appleton, Jeanette and Appleton, Richard},
journal = {Archives of Disease in Childhood},
number = {6},
pages = {534--539},
publisher = {BMJ Group},
title = {{Dyspraxia or developmental coordination disorder? Unravelling the enigma}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17515623},
volume = {92},
year = {2007}
}
@book{No\\e2004,
author = {No$\backslash$$\backslash$"e, A.},
file = {:Users/pkmital/Documents/Mendeley Desktop/Noe/Noe - 2004 - Action in perception - Unknown.pdf:pdf},
isbn = {0262140888},
publisher = {the MIT Press},
title = {{Action in perception}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=kFKvU2hPhxEC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Action+in+Perception\&amp;ots=FZsJHhVms3\&amp;sig=a6QsvWdgjBDQiq2sxDRQ4ivNlt8},
year = {2004}
}
@article{May-Benson2007a,
abstract = {This study developed an assessment of ideational praxis, examined its psychometric properties, and analyzed age and gender trends in children who were typically developing.},
author = {May-Benson, Teresa a and Cermak, Sharon a},
file = {::},
issn = {0272-9490},
journal = {The American journal of occupational therapy. : official publication of the American Occupational Therapy Association},
keywords = {Apraxias,Apraxias: diagnosis,Apraxias: physiopathology,Child,Child, Preschool,Diagnostic Tests, Routine,Diagnostic Tests, Routine: instrumentation,Female,Humans,Male,Psychometrics,Reproducibility of Results,United States},
number = {2},
pages = {148--53},
pmid = {17436836},
title = {{Development of an assessment for ideational praxis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17436836},
volume = {61},
year = {2007}
}
@article{Morrisona,
author = {Morrison, a. and Ross, G. and Chalmers, M.},
doi = {10.1109/INFVIS.2002.1173161},
file = {::},
isbn = {0-7695-1751-X},
journal = {IEEE Symposium on Information Visualization, 2002. INFOVIS 2002.},
pages = {152--158},
publisher = {IEEE Comput. Soc},
title = {{A hybrid layout algorithm for sub-quadratic multidimensional scaling}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1173161}
}
@article{Morrison2003a,
author = {Morrison, Alistair and Ross, Greg and Chalmers, Matthew},
doi = {10.1057/palgrave.ivs.9500040},
file = {::},
issn = {14738716},
journal = {Information Visualization},
month = mar,
number = {1},
pages = {68--77},
title = {{Fast multidimensional scaling through sampling, springs and interpolation}},
url = {http://www.palgrave-journals.com/doifinder/10.1057/palgrave.ivs.9500040},
volume = {2},
year = {2003}
}
@inproceedings{Morrison,
author = {Morrison, a. and Chalmers, M.},
booktitle = {IEEE Symposium on Information Visualization 2003},
doi = {10.1109/INFVIS.2003.1249012},
file = {::},
isbn = {0-7803-8154-8},
pages = {85--90},
publisher = {Ieee},
title = {{Improving hybrid MDS with pivot-based searching}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1249012}
}
@inproceedings{Morrisonb,
author = {Morrison, a. and Chalmers, M.},
booktitle = {IEEE Symposium on Information Visualization 2003},
doi = {10.1109/INFVIS.2003.1249012},
file = {::},
isbn = {0-7803-8154-8},
pages = {85--90},
publisher = {Ieee},
title = {{Improving hybrid MDS with pivot-based searching}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1249012}
}
